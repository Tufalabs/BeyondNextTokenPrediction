
<<<PAGE 1>>>



<<<PAGE 2>>>

This page intentionally left blank

<<<PAGE 3>>>

PROBABILITY THEORY
THE LOGIC OF SCIENCE

<<<PAGE 4>>>



<<<PAGE 5>>>

PROBABILITY THEORY
THE LOGIC OF SCIENCE
E. T. Jaynes
edited by G. Larry Bretthorst


<<<PAGE 6>>>

  Cambridge, New York, Melbourne, Madrid, Cape Town, Singapore, São PauloCambridge University PressThe Edinburgh Building, Cambridge   , United Kingdom
First published in print format 
ISBN-13   978-0-521-59271-0 hardbackISBN-13   978-0-511-06589-7 eBook (NetLibrary)© E. T. Jaynes 2003
2003Information  on this title: www.cambrid ge.org/9780521592710
This book is in copyright. Subject to statutory exception and to the provision ofrelevant collective licensing agreements, no reproduction of any part may take placewithout the written permission of Cambridge University Press.
ISBN-10   0-511-06589-2 eBook (NetLibrary)
ISBN-10   0-521-59271-2 hardback
Cambridge University Press has no responsibility for the persistence or accuracy ofs for external or third-party internet websites referred to in this book, and does not
guarantee that any content on such websites is, or will remain, accurate or appropriate.Published in the United States by Cambridge University Press, New Yorkwww.cambridge.org

<<<PAGE 7>>>

Dedicated to the memory of
Sir Harold Jeffreys, who
saw the truth and preserved it.

<<<PAGE 8>>>



<<<PAGE 9>>>

Contents
Editor ’sforeword pagexvii
Preface xix
Part I Principles and elementary applications
1Plausibl ereasonin g 3
1.1 Deduct iveandplausibl ereasonin g 3
1.2 Analogie swithphysica ltheorie s 6
1.3 Thethinkin gcompute r 7
1.4 Introducin gtherobot 8
1.5 Boolea nalgebr a 9
1.6 Adequat esetsofoperation s 12
1.7 Thebasicdesiderat a 17
1.8 Comment s 19
1.8.1 Commo nlanguag evs.forma llogic 21
1.8.2 Nitpickin g 23
2Thequantitat iverules 24
2.1 Theproduc trule 24
2.2 Thesumrule 30
2.3 Qualitat ivepropertie s 35
2.4 Numerica lvalues 37
2.5 Notatio nandﬁnite-set spolicy 43
2.6 Comment s 44
2.6.1 ‘Subject ive’vs.‘object ive’ 44
2.6.2 G¨odel’stheore m 45
2.6.3 Venndiagram s 47
2.6.4 The‘Kolmogor ovaxioms ’ 49
3Elementar ysamplin gtheor y 51
3.1 Samplin gwithou treplacemen t 52
3.2 Logi cvs.propensit y 60
3.3 Reasonin gfromlessprecis einformatio n 64
3.4 Expectation s 66
3.5 Othe rform sandextension s 68
vii

<<<PAGE 10>>>

viii Contents
3.6 Probabilit yasamathematica ltool 68
3.7 Thebinomia ldistri bution 69
3.8 Samplin gwithreplacemen t 72
3.8.1 Digression :asermo nonrealit yvs.model s 73
3.9 Correctio nforcorrelation s 75
3.10Simpliﬁcatio n 81
3.11Comment s 82
3.11. 1Alookahead 84
4Elementar yhypothesi stestin g 86
4.1 Priorprobabilitie s 87
4.2 Testin gbinar yhypothese swithbinar ydata 90
4.3 Nonextensibilit ybeyondthebinar ycase 97
4.4 Multipl ehypothesi stestin g 98
4.4.1 Digressio nonanothe rderivation 101
4.5 Continuou sprobabilit ydistri butionfunction s 107
4.6 Testin ganinﬁnit enumbe rofhypothese s 109
4.6.1 Historica ldigressio n 112
4.7 Simpl eandcompoun d(orcomposite )hypothese s 115
4.8 Comment s 116
4.8.1 Etymolog y 116
4.8.2 Wha thaveweaccomplished ? 117
5Quee rusesforprobabilit ytheor y 119
5.1 Extrasensor yperceptio n 119
5.2 MrsStewart’stelepathi cpowers 120
5.2.1 Digressio nonthenorma lapproximatio n 122
5.2.2 BacktoMrsStewart 122
5.3 Converginganddivergingviews 126
5.4 Visualperceptio n–evolutio nintoBayesianity ? 132
5.5 ThediscoveryofNeptun e 133
5.5.1 Digressio nonalternat ivehypothese s 135
5.5.2 BacktoNewton 137
5.6 Hors eracin gandweathe rforecastin g 140
5.6.1 Discussio n 142
5.7 Parado xesofintuitio n 143
5.8 Bayesia njurisprudenc e 144
5.9 Comment s 146
5.9.1 Wha tisqueer ? 148
6Elementar yparamete restimatio n 149
6.1 Inversio noftheurndistri bution s 149
6.2 BothNandRunkn own 150
6.3 Unifor mprior 152
6.4 Predict ivedistri bution s 154

<<<PAGE 11>>>

Contents ix
6.5 Truncate dunifor mprior s 157
6.6 Aconc aveprior 158
6.7 Thebinomia lmonkeyprior 160
6.8 Metamorphosi sintocontinuou sparamete restimatio n 163
6.9 Estimatio nwithabinomia lsamplin gdistri bution 163
6.9.1 Digressio nonoptiona lstoppin g 166
6.10Compoun destimatio nproblem s 167
6.11Asimpl eBayesia nestimate :quantitat ivepriorinformatio n 168
6.11. 1Fromposterio rdistri butionfunctio ntoestimat e 172
6.12Effectsofqualitat ivepriorinformatio n 177
6.13Choic eofaprior 178
6.14Onwiththecalculation ! 179
6.15TheJeffreysprior 181
6.16Thepointofitall 183
6.17Inter valestimatio n 186
6.18Calculatio nofvarianc e 186
6.19Generalizatio nandasymptoti cform s 188
6.20Rectangula rsamplin gdistri bution 190
6.21Smal lsample s 192
6.22Mathematica ltrickery 193
6.23Comment s 195
7Thecentral ,Gaussia nornorma ldistri bution 198
7.1 Thegravitatin gphenomeno n 199
7.2 TheHerschel–Maxwel lderivation 200
7.3 TheGaus sderivation 202
7.4 Historica limportanc eofGauss ’sresul t 203
7.5 TheLando nderivation 205
7.6 Whytheubiquitou suseofGaussia ndistri butions ? 207
7.7 Whytheubiquitou ssuccess ? 210
7.8 Wha testimato rshoul dweuse? 211
7.9 Errorcancellatio n 213
7.10Thenearirrelevanceofsamplin gfrequen cydistri bution s 215
7.11Theremarkabl eefﬁcien cyofinformatio ntransfe r 216
7.12Othe rsamplin gdistri bution s 218
7.13Nuisanc eparameter sassafet ydevices 219
7.14Moregenera lpropertie s 220
7.15Convolutio nofGaussian s 221
7.16Thecentra llimittheore m 222
7.17Accura cyofcomputation s 224
7.18Galton ’sdiscovery 227
7.19Populatio ndynamic sandDarwinia nevolutio n 229
7.20Evolutio nofhumming-bird sandﬂowers 231

<<<PAGE 12>>>

x Contents
7.21Applicatio ntoeconomic s 233
7.22Thegreatinequalit yofJupite randSatur n 234
7.23Resolutio nofdistri bution sintoGaussian s 235
7.24Hermit epolynomia lsolution s 236
7.25Fourie rtransfor mrelation s 238
7.26Ther eishopeafterall 239
7.27Comment s 240
7.27. 1Terminolog yagain 240
8Sufﬁcien cy,ancillarit y,andallthat 243
8.1 Sufﬁcien cy 243
8.2 Fishe rsufﬁcien cy 245
8.2.1 Example s 246
8.2.2 TheBlackwell–Ra otheore m 247
8.3 Generalize dsufﬁcien cy 248
8.4 Sufﬁcien cyplusnuisance parameter s 249
8.5 The likelihood principle 250
8.6 Ancillarit y 253
8.7 Generalize dancillar yinformatio n 254
8.8 Asymptotic likelihood: Fishe rinformatio n 256
8.9 Combinin gevidenc efromdifferen tsource s 257
8.10Poolin gthedata 260
8.10. 1Fine-graine dproposition s 261
8.11Sam’sbrokenthermomete r 262
8.12Comment s 264
8.12. 1Thefallacyofsampl ere-us e 264
8.12. 2Afolktheore m 266
8.12. 3Effectofpriorinformatio n 267
8.12. 4Clevertricksandgamesmanshi p 267
9Repetit iveexperiments :probabilit yandfrequen cy 270
9.1 Physica lexperiment s 271
9.2 Thepoorl yinforme drobot 274
9.3 Inductio n 276
9.4 Aretheregenera linduct iverules ? 277
9.5 Multiplicit yfactor s 280
9.6 Partitio nfunctio nalgorithm s 281
9.6.1 Solutio nbyinspectio n 282
9.7 Entro pyalgorithm s 285
9.8 Another way of looking at it 289
9.9 Entropy maximization 290
9.10Probabilit yandfrequen cy 292
9.11 Signiﬁcance tests 293
9.11. 1Implie dalternat ives 296

<<<PAGE 13>>>

Contents xi
9.12Compariso nofpsiandchi-square d 300
9.13Thechi-square dtest 302
9.14Generalizatio n 304
9.15Halley’smortalit ytable 305
9.16Comment s 310
9.16. 1Theirrationalist s 310
9.16. 2Superstition s 312
10Physic sof‘rando mexperiments ’ 314
10.1 Aninterestin gcorrelatio n 314
10.2 Historica lbackgroun d 315
10.3 Howtocheatatcoinanddietossin g 317
10.3. 1 Experimenta levidenc e 320
10.4 Bridg ehand s 321
10.5 Genera lrando mexperiment s 324
10.6 Inductio nrevisite d 326
10.7 Butwhatabou tquantu mtheory ? 327
10.8 Mechanic sunde rthecloud s 329
10.9 Moreoncoinsandsymmetr y 331
10.10Independenc eoftosse s 335
10.11Thearroganc eoftheuninforme d 338
Part II Advanced applications
11Discret epriorprobabilities :theentro pyprincipl e 343
11.1 Anewkindofpriorinformatio n 343
11.2 Minimum/summationtextp2
i 345
11.3 Entro py:Shannon ’stheore m 346
11.4 TheWallisderivation 351
11.5 Anexampl e 354
11.6 Generalization :amorerigorou sproof 355
11.7 Formal properties of maximum entropy
distri bution s 358
11.8 Conceptua lproblem s–frequen cycorrespondenc e 365
11.9 Comment s 370
12Ignoranc eprior sandtransformatio ngroup s 372
12.1 Wha tarewetryin gtodo? 372
12.2 Ignoranc eprior s 374
12.3 Continuou sdistri bution s 374
12.4 Transformatio ngroup s 378
12.4. 1 Locatio nandscaleparameter s 378
12.4. 2 APoisso nrate 382
12.4. 3 Unkn ownprobabilit yforsucces s 382
12.4. 4 Bertrand ’sproble m 386
12.5 Comment s 394

<<<PAGE 14>>>

xii Contents
13Decisio ntheor y,historica lbackgroun d 397
13.1 Inferenc evs.decisio n 397
13.2 Danie lBernoulli ’ssuggestio n 398
13.3 Therational eofinsuranc e 400
13.4 Entro pyandutilit y 402
13.5 Thehones tweatherma n 402
13.6 Reaction stoDanie lBernoull iandLaplac e 404
13.7 Wald’sdecisio ntheor y 406
13.8 Paramete restimatio nforminimu mloss 410
13.9 Reformulatio noftheproble m 412
13.10Effectofvaryin glossfunction s 415
13.11Genera ldecisio ntheor y 417
13.12Comment s 418
13.12. 1‘Object ivity’ofdecisio ntheor y 418
13.12. 2Lossfunction sinhuma nsociet y 421
13.12. 3AnewlookattheJeffreysprior 423
13.12. 4Decisio ntheor yisnotfundamenta l 423
13.12. 5Anothe rdimension ? 424
14Simpl eapplication sofdecisio ntheor y 426
14.1 Deﬁnition sandpreliminarie s 426
14.2 Sufﬁcien cyandinformatio n 428
14.3 Loss functions and criteria of optimum
performanc e 430
14.4 Adiscret eexampl e 432
14.5 Howwouldourrobotdoit? 437
14.6 Historica lremark s 438
14.6. 1 Theclassica lmatche dﬁlter 439
14.7 Thewidge tproble m 440
14.7. 1 Solutio nforStage2 443
14.7. 2 Solutio nforStage3 445
14.7. 3 Solutio nforStage4 449
14.8 Comment s 450
15Parado xesofprobabilit ytheor y 451
15.1 Howdoparado xessurviveandgrow? 451
15.2 Summin gaserie stheeasyway 452
15.3 Nonconglomerabilit y 453
15.4 Thetumblin gtetrahedr a 456
15.5 Solutio nforaﬁnitenumbe roftosse s 459
15.6 Finit evs.countabl eaddit ivity 464
15.7 TheBorel– Kolmogor ovparado x 467
15.8 Themarginalizatio nparado x 470
15.8. 1 Ontogreate rdisaster s 474

<<<PAGE 15>>>

Contents xiii
15.9 Discussio n 478
15.9. 1 TheDSZExampl e#5 480
15.9. 2 Summar y 483
15.10Ausefu lresul tafterall? 484
15.11Howtomass-produc eparado xes 485
15.12Comment s 486
16Orthodo xmethods :historica lbackgroun d 490
16.1 Theearlyproblem s 490
16.2 Sociolog yoforthodo xstatistic s 492
16.3 Ronal dFishe r,Harol dJeffreys,andJerzyNeyman 493
16.4 Pre-dat aandpost-dat aconsideration s 499
16.5 Thesamplin gdistri butionforanestimato r 500
16.6 Pro-causa landanti-causa lbias 503
16.7 Wha tisreal,theprobabilit yorthephenomenon ? 505
16.8 Comment s 506
16.8. 1 Communicatio ndifﬁcultie s 507
17Principle sandpatholog yoforthodo xstatistic s 509
17.1 Informatio nloss 510
17.2 Unbiase destimator s 511
17.3 Patholog yofanunbiase destimat e 516
17.4 Thefundamenta linequalit yofthesamplin gvarianc e 518
17.5 Periodicity :theweathe rinCentra lPark 520
17.5. 1 Thefollyofpre-ﬁlterin gdata 521
17.6 ABayesia nanalysi s 527
17.7 Thefollyofrandomizatio n 531
17.8 Fisher :commo nsenseatRothamste d 532
17.8. 1 TheBayesia nsafet ydevice 532
17.9 Missin gdata 533
17.10Trendandseasonalit yintimeserie s 534
17.10. 1Orthodo xmethod s 535
17.10. 2TheBayesia nmetho d 536
17.10.3 Comparison of Bayesian and orthodox
estimate s 540
17.10. 4Animpr ovedorthodo xestimat e 541
17.10. 5Theorthodo xcriterio nofperformanc e 544
17.11Thegenera lcase 545
17.12Comment s 550
18 The Apdistri butionandruleofsuccessio n 553
18.1 Memor ystorag eforoldrobot s 553
18.2 Relevance 555
18.3 Asurprisin gconsequenc e 557
18.4 Oute randinnerrobot s 559

<<<PAGE 16>>>

xiv Contents
18.5 Anapplicatio n 561
18.6 Laplace ’sruleofsuccessio n 563
18.7 Jeffreys’objectio n 566
18.8 Bassorcarp? 567
18.9 Sowher edoesthisleavetherule? 568
18.10Generalizatio n 568
18.11Conﬁrmatio nandweigh tofevidenc e 571
18.11. 1Isindifferenc ebasedonknowledg eorignorance ? 573
18.12Carnap ’sinduct ivemethod s 574
18.13Probabilit yandfrequen cyinexchangeabl esequence s 576
18.14Predictio noffrequencie s 576
18.15One-dimensiona lneutro nmultiplicatio n 579
18.15. 1Thefrequentis tsolutio n 579
18.15. 2TheLaplac esolutio n 581
18.16ThedeFinett itheore m 586
18.17Comment s 588
19Physica lmeasurement s 589
19.1 Reductio nofequation sofconditio n 589
19.2 Reformulatio nasadecisio nproble m 592
19.2. 1 Sermo nonGaussia nerrordistri bution s 592
19.3 Theunderdetermine dcase:Kissingula r 594
19.4 Theoverdetermine dcase:Kcanbemadenonsingula r 595
19.5 Numerica levaluatio noftheresul t 596
19.6 Accura cyoftheestimate s 597
19.7 Comment s 599
19.7. 1 Aparado x 599
20Mode lcompariso n 601
20.1 Formulatio noftheproble m 602
20.2 Thefairjudgeandthecruelrealis t 603
20.2. 1 Parameter sknowninadvance 604
20.2. 2 Parameter sunkn own 604
20.3 Butwher eistheideaofsimplicity ? 605
20.4 Anexample :linea rrespons emodel s 607
20.4. 1 Digression :theoldsermo nstillanothe rtime 608
20.5 Comment s 613
20.5. 1 Finalcause s 614
21Outlier sandrobustnes s 615
21.1Theexperimenter ’sdilemm a 615
21.2Robustnes s 617
21.3Thetwo-mode lmode l 619
21.4Exchangeabl eselectio n 620
21.5Thegenera lBayesia nsolutio n 622

<<<PAGE 17>>>

Contents xv
21.6Pureoutlier s 624
21.7Onerecedin gdatum 625
22Introductio ntocommunicatio ntheor y 627
22.1Origin softhetheor y 627
22.2Thenoiseles schanne l 628
22.3Theinformatio nsourc e 634
22.4DoestheEnglis hlanguag ehavestatistica lproperties ? 636
22.5Optimu mencoding :letterfrequencie sknown 638
22.6Bette rencodin gfromknowledg eofdigra mfrequencie s 641
22.7Relatio ntoastochasti cmode l 644
22.8Thenoisychanne l 648
Appendi xAOthe rapproache stoprobabilit ytheor y 651
A.1TheKolmogor ovsyste mofprobabilit y 651
A.2ThedeFinett isyste mofprobabilit y 655
A.3Comparat iveprobabilit y 656
A.4Holdout sagains tuniversalcomparabilit y 658
A.5Speculation sabou tlattic etheorie s 659
Appendi xBMathematica lformalitie sandstyle 661
B.1Notatio nandlogica lhierarch y 661
B.2Our‘cautiou sapproach ’policy 662
B.3WillyFelle ronmeasur etheor y 663
B.4Kronec kervs.Weierstras z 665
B.5Wha tisalegitimat emathematica lfunction ? 666
B.5.1Delta-function s 668
B.5.2Nondi fferentiabl efunction s 668
B.5.3Bogu snondi fferentiabl efunction s 669
B.6Countin ginﬁnit esets? 671
B.7 The Hausdorff sphere paradox and mathematical
disease s 672
B.8Wha tamIsuppose dtopublish ? 674
B.9Mathematica lcourtes y 675
Appendi xCConvolution sandcumulant s 677
C.1Relatio nofcumulant sandmoment s 679
C.2Example s 680
References 683
Bibli ography 705
Authorindex 721
Subjec tindex 724

<<<PAGE 18>>>



<<<PAGE 19>>>

Editor’s foreword
E. T. Jaynes died April 30, 1998. Before his death he asked me to ﬁnish and publish his
book on probability theory. I struggled with this for some time, because there is no doubt in
my mind that Jaynes wanted this book ﬁnished. Unfortunately, most of the later chapters,
Jaynes’ intended volume 2 on applications, were either missing or incomplete, and some
of the early chapters also had missing pieces. I could have written these latter chapters andﬁlled in the missing pieces, but if I did so, the work would no longer be Jaynes’; rather, itwould be a Jaynes–Bretthorst hybrid with no way to tell which material came from which
author. In the end, I decided the missing chapters would have to stay missing – the work
would remain Jaynes’.
There were a number of missing pieces of varying length that Jaynes had marked by
inserting the phrase ‘ much more coming ’. I could have left these comments in the
text, but they were ugly and they made the book look very incomplete. Jaynes intended
this book to serve as both a reference and a text book. Consequently, there are questionboxes (Exercises) scattered throughout most chapters. In the end, I decided to replace the‘much more coming ’ comments by introducing ‘Editor’s’ Exercises. If you answer these
questions, you will have ﬁlled in the missing material.
Jaynes wanted to include a series of computer programs that implemented some of the
calculations in the book. I had originally intended to include these programs. But, as timewent on, it became increasingly obvious that many of the programs were not available, and
the ones that were were written in a particularly obscure form of basic (it was the programs
that were obscure, not the basic ). Consequently, I removed the references to these programs
and, where necessary, inserted a few sentences to direct people to the necessary software
tools to implement the calculations.
Numerous references were missing and had to be supplied. Usually the information
available, a last name and date, was sufﬁcient to ﬁnd one or more probable references. Whenthere were several good candidates, and I was unable to determine which Jaynes intended, Iincluded multiple references and modiﬁed the citation. Sometimes the information was sovague that no good candidates were available. Fortunately, I was able to remove the citationwith no detrimental effect. To enable readers to distinguish between cited works and otherpublished sources, Jaynes’ original annotated bibliography has been split into two sections:a Reference list and a Bibliography.
xvii

<<<PAGE 20>>>

xviii Editor’s foreword
Finally, while I am the most obvious person who has worked on getting this book into
publication, I am not the only person to do so. Some of Jaynes’ closest friends have assistedme in completing this work. These include Tom Grandy, Ray Smith, Tom Loredo, MyronTribus and John Skilling, and I would like to thank them for their assistance. I would alsolike to thank Joe Ackerman for allowing me to take the time necessary to get this workpublished.
G. Larry Bretthorst

<<<PAGE 21>>>

Preface
The following material is addressed to readers who are already familiar with applied math-
ematics, at the advanced undergraduate level or preferably higher, and with some ﬁeld,such as physics, chemistry, biology , geology, medicine, economics, sociology, engineering,
operations research, etc., where inference is needed.
1A previous acquaintance with proba-
bility and statistics is not necessary; indeed, a certain amount of innocence in this area may
be desirable, because there will be less to unlearn.
We are concerned with probability theory and all of its conventional mathematics, but
now viewed in a wider context than that of the standard textbooks. Every chapter after the
ﬁrst has ‘new’ (i.e. not previously published) results that we think will be found interestingand useful. Many of our applications lie outside the scope of conventional probability
theory as currently taught. But we think that the results will speak for themselves, and that
something like the theory expounded here will become the conventional probability theory
of the future.
History
The present form of this work is the result of an evolutionary growth over many years. My
interest in probability theory was stimulated ﬁrst by reading the work of Harold Jeffreys(1939) and realizing that his viewpoint makes all the problems of theoretical physics appearin a very different light. But then, in quick succession, discovery of the work of R. T. Cox(1946), Shannon (1948) and P´ olya (1954) opened up new worlds of thought, whose explo-
ration has occupied my mind for some 40 years. In this much larger and permanent worldof rational thinking in general, the current problems of theoretical physics appeared as only
details of temporary interest.
The actual writing started as notes for a series of lectures given at Stanford University in
1956, expounding the then new and exciting work of George P´ olya on ‘Mathematics and
Plausible Reasoning’. He dissected our intuitive ‘common sense’ into a set of elementaryqualitative desiderata and showed that mathematicians had been using them all along to
1By ‘inference’ we mean simply: deductive reasoning whenever enough information is at hand to permit it; inductive or plausible
reasoning when – as is almost invariably the case in real problems – the necessary information is not available. But if a problem
can be solved by deductive reasoning, probability theory is not needed for it; thus our topic is the optimal processing of incomplete
information.
xix

<<<PAGE 22>>>

xx Preface
guide the early stages of discovery, which necessarily precede the ﬁnding of a rigorous proof.
The results were much like those of James Bernoulli’s Art of Conjecture (1713), developed
analytically by Laplace in the late 18th century; but P´ olya thought the resemblance to be
only qualitative.
However, P´ olya demonstrated this qualitative agreement in such complete, exhaustive
detail as to suggest that there must be more to it. Fortunately, the consistency theorems ofR. T. Cox were enough to clinch matters; when one added P´ olya’s qualitative conditions to
them the result was a proof that, if degrees of plausibility are represented by real numbers,then there is a uniquely determined set of quantitative rules for conducting inference. Thatis, any other rules whose results conﬂict with them will necessarily violate an elementary –and nearly inescapable – desideratum of rationality or consistency.
But the ﬁnal result was just the standard rules of probability theory, giv en already by
Daniel Bernoulli and Laplace; so why all the fuss? The important new feature was that
these rules were now seen as uniquely valid principles of logic in general, making no
reference to ‘chance’ or ‘random variables’; so their range of application is v astly greater
than had been supposed in the conventional probability theory that was developed in theearly 20th century. As a result, the imaginary distinction between ‘probability theory’ and
‘statistical inference’ disappears, and the ﬁeld achieves not only logical unity and simplicity,but far greater technical power and ﬂexibility in applications.
In the writer’s lectures, the emphasis was therefore on the quantitative formulation of
P´olya’s viewpoint, so it could be used for general problems of scientiﬁc inference, almost
all of which arise out of incomplete information rather than ‘randomness’. Some personalreminiscences about George P´ olya and this start of the work are in Chapter 5.
Once the development of applications started, the work of Harold Jeffreys, who had
seen so much of it intuitively and seemed to anticipate e very problem I would encounter,
became again the central focus of attention. My debt to him is only partially indicated by the
dedication of this book to his memory. Further comments about his work and its inﬂuenceon mine are scattered about in several chapters.
In the years 1957–1970 the lectures were repeated, with steadily increasing content, at
many other universities and research laboratories.
2In this growth it became clear gradually
that the outstanding difﬁculties of conventional ‘statistical inference’ are easily understood
and overcome. But the rules which now took their place were quite subtle conceptually, and
it required some deep thinking to see how to apply them correctly. Past difﬁculties, whichhad led to rejection of Laplace’s work, were seen ﬁnally as only misapplications, arisingusually from failure to deﬁne the problem unambiguously or to appreciate the cogency ofseemingly trivial side information, and easy to correct once this is recognized. The variousrelations between our ‘extended logic’ approach and the usual ‘random variable’ one appearin almost every chapter, in many different forms.
2Some of the material in the early chapters was issued in 1958 by the Socony-Mobil Oil Company as Number 4 in their series
‘Colloquium Lectures in Pure and Applied Science’.

<<<PAGE 23>>>

Preface xxi
Eventually, the material grew to far more than could be presented in a short series of
lectures, and the work evolved out of the pedagogical phase; with the clearing up of olddifﬁculties accomplished, we found ourselves in possession of a powerful tool for dealingwith new problems. Since about 1970 the accretion has continued at the same pace, butfed instead by the research activity of the writer and his colleagues. We hope that the ﬁnalresult has retained enough of its hybrid origins to be usable either as a textbook or as areference work; indeed, several generations of students have carried away earlier versionsof our notes, and in turn taught it to their students.
In view of the above, we repeat the sentence that Charles Darwin wrote in the Introduction
to his Origin of Species : ‘I hope that I may be excused for entering on these personal details,
as I give them to show that I have not been hasty in coming to a decision.’ But it mightbe thought that work done 30 years ago would be obsolete today. Fortunately, the workof Jeffreys, P´ olya and Cox was of a fundamental, timeless character whose truth does
not change and whose importance grows with time. Their perception about the nature of
inference, which was merely curious 30 years ago, is very important in a half-dozen different
areas of science today; and it will be crucially important in all areas 100 years hence.
Foundations
From many years of experience with its applications in hundreds of real problems, our views
on the foundations of probability theory have evolved into something quite complex, whichcannot be described in any such simplistic terms as ‘pro-this’ or ‘anti-that’. For example,our system of probability could hardly be more different from that of Kolmogorov, in style,philosophy, and purpose. What we consider to be fully half of probability theory as it isneeded in current applications – the principles for assigning probabilities by logical analysisof incomplete information – is not present at all in the Kolmogorov system.
Yet, when all is said and done, we ﬁnd ourselves, to our own surprise, in agreement with
Kolmogorov and in disagreement with his critics, on nearly all technical issues. As noted inAppendix A, each of his axioms turns out to be, for all practical purposes, derivable fromthe P´ olya–Cox desiderata of rationality and consistency. In short, we regard our system of
probability as not contradicting Kolmogorov’s; but rather seeking a deeper logical founda-tion that permits its extension in the directions that are needed for modern applications. Inthis endeavor, many problems have been solved, and those still unsolved appear where weshould naturally expect them: in breaking into new ground.
As another example, it appears at ﬁrst glance to everyone that we are in very close
agreement with the de Finetti system of probability. Indeed, the writer believed this for
some time. Yet when all is said and done we ﬁnd, to our own surprise, that little more than a
loose philosophical agreement remains; on many technical issues we disagree strongly withde Finetti. It appears to us that his way of treating inﬁnite sets has opened up a Pandora’sbox of useless and unnecessary paradoxes; nonconglomerability and ﬁnite additivity areexamples discussed in Chapter 15.

<<<PAGE 24>>>

xxii Preface
Inﬁnite-set paradoxing has become a morbid infection that is today spreading in a way
that threatens the very life of probability theory, and it requires immediate surgical removal.In our system, after this surgery, such paradoxes are avoided automatically; they cannot arisefrom correct application of our basic rules, because those rules admit only ﬁnite sets andinﬁnite sets that arise as well-deﬁned and well-behaved limits of ﬁnite sets. The paradoxingwas caused by (1) jumping directly into an inﬁnite set without specifying any limitingprocess to deﬁne its properties; and then (2) asking questions whose answers depend onhow the limit was approached.
For example, the question: ‘What is the probability that an integer is even?’ can have any
answer we please in (0, 1), depending on what limiting process is used to deﬁne the ‘setof all integers’ (just as a conditionally convergent series can be made to converge to anynumber we please, depending on the order in which we arrange the terms).
In our view, an inﬁnite set cannot be said to possess any ‘existence’ and mathematical
properties at all – at least, in probability theory – until we have speciﬁed the limiting process
that is to generate it from a ﬁnite set. In other words, we sail under the banner of Gauss,Kronecker, and Poincar´ e rather than Cantor, Hilbert, and Bourbaki. We hope that readers
who are shocked by this will study the indictment of Bourbakism by the mathematicianMorris Kline (1980), and then bear with us long enough to see the advantages of ourapproach. Examples appear in almost every chapter.
Comparisons
For many years, there has been controversy over ‘frequentist’ versus ‘Bayesian’ methods
of inference, in which the writer has been an outspoken partisan on the Bayesian side. Therecord of this up to 1981 is given in an earlier book (Jaynes, 1983). In these old worksthere was a strong tendency, on both sides, to argue on the level of philosophy or ideology.We can now hold ourselves somewhat aloof from this, because, thanks to recent work, thereis no longer any need to appeal to such arguments. We are now in possession of proventheorems and masses of worked-out numerical examples. As a result, the superiority ofBayesian methods is now a thoroughly demonstrated fact in a hundred different areas. Onecan argue with a philosophy; it is not so easy to argue with a computer printout, which saysto us: ‘Independently of all your philosophy, here are the facts of actual performance.’ Wepoint this out in some detail whenever there is a substantial difference in the ﬁnal results.Thus we continue to argue vigorously for the Bayesian methods; but we ask the reader to
note that our arguments now proceed by citing facts rather than proclaiming a philosophicalor ideological position.
However, neither the Bayesian nor the frequentist approach is universally applicable, so
in the present, more general, work we take a broader view of things. Our theme is simply:probability theory as extended logic . The ‘new’ perception amounts to the recognition that
the mathematical rules of probability theory are not merely rules for calculating frequencies
of ‘random variables’; they are also the unique consistent rules for conducting inference(i.e. plausible reasoning) of any kind, and we shall apply them in full generality to that end.

<<<PAGE 25>>>

Preface xxiii
It is true that all ‘Bayesian’ calculations are included automatically as particular cases of
our rules; but so are all ‘frequentist’ calculations. Nevertheless, our basic rules are broaderthan either of these, and in many applications our calculations do not ﬁt into either category.
To explain the situation as we see it presently: The traditional ‘frequentist’ methods which
use only sampling distributions are usable and useful in many particularly simple, idealizedproblems; however, they represent the most proscribed special cases of probability theory,because they presuppose conditions (independent repetitions of a ‘random experiment’ butno relevant prior information) that are hardly ever met in real problems. This approach isquite inadequate for the current needs of science.
In addition, frequentist methods provide no technical means to eliminate nuisance pa-
rameters or to take prior information into account, no way even to use all the information inthe data when sufﬁcient or ancillary statistics do not exist. Lacking the necessary theoreticalprinciples, they force one to ‘choose a statistic’ from intuition rather than from probabilitytheory, and then to invent ad hoc devices (such as unbiased estimators, conﬁdence intervals,
tail-area signiﬁcance tests) not contained in the rules of probability theory. Each of these is
usable within the small domain for which it was invented but, as Cox’s theorems guarantee,such arbitrary devices always generate inconsistencies or absurd results when applied toextreme cases; we shall see dozens of examples.
All of these defects are corrected by use of Bayesian methods, which are adequate for what
we might call ‘well-developed’ problems of inference. As Harold Jeffreys demonstrated,they have a superb analytical apparatus, able to deal effortlessly with the technical problemson which frequentist methods fail. They determine the optimal estimators and algorithmsautomatically, while taking into account prior information and making proper allowancefor nuisance parameters, and, being exact, they do not break down – but continue to yieldreasonable results – in extreme cases. Therefore they enable us to solve problems of fargreater complexity than can be discussed at all in frequentist terms. One of our main purposesis to show how all this capability was contained already in the simple product and sum rulesof probability theory interpreted as extended logic, with no need for – indeed, no room for –anyad hoc devices.
Before Bayesian methods can be used, a problem must be developed beyond the
‘exploratory phase’ to the point where it has enough structure to determine all the needed
apparatus (a model, sample space, hypothesis space, prior probabilities, sampling distribu-tion). Almost all scientiﬁc problems pass through an initial exploratory phase in which wehave need for inference, but the frequentist assumptions are invalid and the Bayesian appa-ratus is not yet available. Indeed, some of them never evolve out of the exploratory phase.Problems at this level call for more primitive means of assigning probabilities directly outof our incomplete information.
For this purpose, the Principle of maximum entropy has at present the clearest theoretical
justiﬁcation and is the most highly developed computationally, with an analytical appara-tus as powerful and versatile as the Bayesian one. To apply it we must deﬁne a samplespace, but do not need any model or sampling distribution. In effect, entropy maximizationcreates a model for us out of our data, which proves to be optimal by so many different

<<<PAGE 26>>>

xxiv Preface
criteria3that it is hard to imagine circumstances where one would not want to use it in a
problem where we have a sample space but no model.
Bayesian and maximum entropy methods differ in another respect. Both procedures
yield the optimal inferences from the information that went into them, but we may choosea model for Bayesian analysis; this amounts to expressing some prior knowledge – or someworking hypothesis – about the phenomenon being observed. Usually, such hypothesesextend beyond what is directly observable in the data, and in that sense we might say that
Bayesian methods are – or at least may be – speculative. If the extra hypotheses are true,then we expect that the Bayesian results will improve on maximum entropy; if they arefalse, the Bayesian inferences will likely be worse.
On the other hand, maximum entropy is a nonspeculative procedure, in the sense that it
invokes no hypotheses beyond the sample space and the evidence that is in the availabledata. Thus it predicts only observable facts (functions of future or past observations) ratherthan values of parameters which may exist only in our imagination. It is just for that reasonthat maximum entropy is the appropriate (safest) tool when we have very little knowledge
beyond the raw data; it protects us against drawing conclusions not warranted by the data.But when the information is extremely vague, it may be difﬁcult to deﬁne any appropriate
sample space, and one may wonder whether still more primitive principles than maximumentropy can be found. There is room for much new creative thought here.
For the present, there are many important and highly nontrivial applications where
Maximum Entropy is the only tool we need. Part 2 of this work considers them in de-tail; usually, they require more technical knowledge of the subject-matter area than do themore general applications studied in Part 1. All of presently known statistical mechanics,for example, is included in this, as are the highly successful Maximum Entropy spectrumanalysis and image reconstruction algorithms in current use. However, we think that in thefuture the latter two applications will evolve into the Bayesian phase, as we become moreaware of the appropriate models and hypothesis spaces which enable us to incorporate moreprior information.
We are conscious of having so many theoretical points to explain that we fail to present
as many practical worked-out numerical examples as we should. Fortunately, three recentbooks largely make up this deﬁciency, and should be considered as adjuncts to the presentwork: Bayesian Spectrum Analysis and Parameter Estimation (Bretthorst, 1988), Maximum
Entropy in Action (Buck and Macaulay, 1991), and Data Analysis –A Bayesian Tutorial
(Sivia, 1996), are written from a viewpoint essentially identical to ours and present a wealth
of real problems carried through to numerical solutions. Of course, these works do notcontain nearly as much theoretical explanation as does the present one. Also, the Proceedings
3These concern efﬁcient information handling; for example, (1) the model created is the simplest one that captures all the
information in the constraints (Chapter 11); (2) it is the unique model for which the constraints would have been sufﬁcient
statistics (Chapter 8); (3) if viewed as constructing a sampling distribution for subsequent Bayesian inference from new data D,
the only property of the measurement errors in Dthat are used in that subsequent inference are the ones about which that sampling
distribution contained some deﬁnite prior information (Chapter 7). Thus the formalism automatically takes into account all theinformation we have, but avoids assuming information that we do not have. This contrasts sharply with orthodox methods, whereone does not think in terms of information at all, and in general violates both of these desiderata.

<<<PAGE 27>>>

Preface xxv
volumes of the various annual MAXENT workshops since 1981 consider a great variety of
useful applications.
Mental activity
As one would expect already from P´ olya’s examples, probability theory as extended logic
reproduces many aspects of human mental activity, sometimes in surprising and even dis-turbing detail. In Chapter 5 we ﬁnd our equations exhibiting the phenomenon of a personwho tells the truth and is not believed, even though the disbelievers are reasoning consis-tently. The theory explains why and under what circumstances this will happen.
The equations also reproduce a more complicated phenomenon, divergence of opinions.
One might expect that open discussion of public issues would tend to bring about a generalconsensus. On the contrary, we observe repeatedly that when some controversial issue hasbeen discussed vigorously for a few years, society becomes polarized into two opposite
extreme camps; it is almost impossible to ﬁnd anyone who retains a moderate view. Prob-
ability theory as logic shows how two persons, given the same information, may have their
opinions driven in opposite directions by it, and what must be done to avoid this.
In such respects, it is clear that probability theory is telling us something about the way
our own minds operate when we form intuitive judgments, of which we may not have been
consciously aware. Some may feel uncomfortable at these revelations; others may see inthem useful tools for psychological, sociological, or legal research.
What is ‘safe’?
We are not concerned here only with abstract issues of mathematics and logic. One of
the main practical messages of this work is the great effect of prior information on theconclusions that one should draw from a given data set. Currently, much discussed issues,such as environmental hazards or the toxicity of a food additive, cannot be judged rationallyif one looks only at the current data and ignores the prior information that scientists haveabout the phenomenon. This can lead one to overestimate or underestimate the danger.
A common error, when judging the effects of radioactivity or the toxicity of some sub-
stance, is to assume a linear response model without threshold (i.e. without a dose rate belowwhich there is no ill effect). Presumably there is no threshold effect for cumulative poisonslike heavy metal ions (mercury, lead), which are eliminated only very slowly, if at all. Butfor virtually every organic substance (such as saccharin or cyclamates), the existence of aﬁnite metabolic rate means that there must exist a ﬁnite threshold dose rate, below whichthe substance is decomposed, eliminated, or chemically altered so rapidly that it causes noill effects. If this were not true, the human race could never have survived to the presenttime, in view of all the things we have been eating.
Indeed, every mouthful of food you and I have ever taken contained many billions of
kinds of complex molecules whose structure and physiological effects have never beendetermined – and many millions of which would be toxic or fatal in large doses. We cannot

<<<PAGE 28>>>

xxvi Preface
doubt that we are daily ingesting thousands of substances that are far more dangerous than
saccharin – but in amounts that are safe, because they are far below the various thresholdsof toxicity. At present, there are hardly any substances, except some common drugs, forwhich we actually know the threshold.
Therefore, the goal of inference in this ﬁeld should be to estimate not only the slope
of the response curve, but, far more importantly , to decide whether there is evidence for
a threshold; and, if there is, to estimate its magnitude (the ‘maximum safe dose’). Forexample, to tell us that a sugar substitute can produce a barely detectable incidence ofcancer in doses 1000 times greater than would ever be encountered in practice, is hardly anargument against using the substitute; indeed, the fact that it is necessary to go to kilodosesin order to detect any ill effects at all, is rather conclusive evidence, not of the danger, but ofthesafety , of a tested substance. A similar overdose of sugar would be far more dangerous,
leading not to barely detectable harmful effects, but to sure, immediate death by diabeticcoma; yet nobody has proposed to ban the use of sugar in food.
Kilodose effects are irrelevant because we do not take kilodoses; in the case of a sugar
substitute the important question is: What are the threshold doses for toxicity of a sugarsubstitute and for sugar, compared with the normal doses? If that of a sugar substitute is
higher, then the rational conclusion would be that the substitute is actually safer than sugar,as a food ingredient. To analyze one’s data in terms of a model which does not allow eventhe possibility of a threshold effect is to prejudge the issue in a way that can lead to falseconclusions, however good the data. If we hope to detect any phenomenon, we must use a
model that at least allows the possibility that it may exist.
We emphasize this in the Preface because false conclusions of just this kind are now
not only causing major economic waste, but also creating unnecessary dangers to publichealth and safety. Society has only ﬁnite resources to deal with such problems, so any effort
expended on imaginary dangers means that real dangers are going unattended. Even worse,the error is incorrectible by the currently most used data analysis procedures; a false premisebuilt into a model which is never questioned cannot be removed by any amount of new data.
Use of models which correctly represent the prior information that scientists have about themechanism at work can prevent such folly in the future.
Such considerations are not the only reasons why prior information is essential in infer-
ence; the progress of science itself is at stake. To see this, note a corollary to the precedingparagraph: that new data that we insist on analyzing in terms of old ideas (that is, old modelswhich are not questioned) cannot lead us out of the old ideas . However many data we record
and analyze, we may just keep repeating the same old errors, missing the same cruciallyimportant things that the experiment was competent to ﬁnd. That is what ignoring prior in-formation can do to us; no amount of analyzing coin tossing data by a stochastic model couldhave led us to the discovery of Newtonian mechanics, which alone determines those data.
Old data, when seen in the light of new ideas, can give us an entirely new insight into
a phenomenon; we have an impressive recent example of this in the Bayesian spectrum
analysis of nuclear magnetic resonance data, which enables us to make accurate quantitativedeterminations of phenomena which were not accessible to observation at all with the

<<<PAGE 29>>>

Preface xxvii
previously used data analysis by Fourier transforms. When a data set is mutilated (or, to use
the common euphemism, ‘ﬁltered’) by processing according to false assumptions, importantinformation in it may be destroyed irreversibly. As some have recognized, this is happeningconstantly from orthodox methods of detrending or seasonal adjustment in econometrics.However, old data sets, if preserved unmutilated by old assumptions, may have a new leaseon life when our prior information advances.
Style of presentation
In Part 1, expounding principles and elementary applications, most chapters start with
several pages of verbal discussion of the nature of the problem. Here we try to explainthe constructive ways of looking at it, and the logical pitfalls responsible for past errors.Only then do we turn to the mathematics, solving a few of the problems of the genre to thepoint where the reader may carry it on by straightforward mathematical generalization. InPart 2, expounding more advanced applications, we can concentrate from the start on themathematics.
The writer has learned from much experience that this primary emphasis on the logic of the
problem, rather than the mathematics, is necessary in the early stages. For modern students,the mathematics is the easy part; once a problem has been reduced to a deﬁnite mathematicalexercise, most students can solve it effortlessly and extend it endlessly, without further helpfrom any book or teacher. It is in the conceptual matters (how to make the initial connection
between the real-world problem and the abstract mathematics) that they are perplexed and
unsure how to proceed.
Recent history demonstrates that anyone foolhardy enough to describe his own work as
‘rigorous’ is headed for a fall. Therefore, we shall claim only that we do not knowingly giveerroneous arguments. We are conscious also of writing for a large and varied audience, formost of whom clarity of meaning is more important than ‘rigor’ in the narrow mathematicalsense.
There are two more, even stronger, reasons for placing our primary emphasis on logic
and clarity. Firstly, no argument is stronger than the premises that go into it, and, as HaroldJeffreys noted, those who lay the greatest stress on mathematical rigor are just the ones who,lacking a sure sense of the real world, tie their arguments to unrealistic premises and thusdestroy their relevance. Jeffreys likened this to trying to strengthen a building by anchoringsteel beams into plaster. An argument which makes it clear intuitively whya result is correct
is actually more trustworthy, and more likely of a permanent place in science, than is onethat makes a great overt show of mathematical rigor unaccompanied by understanding.
Secondly, we have to recognize that there are no really trustworthy standards of rigor in a
mathematics that has embraced the theory of inﬁnite sets. Morris Kline (1980, p. 351) cameclose to the Jeffreys simile: ‘Should one design a bridge using theory involving inﬁnite setsor the axiom of choice? Might not the bridge collapse?’ The only real rigor we have todayis in the operations of elementary arithmetic on ﬁnite sets of ﬁnite integers, and our ownbridge will be safest from collapse if we keep this in mind.

<<<PAGE 30>>>

xxviii Preface
Of course, it is essential that we follow this ‘ﬁnite sets’ policy whenever it matters for
our results; but we do not propose to become fanatical about it. In particular, the arts ofcomputation and approximation are on a different level than that of basic principle; and soonce a result is derived from strict application of the rules, we allow ourselves to use anyconvenient analytical methods for evaluation or approximation (such as replacing a sum byan integral) without feeling obliged to show how to generate an uncountable set as the limitof a ﬁnite one.
We impose on ourselves a far stricter adherence to the mathematical rules of probabil-
ity theory than was ever exhibited in the ‘orthodox’ statistical literature, in which authorsrepeatedly invoke the aforementioned intuitive ad hoc devices to do, arbitrarily and im-
perfectly, what the rules of probability theory would have done for them uniquely andoptimally. It is just this strict adherence that enables us to avoid the artiﬁcial paradoxes and
contradictions of orthodox statistics, as described in Chapters 15 and 17.
Equally important, this policy often simpliﬁes the computations in two ways: (i) the
problem of determining the sampling distribution of a ‘statistic’ is eliminated, and theevidence of the data is displayed fully in the likelihood function, which can be writtendown immediately; and (ii) one can eliminate nuisance parameters at the beginning of acalculation, thus reducing the dimensionality of a search algorithm. If there are severalparameters in a problem, this can mean orders of magnitude reduction in computation ov er
what would be needed with a least squares or maximum likelihood algorithm. The Bayesiancomputer programs of Bretthorst (1988) demonstrate these advantages impressively, leadingin some cases to major impro vements in the ability to extract information from data, ove r
previously used methods. But this has barely scratched the surface of what can be done withsophisticated Bayesian models. We expect a great proliferation of this ﬁeld in the near future.
A scientist who has learned how to use probability theory directly as extended logic
has a great advantage in power and versatility over one who has learned only a collectionof unrelated ad hoc devices. As the complexity of our problems increases, so does this
relative advantage. Therefore we think that, in the future, workers in all the quantitativesciences will be obliged, as a matter of practical necessity, to use probability theory in themanner expounded here. This trend is already well under way in several ﬁelds, ranging fromeconometrics to astronomy to magnetic resonance spectroscopy; but, to make progress in a
new area, it is necessary to develop a healthy disrespect for tradition and authority, whichhave retarded progress throughout the 20th century.
Finally, some readers should be warned not to look for hidden subtleties of meaning
which are not present. We shall, of course, explain and use all the standard technical jargonof probability and statistics – because that is our topic. But, although our concern with thenature of logical inference leads us to discuss many of the same issues, our language differsgreatly from the stilted jargon of logicians and philosophers. There are no linguistic tricks,and there is no ‘meta-language’ gobbledygook; only plain English. We think that this willconvey our message clearly enough to anyone who seriously wants to understand it. In anyevent, we feel sure that no further clarity would be achieved by taking the ﬁrst few stepsdown that inﬁnite regress that starts with: ‘What do you mean by “exists”?’

<<<PAGE 31>>>

Preface xxix
Acknowledgments
In addition to the inspiration received from the writings of Jeffreys, Cox, P´ olya, and Shannon,
I have proﬁted by interaction with some 300 former students, who have diligently caughtmy errors and forced me to think more carefully about many issues. Also, over the years, mythinking has been inﬂuenced by discussions with many colleagues; to list a few (in the reversealphabetical order preferred by some): Arnold Zellner, Eugene Wigner, George Uhlenbeck,John Tukey, William Sudderth, Stephen Stigler, Ray Smith, John Skilling, Jimmie Savage,Carlos Rodriguez, Lincoln Moses, Elliott Montroll, Paul Meier, Dennis Lindley, DavidLane, Mark Kac, Harold Jeffreys, Bruce Hill, Mike Hardy, Stephen Gull, Tom Grandy, JackGood, Seymour Geisser, Anthony Garrett, Fritz Fr¨ ohner, Willy Feller, Anthony Edwards,
Morrie de Groot, Phil Dawid, Jerome Cornﬁeld, John Parker Burg, David Blackwell, andGeorge Barnard. While I have not agreed with all of the great variety of things they told me,it has all been taken into account in one way or another in the following pages. Even whenwe ended in disagreement on some issue, I believe that our frank private discussions haveenabled me to avoid misrepresenting their positions, while clarifying my own thinking; Ithank them for their patience.
E. T. Jaynes
July, 1996

<<<PAGE 32>>>



<<<PAGE 33>>>

Part 1
Principles and elementary applications

<<<PAGE 34>>>



<<<PAGE 35>>>

1
Plausible reasoning
The actual science of logic is conversant at present only with things either
certain, impossible, or entirely doubtful, none of which (fortunately) we
have to reason on. Therefore the true logic for this world is the calculusof Probabilities, which takes account of the magnitude of the probabilitywhich is, or ought to be, in a reasonable man’s mind.
James Clerk Maxwell (1850)
Suppose some dark night a policeman walks down a street, apparently deserted. Suddenly he
hears a burglar alarm, looks across the street, and sees a jewelry store with a broken window.Then a gentleman wearing a mask comes crawling out through the broken window, carryinga bag which turns out to be full of expensive jewelry. The policeman doesn’t hesitate at allin deciding that this gentleman is dishonest. But by what reasoning process does he arriveat this conclusion? Let us ﬁrst take a leisurely look at the general nature of such problems.
1.1 Deductive and plausible reasoning
A moment’s thought makes it clear that our policeman’s conclusion was not a logical
deduction from the evidence; for there may have been a perfectly innocent explanationfor everything. It might be, for example, that this gentleman was the owner of the jewelrystore and he was coming home from a masquerade party, and didn’t have the key with him.However, just as he walked by his store, a passing truck threw a stone through the window,and he was only protecting his own property.
Now, while the policeman’s reasoning process was not logical deduction, we will grant
that it had a certain degree of validity. The evidence did not make the gentleman’s dishonestycertain , but it did make it extremely plausible . This is an example of a kind of reasoning
in which we have all become more or less proﬁcient, necessarily, long before studyingmathematical theories. We are hardly able to get through one waking hour without facingsome situation (e.g. will it rain or won’t it?) where we do not have enough information topermit deductive reasoning; but still we must decide immediately what to do.
In spite of its familiarity, the formation of plausible conclusions is a very subtle process.
Although history records discussions of it extending over 24 centuries, probably nobody has
3

<<<PAGE 36>>>

4 Part 1 Principles and elementary applications
ever produced an analysis of the process which anyone else ﬁnds completely satisfactory.
In this work we will be able to report some useful and encouraging new progress, in whichconﬂicting intuitive judgments are replaced by deﬁnite theorems, and ad hoc procedures
are replaced by rules that are determined uniquely by some very elementary – and nearlyinescapable – criteria of rationality.
All discussions of these questions start by giving examples of the contrast between
deductive reasoning and plausible reasoning. As is generally credited to the Organon of
Aristotle (fourth century bc)
1deductive reasoning ( apodeixis ) can be analyzed ultimately
into the repeated application of two strong syllogisms:
ifAis true, then Bis true
Ais true (1.1)
therefore, Bis true,
and its inverse:
ifAis true, then Bis true
Bis false (1.2)
therefore, Ais false.
This is the kind of reasoning we would like to use all the time; but, as noted, in almost all
the situations confronting us we do not have the right kind of information to allow this kindof reasoning. We fall back on weaker syllogisms ( epagoge ):
ifAis true, then Bis true
Bis true (1.3)
therefore, Abecomes more plausible.
The evidence does not prove that Ais true, but veriﬁcation of one of its consequences does
give us more conﬁdence in A. For example, let
A≡it will start to rain by 10 amat the latest;
B≡the sky will become cloudy before 10 am.
Observing clouds at 9:45 amdoes not give us a logical certainty that the rain will follow;
nevertheless our common sense, obeying the weak syllogism, may induce us to change ourplans and behave as if we believed that it will, if those clouds are sufﬁciently dark.
This example shows also that the major premise, ‘if Athen B’ expresses Bonly as a
logical consequence of A; and not necessarily a causal physical consequence, which could
be effective only at a later time. The rain at 10 amis not the physical cause of the clouds at
1Today, several different views are held about the exact nature of Aristotle’s contribution. Such issues are irrelevant to our present
purpose, but the interested reader may ﬁnd an extensive discussion of them in Lukasiewicz (1957).

<<<PAGE 37>>>

1 Plausible reasoning 5
9:45 am. Nevertheless, the proper logical connection is not in the uncertain causal direction
(clouds=⇒ rain), but rather (rain =⇒ clouds), which is certain, although noncausal.
We emphasize at the outset that we are concerned here with logical connections, because
some discussions and applications of inference have fallen into serious error through failureto see the distinction between logical implication and physical causation. The distinctionis analyzed in some depth by Simon and Rescher (1966), who note that all attempts tointerpret implication as expressing physical causation founder on the lack of contrapositionexpressed by the second syllogism (1.2). That is, if we tried to interpret the major premiseas ‘Ais the physical cause of B’, then we would hardly be able to accept that ‘not- Bis
the physical cause of not- A’. In Chapter 3 we shall see that attempts to interpret plausible
inferences in terms of physical causation fare no better.
Another weak syllogism, still using the same major premise, is
IfAis true, then Bis true
Ais false (1.4)
therefore, Bbecomes less plausible.
In this case, the evidence does not prove that Bis false; but one of the possible reasons for
its being true has been eliminated, and so we feel less conﬁdent about B. The reasoning of a
scientist, by which he accepts or rejects his theories, consists almost entirely of syllogisms
of the second and third kind.
Now, the reasoning of our policeman was not even of the above types. It is best described
by a still weaker syllogism:
IfAis true, then Bbecomes more plausible
Bis true (1.5)
therefore, Abecomes more plausible.
But in spite of the apparent weakness of this argument, when stated abstractly in terms of A
andB, we recognize that the policeman’s conclusion has a very strong convincing power.
There is something which makes us believe that, in this particular case, his argument hadalmost the power of deductive reasoning.
These examples show that the brain, in doing plausible reasoning, not only decides
whether something becomes more plausible or less plausible, but that it evaluates the degree
of plausibility in some way. The plausibility for rain by 10 amdepends very much on the
darkness of those clouds at 9:45. And the brain also makes use of old information as well
as the speciﬁc new data of the problem; in deciding what to do we try to recall our past
experience with clouds and rain, and what the weatherman predicted last night.
To illustrate that the policeman was also making use of the past experience of policemen
in general, we have only to change that experience. Suppose that events like these happenedseveral times every night to every policeman – and that in every case the gentleman turned

<<<PAGE 38>>>

6 Part 1 Principles and elementary applications
out to be completely innocent. Very soon, policemen would learn to ignore such trivial
things.
Thus, in our reasoning we depend very much on prior information to help us in evaluating
the degree of plausibility in a new problem. This reasoning process goes on unconsciously,almost instantaneously, and we conceal how complicated it really is by calling it common
sense .
The mathematician George P´ olya (1945, 1954) wrote three books about plausible rea-
soning, pointing out a wealth of interesting examples and showing that there are deﬁniterules by which we do plausible reasoning (although in his work they remain in qualitativeform). The above weak syllogisms appear in his third volume. The reader is strongly urgedto consult P´ olya’s exposition, which was the original source of many of the ideas underlying
the present work. We show below how P´ olya’s principles may be made quantitative, with
resulting useful applications.
Evidently, the deductive reasoning described above has the property that we can go
through long chains of reasoning of the type (1.1) and (1.2) and the conclusions have just asmuch certainty as the premises. With the other kinds of reasoning, (1.3)–(1.5), the reliabilityof the conclusion changes as we go through several stages. But in their quantitative form weshall ﬁnd that in many cases our conclusions can still approach the certainty of deductivereasoning (as the example of the policeman leads us to expect). P´ olya showed that even
a pure mathematician actually uses these weaker forms of reasoning most of the time. Ofcourse, on publishing a new theorem, the mathematician will try very hard to invent anargument which uses only the ﬁrst kind; but the reasoning process which led to the theoremin the ﬁrst place almost always involves one of the weaker forms (based, for example, onfollowing up conjectures suggested by analogies). The same idea is expressed in a remarkof S. Banach (quoted by S. Ulam, 1957):
Good mathematicians see analogies between theorems; great mathematicians see analogies between
analogies.
As a ﬁrst orientation, then, let us note some very suggestive analogies to another ﬁeld –
which is itself based, in the last analysis, on plausible reasoning.
1.2 Analogies with physical theories
In physics, we learn quickly that the world is too complicated for us to analyze it all at once.
We can make progress only if we dissect it into little pieces and study them separately.Sometimes, we can invent a mathematical model which reproduces several features of oneof these pieces, and whenever this happens we feel that progress has been made. Thesemodels are called physical theories . As knowledge advances, we are able to invent better
and better models, which reproduce more and more features of the real world, more and moreaccurately. Nobody knows whether there is some natural end to this process, or whether itwill go on indeﬁnitely.

<<<PAGE 39>>>

1 Plausible reasoning 7
In trying to understand common sense, we shall take a similar course. We won’t try
to understand it all at once, but we shall feel that progress has been made if we areable to construct idealized mathematical models which reproduce a few of its features.We expect that any model we are now able to construct will be replaced by more com-plete ones in the future, and we do not know whether there is any natural end to thisprocess.
The analogy with physical theories is deeper than a mere analogy of method. Often, the
things which are most familiar to us turn out to be the hardest to understand. Phenomenawhose very existence is unknown to the vast majority of the human race (such as the differ-ence in ultraviolet spectra of iron and nickel) can be explained in exhaustive mathematicaldetail – but all of modern science is practically helpless when faced with the complicationsof such a commonplace fact as growth of a blade of grass. Accordingly, we must not expecttoo much of our models; we must be prepared to ﬁnd that some of the most familiar featuresof mental activity may be ones for which we have the greatest difﬁculty in constructing anyadequate model.
There are many more analogies. In physics we are accustomed to ﬁnding that any ad-
vance in knowledge leads to consequences of great practical value, but of an unpredictablenature. R¨ ontgen’s discovery of X-rays led to important new possibilities of medical diag-
nosis; Maxwell’s discovery of one more term in the equation for curl Hled to practically
instantaneous communication all over the earth.
Our mathematical models for common sense also exhibit this feature of practical useful-
ness. Any successful model, even though it may reproduce only a few features of commonsense, will prove to be a powerful extension of common sense in some ﬁeld of application.Within this ﬁeld, it enables us to solve problems of inference which are so involved incomplicated detail that we would never attempt to solve them without its help.
1.3 The thinking computer
Models have practical uses of a quite different type. Many people are fond of saying, ‘They
will never make a machine to replace the human mind – it does many things which nomachine could ever do.’ A beautiful answer to this was given by J. von Neumann in a talkon computers given in Princeton in 1948, which the writer was privileged to attend. In replyto the canonical question from the audience (‘But of course, a mere machine can’t reallythink , can it?’), he said:
Youinsist that there is something a machine cannot do. If you will tell me precisely what it is that a
machine cannot do, then I can always make a machine which will do just that!
In principle, the only operations which a machine cannot perform for us are those which
we cannot describe in detail, or which could not be completed in a ﬁnite number of steps.Of course, some will conjure up images of G¨ odel incompleteness, undecidability, Turing
machines which never stop, etc. But to answer all such doubts we need only point to the

<<<PAGE 40>>>

8 Part 1 Principles and elementary applications
existence of the human brain, which does it. Just as von Neumann indicated, the only
real limitations on making ‘machines which think’ are our own limitations in not knowingexactly what ‘thinking’ consists of.
But in our study of common sense we shall be led to some very explicit ideas about
the mechanism of thinking. Every time we can construct a mathematical model whichreproduces a part of common sense by prescribing a deﬁnite set of operations, this showsus how to ‘build a machine’, (i.e. write a computer program) which operates on incomplete
information and, by applying quantitative versions of the above weak syllogisms, doesplausible reasoning instead of deductive reasoning.
Indeed, the development of such computer software for certain specialized problems of
inference is one of the most active and useful current trends in this ﬁeld. One kind of problem
thus dealt with might be: given a mass of data, comprising 10 000 separate observations,determine in the light of these data and whatever prior information is at hand, the relativeplausibilities of 100 different possible hypotheses about the causes at work.
Our unaided common sense might be adequate for deciding between two hypotheses
whose consequences are very different; but, in dealing with 100 hypotheses which are notvery different, we would be helpless without a computer anda well-developed mathematical
theory that shows us how to program it. That is, what determines, in the policeman’ssyllogism (1.5), whether the plausibility for Aincreases by a large amount, raising it almost
to certainty; or only a negligibly small amount, making the data Balmost irrelevant? The
object of the present work is to develop the mathematical theory which answers such
questions, in the greatest depth and generality now possible.
While we expect a mathematical theory to be useful in programming computers, the
idea of a thinking computer is also helpful psychologically in developing the mathematical
theory. The question of the reasoning process used by actual human brains is charged with
emotion and grotesque misunderstandings. It is hardly possible to say anything about thiswithout becoming involved in debates over issues that are not only undecidable in ourpresent state of knowledge, but are irrelevant to our purpose here.
Obviously, the operation of real human brains is so complicated that we can make no
pretense of explaining its mysteries; and in any event we are not trying to explain, much lessreproduce, all the aberrations and inconsistencies of human brains. That is an interesting andimportant subject; but it is not the subject we are studying here. Our topic is the normative
principles of logic , and not the principles of psychology or neurophysiology .
To emphasize this, instead of asking, ‘How can we build a mathematical model of human
common sense?’, let us ask, ‘How could we build a machine which would carry out usefulplausible reasoning, following clearly deﬁned principles expressing an idealized commonsense?’
1.4 Introducing the robot
In order to direct attention to constructive things and away from controversial irrelevancies,
we shall invent an imaginary being. Its brain is to be designed by us , so that it reasons

<<<PAGE 41>>>

1 Plausible reasoning 9
according to certain deﬁnite rules. These rules will be deduced from simple desiderata
which, it appears to us, would be desirable in human brains; i.e. we think that a rationalperson, on discovering that they were violating one of these desiderata, would wish to revisetheir thinking.
In principle, we are free to adopt any rules we please; that is our way of deﬁning which
robot we shall study. Comparing its reasoning with yours, if you ﬁnd no resemblance youare in turn free to reject our robot and design a different one more to your liking. But if youﬁnd a very strong resemblance, and decide that you want and trust this robot to help you inyour own problems of inference, then that will be an accomplishment of the theory, not apremise.
Our robot is going to reason about propositions. As already indicated above, we shall
denote various propositions by italicized capital letters, {A,B,C,etc.}, and for the time
being we must require that any proposition used must have, to the robot, an unambiguousmeaning and must be of the simple, deﬁnite logical type that must be either true or false. Thatis, until otherwise stated, we shall be concerned only with two-valued logic, or Aristotelianlogic. We do not require that the truth or falsity of such an ‘Aristotelian proposition’ beascertainable by any feasible investigation; indeed, our inability to do this is usually justthe reason why we need the robot’s help. For example, the writer personally considers bothof the following propositions to be true:
A≡Beethoven and Berlioz never met.
B≡Beethoven’s music has a better sustained quality than that of
Berlioz, although Berlioz at his best is the equal of anybody.
Proposition Bis not a permissible one for our robot to think about at present, whereas
proposition Ais, although it is unlikely that its truth or falsity could be deﬁnitely established
today.
2After our theory is developed, it will be of interest to see whether the present
restriction to Aristotelian propositions such as Acan be relaxed, so that the robot might help
us also with more vague propositions such as B(see Chapter 18 on the Ap-distribution).3
1.5 Boolean algebra
To state these ideas more formally, we introduce some notation of the usual symbolic logic,
or Boolean algebra, so called because George Boole (1854) introduced a notation similar
to the following. Of course, the principles of deductive logic itself were well understoodcenturies before Boole, and, as we shall see, all the results that follow from Boolean al-gebra were contained already as special cases in the rules of plausible inference given
2Their meeting is a chronological possibility, since their lives overlapped by 24 years; my reason for doubting it is the failure of
Berlioz to mention any such meeting in his memoirs – on the other hand, neither does he come out and say deﬁnitely that theydidnotmeet.
3The question of how one is to make a machine in some sense ‘cognizant’ of the conceptual meaning that a proposition like Ahas
to humans, might seem very difﬁcult, and much of the subject of artiﬁcial intelligence is devoted to inventing ad hoc devices to
deal with this problem. However, we shall ﬁnd in Chapter 4 that for us the problem is almost nonexistent; our rules for plausiblereasoning automatically provide the means to do the mathematical equivalent of this.

<<<PAGE 42>>>

10 Part 1 Principles and elementary applications
by (1812). The symbol
AB, (1.6)
called the logical product or the conjunction , denotes the proposition ‘both AandBare
true’. Obviously, the order in which we state them does not matter; ABandBAsay the
same thing. The expression
A+B, (1.7)
called the logical sum ordisjunction , stands for ‘at least one of the propositions, A,Bis
true’ and has the same meaning as B+A. These symbols are only a shorthand way of
writing propositions, and do not stand for numerical values.
Given two propositions A,B, it may happen that one is true if and only if the other is true;
we then say that they ha ve the same truth value . This may be only a simple tautology (i.e.
AandBare verbal statements which obviously say the same thing), or it may be that only
after immense mathematical labor is it ﬁnally proved that Ais the necessary and sufﬁcient
condition for B. From the standpoint of logic it does not matter; once it is established,
by any means, that AandBhave the same truth value, then they are logically equivalent
propositions, in the sense that any evidence concerning the truth of one pertains equallywell to the truth of the other, and they have the same implications for any further reasoning.
Evidently, then, it must be the most primitive axiom of plausible reasoning that two
propositions with the same truth value are equally plausible. This might appear almost tootrivial to mention, were it not for the fact that Boole himself (Boole, 1854, p. 286) fell intoerror on this point, by mistakenly identifying two propositions which were in fact different –and then failing to see any contradiction in their different plausibilities. Three years later,
Boole (1857) gave a revised theory which supersedes that in his earlier book; for furthercomments on this incident, see Keynes (1921, pp. 167–168); Jaynes (1976, pp. 240–242).
In Boolean algebra, the equal sign is used to denote not equal numerical value, but equal
truth value: A=B, and the ‘equations’ of Boolean algebra thus consist of assertions that
the proposition on the left-hand side has the same truth value as the one on the right-handside. The symbol ‘≡’ means, as usual, ‘equals by deﬁnition’.
In denoting complicated propositions we use parentheses in the same way as in ordinary
algebra, i.e. to indicate the order in which propositions are to be combined (at times we shall
use them also merely for clarity of expression although they are not strictly necessary). In
their absence we observe the rules of algebraic hierarchy, familiar to those who use handcalculators: thus AB+Cdenotes ( AB)+C; and not A(B+C).
Thedenial of a proposition is indicated by a bar:
A≡Ais false. (1.8)
The relation between A,Ais a reciprocal one:
A=Ais false, (1.9)

<<<PAGE 43>>>

1 Plausible reasoning 11
and it does not matter which proposition we denote by the barred and which by the unbarred
letter. Note that some care is needed in the unambiguous use of the bar. For example,according to the above conventions,
AB=ABis false; (1.10)
AB=both AandBare false. (1.11)
These are quite different propositions; in fact, ABis not the logical product AB, but the
logical sum: AB=A+B.
With these understandings, Boolean algebra is characterized by some rather trivial and
obvious basic identities, which express the properties of:
Idempotence:/braceleftBigg
AA=A
A+A=A
Commutativity:/braceleftBigg
AB=BA
A+B=B+A
Associativity:/braceleftBigg
A(BC)=(AB)C=ABC
A+(B+C)=(A+B)+C=A+B+C
Distributivity:/braceleftBigg
A(B+C)=AB+AC
A+(BC)=(A+B)(A+C)
Duality:/braceleftBigg
IfC=AB, then C=A+B
IfD=A+B, then D=AB(1.12)
but by their application one can prove any number of further relations, some highly non-
trivial. For example, we shall presently have use for the rather elementary theorem:
ifB=ADthen AB=BandBA=A. (1.13)
Implication
The proposition
A⇒B (1.14)
to be read as ‘ Aimplies B’, does not assert that either AorBis true; it means only that AB
is false, or, what is the same thing, ( A+B) is true. This can be written also as the logical
equation A=AB. That is, given (1.14), if Ais true then Bmust be true; or, if Bis false
then Amust be false. This is just what is stated in the strong syllogisms (1.1) and (1.2).

<<<PAGE 44>>>

12 Part 1 Principles and elementary applications
On the other hand, if Ais false, (1.14) says nothing about B: and if Bis true, (1.14) says
nothing about A. But these are just the cases in which our weak syllogisms (1.3), (1.4) do
say something. In one respect, then, the term ‘weak syllogism’ is misleading. The theoryof plausible reasoning based on weak syllogisms is not a ‘weakened’ form of logic; it isanextension of logic with new content not present at all in conventional deductive logic. It
will become clear in the next chapter (see (2.69) and (2.70)) that our rules include deductivelogic as a special case.
A tricky point
Note carefully that in ordinary language one would take ‘ Aimplies B’ to mean that B
is logically deducible from A. But, in formal logic, ‘ Aimplies B’ means only that the
propositions Aand ABhave the same truth value. In general, whether Bis logically
deducible from Adoes not depend only on the propositions AandB; it depends on the
totality of propositions ( A,A
/prime,A/prime/prime,...) that we accept as true and which are therefore
available to use in the deduction. Devinatz (1968, p. 3) and Hamilton (1988, p. 5) give the
truth table for the implication as a binary operation, illustrating that A⇒Bis false only if
Ais true and Bis false; in all other cases A⇒Bis true!
This may seem startling at ﬁrst glance; however, note that, indeed, if AandBare both
true, then A=ABand so A⇒Bis true; in formal logic every true statement implies
every other true statement. On the other hand, if Ais false, then AQis also false for all
Q, thus A=ABandA=ABare both true, so A⇒BandA⇒Bare both true; a false
proposition implies all propositions. If we tried to interpret this as logical deducibility(i.e. both Band
Bare deducible from A), it would follow that every false proposition is
logically contradictory. Yet the proposition: ‘Beethoven outlived Berlioz’ is false but hardlylogically contradictory (for Beethoven did outlive many people who were the same age asBerlioz).
Obviously, merely knowing that propositions AandBare both true does not provide
enough information to decide whether either is logically deducible from the other, plussome unspeciﬁed ‘toolbox’ of other propositions. The question of logical deducibility ofone proposition from a set of others arises in a crucial way in the G¨ odel theorem discussed at
the end of Chapter 2. This great difference in the meaning of the word ‘implies’ in ordinarylanguage and in formal logic is a tricky point that can lead to serious error if it is not properlyunderstood; it appears to us that ‘implication’ is an unfortunate choice of word, and that
this is not sufﬁciently emphasized in conventional expositions of logic.
1.6 Adequate sets of operations
We note some features of deductive logic which will be needed in the design of our robot.
We have deﬁned four operations, or ‘connectives’, by which, starting from two propositions
A,B, other propositions may be deﬁned: the logical product or conjunction AB, the logical

<<<PAGE 45>>>

1 Plausible reasoning 13
sum or disjunction A+B, the implication A⇒B, and the negation A. By combining
these operations repeatedly in every possible way, one can generate any number of newpropositions, such as
C≡(A+
B)(A+AB)+AB(A+B). (1.15)
Many questions then occur to us: How large is the class of new propositions thus generated?
Is it inﬁnite, or is there a ﬁnite set that is closed under these operations? Can every propositiondeﬁned from A,Bbe thus represented, or does this require further connectives beyond the
above four? Or are these four already overcomplete so that some might be dispensed with?What is the smallest set of operations that is adequate to generate all such ‘logic functions’ofAand B? If instead of two starting propositions A,Bwe have an arbitrary number
{A
1,..., An}, is this set of operations still adequate to generate all possible logic functions
of{A1,..., An}?
All these questions are answered easily, with results useful for logic, probability theory,
and computer design. Broadly speaking, we are asking whether, starting from our presentvantage point, we can (1) increase the number of functions, (2) decrease the number ofoperations. The ﬁrst query is simpliﬁed by noting that two propositions, although they mayappear entirely different when written out in the manner (1.15), are not different propositionsfrom the standpoint of logic if they have the same truth value. For example, it is left forthe reader to verify that Cin (1.15) is logically the same statement as the implication
C=(B⇒
A).
Since we are, at this stage, restricting our attention to Aristotelian propositions, any logic
function C=f(A,B) such as (1.15) has only two possible ‘values’, true and false; and
likewise the ‘independent v ariables’ AandBcan take on only those two values.
At this point, a logician might object to our notation, saying that the symbol Ahas
been deﬁned as standing for some ﬁxed proposition, whose truth cannot change; so if wewish to consider logic functions, then instead of writing C=f(A,B) we should introduce
new symbols and write z=f(x,y), where x,y,z, are ‘statement variables’ for which
various speciﬁc statements A,B,Cmay be substituted. But if Astands for some ﬁxed but
unspeciﬁed proposition, then it can still be either true or false. We achieve the same ﬂexibilitymerely by the understanding that equations like (1.15) which deﬁne logic functions are tobe true for all ways of deﬁning A,B; i.e. instead of a statement variable we use a variable
statement.
In relations of the form C=f(A,B), we are concerned with logic functions deﬁned
on a discrete ‘space’ S consisting of only 2
2=4 points; namely those at which Aand
Btake on the ‘values’ {TT,TF,FT,FF}, respectively; and, at each point, the function
f(A,B) can take on independently either of two values {T,F}. There are, therefore, exactly
24=16 different logic functions f(A,B), and no more. An expression B=f(A1,..., An)
involving npropositions is a logic function on a space S of M=2npoints; and there are
exactly 2Msuch functions.

<<<PAGE 46>>>

14 Part 1 Principles and elementary applications
In the case n=1, there are four logic functions {f1(A),..., f4(A)}, which we can deﬁne
by enumeration, listing all their possible values in a truth table:
A TF
f1(A)TT
f2(A)TF
f3(A)FT
f4(A)FF
But it is obvious by inspection that these are just
f1(A)=A+A
f2(A)=A
f3(A)=A
f4(A)=AA,(1.16)
so we prove by enumeration that the three operations: conjunction, disjunction, and negation
are adequate to generate all logic functions of a single proposition.
For the case of general n, consider ﬁrst the special functions, each of which is true at one
and only one point of S. For n=2 there are 2n=4 such functions,
A,B TT TF FT FF
f1(A,B) TFFF
f2(A,B) FTFF
f3(A,B)F F T F
f4(A,B)F F F T
It is clear by inspection that these are just the four basic conjunctions,
f1(A,B)=AB
f2(A,B)=AB
f3(A,B)=AB
f4(A,B)=AB.(1.17)
Consider now any logic function which is true on certain speciﬁed points of S; for example,
f5(A,B) and f6(A,B), deﬁned by
A,B TT TF FT FF
f5(A,B)F T F T
f6(A,B)T F T T

<<<PAGE 47>>>

1 Plausible reasoning 15
We assert that each of these functions is the logical sum of the conjunctions (1.17) that are
true on the same points (this is not trivial; the reader should verify it in detail). Thus,
f5(A,B)=f2(A,B)+f4(A,B)
=AB+AB
=(A+A)B
=B,(1.18)
and, likewise,
f6(A,B)=f1(A,B)+f3(A,B)+f4(A,B)
=AB+AB+AB
=B+AB
=A+B.(1.19)
That is, f6(A,B) is the implication f6(A,B)=(A⇒B), with the truth table discussed
above. Any logic function f(A,B) that is true on at least one point of S can be constructed in
this way as a logical sum of the basic conjunctions (1.17). There are 24−1=15 such func-
tions. For the remaining function, which is always false, it suf ﬁces to take the contradiction,
f16(A,B)≡AA.
This method (called ‘reduction to disjunctive normal form ’ in logic textbooks) will work
for any n. For example, in the case n=5 there are 25=32 basic conjunctions,
{ABCDE ,ABCD E,ABC DE,..., ABCDE}, (1.20)
and 232=4 294 967 296 different logic functions fi(A,B,C,D,E); of which 4 294 967 295
can be written as logical sums of the basic conjunctions, leaving only the contradiction
f4294967296 (A,B,C,D,E)=AA. (1.21)
Thus one can verify by ‘construction in thought’ that the three operations
{conjunction, disjunction, negation }, i.e.{AND, OR, NOT}, (1.22)
sufﬁce to generate all possible logic functions; or, more concisely, the y form an
adequate set .
The duality property (1.12) shows that a smaller set will sufﬁce; for disjunction of A,B
is the same as denying that they are both false:
A+B=(AB). (1.23)
Therefore, the two operations (AND, NOT) already constitute an adequate set for deductive
logic.4This fact will be essential in determining when we have an adequate set of rules for
plausible reasoning; see Chapter 2.
4For you to ponder: Does it follow that these two commands are the only ones needed to write any computer program?

<<<PAGE 48>>>

16 Part 1 Principles and elementary applications
It is clear that we cannot now strike out either of these operations, leaving only the
other; i.e. the operation ‘AND’ cannot be reduced to negations; and negation cannot beaccomplished by any number of ‘AND’ operations. But this still leaves open the possibilitythat both conjunction and negation might be reducible to some third operation, not yetintroduced, so that a single logic operation would constitute an adequate set.
It comes as a pleasant surprise to ﬁnd that there is not only one but two such operations.
The operation ‘NAND’ is deﬁned as the negation of ‘AND’:
A↑B≡
AB=A+B (1.24)
which we can read as ‘ ANAND B’. But then we have at once
A=A↑A
AB=(A↑B)↑(A↑B)
A+B=(A↑A)↑(B↑B).(1.25)
Therefore, every logic function can be constructed with NAND alone. Likewise, the
operation NOR deﬁned by
A↓B≡A+B=AB (1.26)
is also powerful enough to generate all logic functions:
A=A↓A
A+B=(A↓B)↓(A↓B)
AB=(A↓A)↓(B↓B).(1.27)
One can take advantage of this in designing computer and logic circuits. A ‘logic gate’ is a
circuit having, besides a common ground, two input terminals and one output. The voltagerelative to ground at any of these terminals can take on only two values; say +3 volts, or
‘up’, representing ‘true’; and 0 volts or ‘down’, representing ‘false’. A NAND gate is thusone whose output is up if and only if at least one of the inputs is down; or, what is the samething, down if and only if both inputs are up; while for a NOR gate the output is up if and
only if both inputs are down.
One of the standard components of logic circuits is the ‘quad NAND gate’, an integrated
circuit containing four independent NAND gates on one semiconductor chip. Given a sufﬁ-cient number of these and no other circuit components, it is possible to generate any requiredlogic function by interconnecting them in various ways.
This short excursion into deductive logic is as far as we need go for our purposes. Further
developments are given in many textbooks; for example, a modern treatment of Aristotelianlogic is given by Copi (1994). For non-Aristotelian forms with special emphasis on G¨ odel
incompleteness, computability, decidability, Turing machines, etc., see Hamilton (1988).
We turn now to our extension of logic, which is to follow from the conditions discussed
next. We call them ‘desiderata’ rather than ‘axioms’ because they do not assert that anythingis ‘true’ but only state what appear to be desirable goals. Whether these goals are attainable

<<<PAGE 49>>>

1 Plausible reasoning 17
without contradictions, and whether they determine any unique extension of logic, are
matters of mathematical analysis, given in Chapter 2.
1.7 The basic desiderata
To each proposition about which it reasons, our robot must assign some degree of plausi-
bility, based on the evidence we have given it; and whenever it receives new evidence itmust revise these assignments to take that new evidence into account. In order that theseplausibility assignments can be stored and modiﬁed in the circuits of its brain, they mustbe associated with some deﬁnite physical quantity, such as voltage or pulse duration or abinary coded number, etc. – however our engineers want to design the details. For presentpurposes, this means that there will have to be some kind of association between degreesof plausibility and real numbers:
(I) Degrees of plausibility are represented by real numbers . (1.28)
Desideratum (I) is practically forced on us by the requirement that the robot’s brain must
operate by the carrying out of some deﬁnite physical process. However, it will appear(Appendix A) that it is also required theoretically; we do not see the possibility of anyconsistent theory without a property that is equivalent functionally to desideratum (I).
We adopt a natural but nonessential convention: that a greater plausibility shall correspond
to a greater number. It will also be convenient to assume a continuity property, which is hardto state precisely at this stage; to say it intuitively: an inﬁnitesimally greater plausibilityought to correspond only to an inﬁnitesimally greater number.
The plausibility that the robot assigns to some proposition Awill, in general, depend on
whether we told it that some other proposition Bis true. Following the notation of Keynes
(1921) and Cox (1961), we indicate this by the symbol
A|B, (1.29)
which we may call ‘the conditional plausibility that Ais true, given that Bis true’ or just
‘Agiven B’. It stands for some real number. Thus, for example,
A|BC (1.30)
(which we may read as ‘ Agiven BC’) represents the plausibility that Ais true, given that
both BandCare true. Or,
A+B|CD (1.31)
represents the plausibility that at least one of the propositions AandBis true, given that
both CandDare true; and so on. We have decided to represent a greater plausibility by a
greater number, so
(A|B)>(C|B) (1.32)

<<<PAGE 50>>>

18 Part 1 Principles and elementary applications
says that, given B,Ais more plausible than C. In this notation, while the symbol for
plausibility is just of the form A|Bwithout parentheses, we often add parentheses for
clarity of expression. Thus, (1.32) says the same thing as
A|B>C|B, (1.33)
but its meaning is clearer to the eye.
In the interest of avoiding impossible problems, we are not going to ask our robot to
undergo the agony of reasoning from impossible or mutually contradictory premises; therecould be no ‘correct’ answer. Thus, we make no attempt to deﬁne A|BCwhen BandCare
mutually contradictory. Whenever such a symbol appears, it is understood that BandCare
compatible propositions.
Also, we do not want this robot to think in a way that is directly opposed to the way you
and I think. So we shall design it to reason in a way that is at least qualitatively like the way
humans try to reason, as described by the above weak syllogisms and a number of othersimilar ones.
Thus, if it has old information Cwhich gets updated to C
/primein such a way that the plausibility
forAis increased:
(A|C/prime)>(A|C); (1.34)
but the plausibility for Bgiven Ais not changed:
(B|AC/prime)=(B|AC). (1.35)
This can, of course, produce only an increase, never a decrease, in the plausibility that both
AandBare true:
(AB|C/prime)≥(AB|C); (1.36)
and it must produce a decrease in the plausibility that Ais false:
(A|C/prime)<(A|C). (1.37)
This qualitative requirement simply gives the ‘sense of direction’ in which the robot’s
reasoning is to go; it says nothing about how much the plausibilities change, except that
our continuity assumption (which is also a condition for qualitative correspondence withcommon sense) now requires that if A|Cchanges only inﬁnitesimally, it can induce only an
inﬁnitesimal change in AB|Cand
A|C. The speciﬁc ways in which we use these qualitative
requirements will be given in the next chapter, at the point where it is seen why we needthem. For the present we summarize them simply as:
(II) Qualitative correspondence with common sense . (1.38)
Finally, we want to give our robot another desirable property for which honest people strive
without always attaining: that it always reasons consistently . By this we mean just the three

<<<PAGE 51>>>

1 Plausible reasoning 19
common colloquial meanings of the word ‘consistent’:
(IIIa)If a conclusion can be reasoned out in more than one way, then
every possible way must lead to the same result.(1.39a)
(IIIb)The robot always takes into account all of the evidence it has
relevant to a question. It does not arbitrarily ignore some ofthe information, basing its conclusions only on what remains.In other words, the robot is completely nonideological.(1.39b)
(IIIc)The robot always represents equivalent states of knowledge by
equivalent plausibility assignments. That is, if in two problemsthe robot’s state of knowledge is the same (except perhaps forthe labeling of the propositions), then it must assign the sameplausibilities in both.(1.39c)
Desiderata (I), (II), and (IIIa) are the basic ‘structural’ requirements on the inner workings
of our robot’s brain, while (IIIb) and (IIIc) are ‘interface’ conditions which show ho w the
robot’s behavior should relate to the outer world.
At this point, most students are surprised to learn that our search for desiderata is at an end.
The above conditions, it turns out, uniquely determine the rules by which our robot must
reason; i.e. there is only one set of mathematical operations for manipulating plausibilities
which has all these properties. These rules are deduced in Chapter 2.
(At the end of most chapters, we insert a section of informal Comments in which are
collected various side remarks, background material, etc. The reader may skip them without
losing the main thread of the argument.)
1.8 Comments
As politicians, advertisers, salesmen, and propagandists for various political, economic,
moral, religious, psychic, environmental, dietary, and artistic doctrinaire positions knowonly too well, fallible human minds are easily tricked, by clever verbiage, into committingviolations of the above desiderata. We shall try to ensure that they do not succeed with ourrobot.
We emphasize another contrast between the robot and a human brain. By Desideratum
I, the robot’s mental state about any proposition is to be represented by a real number.Now, it is clear that our attitude toward any given proposition may have more than one‘coordinate’. You and I form simultaneous judgments about a proposition not only as towhether it is plausible, but also whether it is desirable, whether it is important, whether itis useful, whether it is interesting, whether it is amusing, whether it is morally right, etc.If we assume that each of these judgments might be represented by a number, then a fullyadequate description of a human state of mind would be represented by a vector in a spaceof a rather large number of dimensions.

<<<PAGE 52>>>

20 Part 1 Principles and elementary applications
Not all propositions require this. For example, the proposition ‘The refractive index of
water is less than 1.3’ generates no emotions; consequently the state of mind which itproduces has very few coordinates. On the other hand, the proposition, ‘Your mother-in-law just wrecked your new car’ generates a state of mind with many coordinates. Quitegenerally, the situations of everyday life are those involving many coordinates. It is just forthis reason, we suggest, that the most familiar examples of mental activity are often themost difﬁcult to reproduce by a model. Perhaps we have here the reason why science andmathematics are the most successful of human activities: they deal with propositions whichproduce the simplest of all mental states. Such states would be the ones least perturbed bya given amount of imperfection in the human mind.
Of course, for many purposes we would not want our robot to adopt any of these more
‘human’ features arising from the other coordinates. It is just the fact that computers do not
get confused by emotional factors, do notget bored with a lengthy problem, do notpursue
hidden motives opposed to ours, that makes them safer agents than men for carrying outcertain tasks.
These remarks are interjected to point out that there is a large unexplored area of possible
generalizations and extensions of the theory to be developed here; perhaps this may inspireothers to try their hand at developing ‘multidimensional theories’ of mental activity, whichwould more and more resemble the behavior of actual human brains – not all of whichis undesirable. Such a theory, if successful, might have an importance beyond our presentability to imagine.
5
For the present, however, we shall have to be content with a much more modest undertak-
ing. Is it possible to develop a consistent ‘one-dimensional’ model of plausible reasoning?Evidently, our problem will be simplest if we can manage to represent a degree of plausibilityuniquely by a single real number, and ignore the other ‘coordinates’ just mentioned.
We stress that we are in no way asserting that degrees of plausibility in actual human
minds have a unique numerical measure. Our job is not to postulate – or indeed to conjectureabout – any such thing; it is to investigate whether it is possible, in our robot, to set up such
a correspondence without contradictions.
But to some it may appear that we have already assumed more than is necessary, thereby
putting gratuitous restrictions on the generality of our theory. Why must we represent degreesof plausibility by real numbers? Would not a ‘comparative’ theory based on a system ofqualitative ordering relations such as (A|C)>(B|C) sufﬁce? This point is discussed further
in Appendix A, where we describe other approaches to probability theory and note that someattempts have been made to develop comparative theories which it was thought would belogically simpler, or more general. But this turned out not to be the case; so, although it isquite possible to develop the foundations in other ways than ours, the ﬁnal results will notbe different.
5Indeed, some psychologists think that as few as ﬁve dimensions might sufﬁce to characterize a human personality; that is, that
we all differ only in having different mixes of ﬁve basic personality traits which may be genetically determined. But it seems to
us that this must be grossly oversimpliﬁed; identiﬁable chemical factors continuously varying in both space and time (such as
the distribution of glucose metabolism in the brain) affect mental activity but cannot be represented faithfully in a space of only
ﬁve dimensions. Yet it may be that ﬁve numbers can capture enough of the truth to be useful for many purposes.

<<<PAGE 53>>>

1 Plausible reasoning 21
1.8.1 Common language vs. formal logic
We should note the distinction between the statements of formal logic and those of ordinary
language. It might be thought that the latter is only a less precise form of expression; but onexamination of details the relation appears different. It appears to us that ordinary language,carefully used, need not be less precise than formal logic; but ordinary language is morecomplicated in its rules and has consequently richer possibilities of expression than weallow ourselves in formal logic.
In particular, common language, being in constant use for other purposes than logic, has
developed subtle nuances – means of implying something without actually stating it – thatare lost on formal logic. Mr A, to afﬁrm his objectivity, says, ‘I believe what I see.’ Mr Bretorts: ‘He doesn’t see what he doesn’t believe.’ From the standpoint of formal logic, itappears that they have said the same thing; yet from the standpoint of common language,those statements had the intent and effect of conveying opposite meanings.
Here is a less trivial example, taken from a mathematics textbook. Let L be a straight line
in a plane, and S an inﬁnite set of points in that plane, each of which is projected onto L.Now consider the following statements:
(I) The projection of the limit is the limit of the projections.
(II) The limit of the projections is the projection of the limit.
These have the grammatical structures ‘ AisB’ and ‘ BisA’, and so they might appear
logically equivalent. Yet in that textbook, (I) was held to be true, and (II) not true in general,on the grounds that the limit of the projections may exist when the limit of the set does not.
As we see from this, in common language – even in mathematics textbooks – we have
learned to read subtle nuances of meaning into the exact phrasing, probably without realizingit until an example like this is pointed out. We interpret ‘ AisB’ as asserting ﬁrst of all,
as a kind of major premise, that Aexists; and the rest of the statement is understood to
be conditional on that premise. Put differently, in common grammar the verb ‘is’ impliesa distinction between subject and object, which the symbol ‘ =’ does not have in formal
logic or in conventional mathematics. (However, in computer languages we encounter suchstatements as ‘J=J+1’, which everybody seems to understand, but in which the ‘ =’ sign
has now acquired that implied distinction after all.)
Another amusing example is the old adage ‘knowledge is power’, which is a very cogent
truth, both in human relations and in thermodynamics. An ad writer for a chemical trade
journal
6fouled this up into ‘power is knowledge’, an absurd – indeed, obscene – falsity.
These examples remind us that the verb ‘is’ has, like any other verb, a subject and a
predicate; but it is seldom noted that this verb has two entirely different meanings. A personwhose native language is English may require some effort to see the different meanings inthe statements: ‘The room is noisy’ and ‘There is noise in the room’. But in Turkish thesemeanings are rendered by different words, which makes the distinction so clear that a visitor
6LC-CG Magazine , March 1988, p. 211.

<<<PAGE 54>>>

22 Part 1 Principles and elementary applications
who uses the wrong word will not be understood. The latter statement is ontological, assert-
ing the physical existence of something, while the former is epistemological, expressingonly the speaker’s personal perception.
Common language – or, at least, the English language – has an almost universal tendency
to disguise epistemological statements by putting them into a grammatical form which sug-gests to the unwary an ontological statement. A major source of error in current probabilitytheory arises from an unthinking failure to perceive this. To interpret the ﬁrst kind of state-ment in the ontological sense is to assert that one’s own private thoughts and sensations arerealities existing externally in Nature. We call this the ‘mind projection fallacy’, and notethe trouble it causes many times in what follows. But this trouble is hardly conﬁned to prob-ability theory; as soon as it is pointed out, it becomes evident that much of the discourse ofphilosophers and Gestalt psychologists, and the attempts of physicists to explain quantumtheory, are reduced to nonsense by the author falling repeatedly into the mind projectionfallacy.
These examples illustrate the care that is needed when we try to translate the complex
statements of common language into the simpler statements of formal logic. Of course,
common language is often less precise than we should want in formal logic. But everybodyexpects this and is on the lookout for it, so it is less dangerous.
It is too much to expect that our robot will grasp all the subtle nuances of common
language, which a human spends perhaps 20 years acquiring. In this respect, our robot willremain like a small child – it interprets all statements literally and blurts out the truth withoutthought of whom this may offend.
It is unclear to the writer how difﬁcult – and even less clear how desirable – it would be
to design a newer model robot with the ability to recognize these ﬁner shades of meaning.Of course, the question of principle is disposed of at once by the existence of the humanbrain, which does this. But, in practice, von Neumann’s principle applies; a robot designedby us cannot do it until someone develops a theory of ‘nuance recognition’, which reducesthe process to a deﬁnitely prescribed set of operations. This we gladly leave to others.
In any event, our present model robot is quite literally real, because today it is almost
universally true that any nontrivial probability evaluation is performed by a computer. Theperson who programmed that computer was necessarily, whether or not they thought of itthat way, designing part of the brain of a robot according to some preconceived notion ofhow the robot should behave. But very few of the computer programs now in use satisfy allour desiderata; indeed, most are intuitive ad hoc procedures that were not chosen with any
well-deﬁned desiderata at all in mind.
Any such adhockery is presumably usable within some special area of application –
that was the criterion for choosing it – but as the proofs of Chapter 2 will show, anyadhockery which conﬂicts with the rules of probability theory must generate demonstrableinconsistencies when we try to apply it beyond some restricted area. Our aim is to avoidthis by developing the general principles of inference once and for all, directly from therequirement of consistency, and in a form applicable to any problem of plausible inferencethat is formulated in a sufﬁciently unambiguous way.

<<<PAGE 55>>>

1 Plausible reasoning 23
1.8.2 Nitpicking
As is apparent from the above, in the present work we use the term ‘Boolean algebra’ in its
long-established meaning as referring to two-valued logic in which symbols like ‘ A’ stand
for propositions. A compulsive nitpicker has complained to us that some mathematicianshave used the term in a slightly different meaning, in which ‘ A’ could refer to a class of
propositions. But the two usages are not in conﬂict; we recognize the broader meaning, butjust ﬁnd no reason to avail ourselves of it.
The set of rules and symbols that we have called ‘Boolean algebra’ is sometimes called
‘the propositional calculus’. The term seems to be used only for the purpose of adding thatwe need also another set of rules and symbols called ‘the predicate calculus ’. However , these
new symbols prove to be only abbreviations for short and familiar phrases. The ‘universal
quantiﬁer’ is only an abbreviation for ‘for all’; the ‘existential quantiﬁer’ is an abbreviationfor ‘there is a’. If we merely write our statements in plain English, we are using automaticallyall of the predicate calculus that we need for our purposes, and doing it more intelligibly.
The validity of the second strong syllogism (in two-valued logic) is sometimes questioned.
However, it appears that in current mathematics it is still considered valid reasoning to saythat a supposed theorem is disproved by exhibiting a counterexample, that a set of statementsis considered inconsistent if we can derive a contradiction from them, and that a propositioncan be established by reductio ad absurdum , deriving a contradiction from its denial. This
is enough for us; we are quite content to follo w this long tradition. Our feeling of security in
this stance comes from the conviction that, while logic may move forward in the future, it
can hardly move backward. A new logic might lead to new results about which Aristotelianlogic has nothing to say; indeed, that is just what we are trying to create here. But surely, ifa new logic was found to conﬂict with Aristotelian logic in an area where Aristotelian logicis applicable, we would consider that a fatal objection to the new logic.
Therefore, to those who feel conﬁned by two-valued deductive logic, we can say only:
‘By all means, investigate other possibilities if you wish to; and please let us know about itas soon as you have found a new result that was not contained in two-valued logic or ourextension of it, andis useful in scientiﬁc inference.’ Actually, there are many different and
mutually inconsistent multiple-valued logics already in the literature. But in Appendix Awe adduce arguments which suggest that they can have no useful content that is not alreadyin two-valued logic; that is, that an n-valued logic applied to one set of propositions is
either equivalent to a two-valued logic applied to an enlarged set, or else it contains internalinconsistencies.
Our experience is consistent with this conjecture; in practice, multiple-valued logics
seem to be used not to ﬁnd new useful results, but rather in attempts to remove supposeddifﬁculties with two-valued logic, particularly in quantum theory, fuzzy sets, and artiﬁcialintelligence. But on closer study, all such difﬁculties known to us have proved to be onlyexamples of the mind projection fallacy, calling for direct revision of the concepts ratherthan a new logic.

<<<PAGE 56>>>

2
The quantitative rules
Probability theory is nothing but common sense reduced to calculation.
Laplace, 1819
We have now formulated our problem, and it is a matter of straightforward mathematics to
work out the consequences of our desiderata, which may be stated broadly as follows:
(I) Representation of degrees of plausibility by real numbers;
(II) Qualitative correspondence with common sense;
(III) Consistency.
The present chapter is devoted entirely to deduction of the quantitative rules for inference
which follow from these desiderata. The resulting rules have a long, complicated, andastonishing history, full of lessons for scientiﬁc methodology in general (see the Commentssections at the end of several chapters).
2.1 The product rule
We ﬁrst seek a consistent rule relating the plausibility of the logical product ABto the
plausibilities of AandBseparately. In particular, let us ﬁnd AB|C. Since the reasoning is
somewhat subtle, we examine this from several different viewpoints.
As a ﬁrst orientation, note that the process of deciding that ABis true can be broken down
into elementary decisions about AandBseparately. The robot can
(1) decide that Bis true; ( B|C)
(2) having accepted Bas true, decide that Ais true. ( A|BC)
Or, equally well,
(1
/prime) decide that Ais true; ( A|C)
(2/prime) having accepted Aas true, decide that Bis true. ( B|AC)
In each case we indicate above the plausibility corresponding to that step.
Now let us describe the ﬁrst procedure in words. In order for ABto be a true proposition,
it is necessary that Bis true. Thus the plausibility B|Cshould be involved. In addition, if B
24

<<<PAGE 57>>>

2 The quantitative rules 25
is true, it is further necessary that Ashould be true; so the plausibility A|BCis also needed.
But if Bis false, then of course ABis false independently of whatever one knows about A,
as expressed by A|BC; if the robot reasons ﬁrst about B, then the plausibility of Awill be
relevant only if Bis true. Thus, if the robot has B|CandA|BCit will not need A|C. That
would tell it nothing about ABthat it did not have already.
Similarly, A|BandB|Aare not needed; whatever plausibility AorBmight have in the
absence of information Ccould not be relevant to judgments of a case in which the robot
knows that Cis true. For example, if the robot learns that the earth is round, then in judging
questions about cosmology today, it does not need to take into account the opinions it mighthave (i.e. the extra possibilities that it would need to take into account) if it did not knowthat the earth is round.
Of course, since the logical product is commutative, AB=BA, we could interchange A
andBin the above statements; i.e. knowledge of A|CandB|ACwould serve equally well
to determine AB|C=BA|C. That the robot must obtain the same value for AB|Cfrom
either procedure is one of our conditions of consistency, desideratum (IIIa).
We can state this in a more deﬁnite form. ( AB|C) will be some function of B|Cand
A|BC:
(AB|C)=F[(B|C),(A|BC)]. (2.1)
Now, if the reasoning we went through here is not completely obvious, let us examine some
alternatives. We might suppose, for example, that
(AB|C)=F[(A|C),(B|C)] (2.2)
might be a permissible form. But we can show easily that no relation of this form could
satisfy our qualitative conditions of desideratum (II). Proposition Amight be very plausible
given C, and Bmight be very plausible given C;b u t ABcould still be very plausible or
very implausible.
For example, it is quite plausible that the next person you meet has blue eyes and also
quite plausible that this person’s hair is black; and it is reasonably plausible that both aretrue. On the other hand it is quite plausible that the left eye is blue, and quite plausible thatthe right eye is brown; but extremely implausible that both of those are true. We would haveno way of taking such inﬂuences into account if we tried to use a formula of this kind. Ourrobot could not reason the way humans do, even qualitatively, with that kind of functionalrelation.
But other possibilities occur to us. The method of trying out all possibilities – a kind of
‘proof by exhaustion’ – can be organized as follows. Introduce the real numbers
u=(AB|C),v=(A|C),w=(B|AC),x=(B|C),y=(A|BC). (2.3)
Ifuis to be expressed as a function of two or more of v,w, x,y, there are 11 possibilities.
You can write out each of them, and subject each one to various extreme conditions, as inthe brown and blue eyes (which was the abstract statement: Aimplies that Bis false). Other
extreme conditions are A=B,A=C,C⇒
A, etc. Carrying out this somewhat tedious

<<<PAGE 58>>>

26 Part 1 Principles and elementary applications
analysis, Tribus (1969) ﬁnds that all but two of the possibilities can exhibit qualitative
violations of common sense in some extreme case. The two which survive are u=F(x,y)
andu=F(w,v), just the two functional forms already suggested by our previous reasoning.
We now apply the qualitative requirement discussed in Chapter 1. Given any change in
the prior information C→C/prime, such that Bbecomes more plausible but Adoes not change,
B|C/prime>B|C, (2.4)
A|BC/prime=A|BC, (2.5)
common sense demands that ABcould only become more plausible, not less:
AB|C/prime≥AB|C, (2.6)
with equality if and only if A|BCcorresponds to impossibility. Likewise, given prior in-
formation C/prime/primesuch that
B|C/prime/prime=B|C, (2.7)
A|BC/prime/prime>A|BC, (2.8)
we require that
AB|C/prime/prime≥AB|C, (2.9)
in which the equality can hold only if Bis impossible, given C(for then ABmight still
be impossible given C/prime/prime, although A|BCis not deﬁned). Furthermore, the function F(x,y)
must be continuous; for otherwise an arbitrarily small increase in one of the plausibilities
on the right-hand side of (2.1) could result in a large increase in AB|C.
In summary, F(x,y) must be a continuous monotonic increasing function of both xandy.
If we assume it is differentiable (this is not necessary; see the discussion following (2.13)),then we have
F
1(x,y)≡∂F
∂x≥0 (2.10a)
with equality if and only if yrepresents impossibility; and also
F2(x,y)≡∂F
∂y≥0 (2.10b)
with equality permitted only if xrepresents impossibility. Note for later purposes that, in
this notation, Fidenotes differentiation with respect to the ith argument of F, whatever it
may be.
Next we impose the desideratum (IIIa) of ‘structural’ consistency. Suppose we try to ﬁnd
the plausibility ( ABC|D) that three propositions would be true simultaneously. Because of
the fact that Boolean algebra is associative: ABC=(AB)C=A(BC), we can do this in
two different ways. If the rule is to be consistent, we must get the same result for either

<<<PAGE 59>>>

2 The quantitative rules 27
order of carrying out the operations. We can say ﬁrst that BCwill be considered a single
proposition, and then apply (2.1):
(ABC|D)=F[(BC|D),(A|BCD )], (2.11)
and then in the plausibility ( BC|D) we can again apply (2.1) to give
(ABC|D)=F{F[(C|D),(B|CD)],(A|BCD )}. (2.12a)
But we could equally well have said that ABshall be considered a single proposition at
ﬁrst. From this we can reason out in the other order to obtain a different expression:
(ABC|D)=F[(C|D),(AB|CD)]=F{(C|D),F[(B|CD),(A|BCD )]}. (2.12b)
If this rule is to represent a consistent way of reasoning, the two expressions (2.12a) and
(2.12b) must always be the same. A necessary condition that our robot will reason consis-tently in this case therefore takes the form of a functional equation,
F[F(x,y),z]=F[x,F(y,z)]. (2.13)
This equation has a long history in mathematics, starting from the work of N. H. Abel (1826).
Acz´el (1966), in his monumental work on functional equations, calls it, very appropriately,
‘The Associativity Equation’, and lists a total of 98 references to works that discuss it or
use it. Acz´ el derives the general solution (2.27), below, without assuming differentiability;
unfortunately, the proof ﬁlls 11 pages (pp. 256–267) of his book (see also Acz´ el, 1987). We
give here the shorter proof by R. T. Cox (1961), which assumes differentiability; see alsothe discussion in Appendix B.
It is evident that (2.13) has a trivial solution, F(x,y)=const. But that violates our
monotonicity requirement (2.10), and is in any event useless for our purposes. Unless (2.13)has a nontrivial solution, this approach will fail; so we seek the most general nontrivialsolution. Using the abbreviations
u≡F(x,y),v≡F(y,z), (2.14)
but still considering (x,y,z) the independent v ariables, the functional equation to be
solved is
F(x,v)=F(u,z). (2.15)
Differentiating with respect to xandywe obtain, in the notation of (2.10),
F
1(x,v)=F1(u,z)F1(x,y)
F2(x,v)F1(y,z)=F1(u,z)F2(x,y).(2.16)
Elimination of F1(u,z) from these equations yields
G(x,v)F1(y,z)=G(x,y) (2.17)

<<<PAGE 60>>>

28 Part 1 Principles and elementary applications
where we use the notation G(x,y)≡F2(x,y)/F1(x,y). Evidently, the left-hand side of
(2.17) must be independent of z. Now, (2.17) can be written equally well as
G(x,v)F2(y,z)=G(x,y)G(y,z), (2.18)
and denoting the left-hand sides of (2.17), (2.18) by U,Vrespectively, we verify that
∂V/∂y=∂U/∂z. Thus, G(x,y)G(y,z) must be independent of y. The most general func-
tionG(x,y) with this property is
G(x,y)=rH(x)
H(y)(2.19)
where ris a constant and the function H(x) is arbitrary. In the present case, G>0b y
monotonicity of F, and so we require that r>0, and H(x) may not change sign in the
region of interest. Using (2.19), (2.17) and (2.18) become
F1(y,z)=H(v)
H(y)(2.20)
F2(y,z)=rH(v)
H(z)(2.21)
and the relation d v=dF(y,z)=F1dy+F2dztakes the form
dv
H(v)=dy
H(y)+rdz
H(z)(2.22)
or, on integration,
w[F(y,z)]=w(v)=w(y)wr(z), (2.23)
where
w(x)≡exp/braceleftbigg/integraldisplayxdx
H(x)/bracerightbigg
. (2.24)
The absence of a lower limit on the integral signiﬁes an arbitrary multiplicative factor in
w. But taking the function w(·) of (2.15) and applying (2.23), we obtain w(x)wr(v)=
w(u)wr(z); applying (2.23) again, our functional equation now reduces to
w(x)wr(y)[w(z)]r2=w(x)wr(y)wr(z). (2.25)
Thus we obtain a nontrivial solution only if r=1, and our ﬁnal result can be expressed in
either of the two forms:
w[F(x,y)]=w(x)w(y) (2.26)
or
F(x,y)=w−1[w(x)w(y)]. (2.27)

<<<PAGE 61>>>

2 The quantitative rules 29
Associativity and commutativity of the logical product thus require that the relation sought
must take the functional form
w(AB|C)=w(A|BC)w(B|C)=w(B|AC)w(A|C), (2.28)
which we shall call henceforth the product rule . By its construction (2.24), w(x) must be a
positive continuous monotonic function, increasing or decreasing according to the sign of
H(x); at this stage it is otherwise arbitrary.
The result (2.28) has been derived as a necessary condition for consistency in the sense
of desideratum (IIIa). Conversely, it is evident that (2.28) is also sufﬁcient to ensure thisconsistency for any number of joint propositions. For example, there are an enormous
number of different ways in which ( ABCDEFG|H) could be expanded by successive
partitions in the manner of (2.12); but if (2.28) is satis ﬁed, they will all yield the same
result.
The requirements of qualitati ve correspondence with common sense impose further con-
ditions on the function w(x). For example, in the ﬁrst given form of (2.28) suppose that
Ais certain, given C. Then in the ‘logical environment’ produced by knowledge of C, the
propositions ABandBare the same, in the sense that one is true if and only if the other
is true. By our most primitive axiom of all, discussed in Chapter 1, propositions with thesame truth value must have equal plausibility:
AB|C=B|C, (2.29)
and also we will have
A|BC=A|C (2.30)
because if Ais already certain given C(i.e.Cimplies A), then, given any other information
Bwhich does not contradict C, it is still certain. In this case, (2.28) reduces to
w(B|C)=w(A|C)w(B|C), (2.31)
and this must hold no matter how plausible or implausible Bis to the robot. So our function
w(x) must have the property that
certainty is represented by w(A|C)=1. (2.32)
Now suppose that Ais impossible, given C. Then the proposition ABis also impossible
given C:
AB|C=A|C, (2.33)
and if Ais already impossible given C(i.e.Cimplies
A), then, given any further information
Bwhich does not contradict C,Awould still be impossible:
A|BC=A|C. (2.34)

<<<PAGE 62>>>

30 Part 1 Principles and elementary applications
In this case, (2.28) reduces to
w(A|C)=w(A|C)w(B|C), (2.35)
and again this equation must hold no matter what plausibility Bmight have. There are only
two possible values of w(A|C) that could satisfy this condition: it could be zero or +∞
(the choice−∞ is ruled out because then by continuity w(B|C) would have to be capable
of negative values; (2.35) would then be a contradiction).
In summary, qualitative correspondence with common sense requires that w(x)b ea
positive continuous monotonic function. It may be either increasing or decreasing. If itis increasing, it must range from zero for impossibility up to one for certainty. If it isdecreasing, it must range from ∞for impossibility down to one for certainty. Thus far, our
conditions say nothing at all about how it varies between these limits.
However, these two possibilities of representation are not different in content. Given any
function w
1(x) which is acceptable by the above criteria and represents impossibility by
∞, we can deﬁne a new function w2(x)≡1/w1(x), which will be equally acceptable and
represents impossibility by zero. Therefore, there will be no loss of generality if we nowadopt the choice 0≤w(x)≤1a sa convention ; that is, as far as content is concerned, all
possibilities consistent with our desiderata are included in this form. (As the reader maycheck, we could just as well have chosen the opposite convention; and the entire developmentof the theory from this point on, including all its applications, would go through equallywell, with equations of a less familiar form but exactly the same content.)
2.2 The sum rule
Since the propositions now being considered are of the Aristotelian logical type which must
be either true or false, the logical product A
Ais always false, the logical sum A+Aalways
true. The plausibility that Ais false must depend in some way on the plausibility that it is
true. If we deﬁne u≡w(A|B),v≡w(A|B), there must exist some functional relation
v=S(u). (2.36)
Evidently, qualitative correspondence with common sense requires that S(u) be a continuous
monotonic decreasing function in 0 ≤u≤1, with extreme values S(0)=1,S(1)=0. But
it cannot be just any function with these properties, for it must be consistent with the fact
that the product rule can be written for either ABorAB:
w(AB|C)=w(A|C)w(B|AC) (2.37)
w(AB|C)=w(A|C)w(B|AC). (2.38)
Thus, using (2.36) and (2.38), Eq. (2.37) becomes
w(AB|C)=w(A|C)S[w(B|AC)]=w(A|C)S/bracketleftbiggw(AB|C)
w(A|C)/bracketrightbigg
. (2.39)

<<<PAGE 63>>>

2 The quantitative rules 31
Again, we invoke commutativity: w(AB|C) is symmetric in A,B, and so consistency
requires that
w(A|C)S/bracketleftbiggw(AB|C)
w(A|C)/bracketrightbigg
=w(B|C)S/bracketleftbiggw(BA|C)
w(B|C)/bracketrightbigg
. (2.40)
This must hold for all propositions A,B,C; in particular, (2.40) must hold when
B=AD, (2.41)
where Dis any new proposition. But then we have the truth values noted before in (1.13):
AB=B, BA=A, (2.42)
and in (2.40) we may write
w(AB|C)=w(B|C)=S[w(B|C)]
w(BA|C)=w(A|C)=S[w(A|C)].(2.43)
Therefore, using the abbreviations
x≡w(A|C), y≡w(B|C), (2.44)
(2.25) becomes a functional equation
xS/bracketleftbiggS(y)
x/bracketrightbigg
=yS/bracketleftbiggS(x)
y/bracketrightbigg
,0≤S(y)≤x
0≤x≤1(2.45)
which expresses a scaling property that S(x) must have in order to be consistent with the
product rule. In the special case y=1, this reduces to
S[S(x)]=x, (2.46)
which states that S(x) is a self-reciprocal function; S(x)=S−1(x). Thus, from (2.36) it
follows also that u=S(v). But this expresses only the evident fact that the relationship
between AandAis a reciprocal one; it does not matter which proposition we denote by
the simple letter, which by the barred letter. We noted this before in (1.8); if it had not been
obvious before, we should be obliged to recognize it at this point.
The domain of validity given in (2.45) is found as follows. The proposition Dis arbitrary,
andso by various choices of Dwe can achieve all values of w(D|AC)i n
0≤w(D|AC)≤1. (2.47)
ButS(y)=w(AD|C)=w(A|C)w(D|AC), and so (2.47) is just (0 ≤S(y)≤x), as stated
in (2.45). This domain is symmetric in x,y; it can be written equally well with them
interchanged. Geometrically, it consists of all points in the xyplane lying in the unit square
(0≤x,y≤1) and on or above the curve y=S(x).
Indeed, the shape of that curve is determined already by what (2.45) says for points lying
inﬁnitesimally above it. For if we set y=S(x)+/epsilon1, then as /epsilon1→0+two terms in (2.45)
tend to S(1)=0, but at different rates. Therefore everything depends on the exact way

<<<PAGE 64>>>

32 Part 1 Principles and elementary applications
in which S(1−δ) tends to zero as δ→0. To investigate this, we deﬁne a new variable
q(x,y)b y
S(x)
y=1−exp{−q}. (2.48)
Then we may choose δ=exp{−q}, deﬁne the function J(q)b y
S(1−δ)=S(1−exp{−q}=exp{−J(q)}, (2.49)
and ﬁnd the asymptotic form of J(q)a sq→∞ .
Considering now x,qas the independent variables, we have from (2.48)
S(y)=S[S(x)]+exp{−q}S(x)S/prime[S(x)]+O(exp{−2q}). (2.50)
Using (2.46) and its derivative S/prime[S(x)]S/prime(x)=1, this reduces to
S(y)
x=1−exp{−(α+q)}+O(exp{−2q}), (2.51)
where
α(x)≡log/bracketleftbigg−xS/prime(x)
S(x)/bracketrightbigg
>0. (2.52)
With these substitutions, our functional equation (2.45) becomes
J(q+α)−J(q)=log/bracketleftbiggx
S(x)/bracketrightbigg
+log(1−exp{−q})+O(exp{−2q}),0<q<∞
0<x≤1
(2.53)
Asq→∞ the last two terms go to zero exponentially fast, so J(q) must be asymptotically
linear,
J(q)∼a+bq+O(exp{−q}), (2.54)
with positive slope
b=α−1log/bracketleftbiggx
S(x)/bracketrightbigg
. (2.55)
In (2.54) there is no periodic term with period α, because (2.53) must hold for a continuum
of different values of x, and therefore for a continuum of values of α(x). But, by deﬁnition,
Jis a function of qonly, so the right-hand side of (2.55) must be independent of x. This
gives, using (2.52),
x
S(x)=/bracketleftbigg−xS/prime(x)
S(x)/bracketrightbiggb
, 0<b<∞, (2.56)
or, rearranging, S(x) must satisfy the differential equation
Sm−1dS+xm−1dx=0, (2.57)

<<<PAGE 65>>>

2 The quantitative rules 33
where m≡1/bis some positive constant. The only solution of this satisfying S(0)=1i s
S(x)=(1−xm)1/m,0≤x≤1
0<m<∞(2.58)
and, conversely, we verify at once that (2.58) is a solution of (2.45).
The result (2.58) was ﬁrst derived by R. T. Cox (1946) by a different argument which
assumed S(x) twice differentiable. Again, Acz´ el (1966) derives the same result without
assuming differentiability. (But to assume differentiability in the present application seemsto us a very innocuous step, for if the functional equations had led us to nondifferentiablefunctions, we would have rejected this whole theory as a qualitative violation of commonsense.) In any event, (2.58) is the most general function satisfying the functional equation(2.45) and the left boundary condition S(0)=1; whereupon we are encouraged to ﬁnd that
it automatically satisﬁes the right boundary condition S(1)=0.
Since our derivation of the functional equation (2.45) used the special choice (2.41) for B,
we have shown thus far only that (2.58) is a necessary condition to satisfy the general con-sistency requirement (2.40). To check its sufﬁciency, substitute (2.58) into (2.40). We obtain
w
m(A|C)−wm(AB|C)=wm(B|C)−wm(BA|C), (2.59)
a trivial identity by virtue of (2.28) and (2.38). Therefore, (2.58) is the necessary and
sufﬁcient condition on S(x) for consistency in the sense (2.40).
Our results up to this point can be summarized as follows. Associativity of the logical
product requires that some monotonic function w(x) of the plausibility x=A|Bmust obey
the product rule (2.28). Our result (2.58) states that this same function must also obey asum rule:
w
m(A|B)+wm(A|B)=1 (2.60)
for some positive m. Of course, the product rule itself can be written equally well as
wm(AB|C)=wm(A|C)wm(B|AC)=wm(B|C)wm(A|BC), (2.61)
but then we see that the value of mis actually irrelevant; for whatever value is chosen, we
can deﬁne a new function
p(x)≡wm(x), (2.62)
and our rules take the form
p(AB|C)=p(A|C)p(B|AC)=p(B|C)p(A|BC), (2.63)
p(A|B)+p(A|B)=1. (2.64)
In fact, this entails no loss of generality, for the only requirement we have imposed on
the function w(x) is that it is a continuous monotonic increasing function ranging from
w=0 for impossibility to w=1 for certainty. But if w(x) satisﬁes this, then so also does
wm(x), 0<m<∞. Therefore, to say that we could use different values of mdoes not give

<<<PAGE 66>>>

34 Part 1 Principles and elementary applications
us any freedom that we did not have already in the arbitrariness of w(x). All possibilities
allowed by our desiderata are contained in (2.63) and (2.64), in which p(x) is any continuous
monotonic increasing function with the range 0 ≤p(x)≤1.
Are further relations needed to yield a complete set of rules for plausible inference,
adequate to determine the plausibility of any logic function f(A1,..., An) from those
of{A1,..., An}? We have, in the product rule (2.63) and sum rule (2.64), formulas for
the plausibility of the conjunction ABand the negation A. However, we have noted, in the
discussion following (1.23), that conjunction and negation are an adequate set of operations,from which all logic functions can be constructed.
Therefore, one would conjecture that our search for basic rules should be ﬁnished; it
ought to be possible, by repeated applications of the product rule and sum rule, to arrive atthe plausibility of any proposition in the Boolean algebra generated by {A
1,..., An}.
To verify this, we seek ﬁrst a formula for the logical sum A+B. Applying the product
rule and sum rule repeatedly, we have
p(A+B|C)=1−p(AB|C)=1−p(A|C)p(B|AC)
=1−p(A|C)[1−p(B|AC)]=p(A|C)+p(AB|C) (2.65)
=p(A|C)+p(B|C)p(A|BC)=p(A|C)+p(B|C)[1−p(A|BC)]
and ﬁnally
p(A+B|C)=p(A|C)+p(B|C)−p(AB|C). (2.66)
This generalized sum rule is one of the most useful in applications. Evidently, the primitive
sum rule (2.64) is a special case of (2.66), with the choice B=A.
Exercise 2.1. Is it possible to ﬁnd a general formula for p(C|A+B), analogous to
(2.66), from the product and sum rules? If so, derive it; if not, explain why this cannotbe done.
Exercise 2.2. Now suppose we have a set of propositions {A1,..., An}which on in-
formation Xare mutually exclusive: p(AiAj|X)=p(Ai|X)δij. Show that p(C|(A1+
A2+···+ AnX) is a weighted average of the separate plausibilities p(C|AiX):
p(C|(A1+···+ AnX)=p(C|A1X+A2X+···+ AnX)=/summationtext
ip(Ai|X)p(C|AiX)/summationtext
ip(Ai|X).
(2.67)
To extend the result (2.66), we noted following (1.17) that any logic function other than the
trivial contradiction can be expressed in disjunctive normal form, as a logical sum of thebasic conjunctions such as (1.17). Now the plausibility of any one of the basic conjunctions

<<<PAGE 67>>>

2 The quantitative rules 35
{Qi,1≤i≤2n}is determined by repeated applications of the product rule; and then
repeated application of (2.66) will yield the plausibility of any logical sum of the Qi.I n
fact, these conjunctions are mutually exclusive, so we shall ﬁnd (see (2.85) below) that thisreduces to a simple sum/summationtext
ip(Qi|C) of at most (2n−1) terms.
So, just as conjunction and negation are an adequate set of operations for deductive
logic, the above product and sum rules are an adequate set for plausible inference, inthe following sense. Whenever the background information is enough to determine theplausibilities of the basic conjunctions, our rules are adequate to determine the plausibilityof every proposition in the Boolean algebra generated by {A
1,..., An}. Thus, in the case
n=4 we need the plausibilities of 24=16 basic conjunctions, whereupon our rules will
determine the plausibility of each of the 216=65 536 propositions in the Boolean algebra.
But this is almost always more than we need in a real application; if the background
information is enough to determine the plausibility of a few of the basic conjunctions, this
may be adequate for the small part of the Boolean algebra that is of concern to us.
2.3 Qualitative properties
Now let us check to see how the theory based on (2.63) and (2.64) is related to the theory of
deductive logic and the various qualitative syllogisms from which we started in Chapter 1.
In the ﬁrst place it is obvious that in the limit as p(A|B)→0o r p(A|B)→1, the sum rule
(2.64) expresses the primitive postulate of Aristotelian logic: if Ais true, then Amust be
false, etc.
Indeed, all of that logic consists of the two strong syllogisms (1.1), (1.2) and all that
follows from them; using now the implication sign (1.14) to state the major premise:
A⇒B
Ais true
Bis trueA⇒B
Bis false
Ais false(2.68)
and the endless stream of their consequences. If we let Cstand for their major premise:
C≡A⇒B (2.69)
then these syllogisms correspond to our product rule (2.63) in the forms
p(B|AC)=p(AB|C)
p(A|C), p(A|BC)=p(AB|C)
p(B|C), (2.70)
respectively. But from (2.68) we have p(AB|C)=p(A|C) and p(AB|C)=0, and so (2.70)
reduces to
p(B|AC)=1, p(A|BC)=0, (2.71)
as stated in the syllogisms (2.68). Thus the relation is simply: Aristotelian deductive logic
is the limiting form of our rules for plausible reasoning, as the robot becomes more andmore certain of its conclusions .

<<<PAGE 68>>>

36 Part 1 Principles and elementary applications
But our rules have also what is not contained in deductive logic: a quantitative form of the
weak syllogisms (1.3) and (1.4). To show that those original qualitative statements alwaysfollow from the present rules, note that the ﬁrst weak syllogism
A⇒B
Bis true (2.72)
therefore, Abecomes more plausible
corresponds to the product rule (2.63) in the form
p(A|BC)=p(A|C)p(B|AC)
p(B|C). (2.73)
But from (2.68), p(B|AC)=1, and since p(B|C)≤1, (2.73) gives
p(A|BC)≥p(A|C), (2.74)
as stated in the syllogism. Likewise, the syllogism (1.4)
A⇒B
Ais false (2.75)
therefore, Bbecomes less plausible
corresponds to the product rule in the form
p(B|AC)=p(B|C)p(A|BC)
p(A|C). (2.76)
But from (2.74) it follows that p(A|BC)≤p(A|C); and so (2.76) gives
p(B|AC)≤p(B|C), (2.77)
as stated in the syllogism.
Finally, the policeman’s syllogism (1.5), which seemed very weak when stated abstractly,
is also contained in our product rule, stated in the form (2.73). Letting Cnow stand for the
background information (not noted explicitly in (1.5) because the need for it was not yet ap-
parent), the major premise, ‘If Ais true, then Bbecomes more plausible’, now takes the form
p(B|AC)>p(B|C), (2.78)
and (2.73) gives at once
p(A|BC)>p(A|C), (2.79)
as stated in the syllogism.
Now we have more than the mere qualitative statement (2.79). In Chapter 1 we wondered,
without answering: What determines whether the evidence Belevates Aalmost to certainty,
or has a negligible effect on its plausibility? The answer from (2.73) is that, since p(B|AC)

<<<PAGE 69>>>

2 The quantitative rules 37
cannot be greater than unity, a large increase in the plausibility of Acan occur only when
p(B|C) is very small. Observing the gentleman’s behavior ( B) makes his guilt ( A) seem
virtually certain, because that behavior is otherwise so very unlikely on the backgroundinformation; no policeman has ever seen an innocent person behaving that way. On theother hand, if knowing that Ais true can make only a negligible increase in the plausibility
ofB, then observing Bcan in turn make only a negligible increase in the plausibility of A.
We could give many more comparisons of this type; indeed, the complete qualitative
correspondence of these rules with common sense has been noted and demonstrated bymany writers, including Keynes (1921), Jeffreys (1939), P´ olya (1945, 1954), R. T. Cox
(1961), Tribus (1969), de Finetti (1974a,b), and Rosenkrantz (1977). The treatment ofP´olya was described brieﬂy in our Preface and Chapter 1, and we have just recounted that
of Cox more fully. However, our aim now is to push ahead to quantitative applications; sowe return to the basic development of the theory.
2.4 Numerical v alues
We have found so far the most general consistent rules by which our robot can manipulate
plausibilities, granted that it must associate them with real numbers, so that its brain canoperate by the carrying out of some deﬁnite physical process. While we are encouraged bythe familiar formal appearance of these rules and their qualitative properties just noted, twoevident circumstances show that our job of designing the robot’s brain is not yet ﬁnished.
In the ﬁrst place, while the rules (2.63), (2.64) place some limitations on how plau-
sibilities of different propositions must be related to each other, it would appear that
we have not yet found any unique rules, but rather an inﬁnite number of possible rules
by which our robot can do plausible reasoning. Corresponding to every different choiceof a monotonic function p(x), there seems to be a different set of rules, with different
content.
Secondly, nothing given so far tells us what actual numerical values of plausibility should
be assigned at the beginning of a problem, so that the robot can get started on its calculations.How is the robot to make its initial encoding of the background information into de ﬁnite
numerical values of plausibilities? For this we must invoke the ‘interface’ desiderata (IIIb),(IIIc) of (1.39), not yet used.
The following analysis answers both of these questions, in a way both interesting and
unexpected. Let us ask for the plausibility ( A
1+A2+A3|B) that at least one of three
propositions{A1,A2,A3}is true. We can ﬁnd this by two applications of the extended sum
rule (2.66), as follows. The ﬁrst application gives
p(A1+A2+A3|B)=p(A1+A2|B)+p(A3|B)−p(A1A3+A2A3|B) (2.80)
where we ﬁrst considered ( A1+A2) as a single proposition, and used the logical relation
(A1+A2)A3=A1A3+A2A3. (2.81)

<<<PAGE 70>>>

38 Part 1 Principles and elementary applications
Applying (2.66) again, we obtain seven terms which can be grouped as follows:
p(A1+A2+A3|B)=p(A1|B)+p(A2|B)+p(A3|B)
−p(A1A2|B)−p(A2A3|B)−p(A3A1|B)
+p(A1A2A3|B).(2.82)
Now suppose these propositions are mutually exclusive; i.e. the evidence Bimplies that no
two of them can be true simultaneously:
p(AiAj|B)=p(Ai|B)δij. (2.83)
Then the last four terms of (2.82) vanish, and we have
p(A1+A2+A3|B)=p(A1|B)+P(A2|B)+P(A3|B). (2.84)
Adding more propositions A4,A5, etc., it is easy to show by induction that if we have n
mutually exclusive propositions {A1,..., An}, (2.84) generalizes to
p(A1+···+ Am|B)=m/summationdisplay
i=1p(Ai|B), 1≤m≤n, (2.85)
a rule which we will be using constantly from now on.
In conventional expositions, Eq. (2.85) is usually introduced ﬁrst as the basic but, as far
as one can see, arbitrary axiom of the theory. The present approach shows that this ruleis deducible from simple qualitative conditions of consistency. The viewpoint which sees(2.85) as the primitive, fundamental relation is one which we are particularly anxious toavoid (see Comments section at the end of this chapter).
Now suppose that the propositions {A
1,..., An}are not only mutually exclusive but also
exhaustive; i.e. the background information Bstipulates that one and only one of them must
be true. In that case, the sum (2.85) for m=nmust be unity:
n/summationdisplay
i=1p(Ai|B)=1. (2.86)
This alone is not enough to determine the individual numerical values p(Ai|B). Depending
on further details of the information B, many different choices might be appropriate, and in
general ﬁnding the p(Ai|B) by logical analysis of Bcan be a difﬁcult problem. It is, in fact,
an open-ended problem, since there is no end to the variety of complicated information thatmight be contained in B; and therefore no end to the complicated mathematical problems
of translating that information into numerical values of p(A
i|B). As we shall see, this is
one of the most important current research problems; every new principle we can discoverfor translating information Binto numerical values of p(A
i|B) will open up a new class of
useful applications of this theory.
There is, however, one case in which the answer is particularly simple, requiring only
direct application of principles already given. But we are entering now into a very delicatearea, a cause of confusion and controversy for over a century. In the early stages of thistheory, as in elementary geometry, our intuition runs so far ahead of logical analysis that

<<<PAGE 71>>>

2 The quantitative rules 39
the point of the logical analysis is often missed. The trouble is that intuition leads us to
the same ﬁnal conclusions far more quickly, but without any correct appreciation of theirrange of validity. The result has been that the development of this theory has been retardedfor some 150 years because various workers have insisted on debating these issues on thebasis, not of demonstrative arguments, but of their conﬂicting intuitions.
At this point, therefore, we must ask the reader to suppress all intuitive feelings you may
have, and allow yourself to be guided solely by the following logical analysis. The point weare about to make cannot be developed too carefully; and, unless it is clearly understood,we will be faced with tremendous conceptual difﬁculties from here on.
Consider two different problems. Problem I is the one just formulated: we have a given
set of mutually exclusive and exhaustive propositions {A
1,..., An}and we seek to evaluate
p(Ai|B)I. Problem II differs in that the labels A1,A2of the ﬁrst two propositions have been
interchanged. These labels are, of course, entirely arbitrary; it makes no difference whichproposition we choose to call A
1and which A2. In Problem II, therefore, we also have a set
of mutually exclusive and exhaustive propositions {A/prime
1,..., A/prime
n}, given by
A/prime
1≡A2,
A/prime
2≡A1,
A/prime
k≡Ak,3≤k≤n,(2.87)
and we seek to evaluate the quantities p(A/prime
i|B)II,i=1,2,..., n.
In interchanging the labels, we have generated a different but closely related problem. It
is clear that, whatever state of knowledge the robot had about A1in Problem I, it must have
the same state of knowledge about A/prime
2in Problem II, for they are the same proposition, the
given information Bis the same in both problems, and it is contemplating the same totality
of propositions{A1,..., An}in both problems. Therefore we must have
p(A1|B)I=p(A/prime
2|B)II, (2.88)
and similarly
p(A2|B)I=p(A/prime
1|B)II. (2.89)
We will call these the transformation equations . They describe only how the two problems
are related to each other, and therefore they must hold whatever the information Bmight
be; in particular, however plausible or implausible the propositions A1,A2might seem to
the robot in Problem I.
Now suppose that information Bis indifferent between propositions A1and A2; i.e.
if it says something about one, it says the same thing about the other, and so it containsnothing that would give the robot any reason to prefer either one over the other. In thiscase, Problems I and II are not merely related, but entirely equivalent; i.e. the robot is inexactly the same state of knowledge about the set of propositions {A
/prime
1,..., A/prime
n}in Problem
II,including their labeling , as it is about the set {A1,..., An}in Problem I.
Now we invoke our desideratum of consistency in the sense (IIIc) in (1.39). This stated that
equivalent states of knowledge must be represented by equivalent plausibility assignments.

<<<PAGE 72>>>

40 Part 1 Principles and elementary applications
In equations, this statement is
p(Ai|B)I=p(A/prime
i|B)II, i=1,2,..., n, (2.90)
which we shall call the symmetry equations . But now, combining (2.88), (2.89), and (2.90),
we obtain
p(A1|B)I=p(A2|B)I. (2.91)
In other words, propositions A1andA2must be assigned equal plausibilities in Problem I
(and, of course, also in Problem II).
At this point, depending on your personality and background in this subject, you will
be either greatly impressed or greatly disappointed by the result (2.91). The argument wehave just given is the ﬁrst ‘baby’ version of the group invariance principle for assigningplausibilities; it will be extended greatly in Chapter 6, when we consider the general problemof assigning ‘noninformative priors’.
More generally, let{A
/prime/prime
1,..., A/prime/prime
n}be any permutation of {A1,..., An}and let Problem III
be that of determining the p(A/prime/prime
i|B). If the permutation is such that A/prime/prime
k≡Ai, there will be
ntransformation equations of the form
p(Ai|B)I=p(A/prime/prime
k|B)III (2.92)
which show how Problems I and III are related to each other; these relations will hold
whatever the given information B.
But if information Bis now indifferent between all the propositions Ai, then the robot
is in exactly the same state of knowledge about the set of propositions {A/prime/prime
1,..., A/prime/prime
n}in
Problem III as it was about the set {A1,..., An}in Problem I; and again our desidera-
tum of consistency demands that it assign equivalent plausibilities in equivalent states ofknowledge, leading to the nsymmetry conditions
p(A
k|B)I=p(A/prime/prime
k|B)III, k=1,2,..., n. (2.93)
From (2.92) and (2.93) we obtain nequations of the form
p(Ai|B)I=p(Ak|B)I. (2.94)
Now, these relations must hold whatever the particular permutation we used to deﬁne Prob-
lem III. There are n! such permutations, and so there are actually n! equivalent problems
among which, for given i, the index kwill range over all of the ( n−1) others in (2.94).
Therefore, the only possibility is that all of the p(Ai|B)Ibe equal (indeed, this is re-
quired already by consideration of a single permutation if it is cyclic of order n). Since the
{A1,..., An}are exhaustive, (2.86) will hold, and the only possibility is therefore
p(Ai|B)I=1
n, (1≤i≤n), (2.95)
and we have ﬁnally arrived at a set of deﬁnite numerical values! Following Keynes (1921),
we shall call this result the principle of indifference .

<<<PAGE 73>>>

2 The quantitative rules 41
Perhaps, in spite of our admonitions, the reader’s intuition had already led to just this
conclusion, without any need for the rather tortuous reasoning we have just been through.If so, then at least that intuition is consistent with our desiderata. But merely writing down(2.95) intuitively gives one no appreciation of the importance and uniqueness of this result.To see the uniqueness, note that if the robot were to assign any values different from (2.95),then by a mere permutation of labels we could exhibit a second problem in which the robot’sstate of knowledge is the same, but in which it is assigning different plausibilities.
To see the importance, note that (2.95) actually answers both of the questions posed
at the beginning of this section. It shows – in one particular case which can be greatlygeneralized – how the information given the robot can lead to deﬁnite numerical values,so that a calculation can start. But it also shows something even more important because itis not at all obvious intuitively; the information given the robot determines the numericalvalues of the quantities p(x)=p(A
i|B), and not the numerical values of the plausibilities
x=Ai|Bfrom which we started. This, also, will be found to be true in general.
Recognizing this gives us a beautiful answer to the ﬁrst question posed at the beginning
of this section; after having found the product and sum rules, it still appeared that we had notfound any unique rules of reasoning, because every different choice of a monotonic function
p(x) would lead to a different set of rules (i.e. a set with different content). But now we see
that no matter what function p(x) we choose, we shall be led to the same result (2.95), and
the same numerical value of p. Furthermore, the robot’s reasoning processes can be carried
out entirely by manipulation of the quantities p, as the product and sum rules show; and the
robot’s ﬁnal conclusions can be stated equally well in terms of the p’s instead of the x’s.
So, we now see that different choices of the function p(x) correspond only to different
ways we could design the robot’s internal memory circuits. For each proposition A
iabout
which it is to reason, it will need a memory address in which it stores some numberrepresenting the degree of plausibility of A
i, on the basis of all the data it has been given.
Of course, instead of storing the number piit could equally well store any strict monotonic
function of pi. But no matter what function it used internally, the externally observable
behavior of the robot would be just the same.
As soon as we recognize this, it is clear that, instead of saying that p(x) is an arbitrary
monotonic function of x, it is much more to the point to turn this around and say that:
The plausibility x≡A|B is an arbitrary monotonic function of p ,
deﬁned in (0≤p≤1).
It is pthat is rigidly ﬁxed by the data, not x.
The question of uniqueness is therefore disposed of automatically by the result (2.95);
in spite of ﬁrst appearances, there is actually only one consistent set of rules by which ourrobot can do plausible reasoning, and, for all practical purposes, the plausibilities x≡A|B
from which we started have faded entirely out of the picture! We will just have no furtheruse for them.
Having seen that our theory of plausible reasoning can be carried out entirely in terms
of the quantities p, we ﬁnally introduce their technical names; from now on, we will call
these quantities probabilities . The word ‘probability’ has been studiously avoided up to this

<<<PAGE 74>>>

42 Part 1 Principles and elementary applications
point, because, whereas the word does have a colloquial meaning to the proverbial ‘man
on the street’, it is for us a technical term, which ought to have a precise meaning. Butuntil it had been demonstrated that these quantities are uniquely determined by the data ofa problem, we had no grounds for supposing that the quantities pwere possessed of any
precise meaning.
We now see that the quantities pdeﬁne a particular scale on which degrees of plausibility
can be measured. Out of all possible monotonic functions which could, in principle, servethis purpose equally well, we choose this particular one, not because it is more ‘correct’,but because it is more convenient; i.e. it is the quantities pthat obey the simplest rules of
combination, the product and sum rules. Because of this, numerical values of pare directly
determined by our information.
This situation is analogous to that in thermodynamics, where out of all possible empirical
temperature scales t, which are monotonic functions of each other, we ﬁnally decide to use
the Kelvin scale T; not because it is more ‘correct’ than others but because it is more
convenient; i.e. the laws of thermodynamics take their simplest form [d U=TdS−PdV,
dG=− SdT+VdP, etc.] in terms of this particular scale. Because of this, numerical
values of temperatures on the kelvin scale are ‘rigidly ﬁxed’ in the sense of being directlymeasurable in experiments, independently of the properties of any particular substance likewater or mercury.
Another rule, equally appealing to our intuition, follows at once from (2.95). Consider
the traditional ‘Bernoulli urn’ of probability theory; ours is known to contain ten balls ofidentical size and weight, labeled {1,2,..., 10}. Three balls (numbers 4, 6, 7) are black,
the other seven are white. We are to shake the urn and draw one ball blindfolded. Thebackground information Bin (2.95) consists of the statements in the last two sentences.
What is the probability that we draw a black one?
Deﬁne the propositions: A
i≡‘theith ball is drawn’, (1 ≤i≤10). Since the background
information is indifferent to these ten possibilities, (2.95) applies, and the robot assigns
p(Ai|B)=1
10,1≤i≤10. (2.96)
The statement that we draw a black ball is that we draw number 4, 6, or 7;
p(black|B)=p(A4+A6+A7|B). (2.97)
But these are mutually exclusive propositions (i.e. they assert mutually exclusive events),
so (2.85) applies, and the robot’s conclusion is
p(black|B)=3
10, (2.98)
as intuition had told us already. More generally, if there are Nsuch balls, and the proposition
Ais deﬁned to be true on any speciﬁed subset of Mof them, (0≤M≤N), false on the
rest, we have
p(A|B)=M
N. (2.99)

<<<PAGE 75>>>

2 The quantitative rules 43
This was the original mathematical deﬁnition of probability, as given by James Bernoulli
(1713) and used by most writers for the next 150 years. For example, Laplace’s great Th´eorie
Analytique des Probabilit ´es(1812) opens with this sentence:
The Probability for an event is the ratio of the number of cases favorable to it, to the number of all
cases possible when nothing leads us to expect that any one of these cases should occur more than
any other, which renders them, for us, equally possible.
Exercise 2.3. As soon as we have the numerical values a=P(A|C) and b=P(B|C),
the product and sum rules place some limits on the possible numerical values for their
conjunction and disjunction. Supposing that a≤b, show that the probability for the
conjunction cannot exceed that of the least probable proposition: 0 ≤P(AB|C)≤a,
and the probability for the disjunction cannot be less than that of the most prob-able proposition: b≤P(A+B|C)≤1. Then show that, if a+b>1, there is a
stronger inequality for the conjunction; and if a+b<1 there is a stronger one for
the disjunction. These necessary general inequalities are helpful in detecting errors incalculations.
2.5 Notation and ﬁnite-sets policy
Now we can introduce the notation to be used in the remainder of this work (discussed more
fully in Appendix B). Henceforth, our formal probability Symbols, will use the capital P:
P(A|B), (2.100)
which signiﬁes that the arguments are propositions . Probabilities whose arguments are
numerical values are generally denoted by other functional symbols, such as
f(r|np), (2.101)
which denote ordinary mathematical functions. The reason for making this distinction is to
avoid ambiguity in the meaning of our symbols, which has been a recent problem in this
ﬁeld. However, in agreement with the customary loose notation in the existing literature,we sometimes relax our standards enough to allow the probability symbols with small
p:p(x|y)o r p(A|B)o r p(x|B) to have arguments which can be either propositions or
numerical values, in any mix. Thus the meaning of expressions with small pcan be judged
only from the surrounding context.
It is very important to note that our consistency theorems have been established only
for probabilities assigned on ﬁnite sets of propositions. In principle, every problem must
start with such ﬁnite-set probabilities; extension to inﬁnite sets is permitted only when thisis the result of a well-deﬁned and well-behaved limiting process from a ﬁnite set. More

<<<PAGE 76>>>

44 Part 1 Principles and elementary applications
generally, in any mathematical operations involving inﬁnite sets, the safe procedure is the
ﬁnite-sets policy:
Apply the ordinary processes of arithmetic and analysis only to expressions with a ﬁnite
number of terms. Then, after the calculation is done, observe how the resulting ﬁniteexpressions behave as the number of terms increases indeﬁnitely.
In laying down this rule of conduct, we are only following the policy that mathematicians
from Archimedes to Gauss have considered clearly necessary for nonsense avoidance inall of mathematics. But, more recently, the popularity of inﬁnite-set theory and measuretheory have led some to disregard it and seek shortcuts which purport to use measure theorydirectly. Note, however, that this rule of conduct is consistent with the original Lebesguedeﬁnition of measure, and when a well-behaved limit exists it leads us automatically to
correct ‘measure theoretic’ results. Indeed, this is how Lebesgue found his ﬁrst results.
The danger is that the present measure theory notation presupposes the inﬁnite limit
already accomplished, but contains no symbol indicating which limiting process was used.Yet, as noted in our Preface, different limiting Processes – equally well-behaved – lead ingeneral to different results. When there is no well-behaved limit, any attempt to go directlyto the limit can result in nonsense, the cause of which cannot be seen as long as one looks
only at the limit, and not at the limiting process .
This little ‘sermon’ is an introduction to Chapter 15 on inﬁnite-set paradoxes, where we
shall see some of the results that have been produced by those who ignored this rule ofconduct, and tried to calculate probabilities directly on an inﬁnite set without consideringany limit from a ﬁnite set. The results are at best ambiguous, at worst nonsensical.
2.6 Comments
It has taken us two chapters of close reasoning to get back to the point (2.99) from which
Laplace started some 180 years ago. We shall try to understand the intervening period, as aweird episode of history, throughout the rest of the present work. The story is so complicatedthat we can unfold it only gradually, over the next ten chapters. To make a start on this,let us consider some of the questions often raised about the use of probability theory as anextension of logic.
2.6.1 ‘Subjective’ vs. ‘objective’
These words are abused so much in probability theory that we try to clarify our use of them.
In the theory we are developing, any probability assignment is necessarily ‘subjective’in the sense that it describes only a state of knowledge, and not anything that could bemeasured in a physical experiment. Inevitably, someone will demand to know: ‘ Whose
state of knowledge?’ The answer is always: ‘That of the robot – or of anyone else who isgiven the same information and reasons according to the desiderata used in our derivationsin this chapter.’
Anyone who has the same information, but comes to a different conclusion than our robot,
is necessarily violating one of those desiderata. While nobody has the authority to forbid

<<<PAGE 77>>>

2 The quantitative rules 45
such violations, it appears to us that a rational person, should he discover that he was violating
one of them, would wish to revise his thinking (in any event, he would surely have difﬁcultyin persuading anyone else, who was aware of that violation, to accept his conclusions).
Now, it was just the function of our interface desiderata (IIIb), (IIIc) to make these prob-
ability assignments completely ‘objective’ in the sense that they are independent of thepersonality of the user. They are a means of describing (or, what is the same thing, ofencoding) the information given in the statement of a problem, independently of whatever
personal feelings (hopes, fears, value judgments, etc.) you or I might have about the propo-sitions involved. It is ‘objectivity’ in this sense that is needed for a scientiﬁcally respectabletheory of inference.
2.6.2 G¨ odel’s theorem
To answer another inevitable question, we recapitulate just what has and what has not been
proved in this chapter. The main constructive requirement which determined our product
and sum rules was the desideratum (IIIa) of ‘structural consistency’. Of course, this does
not mean that our rules have been proved consistent; it means only that any other ruleswhich represent degrees of plausibility by real numbers, but which differ in content from
ours, will lead necessarily either to inconsistencies or violations of our other desiderata.
A famous theorem of Kurt G¨ odel (1931) states that no mathematical system can provide
a proof of its own consistency. Does this prevent us from ever proving the consistency ofprobability theory as logic? We are not prepared to answer this fully, but perhaps we canclarify the situation a little.
Firstly, let us be sure that ‘inconsistency’ means the same thing to us and to a logician.
What we had in mind was that if our rules were inconsistent, then it would be possibleto derive contradictory results from valid application of them; for example, by applyingthe rules in two equally valid ways, one might be able to derive both P(A|BC)=1/3 and
P(A|BC)=2/3. Cox’s functional equations sought to guard against this. Now, when a
logician says that a system of axioms {A
1,A2,..., An}is inconsistent, he means that a
contradiction can be deduced from them; i.e. some proposition Qand its denial Qare both
deducible. Indeed, this is not really different from our meaning.
To understand the above G¨ odel result, the essential point is the principle of ele-
mentary logic that a contradiction AA implies all propositions, true and false. (Given
any two propositions Aand B,w eh a v e A⇒(A+B), therefore AA⇒A(A+B)=
AA+AB⇒B.) Then let A={A1,A2,..., An}be the system of axioms underlying a
mathematical theory and Tany proposition, or theorem, deducible from them:1
A⇒T. (2.102)
1In Chapter 1 we noted the tricky distinction between the weak property of formal implication and the strong one of logical
deducibility; by ‘implications of a proposition C’ we really mean ‘propositions logically deducible from C and the totality of
other background information ’. Conventional expositions of Aristotelian logic are, in our view, ﬂawed by their failure to make
explicit mention of background information, which is usually essential to our reasoning, whether inductive or deductive. But, inthe present argument, we can understand Aas including all the propositions that constitute that background information; then
‘implication’ and ‘logical deducibility’ are the same thing.

<<<PAGE 78>>>

46 Part 1 Principles and elementary applications
Now, whatever Tmay assert, the fact that Tcan be deduced from the axioms cannot prove
that there is no contradiction in them, since, if there were a contradiction, Tcould certainly
be deduced from them!
This is the essence of the G¨ odel theorem, as it pertains to our problems. As noted by Fisher
(1956), it shows us the intuitive reason why G¨ odel’s result is true. We do not suppose that
any logician would accept Fisher’s simple argument as a proof of the full G¨ odel theorem;
yet for most of us it is more convincing than G¨ odel’s long and complicated proof.2
Now suppose that the axioms contain an inconsistency. Then the opposite of Tand
therefore the contradiction TTcan also be deduced from them:
A⇒T. (2.103)
So, if there is an inconsistency, its existence can be proved by exhibiting any proposition
Tand its opposite Tthat are both deducible from the axioms. However, in practice it may
not be easy to ﬁnd a Tfor which one sees how to prove both TandT.
Evidently, we could prove the consistency of a set of axioms if we could ﬁnd a feasible
procedure which is guaranteed to locate an inconsistency if one exists; so G¨ odel’s theorem
seems to imply that no such procedure exists. Actually, it says only that no such procedurederivable from the axioms of the system being tested exists.
We shall ﬁnd that probability theory comes close to this; it is a powerful analytical tool
which can search out a set of propositions and detect a contradiction in them if one exists.The principle is that probabilities conditional on contradictory premises do not exist (thehypothesis space is reduced to the empty set). Therefore, put our robot to work; i.e. write
a computer program to calculate probabilities p(B|E) conditional on a set of propositions
E=(E
1E2...En). Even though no contradiction is apparent from inspection, if there is
a contradiction hidden in E, the computer program will crash.
We discovered this ‘empirically’, and, after some thought, realized that it is not a reason
for dismay, but rather a valuable diagnostic tool that warns us of unforeseen special casesin which our formulation of a problem can break down.
If the computer program does not crash, but prints out valid numbers, then we know that
the conditioning propositions E
iare mutually consistent, and we have accomplished what
one might have thought to be impossible in view of G¨ odel’s theorem. But of course our use
of probability theory appeals to principles not derivable from the propositions being tested,
so there is no difﬁculty; it is important to understand what G¨ odel’s theorem does and does
not prove.
When G¨ odel’s theorem ﬁrst appeared, with its more general conclusion that a mathe-
matical system may contain certain propositions that are undecidable within that system,it seems to have been a great psychological blow to logicians, who saw it at ﬁrst as a dev-astating obstacle to what they were trying to achieve. Yet a moment’s thought shows us
2The 1957 edition of Harold Jeffreys’ Scientiﬁc Inference (see Jeffreys, 1931) has a short summary of G¨ odel’s original reasoning
which is far clearer and easier to read than any other ‘explanation’ we have seen. The full theorem refers to other matters ofconcern in 1931 but of no interest to us right now; the above discussion has abstracted the part of it that we need to understandfor our present purposes.

<<<PAGE 79>>>

2 The quantitative rules 47
that many quite simple questions are undecidable by deductive logic. There are situations
in which one can prove that a certain property must exist in a ﬁnite set, even though it isimpossible to exhibit any member of the set that has that property. For example, two personsare the sole witnesses to an event; they give opposite testimony about it and then both die.Then we know that one of them was lying, but it is impossible to determine which one.
In this example, the undecidability is not an inherent property of the proposition or the
event; it signiﬁes only the incompleteness of our own information. But this is equally trueof abstract mathematical systems; when a proposition is undecidable in such a system, thatmeans only that its axioms do not provide enough information to decide it. But new axioms,
external to the original set, might supply the missing information and make the propositiondecidable after all.
In the future, as science becomes more and more oriented to thinking in terms of informa-
tion content, G¨ odel’s result will be seen as more of a platitude than a paradox. Indeed, from
our viewpoint ‘undecidability’ merely signiﬁes that a problem is one that calls for inference
rather than deduction. Probability theory as extended logic is designed speciﬁcally for suchproblems.
These considerations seem to open up the possibility that, by going into a wider ﬁeld by
invoking principles external to probability theory, one might be able to prove the consistencyof our rules. At the moment, this appears to us to be an open question.
Needless to say, no inconsistency has ever been found from correct application of our
rules, although some of our calculations will put them to a severe test. Apparent inconsis-tencies have always proved, on closer examination, to be misapplications of the rules. Onthe other hand, guided by Cox’s theorems, which tell us where to look, we have never hadthe slightest difﬁculty in exhibiting the inconsistencies in the ad hoc rules which abound
in the literature, which differ in content from ours and whose sole basis is the intuitivejudgment of their inventors. Examples are found throughout this book, but particularly inChapters 5, 15, and 17.
2.6.3 Venn diagrams
Doubtless, some readers will ask, ‘After the rather long and seemingly unmotivated deriva-
tion of the extended sum rule (2.66), which in our new notation now takes the form
P(A+B|C)=P(A|C)+P(B|C)−P(AB|C), (2.104)
why did we not illustrate it by the Venn diagram? That makes its meaning so much clearer.’
(Here we draw two circles labeled Aand B, with intersection labeled AB, all within a
circle C.)
The Venn diagram is indeed a useful device, illustrating – in one special case – why
the negative term appears in (2.104). But it can also mislead, because it suggests to ourintuition more than the actual content of (2.104). Looking at the Venn diagram, we areencouraged to ask, ‘What do the points in the diagram mean?’ If the diagram is intended to

<<<PAGE 80>>>

48 Part 1 Principles and elementary applications
illustrate (2.104), then the probability for Ais, presumably, represented by the area of circle
A; for then the total area covered by circles A,Bis the sum of their separate areas, minus
the area of overlap, corresponding exactly to (2.104).
Now, the circle Acan be broken down into nonoverlapping subregions in many different
ways; what do these subregions mean? Since their areas are additive, if the Venn diagramis to remain applicable they must represent a reﬁnement of Ainto the disjunction of some
mutually exclusive subpropositions. We can – if we have no mathematical scruples aboutapproaching inﬁnite limits – imagine this subdivision carried down to the individual pointsin the diagram. Therefore these points must represent some ultimate ‘elementary’ proposi-tionsω
iinto which Acan be resolved.3Of course, consistency then requires us to suppose
thatBandCcan also be resolved into these same propositions ωi.
We have already jumped to the conclusion that the propositions to which we assign
probabilities correspond to sets of points in some space, that the logical disjunction A+B
stands for the union of the sets, the conjunction ABfor their intersection, and that the prob-
abilities are an additive measure over those sets. But the general theory we are developinghas no such structure; all these things are properties only of the Venn diagram.
In developing our theory of inference we have taken special pains to avoid restrictive
assumptions which would limit its scope; it is to apply, in principle, to any propositionswith unambiguous meaning. In the special case where those propositions happen to bestatements about sets, the Venn diagram is an appropriate illustration of (2.104). But most
of the propositions about which we reason, for example,
A≡it will rain today , (2.105)
B≡the roof will leak , (2.106)
are simply declarative statements of fact, which may or may not be resolvable into a dis-
junction of more elementary propositions within the context of our problem.
Of course, one can always force such a resolution by introducing irrelevancies; for ex-
ample, even though the above-deﬁned Bhas nothing to do with penguins, we could still
resolve it into the disjunction
B=BC
1+BC 2+BC 3+···+ BC N, (2.107)
where Ck≡the number of penguins in Antarctica is k. By choosing Nsufﬁciently large,
we will surely be making a valid statement of Boolean algebra; but this is idle, and it cannothelp us to reason about a leaky roof.
Even if a meaningful resolution exists in our problem, it may not be of any use to us.
For example, the proposition ‘rain today’ could be resolved into an enumeration of everyconceivable trajectory of each individual raindrop; but we do not see how this could help ameteorologist trying to forecast rain. In real problems, there is a natural end to this resolving,beyond which it serves no purpose and degenerates into an empty formal exercise. We shall
3A physicist refuses to call them ‘atomic’ propositions, for obvious reasons.

<<<PAGE 81>>>

2 The quantitative rules 49
give an explicit demonstration of this later (Chapter 8), in the scenario of ‘Sam’s broken
thermometer’: does the exact way in which it broke matter for the conclusions that Samshould draw from his corrupted data?
In some cases there is a resolution so relevant to the context of the problem that it
becomes a useful calculational device; Eq. (2.98) was a trivial example. We shall be gladto take advantage of this whenever we can, but we cannot expect it in general.
Even when both AandBcan be resolved in a way meaningful and useful in our problem,
it would seldom be the case that they are resolvable into the same set of elementary propo-
sitions ω
i. And we always reserve the right to enlarge our context by introducing more
propositions D,E,F,... into the discussion; and we could hardly ever expect that all of
them would continue to be expressible as disjunctions of the same original set of elementary
propositions ωi. To assume this would be to place a quite unnecessary restriction on the
generality of our theory.
Therefore, the conjunction ABshould be regarded simply as the statement that both Aand
Bare true; it is a mistake to try to read any more detailed meaning, such as an intersection
of sets, into it in every problem. Then p(AB|C) should also be regarded as an elementary
quantity in its own right, not necessarily resolvable into a sum of still more elementary ones(although if it is so resolvable this may be a good way of calculating it). We have adheredto the original notation A+B,ABof Boole, instead of the more common A∨B,A∧B,
orA∪B,A∩B, which everyone associates with a set theory context, in order to head off
this confusion as much as possible.
So, rather than saying that the Venn diagram justiﬁes or explains (2.104), we prefer to
saythat (2.104) explains and justi ﬁes the Venn diagram, in one special case. But the Venn
diagram has played a major role in the history of probability theory, as we note next.
2.6.4 The ‘Kolmogorov axioms’
In 1933, A. N. Kolmogorov presented an approach to probability theory phrased in the
language of set theory and measure theory (Kolmogorov, 1933). This language was justthen becoming so fashionable that today many mathematical results are named, not forthe discoverer, but for the one who ﬁrst restated them in that language. For example, inthe theory of continuous groups the term ‘Hurwitz invariant integral’ disappeared, to bereplaced by ‘Haar measure’. Because of this custom, some modern works – particularly bymathematicians – can give one the impression that probability theory started withKolmogorov.
Kolmogorov formalized and axiomatized the picture suggested by the Venn diagram,
which we have just described. At ﬁrst glance, this system appears so totally differentfrom ours that some discussion is needed to see the close relationship between them. InAppendix A we describe the Kolmogorov system and show that, for all practical pur-poses, the four axioms concerning his probability measure, ﬁrst stated arbitrarily (for whichKolmogorov has been criticized), have all been derived in this chapter as necessary to meetour consistency requirements. As a result, we shall ﬁnd ourselves defending Kolmogorov

<<<PAGE 82>>>

50 Part 1 Principles and elementary applications
against his critics on many technical points. The reader who ﬁrst learned probability theory
on the Kolmogorov basis is urged to read Appendix A at this point.
Our system of probability, however, differs conceptually from that of Kolmogorov in
that we do not interpret propositions in terms of sets, but we do interpret probability distri-butions as carriers of incomplete information. Partly as a result, our system has analyticalresources not present at all in the Kolmogorov system. This enables us to formulate and solvemany problems – particularly the so-called ‘ill posed’ problems and ‘generalized inverse’problems – that would be considered outside the scope of probability theory according tothe Kolmogorov system. These problems are just the ones of greatest interest in currentapplications.

<<<PAGE 83>>>

3
Elementary sampling theory
At this point, the mathematical material we have available consists of the basic product and
sum rules
P(AB|C)=P(A|BC)P(B|C)=P(B|AC)P(A|C) (3.1)
P(A|B)+P(A|B)=1 (3.2)
from which we derived the extended sum rule
P(A+B|C)=P(A|C)+P(B|C)−P(AB|C) (3.3)
and with the desideratum (IIIc) of consistency , the principle of indifference: if on background
information Bthe hypotheses ( H1,H2,..., HN) are mutually exclusive and exhaustive, and
Bdoes not favor any one of them over any other, then
P(Hi|B)=1
N, 1≤i≤N. (3.4)
From (3.3) and (3.4) we then derived the Bernoulli urn rule: if Bspeciﬁes that Ais true on
some subset of Mof the Hi, and false on the remaining ( N−M), then
P(A|B)=M
N. (3.5)
It is important to realize how much of probability theory can be derived from no more than
this.
In fact, essentially all of conventional probability theory as currently taught, plus many
important results that are often thought to lie beyond the domain of probability theory, canbe derived from the above foundation. We devote the next several chapters to demonstratingthis in some detail, and then in Chapter 11 we resume the basic development of our robot’sbrain, with a better understanding of what additional principles are needed for advancedapplications.
The ﬁrst applications of the theory given in this chapter are, to be sure, rather simple and
na¨ıve compared with the serious scientiﬁc inference that we hope to achieve later. Neverthe-
less, our reason for considering them in close detail is not mere pedagogical form. Failureto understand the logic of these simplest applications has been one of the major factors
51

<<<PAGE 84>>>

52 Part 1 Principles and elementary applications
retarding the progress of scientiﬁc inference – and therefore of science itself – for many
decades. Therefore we urge the reader, even one who is already familiar with elementarysampling theory, to digest the contents of this chapter carefully before proceeding to morecomplicated problems.
3.1 Sampling without replacement
Let us make the Bernoulli urn scenario a little more speciﬁc by deﬁning the following
propositions.
B≡An urn contains Nballs, identical in every respect except that they carry
numbers (1 ,2,..., N) and Mof them are colored red, with the remaining
(N−M) white, 0≤M≤N.We draw a ball from the urn blindfolded,
observe and record its color, lay it aside, and repeat the process until n
balls have been drawn, 0 ≤n≤N.
R
i≡Red ball on the ith draw.
Wi≡White ball on the ith draw.
Since, according to B, only red or white can be drawn, we have
P(Ri|B)+P(Wi|B)=1, 1≤i≤N, (3.6)
which amounts to saying that, in the ‘logical environment’ created by knowledge of B, the
propositions are related by negation:
Ri=Wi, Wi=Ri, (3.7)
and, for the ﬁrst draw, (3.5) becomes
P(R1|B)=M
N, (3.8)
P(W1|B)=1−M
N. (3.9)
Let us understand clearly what this means. The probability assignments (3.8) and (3.9) are
not assertions of any physical property of the urn or its contents; they are a description
of the state of knowledge of the robot prior to the drawing. Indeed, were the robot’s state of
knowledge different from Bas just deﬁned (for example, if it knew the actual positions of
the red and white balls in the urn, or if it did not know the true values of NandM), then
its probability assignments for R1andW1would be different; but the real properties of the
urn would be just the same.
It is therefore illogical to speak of ‘verifying’ (3.8) by performing experiments with the
urn; that would be like trying to verify a boy’s love for his dog by performing experimentson the dog. At this stage, we are concerned with the logic of consistent reasoning from
incomplete information; not with assertions of physical fact about what will be drawn

<<<PAGE 85>>>

3 Elementary sampling theory 53
from the urn (which are in any event impossible just because of the incompleteness of the
information B).
Eventually, our robot will be able to make some very conﬁdent physical predictions
which can approach, but (except in degenerate cases) not actually reach, the certainty oflogical deduction; but the theory needs to be developed further before we are in a positionto say what quantities can be well predicted, and what kind of information is needed forthis. Put differently, relations between probabilities assigned by the robot in various statesof knowledge, and observable facts in experiments, may not be assumed arbitrarily; weare justiﬁed in using only those relations that can be deduced from the rules of probabilitytheory, as we now seek to do.
Changes in the robot’s state of knowledge appear when we ask for probabilities referring
to the second draw. For example, what is the robot’s probability for red on the ﬁrst twodraws? From the product rule, this is
P(R
1R2|B)=P(R1|B)P(R2|R1B). (3.10)
In the last factor, the robot must take into account that one red ball has been removed at the
ﬁrst draw, so there remain ( N−1) balls of which ( M−1) are red. Therefore
P(R1R2|B)=M
NM−1
N−1. (3.11)
Continuing in this way, the probability for red on the ﬁrst rconsecutive draws is
P(R1R2···Rr|B)=M(M−1)···(M−r+1)
N(N−1)···(N−r+1)
=M!(N−r)!
(M−r)!N!, r≤M.(3.12)
The restriction r≤Mis not necessary if we understand that we deﬁne factorials by the
gamma function relation n!=/Gamma1(n+1), for then the factorial of a negative integer is inﬁnite,
and (3.12) is zero automatically when r>M.
The probability for white on the ﬁrst wdraws is similar but for the interchange of Mand
(N−M):
P(W1W2···Ww|B)=(N−M)!(N−w)!
(N−M−w)!N!. (3.13)
Then, the probability for white on draws ( r+1,r+2,..., r+w) given that we got red
on the ﬁrst rdraws, is given by (3.13), taking into account that NandMhave been reduced
to (N−r) and ( M−r),respectively:
P(Wr+1···Wr+w|R1···RrB)=(N−M)!(N−r−w)!
(N−M−w)!(N−r)!, (3.14)

<<<PAGE 86>>>

54 Part 1 Principles and elementary applications
and so, by the product rule, the probability for obtaining rred followed by w=n−rwhite
inndraws is, from (3.12) and (3.14),
P(R1···RrWr+1···Wn|B)=M!(N−M)!(N−n)!
(M−r)!(N−M−w)!N!, (3.15)
a term ( N−r)! having cancelled out.
Although this result was derived for a particular order of drawing red and white balls,
the probability for drawing exactly rred balls in any speciﬁed order in ndraws is the same.
To see this, write out the expression (3.15) more fully, in the manner
M!
(M−r)!=M(M−1)···(M−r+1) (3.16)
and similarly for the other ratios of factorials in (3.15). The right-hand side becomes
M(M−1)···(M−r+1)(N−M)(N−M−1)···(N−M−w+1)
N(N−1)···(N−n+1). (3.17)
Now suppose that rred and ( n−r)=wwhite are drawn, in any other order. The probability
for this is the product of nfactors; every time red is drawn there is a factor (number of red
balls in urn)/(total number of balls), and similarly for drawing a white one. The number ofballs in the urn decreases by one at each draw; therefore for the kth draw a factor ( N−k+1)
appears in the denominator, whatever the colors of the previous draws.
Just before the kth red ball is drawn, whether this occurs at the kth draw or any later one,
there are ( M−k+1) red balls in the urn; thus, drawing the kth one places a factor ( M−
k+1) in the numerator. Just before the kth white ball is drawn, there are ( N−M−k+1)
white balls in the urn, and so drawing the kth white one places a factor ( N−M−k+1) in
the numerator, regardless of whether this occurs at the kth draw or any later one. Therefore,
by the time all nballs have been drawn, of which rwere red, we have accumulated exactly
the same factors in numerator and denominator as in (3.17); different orders of drawingthem only permute the order of the factors in the numerator. The probability for drawingexactly rballs in any speciﬁed order in ndraws is therefore given by (3.15).
Note carefully that in this result the product rule was expanded in a particular way
that showed us how to organize the calculation into a product of factors, each of which is aprobability at one speciﬁed draw, given the results of all the previous draws . But the product
rule could have been expanded in many other ways, which would give factors conditionalon other information than the previous draws; the fact that all these calculations must lead tothe same ﬁnal result is a nontrivial consistency property, which the derivations of Chapter 2sought to ensure.
Next, we ask: What is the robot’s probability for drawing exactly rred balls in ndraws,
regardless of order? Different orders of appearance of red and white balls are mutuallyexclusive possibilities, so we must sum over all of them; but since each term is equal to(3.15), we merely multiply it by the binomial coefﬁcient
/parenleftbiggn
r/parenrightbigg
=n!
r!(n−r)!, (3.18)

<<<PAGE 87>>>

3 Elementary sampling theory 55
which represents the number of possible orders of drawing rred balls in ndraws, or, as we
shall call it, the multiplicity of the event r. For example, to get three red in three draws can
happen in only
/parenleftbigg3
3/parenrightbigg
=1 (3.19)
way, namely R1R2R3; the event r=3 has a multiplicity of 1. But to get two red in three
draws can happen in
/parenleftbigg3
2/parenrightbigg
=3 (3.20)
ways, namely R1R2W3,R1W2R3,W1R2R3, so the event r=2 has a multiplicity of 3.
Exercise 3.1. Why isn’t the multiplicity factor (3.18) just n!? After all, we started this
discussion by stipulating that the balls, in addition to having colors, also carry labels(1,2,..., N), so that different permutations of the red balls among themselves, which
give the r! in the denominator of (3.18), are distinguishable arrangements.
Hint: In (3.15) we are not specifying which red balls and which white ones are to be
drawn.
Taking the product of (3.15) and (3.18), the many factorials can be reorganized into threebinomial coefﬁcients. Deﬁning A≡‘Exactly rred balls in ndraws, in any order’ and the
function
h(r|N,M,n)≡P(A|B), (3.21)
we have
h(r|N,M,n)=/parenleftbiggM
r/parenrightbigg/parenleftbiggN−M
n−r/parenrightbigg
/parenleftbiggN
n/parenrightbigg , (3.22)
which we shall usually abbreviate to h(r). By the convention x!=/Gamma1(x+1) it vanishes
automatically when r>M,o rr>n,o r( n−r)>(N−M), as it should.
We are here doing a little notational acrobatics for reasons explained in Appendix B. The
point is that in our formal probability symbols P(A|B) with the capital P, the arguments
A,Balways stand for propositions, which can be quite complicated verbal statements. If
we wish to use ordinary numbers for arguments, then for consistency we should deﬁne newfunctional symbols such as h(r|N,M,n). Attempts to try to use a notation like P(r|NMn ),
thereby losing sight of the qualitative stipulations contained in AandB, have led to se-
rious errors from misinterpretation of the equations (such as the marginalization paradoxdiscussed later). However, as already indicated in Chapter 2, we follow the custom of mostcontemporary works by using probability symbols of the form p(A|B), or p(r|n) with small

<<<PAGE 88>>>

56 Part 1 Principles and elementary applications
p, in which we permit the arguments to be either propositions or algebraic variables; in this
case, the meaning must be judged from the context.
The fundamental result (3.22) is called the hypergeometric distribution because it is
related to the coefﬁcients in the power series representation of the Gauss hypergeometricfunction
F(a,b,c;t)=∞/summationdisplay
r=0/Gamma1(a+r)/Gamma1(b+r)/Gamma1(c)
/Gamma1(a)/Gamma1(b)/Gamma1(c+r)tr
r!. (3.23)
If either aorbis a negative integer, the series terminates and this is a polynomial. It is
easily veriﬁed that the generating function
G(t)≡n/summationdisplay
r=0h(r|N,M,n)tr(3.24)
is equal to
G(t)=F(−M,−n,c;t)
F(−M,−n,c;1 ), (3.25)
with c=N−M−n+1. The evident relation G(1)=1 is, from (3.24), just the statement
that the hypergeometric distribution is correctly normalized. In consequence of (3.25),
G(t) satisﬁes the second-order hypergeometric differential equation and has many other
properties useful in calculations.
Although the hypergeometric distribution h(r) appears complicated, it has some surpris-
ingly simple properties. The most probable value of ris found to within one unit by setting
h(r/prime)=h(r/prime−1) and solving for r/prime.W eﬁ n d
r/prime=(n+1)(M+1)
N+2. (3.26)
Ifr/primeis an integer, then r/primeandr/prime−1 are jointly the most probable values. If r/primeis not an
integer, then there is a unique most probable value
ˆr=INT( r/prime), (3.27)
that is, the next integer below r/prime. Thus, the most probable fraction f=r/nof red balls in
the sample drawn is nearly equal to the fraction F=M/Noriginally in the urn, as one
would expect intuitively. This is our ﬁrst crude example of a physical prediction: a relationbetween a quantity Fspeciﬁed in our information and a quantity fmeasurable in a physical
experiment derived from the theory.
The width of the distribution h(r) gives an indication of the accuracy with which the robot
can predict r. Many such questions are answered by calculating the cumulative probability
distribution , which is the probability for ﬁnding Ror fewer red balls. If Ris an integer,
this is
H(R)≡ R/summationdisplay
r=0h(r), (3.28)

<<<PAGE 89>>>

3 Elementary sampling theory 57
but for later formal reasons we deﬁne H(x) to be a staircase function for all non-negative
realx; thus H(x)≡H(R), where R=INT( x) is the greatest integer ≤x.
Themedian of a probability distribution such as h(r) is deﬁned to be a number msuch that
equal probabilities are assigned to the propositions ( r<m) and ( r>m). Strictly speaking,
according to this deﬁnition a discrete distribution has in general no median. If there is aninteger Rfor which H(R−1)=1−H(R) and H(R)>H(R−1), then Ris the unique
median. If there is an integer Rfor which H(R)=1/2, then any rin (R≤r<R
/prime)i sa
median, where R/primeis the next higher jump point of H(x); otherwise there is none.
But for most purposes we may take a more relaxed attitude and approximate the strict
deﬁnition. If nis reasonably large, then it makes reasonably good sense to call that value
ofRfor which H(R) is closest to 1 /2, the ‘median’. In the same relaxed spirit, the values
ofRfor which H(R) is closest to 1 /4, 3/4, may be called the ‘lower quartile’ and ‘upper
quartile’, respectively, and if n/greatermuch10 we may call the value of Rfor which H(R) is closest
tok/10 the ‘ kth decile’, and so on. As n→∞ , these loose deﬁnitions come into conformity
with the strict one.
Usually, the ﬁne details of H(R) are unimportant, and for our purposes it is sufﬁcient
to know the median and the quartiles. Then the (median) ±(interquartile distance) will
provide a good enough idea of the robot’s prediction and its probable accuracy. That is,on the information given to the robot, the true value of ris about as likely to lie in this
interval as outside it. Likewise, the robot assigns a probability of (5 /6)−(1/6)=2/3 (in
other words, odds of 2 : 1) that rlies between the ﬁrst and ﬁfth hexile, odds of 8 : 2 =4:1
that it is bracketed by the ﬁrst and ninth decile, and so on.
Although one can develop rather messy approximate formulas for these distributions
which were much used in the past, it is easier today to calculate the exact distribution by
computer. For example W. H. Press et al. (1986) list two routines that will calculate the
generalized complex hypergeometric distribution for any values of a,bandc. Tables 3.1
and 3.2 give the hypergeometric distribution for N=100, M=50,n=10, and N=100,
M=10,n=50, respectively. In the latter case, it is not possible to draw more than ten red
balls, so the entries for r>10 are all h(r)=0,H(r)=1, and are not tabulated. One is struck
immediately by the fact that the entries for positive h(r) are identical; the hypergeometric
distribution has the symmetry property
h(r|N,M,n)=h(r|N,n,M) (3.29)
under interchange of Mandn. Whether we draw ten balls from an urn containing 50 red
ones, or 50 from an urn containing ten red ones, the probability for ﬁnding rred ones in
the sample drawn is the same. This is readily veriﬁed by closer inspection of (3.22), and itis evident from the symmetry in a,bof the hypergeometric function (3.23).
Another symmetry evident from Tables 3.1 and 3.2 is the symmetry of the distribution
about its peak: h(r|100,50,10)=h(10−r|100,50,10). However, this is not so in general;
changing Nto 99 results in a slightly unsymmetrical peak, as we see from Table 3.3. The
symmetric peak in Table 3.1 arises as follows: if we interchange Mand ( N−M) and at the
same time interchange rand ( n−r) we have in effect only interchanged the words ‘red’

<<<PAGE 90>>>

58 Part 1 Principles and elementary applications
Table 3.1. Hypergeometric distribution;
N,M,n=100,10,50.
rh (r) H(r)
0 0.000593 0.000593
1 0.007237 0.0078302 0.037993 0.0458243 0.113096 0.1589204 0.211413 0.3703335 0.259334 0.6296676 0.211413 0.8410807 0.113096 0.9541778 0.037993 0.9921709 0.007237 0.999407
10 0.000593 1.000000
Table 3.2. Hypergeometric distribution;
N,M,n=100,50,10.
rh (r) H(r)
0 0.000593 0.000593
1 0.007237 0.0078302 0.037993 0.0458243 0.113096 0.1589204 0.211413 0.3703335 0.259334 0.6296676 0.211413 0.8410807 0.113096 0.9541778 0.037993 0.9921709 0.007237 0.999407
10 0.000593 1.000000
and ‘white’, so the distribution is unchanged:
h(n−r|N,N−M,n)=h(r|N,M,n). (3.30)
But when M=N/2, this reduces to the symmetry
h(n−r|N,M,n)=h(r|N,M,n) (3.31)
observed in Table 3.1. By (3.29) the peak must be symmetric also when n=N/2.

<<<PAGE 91>>>

3 Elementary sampling theory 59
Table 3.3. Hypergeometric distribution;
N,M,n=99,50,10.
rh (r) H(r)
0 0.000527 0.000527
1 0.006594 0.0071212 0.035460 0.0425813 0.108070 0.1506514 0.206715 0.3573675 0.259334 0.6167006 0.216111 0.8328127 0.118123 0.9509348 0.040526 0.9914619 0.007880 0.999341
10 0.000659 1.000000
The hypergeometric distribution has two more symmetries not at all obvious intuitively
or even visible in (3.22). Let us ask the robot for its probability P(R2|B) of red on the
second draw. This is not the same calculation as (3.8), because the robot knows that, justprior to the second draw, there are only ( N−1) balls in the urn, not N. But it does not
know what color of ball was removed on the ﬁrst draw, so it does not know whether thenumber of red balls now in the urn is Mor (M−1). Then the basis for the Bernoulli urn
result (3.5) is lost, and it might appear that the problem is indeterminate.
Yet it is quite determinate after all; the following is our ﬁrst example of one of the useful
techniques in probability calculations, which derives from the resolution of a propositioninto disjunctions of simpler ones, as discussed in Chapters 1 and 2. The robot knows thateither R
1orW1is true; therefore using Boolean algebra we have
R2=(R1+W1)R2=R1R2+W1R2. (3.32)
We apply the sum rule and the product rule to get
P(R2|B)=P(R1R2|B)+P(W1R2|B)
=P(R2|R1B)P(R1|B)+P(R2|W1B)P(W1|B).(3.33)
But
P(R2|R1B)=M−1
N−1, P(R2|W1B)=M
N−1, (3.34)
and so
P(R2|B)=M−1
N−1M
N+M
N−1N−M
N=M
N. (3.35)

<<<PAGE 92>>>

60 Part 1 Principles and elementary applications
The complications cancel out, and we have the same probability for red on the ﬁrst and
second draws. Let us see whether this continues. For the third draw we have
R3=(R1+W1)(R2+W2)R3=R1R2R3+R1W2R3+W1R2R3+W1W2R3,(3.36)
and so
P(R3|B)=M
NM−1
N−1M−2
N−2+M
NN−M
N−1M−1
N−2
+N−M
NM
N−1M−1
N−2+N−M
NN−M−1
N−1M
N−2
=M
N.(3.37)
Again all the complications cancel out. The robot’s probability for red at any draw, if it does
not know the result of any other draw , is always the same as the Bernoulli urn result (3.5).
This is the ﬁrst nonobvious symmetry. We shall not prove this in generality here, becauseit is contained as a special case of a still more general result; see Eq. (3.118) below.
The method of calculation illustrated by (3.32) and (3.36) is as follows: resolve the
quantity whose probability is wanted into mutually exclusive subpropositions, then applythe sum rule and the product rule. If the subpropositions are well chosen (i.e. if they havesome simple meaning in the context of the problem), their probabilities are often calculable.If they are not well chosen (as in the example of the penguins at the end of Chapter 2), thenof course this procedure cannot help us.
3.2 Logic vs. propensity
The results of Section 3.1 present us with a new question. In ﬁnding the probability for
red at the kth draw, knowledge of what color was found at some earlier draw is clearly
relevant because an earlier draw affects the number M
kof red balls in the urn for the kth
draw. Would knowledge of the color for a later draw be relevant? At ﬁrst glance, it seemsthat it could not be, because the result of a later draw cannot inﬂuence the value of M
k.
For example, a well-known exposition of statistical mechanics (Penrose, 1979) takes it as afundamental axiom that probabilities referring to the present time can depend only on whathappened earlier, not on what happens later. The author considers this to be a necessaryphysical condition of ‘causality’.
Therefore we stress again, as we did in Chapter 1, that inference is concerned with logical
connections, which may or may not correspond to causal physical inﬂuences. To show whyknowledge of later events is relevant to the probabilities of earlier ones, consider an urnwhich is known (background information B) to contain only one red and one white ball:
N=2,M=1. Given only this information, the probability for red on the ﬁrst draw is
P(R
1|B)=1/2. But then if the robot learns that red occurs on the second draw, it becomes

<<<PAGE 93>>>

3 Elementary sampling theory 61
certain that it did not occur on the ﬁrst:
P(R1|R2B)=0. (3.38)
More generally, the product rule gives us
P(RjRk|B)=P(Rj|RkB)P(Rk|B)=P(Rk|RjB)P(Rj|B). (3.39)
But we have just seen that P(Rj|B)=P(Rk|B)=M/Nfor all j,k,s o
P(Rj|RkB)=P(Rk|RjB), allj,k. (3.40)
Probability theory tells us that the results of later draws have precisely the same relevance
as do the results of earlier ones! Even though performing the later draw does not physicallyaffect the number M
kof red balls in the urn at the kth draw, information about the result of a
later draw has the same effect on our state of knowledge about what could have been taken
on the kth draw, as does information about an earlier one. This is our second nonobvious
symmetry.
This result will be quite disconcerting to some schools of thought about the ‘meaning of
probability’. Although it is generally recognized that logical implication is not the same as
physical causation, nevertheless there is a strong inclination to cling to the idea anyway, bytrying to interpret a probability P(A|B) as expressing some kind of partial causal inﬂuence of
BonA. This is evident not only in the aforementioned work of Penrose, but more strikingly
in the ‘propensity’ theory of probability expounded by the philosopher Karl Popper.
1
It appears to us that such a relation as (3.40) would be quite inexplicable from a propensity
viewpoint, although the simple example (3.38) makes its logical necessity obvious. In anyevent, the theory of logical inference that we are developing here differs fundamentally,in outlook and in results, from the theory of physical causation envisaged by Penroseand Popper. It is evident that logical inference can be applied in many problems whereassumptions of physical causation would not make sense.
This does not mean that we are forbidden to introduce the notion of ‘propensity’ or
physical causation; the point is rather that logical inference is applicable and useful whetheror not a propensity exists. If such a notion (i.e. that some such propensity exists) is formulatedasa well-de ﬁned hypothesis, then our form of probability theory can analyze its implications.
We shall do this in Section 3.10 below. Also, we can test that hypothesis against alternatives
1In his presentation at the Ninth Colston Symposium, Popper (1957) describes his propensity interpretation as ‘purely objective’
but avoids the expression ‘physical inﬂuence’. Instead, he would say that the probability for a particular face in tossing a dieis not a physical property of the die (as Cram´ er (1946) insisted), but rather is an objective property of the whole experimental
arrangement, the die plus the method of tossing. Of course, that the result of the experiment depends on the entire arrangement
and procedure is only a truism. It was stressed repeatedly by Niels Bohr in connection with quantum theory, but presumably
no scientist from Galileo on has ever doubted it. However, unless Popper really meant ‘physical inﬂuence’, his interpretation
would seem to be supernatural rather than objective. In a later article (Popper, 1959) he deﬁnes the propensity interpretation
more completely; now a propensity is held to be ‘objective’ and ‘physically real’ even when applied to the individual trial. In thefollowing we see by mathematical demonstration some of the logical difﬁculties that result from a propensity interpretation.Popper complains that in quantum theory one oscillates between ‘ ...anobjective purely statistical interpretation and a subjective
interpretation in terms of our incomplete knowledge ’, and thinks that the latter is reprehensible and the propensity interpretation
avoids any need for it. He could not possibly be more mistaken. In Chapter 9 we answer this in detail at the conceptual level;obviously, incomplete knowledge is the only working material a scientist has ! In Chapter 10 we consider the detailed physics of
coin tossing, and see just how the method of tossing affects the results by direct physical inﬂuence.

<<<PAGE 94>>>

62 Part 1 Principles and elementary applications
in the light of the evidence, just as we can test any well-deﬁned hypothesis. Indeed, one of
the most common and important applications of probability theory is to decide whether thereis evidence for a causal inﬂuence: is a new medicine more effective, or a new engineeringdesign more reliable? Does a new anticrime law reduce the incidence of crime? Our studyof hypothesis testing starts in Chapter 4.
In all the sciences, logical inference is more generally applicable. We agree that physical
inﬂuences can propagate only forward in time; but logical inferences propagate equallywell in either direction. An archaeologist uncovers an artifact that changes his knowledgeof events thousands of years ago; were it otherwise, archaeology, geology, and paleontologywould be impossible. The reasoning of Sherlock Holmes is also directed to inferring, frompresently existing evidence, what events must have transpired in the past. The soundsreaching your ears from a marching band 600 meters distant change your state of knowledgeabout what the band was playing two seconds earlier. Listening to a Toscanini recordingof a Beethoven symphony changes your state of knowledge about the sounds Toscaninielicited from his orchestra many years ago.
As this suggests, and as we shall verify later, a fully adequate theory of nonequilibrium
phenomena, such as sound propagation, also requires that backward logical inferences berecognized and used, although they do not express physical causes. The point is that the bestinferences we can make about any phenomenon – whether in physics, biology, economics,or any other ﬁeld – must take into account all the relevant information we have, regardlessof whether that information refers to times earlier or later than the phenomenon itself; thisought to be considered a platitude, not a paradox. At the end of this chapter (Exercise 3.6),the reader will have an opportunity to demonstrate this directly, by calculating a backw ard
inference that takes into account a forward causal inﬂuence.
More generally, consider a probability distribution p(x
1···xn|B), where xidenotes the
result of the ith trial, and could take on not just two values (red or white) but, say, the
values xi=(1,2,..., k) labeling kdifferent colors. If the probability is invariant under
any permutation of the xi, then it depends only on the sample numbers ( n1···nk) denoting
how many times the result xi=1 occurs, how many times xi=2 occurs, etc. Such a
distribution is called exchangeable ; as we shall ﬁnd later, exchangeable distributions have
many interesting mathematical properties and important applications.
Returning to our urn problem, it is clear already from the fact that the hypergeometric
distribution is exchangeable that every draw must have just the same relevance to everyother draw, regardless of their time order and regardless of whether they are near or farapart in the sequence. But this is not limited to the hypergeometric distribution; it is trueof any exchangeable distribution (i.e. whenever the probability for a sequence of events isindependent of their order). So, with a little more thought, these symmetries, so inexplicablefrom the standpoint of physical causation, become obvious after all as propositions of logic.
Let us calculate this effect quantitatively. Supposing j<k, the proposition R
jRk(red at
both draws jandk) is in Boolean algebra the same as
RjRk=(R1+W1)···(Rj−1+Wj−1)Rj(Rj+1+Wj+1)···(Rk−1+Wk−1)Rk,(3.41)

<<<PAGE 95>>>

3 Elementary sampling theory 63
which we could expand in the manner of (3.36) into a logical sum of
2j−1×2k−j−1=2k−2(3.42)
propositions, each specifying a full sequence, such as
W1R2W3···Rj···Rk (3.43)
ofkresults. The probability P(RjRk|B) is the sum of all their probabilities. But we know
that, given B, the probability for any one sequence is independent of the order in which
red and white appear. Therefore we can permute each sequence, moving Rjto the ﬁrst
position, and Rkto the second. That is, we can replace the sequence ( W1···Rj···)b y
(R1···Wj···), etc. Recombining them, we have ( R1R2) followed by e very possible result
for draws (3 ,4,..., k). In other words, the probability for RjRkis the same as that of
R1R2(R3+W3)···(Rk+Wk)=R1R2, (3.44)
and we have
P(RjRk|B)=P(R1R2|B)=M(M−1)
N(N−1), (3.45)
and likewise
P(WjRk|B)=P(W1R2|B)=(N−M)M
N(N−1). (3.46)
Therefore by the product rule
P(Rk|RjB)=P(RjRk|B)
P(Rj|B)=M−1
N−1(3.47)
and
P(Rk|WjB)=P(WjRk|B)
P(Wj|B)=M
N−1(3.48)
for all j<k. By (3.40), the results (3.47) and (3.48) are true for all j/negationslash=k.
Since as noted this conclusion appears astonishing to many people, we shall belabor the
point by explaining it still another time in different words. The robot knows that the urnoriginally contained Mred balls and ( N−M) white ones. Then, learning that an earlier
draw gave red, it knows that one less red ball is available for the later draws. The problembecomes the same as if we had started with an urn of ( N−1) balls, of which ( M−1) are
red; (3.47) corresponds just to the solution (3.37) adapted to this different problem.
But why is knowing the result of a later draw equally cogent? Because if the robot knows
that red will be drawn at any later time, then in effect one of the red balls in the urn must be‘set aside’ to make this possible. The number of red balls which could have been taken inearlier draws is reduced by one, as a result of having this information. The above example(3.38) is an extreme special case of this, where the conclusion is particularly obvious.

<<<PAGE 96>>>

64 Part 1 Principles and elementary applications
3.3 Reasoning from less precise information
Now let us try to apply this understanding to a more complicated problem. Suppose the
robot learns that red will be found at least once in later draws, but not at which draw ordraws this will occur. That is, the new information is, as a proposition of Boolean algebra,
R
later≡Rk+1+Rk+2+···+ Rn. (3.49)
This information reduces the number of red available for the kth draw by at least one, but
it is not obvious whether Rlaterhas exactly the same implications as does Rn. To investigate
this we appeal again to the symmetry of the product rule:
P(RkRlater|B)=P(Rk|RlaterB)P(Rlater|B)=P(Rlater|RkB)P(Rk|B), (3.50)
which gives us
P(Rk|RlaterB)=P(Rk|B)P(Rlater|RkB)
P(Rlater|B), (3.51)
and all quantities on the right-hand side are easily calculated.
Seeing (3.49), one might be tempted to reason as follows:
P(Rlater|B)=n/summationdisplay
j=k+1P(Rj|B), (3.52)
but this is not correct because, unless M=1, the events Rjare not mutually exclusive,
and, as we see from (2.82), many more terms would be needed. This method of calculation
would be very tedious.
To organize the calculation better, note that the denial of Rlateris the statement that white
occurs at all the later draws:
Rlater=Wk+1Wk+2···Wn. (3.53)
SoP(Rlater|B) is the probability for white at all the later draws, regardless of what happens
at the earlier ones (i.e. when the robot does not know what happens at the earlier ones).By exchangeability this is the same as the probability for white at the ﬁrst ( n−k) draws,
regardless of what happens at the later ones; from (3.13),
P(
Rlater|B)=(N−M)!(N−n+k)!
N!(N−M−n+k)!=/parenleftbiggN−M
n−k/parenrightbigg/parenleftbiggN
n−k/parenrightbigg−1
. (3.54)
Likewise, P(Rlater|RkB) is the same result for the case of ( N−1) balls, ( M−1) of which
are red:
P(Rlater|RkB)=(N−M)!
(N−1)!(N−n+k−1)!
(N−M−n+k)!=/parenleftbiggN−M
n−k/parenrightbigg/parenleftbiggN−1
n−k/parenrightbigg−1
. (3.55)

<<<PAGE 97>>>

3 Elementary sampling theory 65
Now (3.51) becomes
P(Rk|RlaterB)=M
N−n+k×/parenleftbiggN−1
n−k/parenrightbigg
−/parenleftbiggN−M
n−k/parenrightbigg
/parenleftbiggN
n−k/parenrightbigg
−/parenleftbiggN−M
n−k/parenrightbigg. (3.56)
As a check, note that if n=k+1, this reduces to ( M−1)/(N−1), as it should.
At the moment, however, our interest in (3.56) is not so much in the numerical values, but
in understanding the logic of the result. So let us specialize it to the simplest case that is notentirely trivial. Suppose we draw n=3 times from an urn containing N=4 balls, M=2
of which are white, and ask how knowledge that red occurs at least once on the secondand third draws affects the probability for red at the ﬁrst draw. This is given by (3.56) with
N=4,M=2,n=3,k=1:
P(R
1|R2+R3,B)=6−2
12−2=2
5=/parenleftbigg1
2/parenrightbigg1−1/3
1−1/6, (3.57)
the last form corresponding to (3.51). Compare this to the previously calculated probabili-
ties:
P(R1|B)=1
2, P(R1|R2B)=P(R2|R1B)=1
3. (3.58)
What seems surprising is that
P(R1|RlaterB)>P(R1|R2B). (3.59)
Most people guess at ﬁrst that the inequality should go the other way; i.e. knowing that red
occurs at least once on the later draws ought to decrease the chances of red at the ﬁrst drawmore than does the information R
2. But in this case the numbers are so small that we can
check the calculation (3.51) directly. To ﬁnd P(Rlater|B) by the extended sum rule (2.82)
now requires only one extra term:
P(Rlater|B)=P(R2|B)+P(R3|B)−P(R2R3|B)
=1
2+1
2−1
2×1
3=5
6.(3.60)
We could equally well resolve Rlaterinto mutually exclusive propositions and calculate
P(Rlater|B)=P(R2W3|B)+P(W2R3|B)+P(R2R3|B)
=1
2×2
3+1
2×2
3+1
2×1
3=5
6.(3.61)
The denominator (1 −1/6) in (3.57) has now been calculated in three different ways, with
the same result. If the three results were not the same, we would have found an inconsistencyin our rules, of the kind we sought to prevent by Cox’s functional equation arguments inChapter 2. This is a good example of what ‘consistency’ means in practice, and it showsthe trouble we would be in if our rules did not have it.

<<<PAGE 98>>>

66 Part 1 Principles and elementary applications
Likewise, we can check the numerator of (3.51) by an independent calculation:
P(Rlater|R1B)=P(R2|R1B)+P(R3|R1B)−P(R2R3|R1B)
=1
3+1
3−1
3×0=2
3,(3.62)
and the result (3.57) is conﬁrmed. So we have no choice but to accept the inequality (3.59)
and try to understand it intuitively. Let us reason as follows. The information R2reduces the
number of red balls available for the ﬁrst draw by one, and it reduces the number of balls inthe urn available for the ﬁrst draw by one, giving P(R
1|R2B)=(M−1)/(N−1)=1/3.
The information Rlaterreduces the ‘effective number of red balls’ available for the ﬁrst draw
by more than one, but it reduces the number of balls in the urn available for the ﬁrst drawby two (because it assures the robot that there are two later draws in which two balls areremoved). So let us try tentatively to interpret the result (3.57) as
P(R
1|RlaterB)=(M)eff
N−2, (3.63)
although we are not quite sure what this means. Given Rlater, it is certain that at least one
red ball is removed, and the probability that two are removed is, by the product rule:
P(R2R3|RlaterB)=P(R2R3Rlater|B)
P(Rlater|B)=P(R2R3|B)
P(Rlater|B)
=(1/2)×(1/3)
5/6=1
5(3.64)
because R2R3implies Rlater; i.e. a relation of Boolean algebra is ( R2R3Rlater=R2R3).
Intuitively, given Rlaterthere is probability 1/5 that two red balls are removed, so the effective
number removed is 1 +(1/5)=6/5. The ‘effective’ number remaining for draw one is 4 /5.
Indeed, (3.63) then becomes
P(R1|RlaterB)=4/5
2=2
5, (3.65)
in agreement with our better motivated, but less intuitive, calculation (3.57).
3.4 Expectations
Another way of looking at this result appeals more strongly to our intuition and generalizes
far beyond the present problem. We can hardly suppose that the reader is not already familiarwith the idea of expectation, but this is the ﬁrst time it has appeared in the present work, sowe pause to deﬁne it. If a variable quantity Xcan take on the particular values ( x
1,..., xn)
innmutually exclusive and exhaustive situations, and the robot assigns corresponding
probabilities ( p1,p2,..., pn) to them, then the quantity
/angbracketleftX/angbracketright=E(X)=n/summationdisplay
i=1pixi (3.66)

<<<PAGE 99>>>

3 Elementary sampling theory 67
is called the expectation (in the older literature, mathematical expectation orexpectation
value )o f X. It is a weighted average of the possible values, weighted according to their
probabilities. Statisticians and mathematicians generally use the notation E(X); but physi-
cists, having already pre-empted Eto stand for energy and electric ﬁeld, use the bracket
notation/angbracketleftX/angbracketright. We shall use both notations here; they have the same meaning, but sometimes
one is easier to read than the other.
Like most of the standard terms that arose out of the distant past, the term ‘expectation’
seems singularly inappropriate to us; for it is almost never a value that anyone ‘expects’ toﬁnd. Indeed, it is often known to be an impossible value. But we adhere to it because ofcenturies of precedent.
Given R
later, what is the expectation of the number of red balls in the urn for draw number
one? There are three mutually exclusive possibilities compatible with Rlater:
R2W3,W2R3,R2R3 (3.67)
for which Mis (1,1,0), respectively, and for which the probabilities are as in (3.64) and
(3.65):
P(R2W3|RlaterB)=P(R2W3|B)
P(Rlater|B)=(1/2)×(2/3)
(5/6)=2
5, (3.68)
P(W2R3|RlaterB)=2
5, (3.69)
P(R2R3|RlaterB)=1
5. (3.70)
So
/angbracketleftM/angbracketright=1×2
5+1×2
5+0×1
5=4
5. (3.71)
Thus, what we called intuitively the ‘effective’ value of Min (3.63) is really the expectation
ofM.
We can now state (3.63) in a more cogent way: when the fraction F=M/Nof red balls
is known, then the Bernoulli urn rule applies and P(R1|B)=F. When Fis unknown, the
probability for red is the expectation of F:
P(R1|B)=/angbracketleftF/angbracketright≡E(F). (3.72)
IfMandNare both unknown, the expectation is over the joint probability distribution for
MandN.
That a probability is numerically equal to the expectation of a fraction will prove to be a
general rule that holds as well in thousands of far more complicated situations, providingone of the most useful and common rules for physical prediction. We leave it as an exercisefor the reader to show that the more general result (3.56) can also be calculated in the waysuggested by (3.72).

<<<PAGE 100>>>

68 Part 1 Principles and elementary applications
3.5 Other forms and extensions
The hypergeometric distribution (3.22) can be written in various ways. The nine factorials
can be organized into binomial coefﬁcients also as follows:
h(r|N,M,n)=/parenleftbiggn
r/parenrightbigg/parenleftbiggN−n
M−r/parenrightbigg
/parenleftbiggN
M/parenrightbigg . (3.73)
But the symmetry under exchange of Mandnis still not evident; to see it we must write
out (3.22) or (3.73) in full, displaying all the individual factorials.
We may also rewrite (3.22), as an aid to memory, in a more symmetric form: the probability
for drawing exactly rred balls and wwhite ones in n=r+wdraws, from an urn containing
Rred and Wwhite, is
h(r)=/parenleftbiggR
r/parenrightbigg/parenleftbiggW
w/parenrightbigg
/parenleftbiggR+W
r+w/parenrightbigg, (3.74)
and in this form it is easily generalized. Suppose that, instead of only two colors, there are
kdifferent colors of balls in the urn, N1of color 1, N2of color 2, ..., Nkof color k. The
probability for drawing r1balls of color 1, r2of color 2, ...,rkof color kinn=/summationtextridraws
is, as the reader may verify, the generalized hypergeometric distribution:
h(r1···rk|N1···Nk)=/parenleftbiggN1
r1/parenrightbigg
···/parenleftbiggNk
rk/parenrightbigg
/parenleftbigg/summationtextNi/summationtextri/parenrightbigg. (3.75)
3.6 Probability as a mathematical tool
From the result (3.75) one may obtain a number of identities obeyed by the binomial
coefﬁcients. For example, we may decide not to distinguish between colors 1 and 2; i.e. aball of either color is declared to have color ‘ a’. Then from (3.75) we must have, on the one
hand,
h(r
a,r3,..., rk|Na,N3,..., Nk)=/parenleftbiggNa
ra/parenrightbigg/parenleftbiggN3
r3/parenrightbigg
···/parenleftbiggNk
rk/parenrightbigg
/parenleftbigg/summationtextNi/summationtextri/parenrightbigg (3.76)
with
Na=N1+N2, ra=r1+r2. (3.77)

<<<PAGE 101>>>

3 Elementary sampling theory 69
But the event racan occur for any values of r1,r2satisfying (3.77), and so we must have
also, on the other hand,
h(ra,r3,..., rk|Na,N3,..., Nk)=ra/summationdisplay
r1=0h(r1,ra−r1,r3,..., rk|N1,..., Nk).(3.78)
Then, comparing (3.76) and (3.78), we have the identity
/parenleftbiggNa
ra/parenrightbigg
=ra/summationdisplay
r1=0/parenleftbiggN1
r1/parenrightbigg/parenleftbiggN2
ra−r1/parenrightbigg
. (3.79)
Continuing in this way, we can derive a multitude of more complicated identities obeyed
by the binomial coefﬁcients. For example,
/parenleftbiggN1+N2+N3
ra/parenrightbigg
=ra/summationdisplay
r1=0r1/summationdisplay
r2=0/parenleftbiggN1
r1/parenrightbigg/parenleftbiggN2
r2/parenrightbigg/parenleftbiggN3
ra−r1−r2/parenrightbigg
. (3.80)
In many cases, probabilistic reasoning is a powerful tool for deriving purely mathematical
results; more examples of this are given by Feller (1950, Chap. 2 & 3) and in later chaptersof the present work.
3.7 The binomial distribution
Although somewhat complicated mathematically, the hypergeometric distribution arises
from a problem that is very clear and simple conceptually; there are only a ﬁnite number ofpossibilities and all the above results are exact for the problems as stated. As an introductionto a mathematically simpler, but conceptually far more difﬁcult, problem, we examine alimiting form of the hypergeometric distribution.
The complication of the hypergeometric distribution arises because it is taking into ac-
count the changing contents of the urn; knowing the result of any draw changes the prob-ability for red for any other draw. But if the number Nof balls in the urn is very large
compared with the number drawn ( N/greatermuchn), then this probability changes very little, and
in the limit N→∞ we should have a simpler result, free of such dependencies. To verify
this, we write the hypergeometric distribution (3.22) as
h(r|N,M,n)=/bracketleftbigg1
Nr/parenleftbiggM
r/parenrightbigg/bracketrightbigg/bracketleftbigg1
Nn−r/parenleftbiggN−M
n−r/parenrightbigg/bracketrightbigg
/bracketleftbigg1
Nn/parenleftbiggN
n/parenrightbigg/bracketrightbigg . (3.81)
The ﬁrst factor is
1
Nr/parenleftbiggM
r/parenrightbigg
=1
r!M
N/parenleftbiggM
N−1
N/parenrightbigg/parenleftbiggM
N−2
N/parenrightbigg
···/parenleftbiggM
N−r−1
N/parenrightbigg
, (3.82)

<<<PAGE 102>>>

70 Part 1 Principles and elementary applications
and in the limit N→∞,M→∞,M/N→f,w eh a v e
1
Nr/parenleftbiggM
r/parenrightbigg
→fr
r!. (3.83)
Likewise,
1
Nn−r/parenleftbiggM−1
n−r/parenrightbigg
→(1−f)n−r
(n−r)!, (3.84)
1
Nn/parenleftbiggN
n/parenrightbigg
→1
n!. (3.85)
In principle, we should, of course, take the limit of the product in (3.81), not the product of
the limits. But in (3.81) we have deﬁned the factors so that each has its own independentlimit, so the result is the same; the hypergeometric distribution goes into
h(r|N,M,n)→b(r|n,f)≡/parenleftbiggn
r/parenrightbigg
f
r(1−f)n−r(3.86)
called the binomial distribution, because evaluation of the generating function (3.24) now
reduces to
G(t)≡n/summationdisplay
r=0b(r|n,f)tr=(1−f+ft)n, (3.87)
an example of Newton’s binomial theorem.
Figure 3.1 compares three hypergeometric distributions with N=15,30,100 and
M/N=0.4,n=10 to the binomial distribution with n=10,f=0.4. All have their peak
0123456789
r0.00.10.20.30.40.5
P
R
O
B
A
B
I
L
I
T
Y15
30
100
∞
↓
Fig. 3.1. The hypergeometric distribution for N=15,30,100,∞.

<<<PAGE 103>>>

3 Elementary sampling theory 71
atr=4, and all distributions have the same ﬁrst moment /angbracketleftr/angbracketright=E(r)=4, but the binomial
distribution is broader.
The N=15 hypergeometric distribution is zero for r=0 and r>6, since on drawing
ten balls from an urn containing only six red and nine white, it is not possible to get fewerthan one or more than six red balls. When N>100 the hypergeometric distribution agrees
so closely with the binomial that for most purposes it would not matter which one we used.Analytical properties of the binomial distribution are collected in Chapter 7. In Chapter 9we ﬁnd, in connection with signiﬁcance tests, situations where the binomial distribution isexact for purely combinatorial reasons in a ﬁnite sample space, Eq. (9.46).
We can carry out a similar limiting process on the generalized hypergeometric distribution
(3.75). It is left as an exercise to show that in the limit where all N
i→∞ in such a way
that the fractions
fi≡Ni/summationtextNj(3.88)
tend to constants, (3.75) goes into the multinomial distribution
m(r1···rk|f1···fk)=r!
r1!···rk!fr1
1···frk
k, (3.89)
where r≡/summationtextri. And, as in (3.87), we can deﬁne a generating function of ( k−1) variables,
from which we can prove that (3.89) is correctly normalized and derive many other usefulresults.
Exercise 3.2. Suppose an urn contains N=/summationtextNiballs, N1of color 1, N2of color
2,..., Nkof color k. We draw mballs without replacement; what is the probability
that we have at least one of each color? Supposing k=5, all Ni=10, how many do
we need to draw in order to have at least a 90% probability for getting a full set?
Exercise 3.3. Suppose that in the previous exercise kis initially unknown, but we
know that the urn contains exactly 50 balls. Drawing out 20 of them, we ﬁnd threedifferent colors; now what do we know about k? We know from deductive reasoning
(i.e. with certainty) that 3 ≤k≤33; but can you set narrower limits k
1≤k≤k2within
which it is highly likely to be?Hint: This question goes beyond the sampling theory of this chapter because, like
most real scientiﬁc problems, the answer depends to some degree on our commonsense judgments; nevertheless, our rules of probability theory are quite capable ofdealing with it, and persons with reasonable common sense cannot differ appreciablyin their conclusions.

<<<PAGE 104>>>

72 Part 1 Principles and elementary applications
Exercise 3.4. The Murns are now numbered 1 to M, and Mballs, also numbered
1t oM, are thrown into them, one in each urn. If the numbers of a ball and its urn are
the same, we have a match. Show that the probability for at least one match is
h=M/summationdisplay
k=1(−1)k+1/k! (3.90)
AsM→∞ , this converges to 1 −1/e=0.632. The result is surprising to many,
because, however large Mis, there remains an appreciable probability for no match
at all.
Exercise 3.5. Nballs are tossed into Murns; there are evidently MNways this can
be done. If the robot considers them all equally likely, what is the probability that each
urn receives at least one ball?
3.8 Sampling with replacement
Up to now, we have considered only the case where we sample without replacement; and
that is evidently appropriate for many real situations. For example, in a quality controlapplication, what we have called simply ‘drawing a ball’ might consist of taking a manu-factured item, such as an electric light bulb, from a carton of similar light bulbs and testing
it to destruction. In a chemistry experiment, it might consist of weighing out a sample ofan unknown protein, then dissolving it in hot sulfuric acid to measure its nitrogen content.In either case, there can be no thought of ‘drawing that same ball’ again.
But suppose now that, being less destructive, we sample balls from the urn and, after
recording the ‘color’ (i.e. the relevant property) of each, we replace it in the urn beforedrawing the next ball. This case, of sampling with replacement, is enormously more com-plicated conceptually, but, with some assumptions usually made, ends up being simplermathematically than sampling without replacement. Let us go back to the probability fordrawing two red balls in succession. Denoting by B
/primethe same background information as
before, except for the added stipulation that the balls are to be replaced, we still have an
equation like (3.9):
P(R1R2|B/prime)=P(R1|B/prime)P(R2|R1B/prime) (3.91)
and the ﬁrst factor is still, evidently, ( M/N); but what is the second one?
Answering this would be, in general, a very difﬁcult problem, requiring much additional
analysis if the background information B/primeincludes some simple but highly relevant common
sense information that we all have. What happens to that red ball that we put back in theurn? If we merely dropped it into the urn, and immediately drew another ball, then it was

<<<PAGE 105>>>

3 Elementary sampling theory 73
left lying on the top of the other balls (or in the top layer of balls), and so it is more likely to
be drawn again than any other speciﬁed ball whose location in the urn is unknown. But thisupsets the whole basis of our calculation, because the probability for drawing any particular(ith) ball is no longer given by the Bernoulli urn rule which led to (3.11).
3.8.1 Digression: a sermon on reality vs. models
The difﬁculty we face here is that many things which were irrelevant from symmetry, as
long as the robot’s state of knowledge was invariant under any permutation of the balls,suddenly become relevant, and, by one of our desiderata of rationality, the robot must take
into account all the relevant information it has. But the probability for drawing any particularball now depends on such details as the exact size and shape of the urn, the size of the balls,
the exact way in which the ﬁrst one was tossed back in, the elastic properties of balls and urn,the coefﬁcients of friction between balls and between ball and urn, the e xact way you reach
in to draw the second ball, etc. In a symmetric situation, all of these details are irrelevant.
Even if all these relevant data were at hand, we do not think that a team of the world’s best
scientists and mathematicians, backed up by all the world ’s computing facilities, would be
able to solve the problem; or would even know how to get started on it. Still, it would notbe quite right to say that the problem is unsolvable in principle ; only so complicated that it
is not worth anybody’s time to think about it. So what do we do?
In probability theory there is a very clever trick for handling a problem that becomes too
difﬁcult. We just solve it anyway by:
(1) making it still harder;
(2) redeﬁning what we mean by ‘solving’ it, so that it becomes something we cando;
(3) inventing a digniﬁed and technical-sounding word to describe this procedure, which has the
psychological effect of concealing the real nature of what we have done, and making it appearrespectable.
In the case of sampling with replacement, we apply this strategy as follows.
(1) Suppose that, after tossing the ball in, we shake up the urn. However complicated the problem was
initially, it now becomes many orders of magnitude more complicated, because the solution nowdepends on every detail of the precise way we shake it, in addition to all the factors mentionedabove.
(2) We now assert that the shaking has somehow made all these details irrelevant, so that the problem
reverts back to the simple one where the Bernoulli urn rule applies.
(3) We invent the digniﬁed-sounding word randomization to describe what we have done. This term is,
evidently, a euphemism, whose real meaning is: deliberately throwing away relevant information
when it becomes too complicated for us to handle .
We have described this procedure in laconic terms, because an antidote is needed for the
impression created by some writers on probability theory, who attach a kind of mysticalsigniﬁcance to it. For some, declaring a problem to be ‘randomized’ is an incantation with

<<<PAGE 106>>>

74 Part 1 Principles and elementary applications
the same purpose and effect as those uttered by an exorcist to drive out evil spirits; i.e. it
cleanses their subsequent calculations and renders them immune to criticism. We agnosticsoften envy the True Believer, who thus acquires so easily that sense of security which isforever denied to us.
However, in defense of this procedure, we have to admit that it often leads to a useful
approximation to the correct solution; i.e. the complicated details, while undeniably rele-vant in principle, might nevertheless have little numerical effect on the answers to certainparticularly simple questions, such as the probability for drawing rred balls in ntrials
when nis sufﬁciently small. But from the standpoint of principle, an element of vagueness
necessarily enters at this point; for, while we may feel intuitively that this leads to a goodapproximation, we have no proof of this, much less a reliable estimate of the accuracy ofthe approximation, which presumably improves with more shaking.
The vagueness is evident particularly in the fact that different people have widely di-
vergent views about how much shaking is required to justify step (2). Witness the minorfuror surrounding a US Government-sponsored and nationally televized game of chancesome years ago, when someone objected that the procedure for drawing numbers from aﬁsh bowl to determine the order of call-up of young men for Military Service was ‘unfair’because the bowl hadn’t been shaken enough to make the drawing ‘truly random’, whateverthat means. Yet if anyone had asked the objector: ‘To whom is it unfair?’ he could not have
given any answer except, ‘To those whose numbers are on top; I don’t know who they are.’But after any amount of further shaking, this will still be true! So what does the shakingaccomplish?
Shaking does not make the result ‘random’, because that term is basically meaningless
as an attribute of the real world; it has no clear deﬁnition applicable in the real world. Thebelief that ‘randomness’ is some kind of real property existing in Nature is a form of themind projection fallacy which says, in effect, ‘I don’t know the detailed causes – therefore –
Nature does not know them.’ What shaking accomplishes is very different. It does not affectNature’s workings in any way; it only ensures that no human is able to exert any wilful
inﬂuence on the result. Therefore, nobody can be charged with ‘ﬁxing’ the outcome.
At this point, you may accuse us of nitpicking, because you know that after all this
sermonizing, we are just going to go ahead and use the randomized solution like everybodyelse does. Note, however, that our objection is not to the procedure itself, provided thatwe acknowledge honestly what we are doing; i.e. instead of solving the real problem, weare making a practical compromise and being, of necessity, content with an approximatesolution. That is something we have to do in all areas of applied mathematics, and there isno reason to expect probability theory to be any different.
Our objection is to the belief that by randomization we somehow make our subsequent
equations exact; so exact that we can then subject our solution to all kinds of extremeconditions and believe the results, when applied to the real world. The most serious andmost common error resulting from this belief is in the derivation of limit theorems (i.e.when sampling with replacement, nothing prevents us from passing to the limit n→∞
and obtaining the usual ‘laws of large numbers’). If we do not recognize the approximate

<<<PAGE 107>>>

3 Elementary sampling theory 75
nature of our starting equations, we delude ourselves into believing that we have proved
things (such as the identity of probability and limiting frequency) that are just not true inreal repetitive experiments.
The danger here is particularly great because mathematicians generally regard these limit
theorems as the most important and sophisticated fruits of probability theory, and have atendency to use language which implies that they are proving properties of the real world.Our point is that these theorems are valid properties of the abstract mathematical model
that was deﬁned and analyzed . The issue is: to what extent does that model resemble the
real world? It is probably safe to say that no limit theorem is directly applicable in the realworld, simply because no mathematical model captures every circumstance that is relevantin the real world. Anyone who believes that he is proving things about the real world, is avictim of the mind projection fallacy.
Let us return to the equations. What answer can we now give to the question posed after
Eq. (3.91)? The probability P(R
2|R1B/prime) of dra wing a red ball on the second draw clearly
depends not only on NandM, but also on the fact that a red one has already been drawn and
replaced. But this latter dependence is so complicated that we can’t, in real life, take it intoaccount; so we shake the urn to ‘randomize’ the problem, and then declare R
1to be irrelevant:
P(R2|R1B/prime)=P(R2|B/prime)=M/N. After drawing and replacing the second ball, we again
shake the urn, declare it ‘randomized,’ and set P(R3|R2R1B/prime)=P(R3|B/prime)=M/N, etc. In
this approximation, the probability for drawing a red ball at anytrial is M/N.
This is not just a repetition of what we learned in (3.37); what is new here is that the
result now holds whatever information the robot may have about what happened in the
other trials . This leads us to write the probability for drawing exactly rred balls in ntrials,
regardless of order, as
/parenleftbiggn
r/parenrightbigg/parenleftbiggM
N/parenrightbiggr/parenleftbiggN−M
N/parenrightbiggn−r
, (3.92)
which is just the binomial distribution (3.86). Randomized sampling with replacement from
an urn with ﬁnite Nhas approximately the same effect as passage to the limit N→∞
without replacement.
Evidently, for small n, this approximation will be quite good; but for large nthese small
errors can accumulate (depending on exactly how we shake the urn, etc.) to the point where(3.92) is misleading. Let us demonstrate this by a simple, but realistic, extension of theproblem.
3.9 Correction for correlations
Suppose that, from an intricate logical analysis, drawing and replacing a red ball increases
the probability for a red one at the next draw by some small amount /epsilon1>0, while drawing
and replacing a white one decreases the probability for a red one at the next draw by a(possibly equal) small quantity δ>0; and that the inﬂuence of earlier draws than the last

<<<PAGE 108>>>

76 Part 1 Principles and elementary applications
one is negligible compared with /epsilon1orδ. You may call this effect a small ‘propensity’ if
you like; at least it expresses a physical causation that operates only forward in time. Then,letting Cstand for all the above background information, including the statements just made
about correlations and the information that we draw nballs, we have
P(R
k|Rk−1C)=p+/epsilon1, P(Rk|Wk−1C)=p−δ,
P(Wk|Rk−1C)=1−p−/epsilon1, P(Wk|Wk−1C)=1−p+δ,(3.93)
where p≡M/N. From this, the probability for drawing rred and ( n−r) white balls in
any speciﬁed order is easily seen to be
p(p+/epsilon1)c(p−δ)c/prime(1−p+δ)w(1−p−/epsilon1)w/prime(3.94)
if the ﬁrst draw is red; whereas, if the ﬁrst is white, the ﬁrst factor in (3.94) should be
(1−p). Here, cis the number of red draws preceded by red ones, c/primethe number of red
preceded by white, wthe number of white draws preceded by white, and w/primethe number of
white preceded by red. Evidently,
c+c/prime=/bracketleftbiggr−1
r/bracketrightbigg
,w+w/prime=/bracketleftbiggn−r
n−r−1/bracketrightbigg
, (3.95)
the upper and lower cases holding when the ﬁrst draw is red or white, respectively.
When rand ( n−r) are small, the presence of /epsilon1andδin (3.94) makes little difference,
and the equation reduces for all practical purposes to
pr(1−p)n−r, (3.96)
as in the binomial distribution (3.92). But, as these numbers increase, we can use relations
of the form
/parenleftbigg
1+/epsilon1
p/parenrightbiggc
/similarequalexp/braceleftbigg/epsilon1c
p/bracerightbigg
, (3.97)
and (3.94) goes into
pr(1−p)n−rexp/braceleftbigg/epsilon1c−δc/prime
p+δw−/epsilon1w/prime
1−p/bracerightbigg
. (3.98)
The probability for drawing rred and ( n−r) white balls now depends on the order in which
red and white appear, and, for a given /epsilon1, when the numbers c,c/prime,w,w/primebecome sufﬁciently
large, the probability can become arbitrarily large (or small) compared with (3.92).
We see this effect most clearly if we suppose that N=2M,p=1/2, in which case we
will surely have /epsilon1=δ. The exponential factor in (3.98) then reduces to
exp/braceleftbig
2/epsilon1[(c−c/prime)+(w−w/prime)]/bracerightbig
. (3.99)
This shows that (i) as the number nof draws tends to inﬁnity, the probability for results
containing ‘long runs’ (i.e. long strings of red (or white) balls in succession), becomesarbitrarily large compared with the value given by the ‘randomized’ approximation; (ii) this

<<<PAGE 109>>>

3 Elementary sampling theory 77
effect becomes appreciable when the numbers ( /epsilon1c), etc., become of order unity. Thus, if
/epsilon1=10−2, the randomized approximation can be trusted reasonably well as long as n<
100; beyond that, we might delude ourselves by using it. Indeed, it is notorious that inreal repetitive experiments where conditions appear to be the same at each trial, suchruns – although extremely improbable on the randomized approximation – are neverthelessobserved to happen.
Now let us note how the correlations expressed by (3.93) affect some of our previous
calculations. The probabilities for the ﬁrst draw are of course the same as (3.8); we now usethe notation
p=P(R
1|C)=M
N, q=1−p=P(W1|C)=N−M
N. (3.100)
But for the second trial we have instead of (3.35)
P(R2|C)=P(R2R1|C)+P(R2W1|C)
=P(R2|R1C)P(R1|C)+P(R2|W1C)P(W1|C)
=(p+/epsilon1)p+(p−δ)q
=p+(p/epsilon1−qδ),(3.101)
and continuing for the third trial
P(R3|C)=P(R3|R2C)P(R2|C)+P(R3|W2C)P(W2|C)
=(p+/epsilon1)(p+p/epsilon1−qδ)+(p−δ)(q−p/epsilon1+qδ)
=p+(1+/epsilon1+δ)(p/epsilon1−qδ).(3.102)
We see that P(Rk|C) is no longer independent of k; the correlated probability distribution
is no longer exchangeable. But does P(Rk|C) approach some limit as k→∞ ?
It would be almost impossible to guess the general P(Rk|C) by induction, following the
method in (3.101) and (3.102) a few steps further. For this calculation we need a morepowerful method. If we write the probabilities for the kth trial as a vector,
V
k≡/bracketleftBigg
P(Rk|C)
P(Wk|C)/bracketrightBigg
, (3.103)
then (3.93) can be expressed in matrix form:
Vk=MV k−1, (3.104)
with
M=/parenleftBigg[p+/epsilon1][p−δ]
[q−/epsilon1][q+δ]/parenrightBigg
. (3.105)
This deﬁnes a Markov chain of probabilities, and Mis called the transition matrix .N o w
the slow induction of (3.101) and (3.102) proceeds instantly to any distance we please:
Vk=Mk−1V1. (3.106)

<<<PAGE 110>>>

78 Part 1 Principles and elementary applications
So, to have the general solution, we need only to ﬁnd the eigenvectors and eigenvalues of
M. The characteristic polynomial is
C(λ)≡det(Mij−λδij)=λ2−λ(1+/epsilon1+δ)+(/epsilon1+δ) (3.107)
so the roots of C(λ)=0 are the eigenvalues
λ1=1
λ2=/epsilon1+δ.(3.108)
Now, for any 2×2 matrix
M=/parenleftbiggab
cd/parenrightbigg
(3.109)
with an eigenvalue λ, the corresponding (non-normalized) right eigenvector is
x=(bλ−a), (3.110)
for which we have at once Mx=λx. Therefore, our eigenvectors are
x1=/parenleftbiggp−δ
q−/epsilon1/parenrightbigg
, x2=/parenleftbigg1
−1/parenrightbigg
. (3.111)
These are not orthogonal, since Mis not a symmetric matrix. Nevertheless, if we use (3.111)
to deﬁne the transformation matrix
S=/parenleftbigg[p−δ]1
[q−/epsilon1]−1/parenrightbigg
, (3.112)
we ﬁnd its inverse to be
S−1=1
1−/epsilon1−δ/parenleftbigg11
[q−/epsilon1]−[p−δ]/parenrightbigg
, (3.113)
and we can verify by direct matrix multiplication that
S−1MS=/Lambda1=/parenleftbiggλ10
0λ2/parenrightbigg
, (3.114)
where /Lambda1is the diagonalized matrix. Then we have for any r, positive, negative, or even
complex:
Mr=S/Lambda1rS−1(3.115)
or
Mr=1
1−/epsilon1−δ/parenleftBiggp−δ+[/epsilon1+δ]r[q−/epsilon1][ p−δ][1−(/epsilon1+δ)r]
[q−/epsilon1][1−(/epsilon1+δ)r] q−/epsilon1+[/epsilon1+δ]r[p−δ]/parenrightBigg
, (3.116)
and since
V1=/parenleftbiggp
q/parenrightbigg
(3.117)

<<<PAGE 111>>>

3 Elementary sampling theory 79
the general solution (3.106) sought is
P(Rk|C)=(p−δ)−(/epsilon1+δ)k−1(p/epsilon1−qδ)
1−/epsilon1−δ. (3.118)
We can check that this agrees with (3.100), (3.101) and (3.102). From examining (3.118)
it is clear why it would have been almost impossible to guess the general formula byinduction. When /epsilon1=δ=0, this reduces to P(R
k|C)=p, supplying the proof promised
after Eq. (3.37).
Although we started this discussion by supposing that /epsilon1andδwere small and positive, we
have not actually used that assumption, and so, whatever their values, the solution (3.118) isexact for the abstract model that we have deﬁned. This enables us to include two interestingextreme cases. If not small, /epsilon1andδmust be at least bounded, because all quantities in (3.93)
must be probabilities (i.e. in [0 ,1]). This requires that
−p≤/epsilon1≤q,−q≤δ≤p, (3.119)
or
−1≤/epsilon1+δ≤1. (3.120)
But from (3.119), /epsilon1+δ=1 if and only if /epsilon1=q,δ=p, in which case the transition matrix
reduces to the unit matrix
M=/parenleftbigg10
01/parenrightbigg
(3.121)
and there are no ‘transitions’. This is a degenerate case in which the positive correlations
are so strong that whatever color happens to be drawn on the ﬁrst trial is certain to be drawnalso on all succeeding ones:
P(R
k|C)=p, allk. (3.122)
Likewise, if /epsilon1+δ=−1, then the transition matrix must be
M=/parenleftbigg01
10/parenrightbigg
(3.123)
and we have nothing but transitions; i.e. the negative correlations are so strong that the
colors are certain to alternate after the ﬁrst draw:
P(Rk|C)=/braceleftBigg
p, kodd
q, keven/bracerightBigg
. (3.124)
This case is unrealistic because intuition tells us rather strongly that /epsilon1andδshould be
positive quantities; surely, whatever the logical analysis used to assign the numerical valueof/epsilon1, leaving a red ball in the top layer must increase , not decrease, the probability of red
on the next draw. But if /epsilon1andδmust not be negative, then the lower bound in (3.120) is
really zero, which is achieved only when /epsilon1=δ=0. Then Min (3.105) becomes singular,
and we revert to the binomial distribution case already discussed.

<<<PAGE 112>>>

80 Part 1 Principles and elementary applications
In the intermediate and realistic cases where 0 <|/epsilon1+δ|<1, the last term of (3.118)
attenuates exponentially with k, and in the limit
P(Rk|C)→p−δ
1−/epsilon1−δ. (3.125)
But although these single-trial probabilities settle down to steady values as in an exchange-
able distribution, the underlying correlations are still at work and the limiting distributionis not exchangeable. To see this, let us consider the conditional probabilities P(R
k|RjC).
These are found by noting that the Markov chain relation (3.104) holds whatever the vector
Vk−1; i.e. whether or not it is the vector generated from V1as in (3.106). Therefore, if we
are given that red occurred on the jth trial, then
Vj=/parenleftbigg1
0/parenrightbigg
, (3.126)
and we have from (3.104)
Vk=Mk−jVj, j≤k, (3.127)
from which, using (3.115),
P(Rk|RjC)=(p−δ)+(/epsilon1+δ)k−j(q−/epsilon1)
1−/epsilon1−δ, j<k, (3.128)
which approaches the same limit (3.125). The forward inferences are about what we might
expect; the steady value (3.125) plus a term that decays exponentially with distance. But
the backward inferences are different; note that the general product rule holds, as always:
P(RkRj|C)=P(Rk|RjC)P(Rj|C)=P(Rj|RkC)P(Rk|C). (3.129)
Therefore, since we have seen that P(Rk|C)/negationslash=P(Rj|C), it follows that
P(Rj|RkC)/negationslash=P(Rk|RjC). (3.130)
The backward inference is still possible, but it is no longer the same formula as the forward
inference as it would be in an exchangeable sequence.
As we shall see later, this example is the simplest possible ‘baby’ version of a very
common and important physical problem: an irreversible process in the ‘Markovian ap-proximation’. Another common technical language would call it an autoregressive model
of ﬁrst order. It can be generalized greatly to the case of matrices of arbitrary dimension andmany-step or continuous, rather than single-step, memory inﬂuences. But for reasons notedearlier (confusion of inference and causality in the literature of statistical mechanics), thebackward inference part of the solution is almost always missed. Some try to do backwardinference by extrapolating the forward solution backward in time, with quite bizarre andunphysical results. Therefore the reader is, in effect, conducting new research in doing thefollowing exercise.

<<<PAGE 113>>>

3 Elementary sampling theory 81
Exercise 3.6. Find the explicit formula P(Rj|RkC) for the backward inference cor-
responding to the result (3.128) by using (3.118) and (3.129). (a) Explain the reasonfor the difference between forward and backward inferences in simple intuitive terms.(b) In what way does the backward inference differ from the forward inference extrap-olated backward? Which is more reasonable intuitively? (c) Do backward inferencesalso decay to steady values? If so, is a property somewhat like exchangeability restoredfor events sufﬁciently separated? For example, if we consider only every tenth draw orevery hundredth draw, do we approach an exchangeable distribution on this subset?
3.10 Simpliﬁcation
The above formulas (3.100)–(3.130) hold for any /epsilon1,δsatisfying the inequalities (3.119).
But, on surveying them, we note that a remarkable simpliﬁcation occurs if they satisfy
p/epsilon1=qδ. (3.131)
For then we have
p−δ
1−/epsilon1−δ=p,q−/epsilon1
1−/epsilon1−δ=q,/epsilon1+δ=/epsilon1
q, (3.132)
and our main results (3.118) and (3.128) collapse to
P(Rk|C)=p,allk, (3.133)
P(Rk|RjC)=P(Rj|RkC)=p+q/parenleftbigg/epsilon1
q/parenrightbigg|k−j|
, allk,j. (3.134)
The distribution is still not exchangeable, since the conditional probabilities (3.134) still
depend on the separation |k−j|of the trials; but the symmetry of forward and backward
inferences is restored, even though the causal inﬂuences /epsilon1,δoperate only forward. Indeed,
we see from our derivation of (3.40) that this forward–backward symmetry is a necessaryconsequence of (3.133), whether or not the distribution is exchangeable.
What is the meaning of this magic condition (3.131)? It does not make the matrix M
assume any particularly simple form, and it does not turn off the effect of the correlations.
What it does is to make the solution (3.133) invariant; that is, the initial vector (3.117)
is then equal but for normalization to the eigenvector x
1in (3.111), so the initial vector
remains unchanged by the matrix (3.105).
In general, of course, there is no reason why this simplifying condition should hold.
Yet in the case of our urn, we can see a kind of rationale for it. Suppose that when theurn has initially Nballs, they are in Llayers. Then, after withdrawing one ball, there are
about n=(N−1)/Lof them in the top layer, of which we expect about npto be red,
nq=n(1−p) white. Now we toss the drawn ball back in. If it was red, the probability of

<<<PAGE 114>>>

82 Part 1 Principles and elementary applications
getting red at the next draw if we do not shake the urn is about
np+1
n+1=p+1−p
n+O/parenleftBig1
n2/parenrightBig
, (3.135)
and if it is white the probability for getting white at the next draw is about
n(1−p)+1
n+1=1−p+p
n+O/parenleftBig1
n2/parenrightBig
. (3.136)
Comparing with (3.93) we see that we could estimate /epsilon1andδby
/epsilon1/similarequalq/n,δ/similarequalp/n (3.137)
whereupon our magic condition (3.131) is satisﬁed. Of course, the argument just given is
too crude to be called a derivation, but at least it indicates that there is nothing inherentlyunreasonable about (3.131). We leave it for the reader to speculate about what signiﬁcanceand use this curious fact might have, and whether it generalizes beyond the Markovianapproximation.
We have now had a ﬁrst glimpse of some of the principles and pitfalls of standard sampling
theory. All the results we have found will generalize greatly, and will be useful parts of our‘toolbox’ for the applications to follow.
3.11 Comments
In most real physical experiments we are not, literally, drawing from any ‘urn’. Neverthe-
less, the idea has turned out to be a useful conceptual device, and in the 250 years sinceBernoulli’s Ars Conjectandi it has appeared to scientists that many physical measurements
are very much like ‘drawing from Nature’s urn’. But to some the word ‘urn’ has gruesome
connotations, and in much of the literature one ﬁnds such expressions as ‘drawing from apopulation’.
In a few cases, such as recording counts from a radioactive source, survey sampling, and
industrial quality control testing, one is quite literally drawing from a real, ﬁnite population,and the urn analogy is particularly apt. Then the probability distributions just found, andtheir limiting forms and generalizations noted in Chapter 7, will be appropriate and useful.In some cases, such as agricultural experiments or testing the effectiveness of a new medicalprocedure, our credulity can be strained to the point where we see a vague resemblance tothe urn problem.
In other cases, such as ﬂipping a coin, making repeated measurements of the temperature
and wind velocity, the position of a planet, the weight of a baby, or the price of a commodity,the urn analogy seems so farfetched as to be dangerously misleading. Yet in much ofthe literature one still uses urn distributions to represent the data probabilities, and triesto justify that choice by visualizing the experiment as drawing from some ‘hypotheticalinﬁnite population’ which is entirely a ﬁgment of our imagination. Functionally, the mainconsequence of this is strict independence of successive draws, regardless of all other

<<<PAGE 115>>>

3 Elementary sampling theory 83
circumstances. Obviously, this is not sound reasoning, and a price must be paid eventually
in erroneous conclusions.
This kind of conceptualizing often leads one to suppose that these distributions represent
not just our prior state of knowledge about the data, but the actual long-run variability of
the data in such experiments. Clearly, such a belief cannot be justiﬁed; anyone who claimsto know in advance the long-run results in an experiment that has not been performed isdrawing on a vivid imagination, not on any fund of actual knowledge of the phenomenon.Indeed, if that inﬁnite population is only imagined, then it seems that we are free to imagineany population we please.
From a mere act of the imagination we cannot learn anything about the real world.
To suppose that the resulting probability assignments have any real physical meaning isjust another form of the mind projection fallacy. In practice, this diverts our attention toirrelevancies and away from the things that really matter (such as information about thereal world that is not expressible in terms of any sampling distribution, or does not ﬁtinto the urn picture, but which is nevertheless highly cogent for the inferences we want tomake). Usually, the price paid for this folly is missed opportunities; had we recognized thatinformation, more accurate and/or more reliable inferences could have been made.
Urn-type conceptualizing is capable of dealing with only the most primitive kind of
information, and really sophisticated applications require us to develop principles that gofar beyond the idea of urns. But the situation is quite subtle, because, as we stressed beforein connection with G¨ odel’s theorem, an erroneous argument does not necessarily lead to a
wrong conclusion. In fact, as we shall ﬁnd in Chapter 9, highly sophisticated calculationssometimes lead us back to urn-type distributions, for purely mathematical reasons that hav e
nothing to do conceptually with urns or populations. The hypergeometric and binomial
distributions found in this chapter will continue to reappear, because they have a fundamentalmathematical status quite independent of arguments that we used to ﬁnd them here.
2
On the other hand, we could imagine a different problem in which we would have full
conﬁdence in urn-type reasoning leading to the binomial distribution, although it probablynever arises in the real world. If we had a large supply {U
1,U2,..., Un}of urns known to
have identical contents, and those contents are known with certainty in advance – and thenwe used a fresh new urn for each draw – then we would assign P(A)=M/Nfor every
draw, strictly independently of what we know about any other draw. Such prior informationwould take precedence over any amount of data. If we did not know the contents ( M,N)
of the urns – but we knew they all had identical contents – this strict independence wouldbe lost, because then every draw from one urn would tell us something about the contentsof the other urns, although it does not physically inﬂuence them.
From this we see once again that logical dependence is in general very different from
causal physical dependence. We belabor this point so much because it is not recognizedat all in most expositions of probability theory, and this has led to errors, as is suggested
2In a similar way, exponential functions appear in all parts of analysis because of their fundamental mathematical properties,
although their conceptual basis varies widely.

<<<PAGE 116>>>

84 Part 1 Principles and elementary applications
by Exercise 3.6. In Chapter 4 we shall see a more serious error of this kind (see the
discussion following Eq. (4.29)). But even when one manages to avoid actual error, torestrict probability theory to problems of physical causation is to lose its most importantapplications. The extent of this restriction – and the magnitude of the missed opportunity –does not seem to be realized by those who are victims of this fallacy.
Indeed, most of the problems we have solved in this chapter are not considered to be
within the scope of probability theory, and do not appear at all in those expositions whichregard probability as a physical phenomenon. Such a view restricts one to a small subclass ofthe problems which can be dealt with usefully by probability theory as logic. For example,in the ‘physical probability’ theory it is not even considered legitimate to speak of theprobability for an outcome at a speciﬁed trial; yet that is exactly the kind of thing aboutwhich it is necessary to reason in conducting scientiﬁc inference. The calculations of thischapter have illustrated this many times.
In summary: in each of the applications to follow, one must consider whether the experi-
ment is really ‘like’ drawing from an urn; if it is not, then we must go back to ﬁrst principles
and apply the basic product and sum rules in the new context. This may or may not yieldthe urn distributions.
3.11.1 A look ahead
The probability distributions found in this chapter are called sampling distributions ,o rdirect
probabilities , which indicate that they are of the following form: Given some hypothesis H
about the phenomenon being observed (in the case just studied, the contents ( M,N) of the
urn), what is the probability that we shall obtain some speciﬁed data D(in this case, some
sequence of red and white balls)? Historically, the term ‘direct probability’ has long had theadditional connotation of reasoning from a supposed physical cause to an observable effect.But we have seen that not all sampling distributions can be so interpreted. In the presentwork we shall not use this term, but use ‘sampling distribution’ in the general sense ofreasoning from some speciﬁed hypothesis to potentially observable data , whether the link
between hypothesis and data is logical or causal.
Sampling distributions make predictions, such as the hypergeometric distribution (3.22),
about potential observations (for example, the possible values and relative probabilitiesof different values of r). If the correct hypothesis is indeed known, then we expect the
predictions to agree closely with the observations. If our hypothesis is not correct, they may
be very different; then the nature of the discrepancy gives us a clue toward ﬁnding a better
hypothesis. This is, very broadly stated, the basis for scientiﬁc inference. Just how wide thedisagreement between prediction and observation must be in order to justify our rejectingthe present hypothesis and seeking a new one, is the subject of signiﬁcance tests . It was the
need for such tests in astronomy that led Laplace and Gauss to study probability theory inthe 18th and 19th centuries.
Although sampling theory plays a dominant role in conventional pedagogy, in the real
world such problems are an almost negligible minority. In virtually all real problems of

<<<PAGE 117>>>

3 Elementary sampling theory 85
scientiﬁc inference we are in just the opposite situation; the data Dare known but the correct
hypothesis His not. Then the problem facing the scientist is of the inverse type: Given the
data D, what is the probability that some speciﬁed hypothesis His true? Exercise 3.3
above was a simple introduction to this kind of problem. Indeed, the scientist’s motivationfor collecting data is usually to enable him to learn something about the phenomenon inthis way.
Therefore, in the present work our attention will be directed almost exclusively to the
methods for solving the inverse problem. This does not mean that we do not calculatesampling distributions; we need to do this constantly and it may be a major part of ourcomputational job. But it does mean that for us the ﬁnding of a sampling distribution isalmost never an end in itself.
Although the basic rules of probability theory solve such inverse problems just as readily
as sampling problems, they have appeared quite different conceptually to many writers.A new feature seems present, because it is obvious that the question: ‘What do you knowabout the hypothesis Hafter seeing the data D?’ cannot have any defensible answer unless
we take into account: ‘What did you know about Hbefore seeing D?’ But this matter of
previous knowledge did not ﬁgure in any of our sampling theory calculations. When weasked: ‘What do you know about the data given the contents ( M,N) of the urn?’ we did
not seem to consider: ‘What did you know about the data before you knew ( M,N)?’
This apparent dissymmetry, it will turn out, is more apparent than real; it arises mostly
from some habits of notation that we have slipped into, which obscure the basic unity ofall inference. But we shall need to understand this very well before we can use probabilitytheory effectively for hypothesis tests and their special cases, signiﬁcance tests. In the nextchapter we turn to this problem.

<<<PAGE 118>>>

4
Elementary hypothesis testing
I conceive the mind as a moving thing, and arguments as the motive forces
driving it in one direction or the other.
John Craig (1699)
John Craig was a Scottish mathematician, and one of the ﬁrst scholars to recognize the
merit in Isaac Newton’s new invention of ‘the calculus’. The above sentence, written some
300 years ago in one of the early attempts to create a mathematical model of reasoning,requires changing by only one word in order to describe our present attitude. We would lik e
to think that our minds are swayed not by arguments, but by evidence. And if fallible humans
do not always achieve this objectivity, our desiderata were chosen with the aim of achievingit in our robot. Therefore to see how our robot’s mind is ‘driven in one direction or the other’by new evidence, we examine some applications that, although simple mathematically, haveproved to have practical importance in several different ﬁelds.
As is clear from the basic desiderata listed in Chapter 1, the fundamental principle
underlying all probabilistic inference is:
To form a judgment about the likely truth or falsity of any proposition A,
the correct procedure is to calculate the probability that A is true:
P(A|E
1E2···) (4.1)
conditional on all the evidence at hand.
In a sampling context (i.e. when Astands for some data set), this principle has seemed
obvious to everybody from the start. We used it implicitly throughout Chapter 3 withoutfeeling any need to state it explicitly. But when we turn to a more general context, theprinciple needs to be stressed because it has not been obvious to all workers (as we shallsee repeatedly in later chapters).
The essence of ‘honesty’ or ‘objectivity’ demands that we take into account all the
evidence we have, not just some arbitrarily chosen subset of it. Any such choice wouldamount either to ignoring evidence that we have, or presuming evidence that we do nothave. This leads us to recognize at the outset that some information is always available tothe robot.
86

<<<PAGE 119>>>

4 Elementary hypothesis testing 87
4.1 Prior probabilities
Generally, when we give the robot its current problem, we will give it also some new
information or ‘data’ Dpertaining to the speciﬁc matter at hand. But almost always the
robot will have other information which we denote, for the time being, by X. This includes,
at the very least, all its past experience, from the time it left the factory to the time it receivedits current problem. That is always part of the information available, and our desiderata donot allow the robot to ignore it. If we humans threw away what we knew yesterday inreasoning about our problems today, we would be below the level of wild animals; wecould never know more than we can learn in one day, and education and civilization wouldbe impossible.
So to our robot there is no such thing as an ‘absolute’ probability; all probabilities are
necessarily conditional on Xat least. In solving a problem, its inferences should, according to
the principle (4.1), take the form of calculating probabilities of the form P(A|DX). Usually,
part of Xis irrelevant to the current problem, in which case its presence is unnecessary but
harmless; if it is irrelevant, it will cancel out mathematically. Indeed, that is what we reallymean by ‘irrelevant’.
Any probability P(A|X) that is conditional on Xalone is called a prior probability . But
we caution that the term ‘prior’ is another of those terms from the distant past that can beinappropriate and misleading today. In the ﬁrst place, it does not necessarily mean ‘earlierin time’. Indeed, the very concept of time is not in our general theory (although we may
of course introduce it in a particular problem). The distinction is a purely logical one; anyadditional information beyond the immediate data Dof the current problem is by deﬁnition
‘prior information’.
For example, it has happened more than once that a scientist has gathered a mass of data,
but before getting around to the data analysis he receives some surprising new informationthat completely changes his ideas of how the data should be analyzed. That surprisingnew information is, logically, ‘prior information’ because it is not part of the data. Indeed,the separation of the totality of the evidence into two components called ‘data’ and ‘priorinformation’ is an arbitrary choice made by us, only for our convenience in organizing achain of inferences. Although all such organizations must lead to the same ﬁnal results ifthey succeed at all, some may lead to much easier calculations than others. Therefore, wedo need to consider the order in which different pieces of information shall be taken intoaccount in our calculations.
Because of some strange things that have been thought about prior probabilities in the
past, we point out also that it would be a big mistake to think of Xas standing for some
hidden major premise, or some universally valid proposition about Nature. Old miscon-ceptions about the origin, nature, and proper functional use of prior probabilities are stillcommon among those who continue to use the archaic term ‘ a-priori probabilities ’. The
term ‘ a-priori ’ was introduced by Immanuel Kant to denote a proposition whose truth can
be known independently of experience; which is most emphatically what we do notmean
here. Xdenotes simply whatever additional information the robot has beyond what we have

<<<PAGE 120>>>

88 Part 1 Principles and elementary applications
chosen to call ‘the data’. Those who are actively familiar with the use of prior probabil-
ities in current real problems usually abbreviate further, and instead of saying ‘the priorprobability’ or ‘the prior probability distribution’, they say simply, ‘the prior ’.
There is no single universal rule for assigning priors – the conversion of verbal prior
information into numerical prior probabilities is an open-ended problem of logical analysis,to which we shall return many times. At present, four fairly general principles are known –group invariance, maximum entropy, marginalization, and coding theory – which have ledto successful solutions of many different kinds of problems. Undoubtedly, more principlesare waiting to be discovered, which will open up new areas of application.
In conventional sampling theory, the only scenario considered is essentially that of ‘draw-
ing from an urn’, and the only probabilities that arise are those that presuppose the contentsof the ‘urn’ or the ‘population’ already known, and seek to predict what ‘data’ we are likelyto get as a result. Problems of this type can become arbitrarily complicated in the details,and there is a highly developed mathematical literature dealing with them. For example, themassive two-volume work of Feller (1950, 1966) and the weighty compendium of Kendall
and Stuart (1977) are restricted entirely to the calculation of sampling distributions. These
works contain hundreds of nontrivial solutions that are useful in all parts of probabilitytheory, and every worker in the ﬁeld should be familiar with what is available in them.
However, as noted in the preceding chapter, almost all real problems of scientiﬁc inference
involve us in the opposite situation; we already know the data D, and want probability
theory to help us decide on the likely contents of the ‘urn’. Stated more generally, we wantprobability theory to indicate which of a given set of hypotheses {H
1,H2,...}is most likely
to be true in the light of the data and any other evidence at hand. For example, the hypothesesmay be various suppositions about the physical mechanism that is generating the data. Butfundamentally, as in Chapter 3, physical causation is not an essential ingredient of the
problem; what is essential is only that there be some kind of logical connection between
the hypotheses and the data.
To solve this problem does not require any new principles beyond the product rule (3.1)
that we used to ﬁnd conditional sampling distributions; we need only to make a differentchoice of the propositions. Let us now use the notation
X=prior information,
H=some hypothesis to be tested,
D=the data,
and write the product rule in the form
P(DH|X)=P(D|HX)P(H|X)=P(H|DX)P(D|X). (4.2)
We recognize P(D|HX) as the sampling distribution which we studied in Chapter 3, but
now written in a more ﬂexible notation. In Chapter 3 we did not need to take any particularnote of the prior information X, because all probabilities were conditional on H, and so we
could suppose implicitly that the general verbal prior information deﬁning the problem wasincluded in H. This is the habit of notation that we have slipped into, which has obscured

<<<PAGE 121>>>

4 Elementary hypothesis testing 89
the uniﬁed nature of all inference. Throughout all of sampling theory one can get away
with this, and as a result the very term ‘prior information’ is absent from the literature ofsampling theory.
Now, however, we are advancing to probabilities that are not conditional on H, but are
still conditional on X, so we need separate notations for them. We see from (4.2) that to
judge the likely truth of Hin the light of the data, we need not only the sampling probability
P(D|HX) but also the prior probabilities for DandH:
P(H|DX)=P(H|X)P(D|HX)
P(D|X). (4.3)
Although the derivation (4.2)–(4.3) is only the same mathematical result as (3.50)–(3.51),
it has appeared to many workers to have a different logical status. From the start it hasseemed clear how one determines numerical values of sampling probabilities, but not whatdetermines the prior probabilities. In the present work we shall see that this was only an
artifact of an unsymmetrical way of formulating problems, which left them ill-posed. Onecould see clearly how to assign sampling probabilities because the hypothesis Hwas stated
very speciﬁcally; had the prior information Xbeen speciﬁed equally well, it would have
been equally clear how to assign prior probabilities.
When we look at these problems on a sufﬁciently fundamental level and realize how
careful one must be to specify the prior information before we have a well-posed problem,it becomes evident that there is in fact no logical difference between (3.51) and (4.3); exactlythe same principles are needed to assign either sampling probabilities or prior probabilities,and one man’s sampling probability is another man’s prior probability.
The left-hand side of (4.3), P(H|DX), is generally called a ‘ posterior probability ’, with
the same caveat that this means only ‘logically later in the particular chain of inference
being made’, and not necessarily ‘later in time’. And again the distinction is conventional,
not fundamental; one man’s prior probability is another man’s posterior probability. Thereis really only one kind of probability; our different names for them refer only to a particularway of organizing a calculation.
The last factor in (4.3) also needs a name, and it is called the likelihood L (H). To explain
current usage, we may consider a ﬁxed hypothesis and its implications for different datasets; as we have noted before, the term P(D|HX), in its dependence on Dfor ﬁxed H,
is called the ‘sampling distribution’. But we may consider a ﬁxed data set in the light ofvarious different hypotheses {H,H
/prime,...}; in its dependence on Hfor ﬁxed D,P(D|HX)
is called the ‘likelihood’.
A likelihood L(H) is not itself a probability for H; it is a dimensionless numerical function
which, when multiplied by a prior probability and a normalization factor, may become aprobability. Because of this, constant factors are irrelevant, and may be struck out. Thus, thequantity L(H
i)=y(D)P(D|HiX) is equally deserving to be called the likelihood, where y
is any positive number which may depend on Dbut is independent of the hypotheses {Hi}.
Equation (4.3) is then the fundamental principle underlying a wide class of scientiﬁc
inferences in which we try to draw conclusions from data. Whether we are trying to learn

<<<PAGE 122>>>

90 Part 1 Principles and elementary applications
the character of a chemical bond from nuclear magnetic resonance data, the effectiveness
of a medicine from clinical data, the structure of the earth’s interior from seismic data,the elasticity of a demand from economic data, or the structure of a distant galaxy fromtelescopic data, (4.3) indicates what probabilities we need to ﬁnd in order to see whatconclusions are justiﬁed by the totality of our evidence. If P(H|DX) is very close to one
(zero), then we may conclude that His very likely to be true (false) and act accordingly.
But if P(H|DX) is not far from 1 /2, then the robot is warning us that the available evidence
is not sufﬁcient to justify any very conﬁdent conclusion, and we need to obtain more andbetter evidence.
4.2 Testing binary hypotheses with binary data
The simplest nontrivial problem of hypothesis testing is the one where we have only two
hypotheses to test and only two possible data values. Surprisingly, this turns out to be a
realistic and valuable model of many important inference and decision problems. Firstly,let us adapt (4.3) to this binary case. It gives us the probability that His true, but we could
have written it equally well for the probability that His false:
P(
H|DX)=P(H|X)P(D|HX)
P(D|X), (4.4)
and if we take the ratio of the two equations,
P(H|DX)
P(H|DX)=P(H|X)
P(H|X)P(D|HX)
P(D|HX), (4.5)
the term P(D|X) will drop out. This may not look like any particular advantage, but the
quantity that we have here, the ratio of the probability that His true to the probability that
it is false, has a technical name. We call it the ‘ odds ’ on the proposition H. So if we write
the ‘odds on H,g i v e n DandX’, as the symbol
O(H|DX)≡P(H|DX)
P(H|DX), (4.6)
then we can combine (4.3) and (4.4) into the following form:
O(H|DX)=O(H|X)P(D|HX)
P(D|HX). (4.7)
The posterior odds on His (are?) equal to the prior odds multiplied by a dimensionless
factor, which is also called a likelihood ratio. The odds are (is?) a strict monotonic function
of the probability, so we could equally well calculate this quantity.1
1Our uncertain phrasing here indicates that ‘odds’ is a grammatically slippery word. We are inclined to agree with purists who
say that it is, like ‘mathematics’ and ‘physics’, a singular noun in spite of appearances. Yet the urge to follow the vernacular and
treat it as plural is sometimes irresistible, and so we shall be knowingly inconsistent and use it both ways, judging what seemseuphonious in each case.

<<<PAGE 123>>>

4 Elementary hypothesis testing 91
In many applications it is convenient to take the logarithm of the odds because of the fact
that we can then add up terms. Now we could take logarithms to any base we please, andthis cost the writer some trouble. Our analytical expressions always look neater in termsof natural (base e) logarithms. But back in the 1940s and 1950s when this theory was ﬁrstdeveloped, we used base 10 logarithms because they were easier to ﬁnd numerically; thefour-ﬁgure tables would ﬁt on a single page. Finding a natural logarithm was a tediousprocess, requiring leaﬁng through enormous old volumes of tables.
Today, thanks to hand calculators, all such tables are obsolete and anyone can ﬁnd a ten-
digit natural logarithm just as easily as a base 10 logarithm. Therefore, we started happilyto rewrite this section in terms of the aesthetically prettier natural logarithms. But the resulttaught us that there is another, even stronger, reason for using base 10 logarithms. Our mindsare thoroughly conditioned to the base 10 number system, and base 10 logarithms have animmediate, clear intuitive meaning to all of us. However, we just don’t know what to makeof a conclusion that is stated in terms of natural logarithms, until it is translated back intobase 10 terms. Therefore, we re-rewrote this discussion, reluctantly, back into the old, ugly
base 10 convention.
We deﬁne a new function, which we will call the evidence forHgiven DandX:
e(H|DX)≡10 log
10O(H|DX). (4.8)
This is still a monotonic function of the probability . By using the base 10 and putting the
factor 10 in front, we are now measuring evidence in decibels (hereafter abbreviated to db).
The evidence for H,g i v e n D, is equal to the prior evidence plus the number of db provided
by working out the log likelihood in the last term below:
e(H|DX)=e(H|X)+10 log10/bracketleftbiggP(D|HX)
P(D|HX)/bracketrightbigg
. (4.9)
Now suppose that this new information Dactually consisted of several different
propositions:
D=D1D2D3···. (4.10)
Then we could expand the likelihood ratio by successive applications of the product rule:
e(H|DX)=e(H|X)+10 log10/bracketleftbiggP(D1|HX)
P(D1|HX)/bracketrightbigg
+10 log10/bracketleftbiggP(D2|D1HX)
P(D2|D1HX)/bracketrightbigg
+···.
(4.11)
But, in many cases, the probability for getting D2is not inﬂuenced by knowledge of D1:
P(D2|D1HX)=P(D2|HX). (4.12)
One then says conventionally that D1andD2areindependent . Of course, we should really
say that the probabilities which the robot assigns to them are independent. It is a semantic
confusion to attribute the property of ‘independence’ to propositions or events; for thatimplies, in common language, physical causal independence. We are concerned here with
the very different quality of logical independence.

<<<PAGE 124>>>

92 Part 1 Principles and elementary applications
To emphasize this, note that neither kind of independence implies the other. Two events
may be in fact causally dependent (i.e. one inﬂuences the other); but for a scientist whohas not yet discovered this, the probabilities representing his state of knowledge – whichdetermine the only inferences he is able to make – might be independent. On the otherhand, two events may be causally independent in the sense that neither exerts any causalinﬂuence on the other (for example, the apple crop and the peach crop); yet we perceive alogical connection between them, so that new information about one changes our state ofknowledge about the other. Then for us their probabilities are not independent.
Quite generally, as the robot’s state of knowledge represented by Hand Xchanges,
probabilities conditional on them may change from independent to dependent or vice versa ;
yet the real properties of the events remain the same. Then one who attributed the propertyof dependence or independence to the events would be, in effect, claiming for the robot thepower of psychokinesis. We must be vigilant against this confusion between reality and astate of knowledge about reality, which we have called the ‘mind projection fallacy’.
The point we are making is not just pedantic nitpicking; we shall see presently (Eq. (4.29))
that it has very real, substantive consequences. In Chapter 3 we have discussed some of
the conditions under which these probabilities might be independent, in connection withsampling from a very large known population and sampling with replacement. In the closingComments section, we noted that whether urn probabilities do or do not factor can dependon whether we do or do not know that the contents of several urns are the same. In our presentproblem, as in Chapter 3, to interpret causal independence as logical independence, or tointerpret logical dependence as causal dependence, has led some to nonsensical conclusionsin ﬁelds ranging from psychology to quantum theory.
In case these several pieces of data are logically independent given ( HX) and also given
(
HX), (4.11) becomes
e(H|DX)=e(H|X)+10/summationdisplay
ilog10/bracketleftbiggP(Di|HX)
P(Di|HX)/bracketrightbigg
, (4.13)
where the sum is over all the extra pieces of information that we obtain.
To get some feeling for numerical values here, let us construct Table 4.1. We have
three different scales on which we can measure degrees of plausibility: evidence, odds, or
probability; they are all monotonic functions of each other. Zero db of evidence correspondsto odds of 1 or to a probability of 1/2. Now, every physicist or electrical engineer knowsthat 3 db means a factor of 2 (nearly) and 10 db is a factor of 10 (exactly); and so if we goin steps of 3 db, or 10, we can construct this table very easily.
It is obvious from Table 4.1 why it is very cogent to give evidence in decibels. When
probabilities approach one or zero, our intuition doesn’t work very well. Does the differencebetween the probability of 0.999 and 0.9999 mean a great deal to you? It certainly doesn’t tothe writer. But after living with this for only a short while, the difference between evidenceof plus 30 db and plus 40 db does have a clear meaning to us. It is now in a scale whichour minds comprehend naturally. This is just another example of the Weber–Fechner law;
intuitive human sensations tend to be logarithmic functions of the stimulus.

<<<PAGE 125>>>

4 Elementary hypothesis testing 93
Table 4.1. Evidence, odds, and probability.
eO p
0 1:1 1 /2
3 2:1 2 /3
6 4:1 4 /5
10 10:1 10 /11
20 100:1 100 /101
30 1000:1 0.99940 10
4:1 0.9999
−e 1/O 1−p
Even the factor of 10 in (4.8) is appropriate. In the original acoustical applications, it was
introduced so that a 1 db change in sound intensity would be, psychologically, about the
smallest change perceptible to our ears. With a little familiarity and a little introspection, wethink that the reader will agree that a 1 db change in evidence is about the smallest increment
of plausibility that is perceptible to our intuition. Nobody claims that the Weber–Fechner
law is a precise rule for all human sensations, but its general usefulness and appropriatenessis clear; almost always it is not the absolute change, but more nearly the relative change, in
some stimulus that we perceive. For an interesting account of the life and work of GustavTheodor Fechner (1801–87), see Stigler (1986c).
Now let us apply (4.13) to a speciﬁc calculation, which we shall describe as a problem of
industrial quality control (although it could be phrased equally well as a problem of cryp-tography, chemical analysis, interpretation of a physics experiment, judging two economictheories, etc.). Following the example of Good (1950), we assume numbers which are notvery realistic in order to elucidate some points of principle. Let the prior information X
consist of the following statements:
X≡We have 11 automatic machines turning out widgets, which pour out of the
machines into 11 boxes. This example corresponds to a very early stage in thedevelopment of widgets, because ten of the machines produce one in six defective.The 11th machine is even worse; it makes one in three defective. The output of eachmachine has been collected in an unlabeled box and stored in the warehouse.
We choose one of the boxes and test a few of the widgets, classifying them as ‘good’ or
‘bad’. Our job is to decide whether we chose a box from the bad machine or not; that is,whether we are going to accept this batch or reject it.
Let us turn this job over to our robot and see how it performs. Firstly, it must ﬁnd the
prior evidence for the various propositions of interest. Let
A≡we chose a bad batch (1/3 defective),
B≡we chose a good batch (1/6 defective).

<<<PAGE 126>>>

94 Part 1 Principles and elementary applications
The qualitative part of our prior information Xtold us that there are only two possibilities;
so in the ‘logical environment’ generated by X, these propositions are related by negation:
given X, we can say that
A=B, B=A. (4.14)
The only quantitative prior information is that there are 11 machines and we do not know
which one made our batch, so, by the principle of indifference, P(A|X)=1/11, and
e(A|X)=10 log10P(A|X)
P(A|X)=10 log10(1/11)
(10/11)=−10 db, (4.15)
whereupon we have necessarily e(B|X)=+10 db.
Evidently, in this problem the only properties of Xthat will be relevant for the calculation
are just these numbers, ±10 db. Any other kind of prior information which led to the same
numbers would give us just the same mathematical problem from this point on. So, it is notnecessary to say that we are talking only about a problem where there are 11 machines, and
so on. There might be only one machine, and the prior information consists of our previous
experience with it.
Our reason for stating the problem in terms of 11 machines was that we have, thus far,
only one principle, indifference, by which we can convert raw information into numericalprobability assignments. We interject this remark because of a famous statement by Feller(1950) about a single machine, which we consider in Chapter 17 after accumulating somemore evidence pertaining to the issue he raised. To our robot, it makes no difference howmany machines there are; the only thing that matters is the prior probability for a bad batch,however this information was arrived at.
2
Now, from this box we take out a widget and test it to see whether it is defective.
If we pull out a bad one, what will that do to the evidence for a bad batch? That willadd to it
10 log
10P(bad|AX)
P(bad|AX)db (4.16)
where P(bad|AX) represents the probability for getting a bad widget, given A, etc.; these
are sampling probabilities, and we have already seen how to calculate them. Our procedureis very much ‘like’ drawing from an urn, and, as in Chapter 3, on one draw our datum
Dnow consists only of a binary choice: (good/bad). The sampling distribution P(D|HX)
2Notice that in this observation we have the answer to a point raised in Chapter 1: How does one make the robot ‘cognizant’
of the semantic meanings of the various propositions that it is being called upon to deal with? The answer is that the robot
does not need to be ‘cognizant’ of anything. If we give it, in addition to the model and the data, a list of the propositions to
be considered, with their prior probabilities, this conveys all the ‘meaning’ needed to deﬁne the robot’s mathematical problem
for the applications now being considered. Later, we shall wish to design a more sophisticated robot which can also help us toassign prior probabilities by analysis of complicated but incomplete information, by the maximum entropy principle. But, eventhen, we can always deﬁne the robot’s mathematical problem without going into semantics.

<<<PAGE 127>>>

4 Elementary hypothesis testing 95
reduces to
P(bad|AX)=1
3, P(good|AX)=2
3, (4.17)
P(bad|BX)=1
6, P(good|BX)=5
6. (4.18)
Thus, if we ﬁnd a bad widget on the ﬁrst draw, this will increase the evidence for Aby
10 log10(1/3)
(1/6)=10 log102=3d b. (4.19)
What happens now if we draw a second bad one? We are sampling without replacement, so
as we noted in (3.11), the factor (1/3) in (4.19) should be updated to
(N/3)−1
N−1=1
3−2
3(N−1), (4.20)
where Nis the number of widgets in the batch. But, to avoid this complication, we suppose
thatNis very much larger than any number that we contemplate testing; i.e. we are going
to test such a negligible fraction of the batch that the proportion of bad and good ones in
it is not changed appreciably by the drawing. Then the limiting form of the hypergeomet-
ric distribution (3.22) will apply, namely the binomial distribution (3.86). Thus we shallconsider that, given AorB, the probability for drawing a bad widget is the same at every
draw regardless of what has been drawn previously; so every bad one we draw will provide+3 db of evidence in favor of hypothesis A.
Now suppose we ﬁnd a good widget. Using (4.14), we get evidence forAof
10 log
10P(good|AX)
P(good|BX)=10 log10(2/3)
(5/6)=−0.97 db, (4.21)
but let’s call it−1 db. Again, this will hold for any draw, if the number in the batch is
sufﬁciently large. If we have inspected nwidgets, of which we found nbbad ones and ng
good ones, the evidence that we have the bad batch will be
e(A|DX)=e(A|X)+3nb−ng. (4.22)
You see how easy this is to do once we have set up the logarithmic machinery. The robot’s
mind is ‘driven in one direction or the other’ in a very simple, direct way.
Perhaps this result gives us a deeper insight into why the Weber–Fechner law applies
to intuitive plausible inference. Our ‘evidence’ function is related to the data that we haveobserved in about the most natural way imaginable; a given increment of evidence corre-sponds to a given increment of data. For example, if the ﬁrst 12 widgets we test yield ﬁvebad ones, then
e(A|DX)=−10+3×5−7=−2d b, (4.23)
or, the probability for a bad batch is raised by the data from (1 /11)=0.09 to
P(A|DX)/similarequal0.4.

<<<PAGE 128>>>

96 Part 1 Principles and elementary applications
In order to get at least 20 db of evidence for proposition A, how many bad widgets would
we have to ﬁnd in a certain sequence of n=nb+ngtests? This requires
3nb−ng=4nb−n=n(4fb−1)≥20, (4.24)
so, if the fraction fb≡nb/nof bad ones remains greater than 1/4, we shall accumulate
eventually 20 db, or any other positive amount, of evidence for A. It appears that fb=1/4
is the threshold value at which the test can provide no evidence for either AorBover the
other; but note that the +3 and−1 in (4.22) are only approximate. The exact threshold
fraction of bad ones is, from (4.19) and (4.21),
ft=log/parenleftbig5
4/parenrightbig
log(2)+log/parenleftbig5
4/parenrightbig=0.2435292 , (4.25)
in which the base of the logarithms does not matter. Sampling fractions greater (less) than
this give evidence for Aover B(Bover A); but if the observed fraction is close to the
threshold, it will require many tests to accumulate enough evidence.
Now all we have here is the probability or odds or evidence, whatever you wish to call
it, of the proposition that we chose the bad batch. Eventually, we have t o make a decision:
we’re going to accept it, or we’re going to reject it. How are we going to do that? Well, we
might decide beforehand: if the probability of proposition Areaches a certain level, then
we’ll decide that Ais true. If it gets down to a certain value, then we ’ll decide that Ais false.
There is nothing in probability theory per se which can tell us where to put these critical
levels at which we make our decision. This has to be based on value judgments: what are theconsequences of making wrong decisions, and what are the costs of making further tests?
This takes us into the realm of decision theory, considered in Chapters 13 and 14. But for
now it is clear that making one kind of error (accepting a bad batch) might be more seriousthan making the other kind of error (rejecting a good batch). That would have an obviouseffect on where we place our critical levels.
So we could give the robot some instructions such as ‘If the evidence for Ais greater
than+0 db, then reject this batch (it is more likely to be bad than good). If it goes as low
as−13 db, then accept it (there is at least a 95% probability that it is good). Otherwise,
continue testing.’ We start doing the tests, and every time we ﬁnd a bad widget the evidencefor the bad batch goes up 3 db; every time we ﬁnd a good one, it goes down 1 db. The teststerminate as soon as we enter either the accept or reject region for the ﬁrst time.
The way described above is how our robot would do it if we told it to reject or accept on
the basis that the posterior probability of proposition Areaches a certain level. This very
useful and powerful procedure is called ‘sequential inference’ in the statistical literature,the term signifying that the number of tests is not determined in advance, but dependson the sequence of data values that we ﬁnd; at each step in the sequence we make oneof three choices: (a) stop with acceptance; (b) stop with rejection; (c) make another test.The term should not be confused with what has come to be called ‘sequential analysiswith nonoptional stopping’, which is a serious misapplication of probability theory; see thediscussions of optional stopping in Chapters 6 and 17.

<<<PAGE 129>>>

4 Elementary hypothesis testing 97
4.3 Nonextensibility beyond the binary case
The binary hypothesis testing problem turned out to have such a beautifully simple solution
that we might like to extend it to the case of more than two hypotheses. Unfortunately, theconvenient independent additivity over data sets in (4.13) and the linearity in (4.22) do notgeneralize. By ‘independent additivity’ we mean that the increment of evidence from a givendatum D
idepends only on DiandH; not on what other data have been observed. As (4.11)
shows, we always have additivity, but not independent additivity unless the probabilitiesare independent.
We state the reason for this nonextensibility in the form of an exercise for the reader; to
prepare for it, suppose that we have nhypotheses{H
1,..., Hn}which on prior information
Xare mutually exclusive and exhaustive:
P(HiHj|X)=P(Hi|X)δij,n/summationdisplay
i=1P(Hi|X)=1. (4.26)
Also, we have acquired mdata sets{D1,..., Dm}, and as a result the probabilities of the
Hibecome updated in odds form by (4.7) , which now becomes
O(Hi|D1,..., DmX)=O(Hi|X)P(D1,..., Dm|HiX)
P(D1,..., Dm|HiX). (4.27)
It is common that the numerator will factor because of the logical independence of the Dj,
given Hi:
P(D1,..., Dm|HiX)=/productdisplay
jP(Dj|HiX),1≤i≤n. (4.28)
If the denominator should also factor,
P(D1,..., Dm|HiX)=/productdisplay
jP(Dj|HiX),1≤i≤n, (4.29)
then (4.27) would split into a product of the updates produced by each Djseparately, and
the log-odds formula (4.9) would again take a form independently additive over the Djas
in (4.13).
Exercise 4.1. Show that there is no such nontrivial extension of the binary case. More
speciﬁcally, prove that if (4.28) and (4.29) hold with n>2, then at most one of the
factors
P(D1|HiX)
P(D1|HiX)···P(Dm|HiX)
P(Dm|HiX)(4.30)
is different from unity , therefore at most one of the data sets Djcan produce any
updating of the probability for Hi.

<<<PAGE 130>>>

98 Part 1 Principles and elementary applications
This has been a controversial issue in the literature of artiﬁcial intelligence (Glymour,
1985; R. W. Johnson, 1985). Those who fail to distinguish between logical independenceand causal independence would suppose that (4.29) is always valid, provided only that no
D
iexerts a physical inﬂuence on any other Dj. But we have already noted the folly of such
reasoning; this is an occasion when the semantic confusion can lead to serious numericalerrors. When n=2, (4.29) follows from (4.28). But when n>2, (4.29) is such a strong
condition that it would reduce the whole problem to a triviality not worth considering; wehave left it (Exercise 4.1) for the reader to examine the equations to see why this is so.Because of Cox’s theorems expounded in Chapter 2, the verdict of probability theory isthat our conclusion about nonextensibility can be evaded only at the price of committingdemonstrable inconsistencies in our reasoning.
To head off a possible misunderstanding of what is being said here, let us add the follow-
ing. However many hypotheses we have in mind, it is of course always possible to pick outtwo of them and compare them only against each other. This reverts to the binary choice casealready analyzed, and the independent additive property holds within that smaller problem(ﬁnd the status of an hypothesis relative to a single alternative).
We could organize this by choosing A
1as the standard ‘null hypothesis’ and comparing
each of the others with it by solving n−1 binary problems; whereupon the relative status
of any two propositions is determined. For example, if A5andA7are favored over A1by
22.3 db and 31.9 db, respectively, then A7is favored over A5by 31.9−22.3=9.6d b .I f
such binary comparisons provide all the information one wants, there is no need to considermultiple hypothesis testing at all.
But that would not solve our present problem; giv en the solutions of all these binary
problems, it would still require a calculation as big as the one we are about to do toconvert that information into the absolute status of any given hypothesis relative to the
entire class of nhypotheses. Here we are going after the solution of the larger problem
directly.
In any event, we need not base our stance merely on claims of authoritarian ﬁnality for an
abstract theorem; more constructively, we now show that probability theory does lead us toa deﬁnite, useful procedure for multiple hypothesis testing, which gives us a much deeperinsight and makes it clear why the independent additivity cannot, and should not , hold
when n>2. It would then ignore some very cogent information; that is the demonstrable
inconsistency.
4.4 Multiple hypothesis testing
Suppose that something very remarkable happens in the sequential test just discussed: we
tested 50 widgets and every one turned out to be bad. According to (4.22), that would giveus 150 db of evidence for the proposition that we had the bad batch. e(A|E) would end up
at+140 db, which is a probability which differs from unity by one part in 10
14.N o w ,o u r
common sense rejects this conclusion; some kind of innate skepticism rises in us. If youtest 50 widgets and you ﬁnd that all 50 are bad, you are not willing to believe that you have

<<<PAGE 131>>>

4 Elementary hypothesis testing 99
a batch in which only one in three are really bad. So what went wrong here? Why doesn’t
our robot work in this case?
We have to recognize that our robot is immature; it reasons like a four-year-old child does.
The remarkable thing about small children is that you can tell them the most ridiculous thingsand they will accept it all with wide open eyes, open mouth, and it never occurs to them to
question you. They will believe anything you tell them.
Adults learn to make mental allowance for the reliability of the source when told some-
thing hard to believe. One might think that, ideally, the information which our robot shouldhave put into its memory was not that we had either 1/3 bad or 1/6 bad; the informationit should have put in was that some unreliable human said that we had either 1/3 bad or
1/6 bad.
More generally, it might be useful in many problems if the robot could take into ac-
count the fact that the information it has been given may not be perfectly reliable to beginwith. There is always a small chance that the prior information or data that we fed tothe robot was wrong. In a real problem there are always hundreds of possibilities, and if
you start out the robot with dogmatic initial statements which say that there are only two
possibilities, then of course you must not expect its conclusions to make sense in everycase.
To accomplish this skeptically mature behavior automatically in a robot is something
that we can do, when we come to consider signiﬁcance tests; but fortunately, after furtherreﬂection, we realize that for most problems the present immature robot is what we wantafter all, because we have better control over it.
Wedowant the robot to believe whatever we tell it; it would be dangerous to have a robot
who suddenly became skeptical in a way not under our control when we tried to tell it some
true but startling – and therefore highly important – new fact. But then the onus is on us tobe aware of this situation, and when there is a good chance that skepticism will be needed,it is up to us to give the robot a hint about how to be skeptical for that particular problem.
In the present problem we can give the hint which makes the robot skeptical about A
when it sees ‘too many’ bad widgets, by providing it with one more possible hypothesis,which notes that possibility and therefore, in effect, puts the robot on the lookout for it.As before, let proposition Amean that we have a box with 1/3 defective, and proposition
Bis the statement that we have a box with 1/6 bad. We add a third proposition, C, that
something went entirely wrong with the machine that made our widgets, and it is turningout 99% defective.
Now we have to adjust our prior probabilities to take this new possibility into account.
But we do not want this to be a major change in the nature of the problem; so let hypothesis
Chave a very low prior probability P(C|X)o f1 0
−6(−60 db). We could write out Xas
a verbal statement which would imply this, but as in the previous footnote we can statewhat proposition Xis, with no ambiguity at all for the robot’s purposes, simply by giving
it the probabilities conditional on X, of all the propositions that we’re going to use in this
problem. In that way we don’t state everything about Xthat is important to us conceptually;
but we state everything about Xthat is relevant to the robot’s current mathematical problem.

<<<PAGE 132>>>

100 Part 1 Principles and elementary applications
So, suppose we start out with these initial probabilities:
P(A|X)=1
11(1−10−6),
P(B|X)=10
11(1−10−6), (4.31)
P(C|X)=10−6,
where
A≡we have a box with 1/3 defective,
B≡we have a box with 1/6 defective,
C≡we have a box with 99/100 defective.
The factors (1−10−6) are practically negligible, and for all practical purposes we will start
out with the initial values of evidence:
−10 db for A,
+10 db for B,
−60 db for C.(4.32)
The data proposition Dstands for the statement that ‘ mwidgets were tested and every one
was defective’. Now, from (4.9), the posterior evidence for proposition Cis equal to the
prior evidence plus ten times the logarithm of this probability ratio:
e(C|DX)=e(C|X)+10 log10P(D|CX)
P(D|CX). (4.33)
Our discussion of sampling with and without replacement in Chapter 3 shows that
P(D|CX)=/parenleftbigg99
100/parenrightbiggm
(4.34)
is the probability that the ﬁrst mare all bad, given that 99% of the machine’s output is bad,
under our assumption that the total number in the box is large compared with the numbermtested.
We also need the probability P(D|
CX), which we can evaluate by two applications of
the product rule (4.3):
P(D|CX)=P(D|X)P(C|DX)
P(C|X). (4.35)
In this problem, the prior information states dogmatically that there are only three possibil-
ities, and so the statement C≡‘Cis false’ implies that either AorBmust be true:
P(C|DX)=P(A+B|DX)=P(A|DX)+P(B|DX), (4.36)

<<<PAGE 133>>>

4 Elementary hypothesis testing 101
where we used the general sum rule (2.66), the negative term dropping out because Aand
Bare mutually exclusive. Similarly,
P(C|X)=P(A|X)+P(B|X). (4.37)
Now, if we substitute (4.36) into (4.35), the product rule will be applicable again in the form
P(AD|X)=P(D|X)P(A|DX)=P(A|X)P(D|AX)
P(BD|X)=P(D|X)P(B|DX)=P(B|X)P(D|BX),(4.38)
and so (4.35) becomes
P(D|CX)=P(D|AX)P(A|X)+P(D|BX)P(B|X)
P(A|X)+P(B|X), (4.39)
in which all probabilities are known from the statement of the problem.
4.4.1 Digression on another derivation
Although we have the desired result (4.39), let us note that there is another way of deriving
it, which is often easier than direct application of (4.3). The principle was introduced in ourderivation of (3.33): resolve the proposition whose probability is desired (in this case D)
into mutually exclusive propositions, and calculate the sum of their probabilities. We can
carry out this resolution in many different ways by ‘introducing into the conversation’ any
set of mutually exclusive and exhaustive propositions {P,Q,R,...}and using the rules of
Boolean algebra:
D=D(P+Q+R+··· )=DP+DQ+DR+···. (4.40)
But the success of the method depends on our cleverness at choosing a particular set for
which we can complete the calculation. This means that the propositions introduced musthave a known kind of relevance to the question being asked; the example of penguins at theend of Chapter 2 will not be helpful if that question has nothing to do with penguins.
In the present case, for evaluation of P(D|
CX), it appears that propositions AandB
have this kind of relevance. Again, we note that proposition Cimplies ( A+B); and so
P(D|CX)=P(D(A+B)|CX)=P(DA+DB|CX)
=P(DA|CX)+P(DB|CX).(4.41)
These probabilities can be factored by the product rule:
P(D|CX)=P(D|ACX)P(A|CX)+P(D|BCX)P(B|CX). (4.42)
But we can abbreviate: P(D|ACX)≡P(D|AX) and P(D|BCX)≡P(D|BX), because,
in the way we set up this problem, the statement that either AorBis true implies that C
must be false. For this same reason, P(C|AX)=1, and so, by the product rule,
P(A|CX)=P(A|X)
P(C|X), (4.43)

<<<PAGE 134>>>

102 Part 1 Principles and elementary applications
and similarly for P(B|CX). Substituting these results into (4.42) and using (4.37), we again
arrive at (4.39). This agreement provides another illustration – and a rather severe test – ofthe consistency of our rules for extended logic.
Returning to (4.39), we have the numerical value
P(D|
CX)=/parenleftbigg1
3/parenrightbiggm/parenleftbigg1
11/parenrightbigg
+/parenleftbigg1
6/parenrightbiggm10
11, (4.44)
and everything in (4.33) is now at hand. If we put all these things together, we ﬁnd that the
evidence for proposition Cis:
e(C|DX)=−60+10 log10/bracketleftBigg/parenleftbig99
100/parenrightbigm
1
11/parenleftbig1
3/parenrightbigm+10
11/parenleftbig1
6/parenrightbigm/bracketrightBigg
. (4.45)
Ifm>5, a good approximation is
e(C|DX)/similarequal−49.6+4.73m, m>5, (4.46)
and if m<3, a crude approximation is
e(C|DX)/similarequal−60+7.73m, m<3. (4.47)
Proposition Cstarts out at−60 db, and the ﬁrst few bad widgets we ﬁnd will each give
about 7.73 db of evidence in favor of C, so the graph of e(C|DX)v s.mwill start upward at
a slope of 7.73. But then the slope drops, when m>5, to 4.73. The evidence for Creaches
0 db when m/similarequal49.6/4.73=10.5. So, ten consecutive bad widgets would be enough to
raise this initially very improbable hypothesis by 58 db, to the place where the robot is readyto consider it very seriously; and 11 consecutive bad ones would take it over the threshold,to where the robot considers it more likely to be true than false.
In the meantime, what is happening to our propositions AandB? As before, Astarts
off at−10 db, Bstarts off at+10 db, and the plausibility for Astarts going up 3 db per
defective widget. But after we’ve found too many bad ones, that skepticism would set in,and you and I would begin to doubt whether the evidence really supports proposition A
after all; proposition Cis becoming a much easier way to explain what is observed. Has the
robot also learned to be skeptical?
After mwidgets have been tested, and all proved to be bad, the evidence for propositions
AandB, and the approximate forms, are as follows:
e(A|DX)=−10+10 log
10/bracketleftBigg/parenleftbig1
3/parenrightbigm
/parenleftbig1
6/parenrightbigm+11
10×10−6/parenleftbig99
100/parenrightbigm/bracketrightBigg
/similarequal/braceleftBigg
−10+3m form<7
+49.6−4.73m form>8/bracerightBigg (4.48)

<<<PAGE 135>>>

4 Elementary hypothesis testing 103
0 5 10 15 20−60−50−40−30−20−1001020
A
BCEvidence, db.
Number of tests.↓
Fig. 4.1. A surprising multiple sequential test wherein a dead hypothesis ( C) is resurrected.
e(B|DX)=+10+10 log10/bracketleftBigg/parenleftbig1
6/parenrightbigm
/parenleftbig1
3/parenrightbigm+11×10−6/parenleftbig99
100/parenrightbigm/bracketrightBigg
/similarequal/braceleftBigg
10−3m form<10
59.6−7.33m form>11/bracerightBigg
.(4.49)
The exact results are summarized in Figure 4.1. We can learn quite a lot about multiple
hypothesis testing from studying this diagram. The initial straight line part of the Aand
Bcurves represents the solution as we found it before we introduced proposition C; the
change in plausibility for propositions AandBstarts off just the same as in the previous
problem. The effect of proposition Cdoes not appear until we have reached the place where
Ccrosses B. At this point, suddenly the character of the Acurve changes; instead of going
on up, at m=7 it has reached its highest value of 10 db. Then it turns around and comes
back down; the robot has indeed learned how to become skeptical. But the Bcurve does
notchange at this point; it continues on linearly until it reaches the place where AandC
have the same plausibility, and at this point it has a change in slope. From then on, it fallsoff more rapidly.
Most people ﬁnd all this surprising and mysterious at ﬁrst glance; but then a little medi-
tation is enough to make us perceive what is happening and why. The change in plausibilityforAdue to one more test arises from the fact that we are now testing hypothesis Aagainst
two alternatives: BandC. But, initially, Bis so much more plausible than C, that for all

<<<PAGE 136>>>

104 Part 1 Principles and elementary applications
practical purposes we are simply testing Aagainst B, and reproducing our previous solution
(4.22). After enough evidence has accumulated to bring the plausibility for Cup to the same
level as B, then from that point on Ais essentially being tested against Cinstead of B,
which is a very different situation.
All of these changes in slope can be interpreted in this way. Once we see this principle, it
is clear that the same thing is going to be true more generally. As long as we have a discreteset of hypotheses, a change in plausibility for any one of them will be approximately theresult of a test of this hypothesis against a single alternative – the single alternative beingthat one of the remaining hypotheses which is most plausible at that time. As the relativeplausibilities of the alternatives change, the slope of the Acurve must also change; this is
the cogent information that would be lost if we tried to retain the independent additive form
(4.13) when n>2.
Whenever the hypotheses are separated by about 10 db or more, then multiple hypothesis
testing reduces approximately to testing each hypothesis against a single alternative. So,seeing this, you can construct curves of the sort shown in Fig. 4.1 very rapidly without
even writing down the equations, because what would happen in the two-hypothesis case
is easily seen once and for all. The diagram has a number of other interesting geometricalproperties, suggested by drawing the six asymptotes and noting their vertical alignment(dotted lines), which we leave for the reader to explore.
All the information needed to construct fairly accurate charts resulting from any se-
quence of good and bad tests is contained in the ‘plausibility ﬂow diagrams’ of Figure 4.2,which summarize the solutions of all those binary problems; every possible way to testone proposition against a single alternative. It indicates, for example, that ﬁnding a good
widget raises the evidence for Bb y1d bi f Bis being tested against A, and by 19.22 db
if it is being tested against C. Similarly, ﬁnding a bad widget raises the evidence for Aby
3d bi f Ais being tested against B, but lowers it by 4.73 db if it is being tested against
C. Likewise, we see that ﬁnding a single good widget lowers the evidence for Cby an
amount that cannot be recovered by two bad ones; so there is a ‘threshold of skepticism’.
Cwill never attain an appreciable probability; i.e. the robot will never become skepti-
cal about propositions AandB, as long as the observed fraction fof bad ones remains
less than 2/3.
More precisely, we deﬁne a threshold fraction f
tthus: as the number of tests m→∞ with
f=mb/m→const.,e(C|DX) tends to+∞ iff>ft, and to−∞ iff<ft. The exact
threshold turns out to be greater than 2/3: ft=0.793951 (Exercise 4.2). If the observed
GOOD: A 1.0 B 19.22 C 18.24 A
BAD: A 3.0 B 7.73 C 4.73 A↓
↓
↓
↓
↓↓
↓
↓
↓
↓↓
↓
Fig. 4.2. Plausibility ﬂow diagrams.

<<<PAGE 137>>>

4 Elementary hypothesis testing 105
fraction of bad widgets remains above this value, the robot will be led eventually to prefer
proposition Cover AandB.
Exercise 4.2. Calculate the exact threshold of skepticism ft(x,y), supposing that
proposition Chas instead of 10−6an arbitrary prior probability P(C|X)=x, and
speciﬁes instead of 99/100 an arbitrary fraction yof bad widgets. Then discuss how the
dependence on xandycorresponds – or fails to correspond – to human common sense.
Hint: In problems like this, always try ﬁrst to get an analytic solution in closed form.
If you are unable to do this, then you must write a short computer program which willdisplay the correct numerical values in tables or graphs.
Exercise 4.3. Show how to make the robot skeptical about both unexpectedly high
and unexpectedly low numbers of bad widgets in the observed sample. Give the fullequations. Note particularly the following: if Ais true, then we would expect, according
to the binomial distribution (3.86), that the observed fraction of bad ones would tendto about 1/3 with many tests, while ifBis true it should tend to 1/6. Suppose that it is
found to tend to the threshold value (4.24), close to 1/4. On sufﬁciently large m, you
and I would then become skeptical about AandB; but intuition tells us that this would
require a much larger mthan ten, which was enough to make us and the robot skeptical
when we ﬁnd them all bad. Do the equations agree with our intuition here, if a newhypothesis Fis introduced which speciﬁes P(bad|FX)/similarequal1/4?
In summary, the role of our new hypothesis Cwas only to be held in abeyance until
needed, like a ﬁre extinguisher. In a normal testing situation it is ‘dead’, playing no part inthe inference because its probability is and remains far below that of the other hypotheses.But a dead hypothesis can be resurrected to life by very unexpected data. Exercises 4.2 and4.3 ask the reader to explore the phenomenon of resurrection of dead hypotheses in moredetail than we do in this chapter, but we return to the subject in Chapter 5.
Figure 4.1 shows an interesting thing. Suppose we had decided to stop the test and accept
hypothesis Aif the evidence for it reached +6 db. As we see, it would overshoot that value
at the sixth trial. If we stopped the testing at that point, then we would never see the rest ofthis curve and see that it really goes down again. If we had continued the testing beyondthis point, then we would have changed our minds again.
At ﬁrst glance this seems disconcerting, but notice that it is inherent in all problems of
hypothesis testing. If we stop the test at any ﬁnite number of trials, then we can never beabsolutely sure that we have made the right decision. It is always possible that still moretests would have led us to change our decision. But note also that probability theory aslogic has automatic built-in safety devices that can protect us against unpleasant surprises.Although it is always possible that our decision is wrong, this is extremely improbable if

<<<PAGE 138>>>

106 Part 1 Principles and elementary applications
our critical level for decision requires e(A|DX) to be large and positive. For example, if
e(A|DX)≥20 db, then P(A|DX)>0.99, and the total probability for all the alternatives
is less than 0.01; then few of us would hesitate to decide conﬁdently in favor of A.
In a real problem we may not have enough data to give such good evidence, and we
might suppose that we could decide safely if the most likely hypothesis Ais well separated
from the alternatives, even though e(A|DX) is itself not large. Indeed, if there are 1000
alternatives but the separation of Afrom the most likely alternative is more than 20 db, then
the odds favor Aby more than 100:1 over any one of the alternatives, and if we were obliged
to make a deﬁnite choice of one hypothesis here and now, there could still be no hesitationin choosing A; it is clearly the best we can do with the information we have. Yet we cannot
do it so conﬁdently, for it is now very plausible that the decision is wrong, because the classof alternatives as a whole is about as probable as A. But probability theory warns us, by the
numerical value of e(A|DX), that this is the case; we need not be surprised by it.
In scientiﬁc inference our job is always to do the best we can with whatever information
we have; there is no advance guarantee that our information will be suf ﬁcient to lead
us to the truth. But many of the supposed difﬁculties arise from an inexperienced user’sfailure to recognize and use the safety devices that probability theory as logic alwaysprovides. Unfortunately, the current literature offers little help here because its viewpoint,concentrated mainly on sampling theory, directs attention to other things such as assumedsampling frequencies, as the following exercises illustrate.
Exercise 4.4. Suppose that Bis in fact true; estimate how many tests it will probably
require in order to accumulate an additional 20 db of evidence (above the prior 10 db)in favor of B. Show that the sampling probability that we could ever obtain 20 db of
evidence for Ais negligibly small, even if we sample millions of times. In other words it
is, for all practical purposes, impossible for a doctrinaire zealot to sample to a foregonefalse conclusion merely by continuing until he ﬁnally gets the evidence he wants.Note: The calculations called for here are called ‘random walk’ problems; they are
sampling theory exercises. Of course, the results are not wrong, only incomplete. Someessential aspects of inference in the real world are not recognized by sampling theory.
Exercise 4.5. The estimate asked for in Exercise 4.4 is called the ‘average sample
number’ (ASN), and the original rationale for the sequential procedure (Wald, 1947)was not our derivation from probability theory as logic, but Wald’s conjecture (unprovenat the time) that the sequential probability-ratio tests such as (4.19) and (4.21) minimizethe ASN for a given reliability of conclusion. Discuss the validity of this conjecture;can one deﬁne the term ‘reliability of conclusion’ in such a way that the conjecture canbe proved true?

<<<PAGE 139>>>

4 Elementary hypothesis testing 107
Evidently, we could extend this example in many different directions. Introducing more
‘discrete’ hypotheses would be perfectly straightforward, as we have seen. More interestingwould be the introduction of a continuous range of hypotheses, such as
H
f≡the machine is putting out a fraction fbad.
Then, instead of a discrete prior probability distribution, our robot would have a continuous
distribution in 0≤f≤1, and it would calculate the posterior probabilities for various
values of fon the basis of the observed samples, from which various decisions could be
made. In fact, although we have not yet given a formal discussion of continuous probabilitydistributions, the extension is so easy that we can give it as an introduction to this example.
4.5 Continuous probability distribution functions
Our rules for inference were derived in Chapter 2 only for the case of ﬁnite sets of discrete
propositions ( A,B,...). But this is all we ever need in practice. Suppose that fis any
continuously variable real parameter of interest, then the propositions
F
/prime≡(f≤q)
F/prime/prime≡(f>q)(4.50)
are discrete, mutually exclusive, and exhaustive; so our rules will surely apply to them.
Given some information Y, the probability for F/primewill in general depend on q, deﬁning a
function
G(q)≡P(F/prime|Y), (4.51)
which is evidently monotonic increasing. Then what is the probability that flies in any
speciﬁed interval ( a<f≤b)? The answer is probably obvious intuitively, but it is worth
noting that it is determined uniquely by the sum rule of probability theory, as follows. Deﬁnethe propositions
A≡(f≤a), B≡(f≤b), W≡(a<f≤b). (4.52)
Then a relation of Boolean algebra is B=A+W, and since AandWare mutually exclu-
sive, the sum rule reduces to
P(B|Y)=P(A|Y)+P(W|Y). (4.53)
ButP(B|Y)=G(b), and P(A|Y)=G(a), so we have the result
P(a<f≤b|Y)=P(W|Y)=G(b)−G(a). (4.54)
In the present case, G(q) is continuous and differentiable, so we may write also
P(a<f≤b|Y)=/integraldisplay
b
adfg(f), (4.55)

<<<PAGE 140>>>

108 Part 1 Principles and elementary applications
where g(f)=G/prime(f)≥0 is the derivative of G, generally called the probability distribution
function , or the probability density function forf,g i v e n Y; either reading is consistent with
the abbreviation pdf which we use henceforth, following the example of Zellner (1971). Itsintegral G(f) may be called the cumulative distribution function forf.
Thus, limiting our basic theory to ﬁnite sets of propositions has not in any way hin-
dered our ability to deal with continuous probability distributions; we have applied thebasic product and sum rules only to discrete propositions in ﬁnite sets. As long as contin-uous distributions are deﬁned as above (Eqs. (4.54), (4.55)) from a basis of ﬁnite sets ofpropositions, we are protected from inconsistencies by Cox’s theorems. But if we becomeoverconﬁdent and try to operate directly on inﬁnite sets without considering how they areto be generated from ﬁnite sets, this protection is lost and we stand at the mercy of all theparadoxes of inﬁnite-set theory, as discussed in Chapter 15; we can then derive sense andnonsense with equal ease.
We must warn the reader about another semantic confusion which has caused error and
controversy in probability theory for many decades. It would be quite wrong and misleadingto call g(f) the ‘posterior distribution off’, because that verbiage would imply to the
unwary that fitself is varying and is ‘distributed’ in some way. This would be another form
of the mind projection fallacy, confusing reality with a state of knowledge about reality.
In the problem we are discussing, fis simply an unknown constant parameter; what is
‘distributed’ is not the parameter , but the probability . Use of the terminology ‘probability
distribution forf’ will be follo wed, in order to emphasize this constantly.
Of course, nothing in probability theory forbids us to consider the possibility that fmight
vary with time or with circumstance; indeed, probability theory enables us to analyze thatcase fully, as we shall see later. But then we should recognize that we are considering a
different problem than the one just discussed; it involves different quantities with different
states of knowledge about them, and requires a different calculation. Confusion of thesetwo problems is perhaps the major occupational disease of those who fool themselves byusing the above misleading terminology. The pragmatic consequence is that one is led toquite wrong conclusions about the accuracy and range of validity of the results.
Questions about what happens when G(q) is discontinuous at a point q
0are discussed
further in Appendix B; for the present it sufﬁces to note that, of course, approaching adiscontinuous G(q) as the limit of a sequence of continuous functions leads us to the
correct results. As Gauss stressed long ago, any kind of singular mathematics acquires
a meaning only as a limiting form of some kind of well-behaved mathematics, and it
is ambiguous until we specify exactly what limiting process we propose to use. In thissense, singular mathematics has necessarily a kind of anthropomorphic character; the ques-tion is not what is it, bu t rather how shall we de ﬁne it so that it is in some way useful
to us?
In the present case, we approach the limit in such a way that the density function develops
a sharper and sharper peak, going in the limit into a delta function p
0δ(q−q0) signifying
a discrete hypothesis H0, and enclosing a limiting area equal to the probability p0of that
hypothesis; Eq. (4.65) below is an example.

<<<PAGE 141>>>

4 Elementary hypothesis testing 109
But, in fact, if we become pragmatic we note that fis not really a continuously variable
parameter. In its working lifetime, a machine will produce only a ﬁnite number of widgets;if it is so well built that it makes 10
8of them, then the possible values of fare a ﬁnite
set of integer multiples of 10−8. Then our ﬁnite-set theory will apply, and consideration
of a continuously variable fis only an approximation to the exact discrete theory. There
is never any need to consider inﬁnite sets or measure theory in the real, exact problem.Likewise, any data set that can actually be recorded and analyzed is digitized into multiplesof some smallest element. Most cases of allegedly continuously variable quantities are likethis when one takes note of the actual, real-world situation.
4.6 Testing an inﬁnite number of hypotheses
In spite of the pragmatic argument just given, thinking of continuously variable parameters
is often a natural and convenient approximation to a real problem (only we should not takeit so seriously that we get bogged down in the irrelevancies for the real world that inﬁnitesets and measure theory generate). So, suppose that we are now testing simultaneously anuncountably inﬁnite number of hypotheses about the machine. As often happens in math-ematics, this actually makes things simpler because analytical methods become available.However, the logarithmic form of the previous equations is now awkward, and so we willgo back to the original probability form (4.3):
P(A|DX)=P(A|X)P(D|AX)
P(D|X). (4.56)
Letting Anow stand for the proposition ‘The fraction of bad widgets is in the range
(f,f+df)’, there is a prior pdf
P(A|X)=g(f|X)df, (4.57)
which gives the probability that the fraction of bad widgets is in the range d f; and let D
stand for the results thus far of our experiment,
D≡Nwidgets were tested and we found the results GGBGBBG···, containing in all n
bad ones and ( N−n) good ones.
Then the posterior pdf for fis given by
P(A|DX)=P(A|X)P(D|AX)
P(D|X)=g(f|DX)df, (4.58)
so the prior and posterior pdfs are related by
g(f|DX)=g(f|X)P(D|AX)
P(D|X). (4.59)
The denominator is just a normalizing constant, which we could calculate directly; but
usually it is easier to determine (if it is needed at all) from requiring that the posterior pdf

<<<PAGE 142>>>

110 Part 1 Principles and elementary applications
satisfy the normalization condition
P(0≤f≤1|DX)=/integraldisplay1
0dfg(f|DX)=1, (4.60)
which we should think of as an extremely good approximation to the exact formula, which
has a sum over an enormous number of discrete values of f, instead of an integral.
The evidence of the data thus lies entirely in the fdependence of P(D|AX). At this
point, let us be very careful, in view of some errors that have trapped the unwary. In thisprobability, the conditioning statement Aspeciﬁes an interval d f, not a point value of f. Are
we justiﬁed in taking an implied limit d f→0 and replacing P(D|AX) with P(D|H
fX)?
Most writers have not hesitated to do this.
Mathematically, the correct procedure would be to evaluate P(D|AX) exactly for positive
df, and pass to the limit d f→0 only afterward. But a tricky point is that if the problem
contains another parameter θin addition to f, then this procedure is ambiguous until we take
the warning of Gauss very seriously, and specify exactly how the limit is to be approached
(does d ftend to zero at the same rate for all values of θ?). For example, if we set d f=/epsilon1h(θ)
and pass to the limit /epsilon1→0, our ﬁnal conclusions may depend on which function h(θ)w a s
used. Those who fail to notice this fall into the famous Borel–Kolmogorov paradox, inwhich a seemingly well-posed problem appears to have many different correct solutions.We shall discuss this in more detail later (Chapter 15), and show that the paradox is avertedby strict adherence to our Chapter 2 rules.
In the present relatively simple problem, fis the only parameter present and P(D|H
fX)
is a continuous function of f; this is surely enough to guarantee that the limit is well-
behaved and uneventful. But, just to be sure, let us take the trouble to demonstrate this bydirect application of our Chapter 2 rules, keeping in mind that this continuum treatment isreally an approximation to an exact discrete one. Then with d f>0, we can resolve Ainto
a disjunction of a ﬁnite number of discrete propositions:
A=A
1+A2+···+ An, (4.61)
where A1=Hf(fbeing one of the possible discrete values) and the Aispecify the discrete
values of fin the interval ( f,f+df). They are mutually exclusive, so, as we noted in
Chapter 2, Eq. (2.67), application of the product rule and the sum rule gives the general result
P(D|AX)=P(D|A1+A2+···+ An,X)=/summationtext
iP(Ai|X)P(D|AiX)/summationtext
iP(Ai|X), (4.62)
which is a weighted average of the separate probabilities P(D|AiX). This may be regarded
also as a generalization of (4.39).
Then if all the P(D|AiX) were equal, (4.62) would become independent of their prior
probabilities P(Ai|X) and equal to P(D|A1X)=P(D|HfX); the fact that the conditioning
statement on the left-hand side of (4.62) is a logical sum makes no difference, and P(D|AX)
would be rigorously equal to P(D|HfX). Even if the P(D|AiX) are not equal, as d f→0,
we have n→1 and eventually A=A1, with the same result.

<<<PAGE 143>>>

4 Elementary hypothesis testing 111
It may appear that we have gone to extraordinary lengths to argue for an almost trivially
simple conclusion. But the story of the schoolboy who made a mistake in his sums andconcluded that the rules of arithmetic are all wrong, is not fanciful. There is a long history ofworkers who did seemingly obvious things in probability theory without bothering to derivethem by strict application of the basic rules, obtained nonsensical results – and concludedthat probability theory as logic was at fault. The greatest, most respected mathematiciansand logicians have fallen into this trap momentarily, and some philosophers spend theirentire lives mired in it; we shall see some examples in the next chapter.
Such a simple operation as passing to the limit d f→0 may produce results that seem to
us obvious and trivial; or it may generate a Borel–Kolmogorov paradox. We have learnedfrom much experience that this care is needed whenever we venture into a new area ofapplications; we must go back to the beginning and derive everything directly from ﬁrstprinciples applied to ﬁnite sets. If we obey the Chapter 2 rules prescribed by Cox’s theorems,
we are rewarded by ﬁnding beautiful and useful results, free of contradictions.
Now, if we were given that fis the correct fraction of bad widgets, then the probability
for getting a bad one at each trial would be f, and the probability for getting a good one
would be (1−f). The probabilities at different trials are, by hypothesis (i.e. one of the many
statements hidden there in X), logically independent given f, and so, as in our derivation
of the binomial distribution (3.86),
P(D|H
fX)=fn(1−f)N−n(4.63)
(note that the experimental data Dtold us not only how many good and bad widgets were
found, but also the order in which they appeared). Therefore, we have the posterior pdf
g(f|DX)=fn(1−f)N−ng(f|X)
/integraltext1
0dffn(1−f)N−ng(f|X). (4.64)
You may be startled to realize that all of our previous discussion in this chapter is contained
in this simple looking equation, as special cases. For example, the multiple hypothesis teststarting with (4.43) and including the ﬁnal results (4.45)–(4.49) is all contained in (4.64)corresponding to the particular choice of prior pdf:
g(f|X)=10
11(1−10−6)δ/parenleftbigg
f−1
6/parenrightbigg
+1
11(1−10−6)δ/parenleftbigg
f−1
3/parenrightbigg
+10−6δ/parenleftbigg
f−99
100/parenrightbigg
.
(4.65)
This is a case where the cumulative pdf, G(f), is discontinuous. The three delta-functions
correspond to the three discrete hypotheses B,A,C,respectively, of that example. They
appear in the prior pdf (4.65) with coefﬁcients which are the prior probabilities (4.31); andin the posterior pdf (4.64) with altered coefﬁcients, which are just the posterior probabilities(4.45), (4.48) and (4.49).
Readers who have been taught to mistrust delta-functions as ‘nonrigorous’ are urged to
read Appendix B at this point. The issue has nothing to do with mathematical rigor; it is

<<<PAGE 144>>>

112 Part 1 Principles and elementary applications
simply one of notation appropriate to the problem. It would be difﬁcult and awkward to
express the information conveyed in (4.65) by a single equation in Lebesgue–Stieltjes typenotation. Indeed, failure to use delta-functions where they are clearly called for has ledmathematicians into elementary errors, as noted in Appendix B.
Suppose that at the start of this test our robot was fresh from the factory; it had no
prior knowledge about the machines at all, except for our assurance that it is possible for
a machine to make a good widget, and also possible for it to make a bad one. In this state
of ignorance, what prior pdf g(f|X) should it assign? If we have deﬁnite prior knowledge
about f, this is the place to put it in; but we have not yet seen the principles needed to assign
such priors. Even the problem of assigning priors to represent ‘ignorance’ will need muchdiscussion later; but, for a simple result now, it may seem to the reader, as it did to Laplace200 years ago, that in the present case the robot has no basis for assigning to any particularinterval d fa higher probability than to any other interval of the same size. Thus, the only
honest way it can describe what it knows is to assign a uniform prior probability density,
g(f|X)=const.This will receive a better theoretical justiﬁcation later; to normalize it
correctly as in (4.60) we must take
g(f|X)=1,0≤f≤1. (4.66)
The integral in (4.64) is then the well-known Eulerian integral of the ﬁrst kind, today more
commonly called the complete beta-function; and (4.64) reduces to
g(f|DX)=(N+1)!
n!(N−n)!fn(1−f)N−n. (4.67)
4.6.1 Historical digression
It appears that this result was ﬁrst found by an amateur mathematician, the Rev. Thomas
Bayes (1763). For this reason, the kind of calculations we are doing are called ‘Bayesian’.We shall follow this long-established custom, although it is misleading in several respects.The general result (4.3) is always called ‘Bayes’ theorem’, although Bayes never wrote it;and it is really nothing but the product rule of probability theory which had been recognizedby others, such as James Bernoulli and A. de Moivre (1718), long before the work of Bayes.Furthermore, it was not Bayes but Laplace (1774) who ﬁrst saw the result in generality andshowed how to use it in real problems of inference. Finally, the calculations we are doing –
the direct application of probability theory as logic – are more general than mere application
of Bayes’ theorem; that is only one of several items in our toolbox.
The right-hand side of (4.67) has a single peak in (0 ≤f≤1), located by differ-
entiation at
f=ˆf≡n
N, (4.68)

<<<PAGE 145>>>

4 Elementary hypothesis testing 113
just the observed proportion, or relative frequency, of bad widgets. To ﬁnd the sharpness of
the peak, we write
L(f)≡logg(f|DX)=nlog(f)+(N−n) log(1−f)+const., (4.69)
and expand L(f) in a power series about ˆf. The ﬁrst terms are
L(f)=L(ˆf)−(f−ˆf)2
2σ2+···, (4.70)
where
σ2≡ˆf(1−ˆf)
N, (4.71)
and so, to this approximation, (4.67) is a Gaussian ,o rnormal , distribution:
g(f|DX)/similarequalKexp/braceleftBigg
−(f−ˆf)2
2σ2/bracerightBigg
(4.72)
andKis a normalizing constant. Equations (4.71) and (4.72) constitute the de Moivre–
Laplace theorem. It is actually an excellent approximation to (4.67) in the entire interval(0<f<1) in the sense that the difference of the two sides tends to zero (although their
ratio does not tend to unity), provided that n/greatermuch1 and ( N−n)/greatermuch1. Properties of the
Gaussian distribution are discussed in depth in Chapter 7.
Thus, after observing nbad widgets in Ntrials, the robot’s state of knowledge about f
can be described reasonably well by saying that it considers the most likely value of fto be
just the observed fraction of bad widgets, and it considers the accuracy of this estimate to
be such that the interval ˆf±σis reasonably likely to contain the true value. The parameter
σis called the standard deviation andσ
2is the variance of the pdf (4.72). More precisely,
from numerical analysis of (4.72), the robot assigns:
50% probability that the true value of fis contained in the interval ˆf±0.68σ;
90% probability that it is contained in ˆf±1.65σ;
99% probability that it is contained in ˆf±2.57σ.
As the number Nof tests increases, these intervals shrink, according to (4.71), proportional
to 1/√
N, a common rule that arises repeatedly in probability theory.
In this way, we see that the robot starts in a state of ‘complete ignorance’ about f; but,
as it accumulates information from the tests, it acquires more and more deﬁnite opinionsabout f, which correspond very nicely to common sense. Two cautions: (1) all this applies
only to the case where, although the numerical value of fis initially unknown, it was one of
the conditions deﬁning the problem that fis known not to be changing with time, and (2)
again we must warn against the error of calling σthe ‘variance of f’, which would imply
that fis varying, and that σis a real (i.e. measurable) physical property of f. That is one
of the most common forms of the mind projection fallacy.

<<<PAGE 146>>>

114 Part 1 Principles and elementary applications
It is really necessary to belabor this point: σis not a real property of f, but only a
property of the probability distribution that the robot assigns to represent its state of knowl-
edge about f. Two robots with different information would, naturally and properly, assign
different pdfs for the same unknown quantity f, and the one which is better informed
will probably – and deservedly – be able to estimate fmore accurately; i.e., to use a
smaller σ.
But, as noted, we may consider a different problem in which fis variable if we wish
to do so. Then the mean-square variation s2offover some class of cases will become a
‘real’ property, in principle measurable, and the question of its relation, if any, to the σ2of
the robot’s pdf for that problem can be investigated mathematically, as we shall do later inconnection with time series. The relation will prove to be: if we know σbut have as yet no
data and no other prior information about s, then the best prediction of sthat we can make
is essentially equal to σ; and if we do have the data but do not know σand have no other
prior information about σ, then the best estimate of σthat we can make is nearly equal
tos. These relations are mathematically derivable consequences of probability theory as
logic.
Indeed, it would be interesting, and more realistic for some quality-control situations,
to introduce the possibility that fmight vary with time, and the robot’s job is to make
the best possible inferences about whether a machine is drifting slowly out of adjustment,with the hope of correcting trouble before it became serious. Many other extensions ofour problem occur to us: a simple classiﬁcation of widgets as good and bad is not toorealistic; there is likely a continuous gradation of quality, and by taking that into accountwe could reﬁne these methods. There might be several important properties instead of just‘badness’ and ‘goodness’ (for example, if our widgets are semiconductor diodes, forwardresistance, noise temperature, rf impedance, low-level rectiﬁcation efﬁciency, etc.), and wemight also have to control the quality with respect to all of these. There might be a greatmany different machine characteristics, instead of just H
f, about which we need plausible
inference.
It is clear that we could spend years and write volumes on all the further ramiﬁcations
of this problem, and there is already a huge literature on it. Although there is no end tothe complicated details that can be generated, there is in principle no difﬁculty in mak-ing whatever generalization we need. It requires no new principles beyond what we ha ve
given.
In the problem of detecting a drift in machine characteristics, we would want to compare
our robot’s procedure with the ones proposed long ago by Shewhart (1931). We would ﬁndthat Shewhart’s methods are intuitive approximations to what our robot would do; in someof the cases involving a normal distribution they are the same (but for the fact that Shewhartwas not thinking sequentially; he considered the number of tests determined in advance).These are, incidentally, the only cases where Shewhart felt that his proposed methods werefully satisfactory.
This is really the same problem as that of detecting a signal in noise, which we shall
study in more detail later on.

<<<PAGE 147>>>

4 Elementary hypothesis testing 115
4.7 Simple and compound (or composite) hypotheses
The hypotheses ( A,B,C,Hf) that we have considered thus far refer to a single parameter
f=M/N, the unknown fraction of bad widgets in our box, and specify a sharply deﬁned
value for f(inHf, it can be any prescribed number in 0 ≤f≤1). Such hypotheses are
called simple , because if we formalize this a bit more by deﬁning an abstract ‘parameter
space’ /Omega1consisting of all values of the parameter or parameters that we consider to be
possible, such an hypothesis is represented by a single point in /Omega1.
Testing all the simple hypotheses in /Omega1, however, may be more than we need for our
purposes. It may be that we care only whether our parameter lies in some subset /Omega11∈/Omega1
or in the complementary set /Omega12=/Omega1−/Omega11, and the particular value of fin that subset
is uninteresting (i.e. it would make no difference for what we plan to do next). Can we
proceed directly to the question of interest, instead of requiring our robot to test every
simple hypothesis in /Omega11?
The question is, to us, trivial; our starting point, Eq. (4.3), applies for all hypotheses
H, simple or otherwise, so we have only to evaluate the terms in it for this case. But in
(4.64) we have done almost all of that, and need only one more integration. Suppose that if
f>0.1 then we need to take some action (stop the machine and readjust it), but if f≤0.1
we should allow it to continue running. The space /Omega1then consists of all fin [0, 1], and
we take /Omega11as comprising all fin [0.1, 1], Has the hypothesis that fis in/Omega11. Since the
actual value of fis not of interest, fis now called a nuisance parameter ; and we want to
get rid of it.
In view of the fact that the problem has no other parameter than fand different intervals
dfare mutually exclusive, the discrete sum rule P(A1+···+ An|B)=/summationtext
iP(Ai|B) will
surely generalize to an integral as the Aibecome more and more numerous. Then the
nuisance parameter fis removed by integrating it out of (4.64):
P(/Omega11|DX)=/integraltext
/Omega11dffn(1−f)N−ng(f|X)/integraltext
/Omega1dffn(1−f)N−ng(f|X). (4.73)
In the case of a uniform prior pdf for f, we may use (4.64) and the result is the
incomplete beta-function: the posterior probability that fis in any speciﬁed interval
(a<f<b)i s
P(a<f<b|DX)=(N+1)!
n!(N−n)!/integraldisplayb
adffn(1−f)N−n, (4.74)
and in this form computer evaluation is easy.
More generally, when we have any composite hypothesis to test, probability theory
tells us that the proper procedure is simply to apply the principle (4.1) by summing orintegrating out, with respect to appropriate priors, whatever nuisance parameters it contains.The conclusions thus found take fully into account all of the evidence contained in the dataand in the prior information about the parameters. Probability theory used as logic enables us

<<<PAGE 148>>>

116 Part 1 Principles and elementary applications
to test, with a single principle, any number of hypotheses, simple or compound, in the light
of the data and prior information. In later chapters we shall demonstrate these properties inmany quantitatively worked out examples.
4.8 Comments
4.8.1 Etymology
Our opening quotation from John Craig (1699) is from a curious work on the probabil-
ities of historical events, and how they change as the evidence changes. Craig’s workwas ridiculed mercilessly in the 19th century; and, indeed, his applications to religious
issues do seem weird to us today. But Stigler (1986a) notes that Craig was writing at atime when the term ‘probability’ had not yet settled down to its present technical mean-ing, as referring to a (0–1) scale; and if we merely interpret Craig’s ‘probability foran hypothesis’ as our log-odds measure (which we have seen to have in some respectsa more primitive and intuitive meaning than probability), Craig’s reasoning was actu-ally quite good, and may be regarded as an anticipation of what we have done in thischapter.
Today, the logarithm-of-odds {u=log[p/(1−p)]}has proved to be such an important
quantity that it deserves a shorter name; but we have had trouble ﬁnding one. Good (1950)was perhaps the ﬁrst author to stress its importance in a published work, and he proposedthe name lods, but the term has a leaden ring to our ears, as well as a nondescriptive quality,
and it has never caught on.
Our same quantity (4.8) was used by Alan Turing and I. J. Good from 1941, in classiﬁed
cryptographic work in England during World War II. Good (1980) later reminisced aboutthis brieﬂy, and noted that Turing coined the name ‘deciban’ for it. This has not caught on,presumably because nobody today can see any rationale for it.
The present writer, in his lectures of 1955–64 (for example, Jaynes, 1956), proposed the
name evidence , which is intuitive and descriptive in the sense that, for given proportions,
twice as many data provide twice as much evidence for an hypothesis. This was adopted byTribus (1969), but it has not caught on either.
More recently, the term logit forU≡log[y/(a−y)], where{y
i}are some items of data
andais chosen by some convention such as a=100, has come into use. Likewise, graphs
using Ufor one axis are called logistic . For example, in one commercial software graphics
program, an axis on which values of Uare plotted is called a ‘logit axis’ and regression
on that graph is called ‘ logistic regression ’. There is at least a mathematical similarity to
what we do here, but not any very obvious conceptual relation because Uis not a measure
of probability. In any event, the term ‘logistic’ had already an established usage datingback to Poincar´ e and Peano, as referring to the Russell–Whitehead attempt to reduce all
mathematics to logic.
3
3This terminology has a much longer historical basis. Alexander the Great sought to make all countries Greek in character, but
he died before completing this goal, with the result that the countries he conquered had some Greek characteristics, but not

<<<PAGE 149>>>

4 Elementary hypothesis testing 117
In the face of this confusion, we propose and use the following terminology. Note that we
need two terms: the name of the quantity, and the name of the units in which it is measured.For the former we have retained the name evidence , which has at least the merit that it
has been deﬁned, and used consistently with the deﬁnition, in previously published works.One can then use various different units, with different names. In this chapter we havemeasured evidence in decibels because of its familiarity to scientists, the ease of ﬁnding
numerical values, and the connection with the base ten number system which makes theresults intuitively clear.
4.8.2 What have we accomplished?
The things which we have done in such a simple way in this chapter have been, in one
sense, deceptive. We have had an introduction, in an atmosphere of apparent triviality,into almost every kind of problem that arises in the hypothesis testing business. Butdo not be deceived by the simplicity of our calculations into thinking that we have notreached the real nontrivial problems of the ﬁeld. Those problems are only straightfor-ward mathematical generalizations of what we have done here, and mathematically maturereaders who have understood this chapter can now solve them for themselves, probablywith less effort than it would require toﬁnd and understand the solutions available in the
literature.
In fact, the methods of solution that we have indicated have far surpassed, in power to
yield useful results, the methods available in the conventional non-Bayesian literature of
hypothesis testing. To the best of our knowledge, no comprehension of the facts of multiple
hypothesis testing, as illustrated in Figure 4.1, can be found in the orthodox literature (whichexplains why the principles of multiple hypothesis testing have been controversial in thatliterature). Likewise, our form of solution of the compound hypothesis problem (4.73) willnot be found in the ‘orthodox’ literature of the subject.
It was our use of probability theory as logic that has enabled us to do so easily what was
impossible for those who thought of probability as a physical phenomenon associated with‘randomness’. Quite the opposite; we have thought of probability distributions as carriers
of information . At the same time, under the protection of Cox’s theorems, we have avoided
the inconsistencies and absurdities which are generated inevitably by those who try to dealwith the problems of scientiﬁc inference by inventing ad hoc devices instead of applying
the rules of probability theory . For a devastating criticism of these devices, see the book
review by Pratt (1961).
It is not only in hypothesis testing, however, that the foundations of the theory matter for
applications. As indicated in Chapter 1 and Appendix A, our formulation was chosen withthe aim of giving the theory the widest possible range of useful applications. To drive homehow much the scope of solvable problems depends on the chosen foundations, the readermay try Exercise 4.6.
all of them. So instead of calling them Hellenic , they were called Hellenistic . Thus, logistic implies something that has some
properties of logic, but not all of them.

<<<PAGE 150>>>

118 Part 1 Principles and elementary applications
Exercise 4.6. In place of our product and sum rules, Ruelle (1991, p. 17) deﬁnes the
‘mathematical presentation’ of probability theory by three basic rules:
p(A)=1−p(A);
ifAandBare mutually exclusive, p(A+B)=p(A)+p(B); (4.75)
if A and B are independent, p(AB)=p(A)p(B).
Survey the preceding two chapters, and determine how many of the applications that
we solved in Chapters 3 and 4 could have been solved by application of these rules.Hint: IfAandBare not independent, is p(AB) determined by them? Is the notion
of conditional probability deﬁned? Ruelle makes no distinction between logical andcausal independence; he deﬁnes ‘independence’ of AandBas meaning: ‘the fact that
one is realized has in the average no inﬂuence on the realization of the other’. It appears,then, that he would always accept (4.29) for all n.
This exercise makes it clear why conventional expositions do not consider scientiﬁc in-
ference to be a part of probability theory. Indeed, orthodox statistical theory is helpless todeal with such problems because, thinking of probability as a physical phenomenon, it rec-ognizes the existence only of sampling probabilities; thus it denies itself the technical toolsneeded to incorporate prior information, to eliminate nuisance parameters, or to recognizethe information contained in a posterior probability. However, even most of the samplingtheory results that we derived in Chapter 3 are beyond the scope of the mathematical andconceptual foundation given by Ruelle, as are virtually all of the parameter estimationresults to be derived in Chapter 6.
We shall ﬁnd later that our way of treating compound hypotheses illustrated here also
generates automatically the conventional orthodox signiﬁcance tests or superior ones; andat the same time gives a clear statement of what they are testing and their range of validity,previously lacking in the orthodox literature.
Now that we have seen the beginnings of this situation, before turning to more serious
and mathematically more sophisticated problems, we shall relax and amuse ourselves in thenext chapter by examining how probability theory as logic can clear up all kinds of weirderrors, in the older literature, that arose from very simple misuse of probability theory, butwhose consequences were relatively trivial. In Chapters 15 and 17 we consider some morecomplicated and serious errors that are causing major confusion in the current literature.

<<<PAGE 151>>>

5
Queer uses for probability theory
I cannot conceal the fact here that in the speciﬁc application of these
rules, I foresee many things happening which can cause one to be badly
mistaken if he does not proceed cautiously.
James Bernoulli (1713, Part 4, Chapter III)
I. J. Good (1950) has shown how we can use probability theory backwards to measure our
own strengths of belief about propositions. For example, how strongly do you believe inextrasensory perception?
5.1 Extrasensory perception
What probability would you assign to the hypothesis that Mr Smith has perfect extrasensory
perception? More speciﬁcally, that he can guess right every time which number you have
written down. To say zero is too dogmatic. According to our theory, this means that weare never going to allow the robot’s mind to be changed by any amount of evidence,
and we don’t really want that. But where isour strength of belief in a proposition like
this?
Our brains work pretty much the way this robot works, but we have an intuitive feeling
for plausibility only when it’s not too far from 0 db. We get fairly deﬁnite feelings thatsomething is more than likely to be so or less than likely to be so. So the trick is to imaginean experiment. How much evidence would it take to bring your state of belief up to the placewhere you felt very perplexed and unsure about it? Not to the place where you believedit – that would overshoot the mark, and again we’d lose our resolving power. How muchevidence would it take to bring you just up to the point where you were beginning to considerthe possibility seriously?
So, we consider Mr Smith, who says he has extrasensory perception (ESP), and we will
write down some numbers from one to ten on a piece of paper and ask him to guess whichnumbers we’ve written down. We’ll take the usual precautions to make sure against otherways of ﬁnding out. If he guesses the ﬁrst number correctly, of course we will all say ‘you’rea very lucky person, but I don’t believe you have ESP’. And if he guesses two numberscorrectly, we’ll still say ‘you’re a very lucky person, but I still don’t believe you have ESP’.
119

<<<PAGE 152>>>

120 Part 1 Principles and elementary applications
By the time he’s guessed four numbers correctly – well, I still wouldn’t believe it. So my
state of belief is certainly lower than −40 db.
How many numbers would he have to guess correctly before you would really seri-
ously consider the hypothesis that he has extrasensory perception? In my own case, I thinksomewhere around ten. My personal state of belief is, therefore, about −100 db. You could
talk me into a±10 db change, and perhaps as much as ±30 db, but not much more than
that.
After further thought, we see that, although this result is correct, it is far from the whole
story. In fact, if he guessed 1000 numbers correctly, I still would not believe that he has ESP,for an extension of the same reason that we noted in Chapter 4 when we ﬁrst encounteredthe phenomenon of resurrection of dead hypotheses. An hypothesis Athat starts out down
at−100 db can hardly ever come to be believed, whatever the data, because there are almost
sure to be alternative hypotheses ( B
1,B2,...) above it, perhaps down at −60 db. Then, when
we obtain astonishing data that might have resurrected A, the alternatives will be resurrected
instead. Let us illustrate this by two famous examples, involving telepathy and the discovery
of Neptune. Also we note some interesting variants of this. Some are potentially useful,some are instructive case histories of probability theory gone wrong, in the way Bernoulliwarned us about.
5.2 Mrs Stewart’s telepathic powers
Before venturing into this weird area, the writer must issue a disclaimer. I was not there, and
am not in a position to afﬁrm that the experiment to be discussed actually took place; or, if itdid, that the data were actually obtained in a valid way. Indeed, that is just the problem thatyou and I always face when someone tries to persuade us of the reality of ESP or some othermarvellous thing – such things never happen to us or in our presence. All we are able toafﬁrm is that the experiment and data have been reported in a real, veriﬁable reference (Soaland Bateman, 1954). This is the circumstance that we want to analyze now by probabilitytheory. Lindley (1957) and Bernardo (1980) have also taken note of it from the standpointof probability theory, and Boring (1955) discusses it from the standpoint of psychology.
In the reported experiment, from the experimental design the probability for guessing a
card correctly should have been p=0.2, independently in each trial. Let H
pbe the ‘null
hypothesis’ which states this, and supposes that only ‘pure chance’ is operating (whateverthat means). According to the binomial distribution (3.86), H
ppredicts that if a subject has
no ESP, the number rof successful guesses in ntrials should be about (mean ±standard
deviation)
(r)est=np±/radicalbig
np(1−p). (5.1)
Forn=37100 trials, this is 7420 ±77.
But, according to the report, Mrs Gloria Stewart guessed correctly r=9410 times
in 37100 trials, for a fractional success rate of f=0.2536. These numbers constitute

<<<PAGE 153>>>

5 Queer uses for probability theory 121
our data D. At ﬁrst glance, they may not look very sensational; note, however, that her
score was
9410−7420
77=25.8 (5.2)
standard deviations away from the chance expectation.
The probability for getting these data, on hypothesis Hp, is then the binomial
P(D|Hp)=/parenleftbiggn
r/parenrightbigg
pr(1−p)n−r. (5.3)
But the numbers n,rare so large that we need the Stirling approximation to the binomial,
derived in Chapter 9:
P(D|Hp)=Aexp{nH(f,p)}, (5.4)
where
H(f,p)=flog/parenleftbiggp
f/parenrightbigg
+(1−f) log/bracketleftbigg1−p
1−f/bracketrightbigg
=−0.008452 (5.5)
is the entropy of the observed distribution ( f,1−f)=(0.2536,0.7464) relative to the
expected one, ( p,1−p)=(0.2000,0.8000), and
A≡/radicalBigg/bracketleftbiggn
2πr(n−r)/bracketrightbigg
=0.00476 . (5.6)
Then we may take as the likelihood LpofHp, the sampling probability
Lp=P(D|Hp)=0.00476 exp{−313.6}=3.15×10−139. (5.7)
This looks fantastically small; however, before jumping to conclusions, the robot should
ask: ‘Are the data also fantastically improbable on the hypothesis that Mrs Stewart hastelepathic powers?’ If they are, then (5.7) may not be so signiﬁcant after all.
Consider the Bernoulli class of alternative hypotheses H
q(0≤q≤1), which sup-
pose that the trials are independent, but that assign different probabilities of success q
to Mrs Stewart ( q>0.2 if the hypothesis considers her to be telepathic). Out of this class,
the hypothesis Hfthat assigns q=f=0.2536 yields the greatest P(D|Hq) that can be
attained in the Bernoulli class, and for this the entropy (5.5) is zero, yielding a maximumlikelihood of
L
f=P(D|Hf)=A=0.00476 . (5.8)
So, if the robot knew for a fact that Mrs Stewart is telepathic to the extent of q=0.2536,
then the probability that she could generate the observed data would not be particularlysmall. Therefore, the smallness of (5.7) is indeed highly signiﬁcant; for then the likelihoodratio for the two hypotheses must be fantastically small. The relative likelihood depends

<<<PAGE 154>>>

122 Part 1 Principles and elementary applications
only on the entropy factor:
Lp
Lf=P(D|Hp)
P(D|Hf)=exp{nH}=exp{−313.6}=6.61×10−137, (5.9)
and the robot would report: ‘The data do indeed support Hfover Hpby an enormous factor.’
5.2.1 Digression on the normal approximation
Note, in passing, that in this calculation large errors could be made by unthinking use of the
normal approximation to the binomial, also derived in Chapter 9 (or compare with (4.72)):
P(D|Hp,X)/similarequal(const.)×exp/braceleftbigg−n(f−p)2
2p(1−p)/bracerightbigg
. (5.10)
To use it here instead of the entropy approximation (5.4), amounts to replacing the entropy
H(f,p) by the ﬁrst term of its power series expansion about the peak. Then we would have
found instead a likelihood ratio exp {−333.1}. Thus, the normal approximation would have
made Mrs Stewart appear even more marvellous than the data indicate, by an additionalodds ratio factor of
exp{333.1−313.6}=exp{19.5}=2.94×10
8. (5.11)
This should warn us that, quite generally, normal approximations cannot be trusted fa r out
in the tails of a distribution. In this case, we are 25.8 standard deviations out, and the normal
approximation is in error by over eight orders of magnitude.
Unfortunately, this is just the approximation used by the chi-squared test discussed later,
which can therefore lead us to wildly misleading conclusions when the ‘null hypothesis’
being tested ﬁts the data very poorly. Those who use the chi-squared test to support theirclaims of marvels are usually helping themselves by factors such as (5.11). In practice,the entropy calculation (5.5) is just as easy and far more trustworthy (although the entropyand chi-squared test amount to the same thing within one or two standard deviations of thepeak).
5.2.2 Back to Mrs Stewart
In any event, our present numbers are indeed fantastic; on the basis of such a result, ESP
researchers would proclaim a virtual certainty that ESP is real. If we compare H
pandHf
by probability theory, the posterior probability that Mrs Stewart has ESP to the extent of
q=f=0.2536 is
P(Hf|DX)=P(Hf|X)P(D|HfX)
P(D|X)=PfLf
PfLf+PpLp, (5.12)
where Pp,Pfare the prior probabilities of Hp,Hf. But, because of (5.9), it hardly matters
what these prior probabilities are; in the view of an ESP researcher who does not consider

<<<PAGE 155>>>

5 Queer uses for probability theory 123
the prior probability Pf=P(Hf|X) particularly small, P(Hf|DX) is so close to unity that
its decimal expression starts with over 100 nines.
He will then react with anger and dismay when, in spite of what he considers this
overwhelming evidence, we persist in not believing in ESP. Why are we, as he sees it,so perversely illogical and unscientiﬁc?
The trouble is that the above calculations, (5.9) and (5.12), represent a very na¨ ıve appli-
cation of probability theory, in that they consider only H
pandHf, and no other hypotheses.
If we really knew that HpandHfwere the only possible ways the data (or, more precisely,
the observable report of the experiment and data) could be generated, then the conclusionsthat follow from (5.9) and (5.12) would be perfectly all right. But, in the real world, ourintuition is taking into account some additional possibilities that they ignore.
Probability theory gives us the results of consistent plausible reasoning from the infor-
mation that was actually used in our calculation. It can lead us wildly astray, as Bernoulli
noted in our opening quotation, if we fail to use all the information that our common sense
tells us is relevant to the question we are asking. When we are dealing with some extremelyimplausible hypothesis, recognition of a seemingly trivial alternative possibility can makemany orders of magnitude difference in the conclusions. Taking note of this, let us show howa more sophisticated application of probability theory explains and justiﬁes our intuitivedoubts.
LetH
p,Hf, and Lp,Lf,Pp,Pfbe as above; but now we introduce some new hypotheses
about how this report of the experiment and data might have come about, which will surely
be entertained by the readers of the report even if they are discounted by its writers.
These new hypotheses ( H1,H2,..., Hk) range all the way from innocent possibili-
ties, such as unintentional error in the record keeping, through frivolous ones (perhapsMrs Stewart was having fun with those foolish people, with the aid of a little mirror thatthey did not notice), to less innocent possibilities such as selection of the data (not reportingthe days when Mrs Stewart was not at her best), to deliberate falsiﬁcation of the wholeexperiment for wholly reprehensible motives. Let us call them all, simply, ‘deception’. Forour purposes, it does not matter whether it is we or the researchers who are being deceived,or whether the deception was accidental or deliberate. Let the deception hypotheses havelikelihoods and prior probabilities L
i,Pi,i=(1,2,..., k).
There are, perhaps, 100 different deception hypotheses that we could think of and are not
too far-fetched to consider, although a single one would sufﬁce to make our point.
In this new logical environment, what is the posterior probability for the hypothesis Hf
that was supported so overwhelmingly before? Probability theory now tells us that
P(Hf|DX)=PfLf
PfLf+PpLp+/summationtextPiLi. (5.13)
Introduction of the deception hypotheses has changed the calculation greatly; in order for
P(Hf|DX) to come anywhere near unity it is now necessary that
PpLp+/summationdisplay
iPiLi/lessmuchPfLf. (5.14)

<<<PAGE 156>>>

124 Part 1 Principles and elementary applications
Let us suppose that the deception hypotheses have likelihoods Liof the same order as Lfin
(5.8); i.e. a deception mechanism could produce the reported data about as easily as coulda truly telepathic Mrs Stewart. From (5.7), P
pLpis completely negligible, so (5.14) is not
greatly different from
/summationdisplay
Pi/lessmuchPf. (5.15)
But each of the deception hypotheses is, in my judgment, more likely than Hf, so there is
not the remotest possibility that the inequality (5.15) could ever be satisﬁed.
Therefore, this kind of experiment can never convince me of the reality of Mrs Stewart’s
ESP; not because I assert Pf=0 dogmatically at the start, but because the veriﬁable facts
can be accounted for by many alternative hypotheses, every one of which I consider inher-
ently more plausible than Hf, and none of which is ruled out by the information available
to me.
Indeed, the very evidence which the ESP’ers throw at us to convince us, has the opposite
effect on our state of belief; issuing reports of sensational data defeats its own purpose. Forif the prior probability for deception is greater than that of ESP, then the more improbablethe alleged data are on the null hypothesis of no deception and no ESP, the more stronglywe are led to believe, not in ESP, but in deception. For this reason, the advocates of ESP(or any other marvel) will never succeed in persuading scientists that their phenomenon is
real, until they learn how to eliminate the possibility of deception in the mind of the reader.As (5.15) shows, the reader’s total prior probability for deception by all mechanisms mustbe pushed down below that of ESP.
It is interesting that Laplace perceived this phenomenon long ago. His Essai
Philosophique sur les Probabilit ´es(1814, 1819) has a long chapter on the ‘Probabilities
of testimonies’, in which he calls attention to ‘the immense weight of testimonies nec-essary to admit a suspension of natural laws’. He notes that those who make recitals ofmiracles,
decrease rather than augment the belief which they wish to inspire; for then those recitals render very
probable the error or the falsehood of their authors. But that which diminishes the belief of educatedmen often increases that of the uneducated, always avid for the marvellous.
We observe the same phenomenon at work today, not only in the ESP enthusiast, but
in the astrologer, reincarnationist, exorcist, fundamentalist preacher or cultist of any sort,who attracts a loyal following among the uneducated by claiming all kinds of miracles, buthas zero success in converting educated people to his teachings. Educated people, taughtto believe that a cause–effect relation requires a physical mechanism to bring it about, arescornful of arguments which invoke miracles; but the uneducated seem actually to preferthem.
Note that we can recognize the clear truth of this psychological phenomenon without
taking any stand about the truth of the miracle; it is possible that the educated people are
wrong. For example, in Laplace’s youth educated persons did not believe in meteorites, but
dismissed them as ignorant folklore because they are so rarely observed. For one familiar

<<<PAGE 157>>>

5 Queer uses for probability theory 125
with the laws of mechanics the notion that ‘stones fall from the sky’ seemed preposterous,
while those without any conception of mechanical law saw no difﬁculty in the idea. Butthe fall at Laigle in 1803, which left fragments studied by Biot and other French scien-tists, changed the opinions of the educated – including Laplace himself. In this case, theuneducated, avid for the marvellous, happened to be right: c’est la vie .
Indeed, in the course of writing this chapter, the writer found himself a victim of this
phenomenon. In the 1987 Ph.D. thesis of G. L. Bretthorst, and more fully in Bretthorst(1988), we applied Bayesian analysis to estimation of frequencies of nonstationary sinu-soidal signals, such as exponential decay in nuclear magnetic resonance (NMR) data, orchirp in oceanographic waves. We found – as was expected on theoretical grounds – animproved resolution over the previously used Fourier transform methods.
If we had claimed a 50% improvement, we would have been believed at once, and
other researchers would have adopted this method eagerly. But, in fact, we found orders ofmagnitude improvement in resolution. It was, in retrospect, foolish of us to mention thisat the outset, for in the minds of others the prior probability that we were irresponsiblecharlatans was greater than the prior probability that a new method could possibly be thatgood; and we were not at ﬁrst believed.
Fortunately, we were able, by presenting many numerical analyses of data and distributing
free computer programs so that doubters could check our claims for themselves on whateverdata they chose, to eliminate the possibility of deception in the minds of our audience, andthe method did ﬁnd acceptance after all. The Bayesian analyses of free decay NMR signalsnow permits experimentalists to extract much more information from their data than waspossible by taking Fourier transforms.
The reader should be warned, however, that our probability analysis (5.13) of
Mrs Stewart’s performance is still rather na¨ ıve in that it neglects correlations; having seen
a persistent deviation from the chance expectation p=0.2 in the ﬁrst few hundred trials,
common sense would lead us to form the hypothesis that some unknown systematic causeis at work, and we would come to expect the same deviation in the future. This wouldalter the numerical values given above, but not enough to change our general conclusions.More sophisticated probability models which are able to take such things into account aregiven in our discussions of advanced applications later; relevant topics are Dirichlet priors,
exchangeable sequences, and autoregressive models.
Now let us return to that original device of I. J. Good, which started this train of thought.
After all this analysis, why do we still hold that na¨ ıve ﬁrst answer of −100 db for my
prior probability for ESP, as recorded above, to be correct? Because Jack Good’s imaginarydevice can be applied to whatever state of knowledge we choose to imagine; it need not bethe real one. If I knew that true ESP and pure chance were the only possibilities, then thedevice would apply and my assignment of −100 db would hold. But, knowing that there
are other possibilities in the real world does not change my state of belief about ESP; sothe ﬁgure of−100 db still holds.
Therefore, in the present state of development of probability theory, the device of imagi-
nary results is usable and useful in a very wide variety of situations, where we might not at

<<<PAGE 158>>>

126 Part 1 Principles and elementary applications
ﬁrst think it applicable. We shall ﬁnd it helpful in many cases where our prior information
seems at ﬁrst too vague to lead to any deﬁnite prior probabilities; it stimulates our thinkingand tells us how to assign them after all. Perhaps in the future we shall have more formalprinciples that make it unnecessary.
Exercise 5.1. By applying the device of imaginary results, ﬁnd your own strength of
belief in any three of the following propositions: (1) Julius Caesar is a real historicalperson (i.e. not a myth invented by later writers); (2) Achilles is a real historical person;(3) the Earth is more than a million years old; (4) dinosaurs did not die out; they arestill living in remote places; (5) owls can see in total darkness; (6) the conﬁguration ofthe planets inﬂuences our destiny; (7) automobile seat belts do more harm than good;(8) high interest rates combat inﬂation; (9) high interest rates cause inﬂation.Hint: Try to imagine a situation in which the proposition H
0being tested, and a single
alternative H1, would be the only possibilities, and you receive new ‘data’ Dconsistent
with H0:P(D|H0)/similarequal1. The imaginary alternative and data are to be such that you can
calculate the probability P(D|H1). Always use an H0that you are inclined not to
believe; if the proposition as stated seems highly plausible to you, then for H0choose
its denial.
Much more has been written about the Soal experiments in ESP. The deception hypothesis,
already strongly indicated by our probability analysis, is supported by additional evidence(Hansel, 1980; Kurtz, 1985). Altogether, an appalling amount of effort has been expendedon this incident, and it might appear that the only result was to provide a pedagogicalexample of the use of probability theory with very unlikely hypotheses. Can anything moreuseful be salvaged from it?
We think that this incident has some lasting value both for psychology and for probability
theory, because it has made us aware of an important general phenomenon, which hasnothing to do with ESP; a person may tell the truth and not be believed, even though thedisbelievers are reasoning in a rational, consistent way. To the best of our knowledge it hasnot been noted before that probability theory as logic automatically reproduces and e xplains
this phenomenon. This leads us to conjecture that it may generalize to other more complexand puzzling psychological phenomena.
5.3 Converging and diverging views
Suppose that two people, Mr Aand Mr Bhave differing views (due to their differing prior
information) about some issue, say the truth or falsity of some controversial proposition S.
Now we give them both a number of new pieces of information or ‘data’, D
1,D2,..., Dn,
some favorable to S, some unfavorable. As nincreases, the totality of their information
comes to be more nearly the same, therefore we might expect that their opinions about S
will converge toward a common agreement. Indeed, some authors consider this so obvious

<<<PAGE 159>>>

5 Queer uses for probability theory 127
that they see no need to demonstrate it explicitly, while Howson and Urbach (1989, p. 290)
claim to have demonstrated it.
Nevertheless, let us see for ourselves whether probability theory can reproduce such
phenomena. Denote the prior information by IA,IB, respectively, and let Mr Abe initially
a believer, Mr Ba doubter:
P(S|IA)/similarequal1, P(S|IB)/similarequal0; (5.16)
after receiving data D, their posterior probabilities are changed to
P(S|DIA)=P(S|IA)P(D|SIA)
P(D|IA)(5.17)
P(S|DIB)=P(S|IB)P(D|SIB)
P(D|IB).
IfDsupports S, then since Mr Aalready considers Salmost certainly true, we have
P(D|SIA)/similarequalP(D|IA), and so
P(S|DIA)/similarequalP(S|IA). (5.18)
Data Dhave no appreciable effect on Mr A’s opinion. But now one would think that if
MrBreasons soundly, he must recognize that P(D|SIB)>P(D|IB), and thus
P(S|DIB)>P(S|IB). (5.19)
MrB’s opinion should be changed in the direction of Mr A’s. Likewise, if Dhad tended to
refute S, one would expect that Mr B’s opinions are little changed by it, whereas Mr A’s
will move in the direction of Mr B’s. From this we might conjecture that, whatever the
new information D, it should tend to bring different people into closer agreement with each
other, in the sense that
|P(S|DIA)−P(S|DIB)|<|P(S|IA)−P(S|IB)|. (5.20)
Although this can be veriﬁed in special cases, it is not true in general.
Is there some other measure of ‘closeness of agreement’ such as log[ P(S|DIA)/
P(S|DIB)], for which this converging of opinions can be proved as a general theorem?
Not even this is possible; the failure of probability theory to give this expected result tellsus that convergence of views is not a general phenomenon. For robots and humans whoreason according to the consistency desiderata of Chapter 1, something more subtle andsophisticated is at work.
Indeed, in practice we ﬁnd that this convergence of opinions usually happens for small
children; for adults it happens sometimes but not always. For example, new experimentalevidence does cause scientists to come into closer agreement with each other about theexplanation of a phenomenon.
Then it might be thought (and for some it is an article of faith in democracy) that open
discussion of public issues would tend to bring about a general consensus on them. Onthe contrary, we observe repeatedly that when some controversial issue has been discussed

<<<PAGE 160>>>

128 Part 1 Principles and elementary applications
vigorously for a few years, society becomes polarized into opposite extreme camps; it is
almost impossible to ﬁnd anyone who retains a moderate view. The Dreyfus affair in France,which tore the nation apart for 20 years, is one of the most thoroughly documented examplesof this (Bredin, 1986). Today, such issues as nuclear power, abortion, criminal justice, etc.,are following the same course. New information given simultaneously to different peoplemay cause a convergence of views; but it may equally well cause a divergence.
This divergence phenomenon is observed also in relatively well-controlled psychological
experiments. Some have concluded that people reason in a basically irrational way; preju-dices seem to be strengthened by new information which ought to have the opposite effect.Kahneman and Tversky (1972) draw the opposite conclusion from such psychological tests,and consider them an argument against Bayesian methods.
But now, in view of the above ESP example, we wonder whether probability theory
might also account for this divergence and indicate that people may be, after all, thinkingin a reasonably rational, Bayesian way (i.e. in a way consistent with their prior informationand prior beliefs). The key to the ESP example is that our new information was not
S≡fully adequate precautions against error or deception were taken,
and Mrs Stewart did in fact deliver that phenomenal performance.(5.21)
It was that some ESP researcher has claimed thatSis true. But if our prior probability for
Sis lower than our prior probability that we are being deceived, hearing this claim has the
opposite effect on our state of belief from what the claimant intended.
The same is true in science and politics; the new information a scientist gets is not that
an experiment did in fact yield this result, with adequate protection against error. It is thatsome colleague has claimed that it did. The information we get from the TV evening news
is not that a certain event actually happened in a certain way; it is that some news reporterhasclaimed that it did.
1
Scientists can reach agreement quickly because we trust our experimental colleagues to
have high standards of intellectual honesty and sharp perception to detect possible sourcesof error. And this belief is justiﬁed because, after all, hundreds of new experiments arereported every month, but only about once in a decade is an experiment reported that turnsout later to have been wrong. So our prior probability for deception is very low; like trustingchildren, we believe what experimentalists tell us.
In politics, we have a very different situation. Not only do we doubt a politician’s promises,
few people believe that news reporters deal truthfully and objectively with economic, social,or political topics. We are convinced that virtually all news reporting is selective and dis-torted, designed not to report the facts, but to indoctrinate us in the reporter’s socio-politicalviews. And this belief is justiﬁed abundantly by the internal evidence in the reporter’s ownproduct – every choice of words and inﬂection of voice shifting the bias invariably in thesame direction.
1Even seeing the event on our screens can no longer convince us, after recent revelations that all major US networks had faked
some videotapes of alleged news events.

<<<PAGE 161>>>

5 Queer uses for probability theory 129
Not only in political speeches and news reporting, but wherever we seek for information
on political matters, we run up against this same obstacle; we cannot trust anyone to tell usthe truth, because we perceive that everyone who wants to talk about it is motivated eitherby self-interest or by ideology. In political matters, whatever the source of information, ourprior probability for deception is always very high. However, it is not obvious whether thisalone can prevent us from coming to agreement.
With this in mind, let us re-examine the equations of probability theory. To compare the
reasoning of Mr Aand Mr B, we could write Bayes’ theorem (5.17) in the logarithmic form
log/bracketleftbiggP(S|DI
A)
P(S|DIB)/bracketrightbigg
=log/bracketleftbiggP(S|IA)
P(S|IB)/bracketrightbigg
+log/bracketleftbiggP(D|SIA)P(D|IB)
P(D|IA)P(D|SIB)/bracketrightbigg
, (5.22)
which might be described by a simple hand-waving mnemonic like
log posterior=log prior+log likelihood. (5.23)
Note, however, that (5.22) differs from our log-odds equations of Chapter 4, which might
be described by the same mnemonic. There we compared different hypotheses, given the
same prior information, and some factors P(D|I) cancelled out. Here we are considering
a ﬁxed hypothesis S, in the light of different prior information, and the y do not cancel, so
the ‘likelihood’ term is different.
In the above, we supposed Mr Ato be the believer, so log (prior) >0. Then it is clear that
on the log scale their views will converge as expected, the left-hand side of (5.22) tendingto zero monotonically (i.e. Mr Awill remain a stronger believer than Mr B)i f
−log(prior) <log(likelihood) <0, (5.24)
and they will diverge monotonically if
log(likelihood) >0. (5.25)
But they will converge with reversal (Mr Bbecomes a stronger believer than Mr A)i f
−2 log(prior) <log(likelihood) <−log(prior) , (5.26)
and they will diverge with reversal if
log(likelihood) <−2 log(prior) . (5.27)
Thus, probability theory appears to allow, in principle, that a single piece of new information
Dcould have every conceivable effect on their relative states of belief.
But perhaps there are additional restrictions, not yet noted, which make some of these
outcomes impossible; can we produce speciﬁc and realistic examples of all four types ofbehavior? Let us examine only the monotonic convergence and divergence by the followingscenario, leaving it as an exercise for the reader to make a similar examination of the reversalphenomena.
The new information Dis: ‘Mr Nhas gone on TV with a sensational claim that a
commonly used drug is unsafe’, and three viewers, Mr A,M r B, and Mr C, see this. Their

<<<PAGE 162>>>

130 Part 1 Principles and elementary applications
prior probabilities P(S|I) that the drug is safe are (0.9, 0.1, 0.9), respectively; i.e. initially,
MrAand Mr Cwere believers in the safety of the drug, Mr Ba disbeliever.
But they interpret the information Dvery differently, because they have different views
about the reliability of Mr N. They all agree that, if the drug had really been proved unsafe,
MrNwould be right there shouting it: that is, their probabilities P(D|SI) are (1, 1, 1); but
MrAtrusts his honesty while Mr Cdoes not. Their probabilities P(D|SI) that, if the drug
is safe, Mr Nwould say that it is unsafe, are (0.01, 0.3, 0.99), respectively.
Applying Bayes’ theorem P(S|DI)=P(S|I)P(D|SI)/P(D|I), and expanding the de-
nominator by the product and sum rules, P(D|I)=P(S|I)P(D|SI)+P(S|I)P(D|SI),
we ﬁnd their posterior probabilities that the drug is safe to be (0.083, 0.032, 0.899), respec-tively. Put verbally, they have reasoned as follows:
A‘MrNis a ﬁne fellow, doing a notable public service. I had thought the drug to be safe from other
evidence, but he would not knowingly misrepresent the facts; therefore hearing his report leadsme to change my mind and think that the drug is unsafe after all. My belief in safety is lowered by20.0 db, so I will not buy any more.’
B‘MrNis an erratic fellow, inclined to accept adverse evidence too quickly. I was already convinced
that the drug is unsafe; but even if it is safe he might be carried away into saying otherwise. So,
hearing his claim does strengthen my opinion, but only by 5 .3 db. I would never under any
circumstances use the drug.’
C‘MrNis an unscrupulous rascal, who does everything in his power to stir up trouble by sensational
publicity. The drug is probably safe, but he would almost certainly claim it is unsafe whatever thefacts. So hearing his claim has practically no effect (only 0 .005 db) on my conﬁdence that the drug
is safe. I will continue to buy it and use it.’
The opinions of Mr Aand Mr Bconverge in about the way we conjectured in (5.20) because
both are willing to trust Mr N’s veracity to some extent. But Mr Aand Mr Cdiverge because
their prior probabilities of deception are entirely different. So one cause of divergence isnot merely that prior probabilities of deception are large, but that they are greatly differentfor different people.
This is not the only cause of divergence, however; to show this we introduce Mr Xand
MrY, who agree in their judgment of Mr N:
P(D|SI
X)=P(D|SIY)=a, P(D|SIX)=P(D|SIY)=b. (5.28)
Ifa<b, then they consider him to be more likely to be telling the truth than lying. But they
have different prior probabilities for the safety of the drug:
P(S|IX)=x, P(S|IY)=y. (5.29)
Their posterior probabilities are then
P(S|DIX)=ax
ax+b(1−x), P(S|DIY)=ay
ay+b(1−y), (5.30)

<<<PAGE 163>>>

5 Queer uses for probability theory 131
from which we see that not only are their opinions always changed in the same direction,
on the evidence scale they are always changed by the same amount, log( a/b):
log/bracketleftbiggP(S|DIX)
P(S|DIX)/bracketrightbigg
=log/bracketleftbiggx
1−x/bracketrightbigg
+log/bracketleftBiga
b/bracketrightBig
log/bracketleftbiggP(S|DIY)
P(S|DIY)/bracketrightbigg
=log/bracketleftbiggy
1−y/bracketrightbigg
+log/bracketleftBiga
b/bracketrightBig
.(5.31)
This means that, on the probability scale, they can either converge or diverge – see
Exercise 5.2. These equations correspond closely to those in our sequential widget testin Chapter 4, but have now a different interpretation. If a=b, then they consider Mr N
totally unreliable and their views are unchanged by his testimony. If a>b, they distrust
MrNso much that their opinions are driven in the opposite direction from what he intended.
Indeed, if b→0, then log( a/b)→∞ ; they consider it certain that he is lying, and so they
are both driven to complete belief in the safety of the drug: P(S|DI
X)=P(S|DIY)=1,
independently of their prior probabilities.
Exercise 5.2. From these equations, ﬁnd the exact conditions on ( x,y,a,b) for
divergence on the probability scale; that is,
|P(S|DIX)−P(S|DIY)|>|P(S|IX)−P(S|IY)|. (5.32)
Exercise 5.3. It is evident from (5.31) that Mr Xand Mr Ycan never experience
a reversal of viewpoint; that is, if initially Mr Xbelieves more strongly than Mr Y
in the safety of the drug, this will remain true whatever the values of a,b. There-
fore, a necessary condition for reversal must be that they have different opinions aboutMrN;a
x/negationslash=ayand/or bx/negationslash=by. But this does not prove that reversal is actually pos-
sible, so more analysis is needed. If reversal is possible, ﬁnd a sufﬁcient condition on(x,y,a
x,ay,bx,by) for this to take place, and illustrate it by a verbal scenario like
the above. If it is not possible, prove this and explain the intuitive reason why reversalcannot happen.
We see that divergence of opinions is readily explained by probability theory as logic, and
that it is to be expected when persons have widely different prior information. But wherewas the error in the reasoning that led us to conjecture (5.20)? We committed a subtle formof the mind projection fallacy by supposing that the relation ‘ Dsupports S’ is an absolute
property of the propositions DandS. We need to recognize the relativity of it; whether D
does or does not support Sdepends on our prior information. The same Dthat supports S
for one person may refute it for another. As soon as we recognize this, then we no longer

<<<PAGE 164>>>

132 Part 1 Principles and elementary applications
expect anything like (5.20) to hold in general. This error is very common; we shall see
another example of it in Section 5.7.
Kahneman and Tversky (1972) claimed that we are not Bayesians, because in psycho-
logical tests people often commit violations of Bayesian principles. However, this claim isseen differently in view of what we have just noted. We suggest that people are reasoningaccording to a more sophisticated version of Bayesian inference than they had in mind.
This conclusion is strengthened by noting that similar things are found even in deductive
logic. Wason and Johnson-Laird (1972) report psychological experiments in which subjectserred systematically in simple tests which amounted to applying a single syllogism. It seemsthat when asked to test the hypothesis ‘ Aimplies B’, they had a very strong tendency to
consider it equivalent to ‘ Bimplies A’ instead of ‘not- Bimplies not- A’. Even professional
logicians could err in this way.
2
Strangely enough, the nature of this error suggests a tendency toward Bayesianity, the
opposite of the Kahneman–Tversky conclusion. For, if Asupports Bin the sense that for
some X,P(B|AX)>P(B|X), then Bayes’ theorem states that Bsupports Ain the same
sense: P(A|BX)>P(A|X). But it also states that P(A|BX)>P(A|X), corresponding to
the syllogism. In the limit P(B|AX)→1, Bayes’ theorem does not give P(A|BX)→1,
but gives P(A|BX)→1, in agreement with the syllogism, as we noted in Chapter 2.
Errors made in staged psychological tests may indicate only that the subjects were pur-
suing different goals than the psychologists; they saw the tests as basically foolish, and didnot think it worth making any mental effort before replying to the questions – or perhapseven thought that the psychologists would be more pleased to see them answer wrongly.Had they been faced with logically equivalent situations where their interests were stronglyinvolved (for example, avoiding a serious accidental injury), they might have reasoned bet-ter. Indeed, there are stronger grounds – Darwinian natural selection – for expecting thatwe would reason in a basically Bayesian way.
5.4 Visual perception – evolution into Bayesianity?
Another class of psychological experiments ﬁts nicely into this discussion. In the early 20th
century, Adelbert Ames Jr was Professor of Physiological Optics at Dartmouth College. He
devised ingenious experiments which fool one into ‘seeing’ something very different from
the reality – one misjudges the size, shape, distance of objects. Some dismissed this as idleoptical illusioning, but others who sa w these demonstrations – notably including Alfred
North Whitehead and Albert Einstein – saw their true importance as revealing surprisingthings about the mechanism of visual perception.
3His work was carried on by Professor
Hadley Cantril of Princeton University, who discussed these phenomena and producedmovie demonstrations of them (Cantril, 1950).
2A possible complication of these tests – semantic confusion – readily suggests itself. We noted in Chapter 1 that the word
‘implication’ has a different meaning in formal logic than it has in ordinary language; ‘ Aimplies B’ does not have the usual
colloquial meaning that Bis logically deducible from A, as the subjects may have supposed.
3One of Ames’ most impressive demonstrations has been recreated at the Exploratorium in San Francisco, the full-sized ‘Ames
room’ into which visitors can look to see these phenomena at ﬁrst hand.

<<<PAGE 165>>>

5 Queer uses for probability theory 133
The brain develops in infancy certain assumptions about the world based on all the sensory
information it receives. For example, nearer objects appear larger, have greater parallax,and occlude distant objects in the same line of sight; a straight line appears straight fromwhatever direction it is viewed, etc. These assumptions are incorporated into the artist’s rulesof perspective and in three-dimensional computer graphics programs. We hold tenaciouslyonto them because they have been successful in correlating many different experiences. Wewill not relinquish successful hypotheses as long as they work; the only way to make onechange these assumptions is to put one in a situation where they don’t work. For example,in that Ames room where perceived size and distance correlate in the wrong way, a childwalking across the room doubles in height.
The general conclusion from all these experiments is less surprising to our relativist
generation than it was to the absolutist generation which made the discoveries. Seeing isnot a direct apprehension of reality, as we often like to pretend. Quite the contrary: seeing
is inference from incomplete information , no different in nature from the inference that we
are studying here. The information that reaches us through our eyes is grossly inadequate
to determine what is ‘really there’ before us. The failures of perception revealed by the
experiments of Ames and Cantrell are not mechanical failures in the lens, retina, or opticnerve; they are the reactions of the subsequent inference process in the brain when it receives
new data that are inconsistent with its prior information . These are just the situations
where one is obliged to resurrect some alternative hypothesis; and that is what we ‘see’.We expect that detailed analysis of these cases would show an excellent correspondencewith Bayesian inference, in much the same way as in our ESP and diverging opinionsexamples.
Active study of visual perception has continued, and volumes of new knowledge have
accumulated, but we still have almost no conception of how this is accomplished at thelevel of the neurons. Workers note the seeming absence of any organizing principle; wewonder whether the principles of Bayesian inference might serve as a start. We wouldexpect Darwinian natural selection to produce such a result; after all, any reasoning formatwhose results conﬂict with Bayesian inference will place a creature at a decided survivaldisadvantage. Indeed, as we noted long ago (Jaynes, 1957b), in view of Cox’s theorems,to deny that we reason in a Bayesian way is to assert that we reason in a deliberatelyinconsistent way; we ﬁnd this very hard to believe. Presumably, a dozen other examples ofhuman and animal perception would be found to obey a Bayesian reasoning format as its‘high level’ organizing principle, for the same reason. With this in mind, let us examine afamous case history.
5.5 The discovery of Neptune
Another potential application for probability theory, which has been discussed vigorously
by philosophers for over a century, concerns the reasoning process of a scientist, by whichhe accepts or rejects his theories in the light of the observed facts. We noted in Chapter 1

<<<PAGE 166>>>

134 Part 1 Principles and elementary applications
that this consists largely of the use of two forms of syllogism,
one strong:

ifA, then B
Bfalse
Afalse

and one weak:

ifA, then B
Btrue
Amore plausible

. (5.33)
In Chapter 2 we noted that these correspond to the use of Bayes’ theorem in the forms
P(A|BX)=P(A|X)P(B|AX)
P(B|X), P(A|BX)=P(A|X)P(B|AX)
P(B|X),(5.34)
respectively, and that these forms do agree qualitatively with the syllogisms.
Interest here centers on the question of whether the second form of Bayes’ theorem gives
a satisfactory quantitative version of the weak syllogism, as scientists use it in practice. Let
us consider a speciﬁc example given by P´ olya (1954, V ol. II, pp. 130–132). This will give
us a more useful example of the resurrection of alternative hypotheses.
The planet Uranus was disco vered by Wm Herschel in 1781. Within a few decades
(i.e. by the time Uranus had traversed about one-third of its orbit), it was clear that it
was not following exactly the path prescribed for it by the Newtonian theory (laws ofmechanics and gravitation). At this point, a na¨ ıve application of the strong syllogism might
lead one to conclude that the Newtonian theory was demolished. However, its many othersuccesses had established the Newtonian theory so ﬁrmly that in the minds of astronomersthe probability for the hypothesis: ‘Newton’s theory is false’ was already down at perhaps−50 db. Therefore, for the French astronomer Urbain Jean Joseph Leverrier (1811–1877)
and the English scholar John Couch Adams (1819–1892) at St John’s College, Cambridge,an alternative hypothesis down at perhaps −20 db was resurrected: there must be still another
planet beyond Uranus, whose gravitational pull is causing the discrepancy.
Working unknown to each other and backwards, Leverrier and Adams computed the mass
and orbit of a planet which could produce the observed deviation and predicted where thenew planet would be found, with nearly the same results. The Berlin observatory receivedLeverrier’s prediction on September 23, 1846, and, on the evening of the same day, theastronomer Johann Gottfried Galle (1812–1910) found the new planet (Neptune) withinabout one degree of the predicted position. For many more details, see Smart (1947) or
Grosser (1979).
Instinctively, we feel that the plausibility for the Newtonian theory was increased by
this little drama. The question is, how much? The attempt to apply probability theory to
this problem will give us a good example of the complexity of actual situations faced by
scientists, and also of the caution one needs in reading the rather confused literature onthese problems.
Following P´ olya’s notation, let Tstand for the Newtonian theory, Nfor the part
of Leverrier’s prediction that was veriﬁed. Then probability theory gives the posterior

<<<PAGE 167>>>

5 Queer uses for probability theory 135
probability for Tas
P(T|NX)=P(T|X)P(N|TX)
P(N|X). (5.35)
Suppose we try to evaluate P(N|X). This is the prior probability for N, regardless of whether
Tis true or not. As usual, denote the denial of TbyT. Since N=N(T+T)=NT+NT,
we have, by applying the sum and product rules,
P(N|X)=P(NT+NT|X)=P(NT|X)+P(NT|X)
=P(N|TX)P(T|X)+P(N|TX)P(T|X),(5.36)
andP(N|TX) has intruded itself into the problem. But in the problem as stated this quantity
is not deﬁned; the statement T≡‘Newton’s theory is false’ has no deﬁnite implications
until we specify what alternative we have to put in place of Newton’s theory.
For example, if there were only a single possible alternative according to which there
could be no planets beyond Uranus, then P(N|TX)=0, and probability theory would again
reduce to deductive reasoning, giving P(T|NX)=1, independently of the prior probability
P(T|X).
On the other hand, if Einstein’s theory were the only possible alternative, its predictions
do not differ appreciably from those of Newton’s theory for this phenomenon, and we wouldhave P(N|
TX)=P(N|TX), whereupon P(T|NX)=P(T|X).
Thus, veriﬁcation of the Leverrier–Adams prediction might elevate the Newtonian theory
to certainty, or it might have no effect at all on its plausibility. It depends entirely on this:against which speciﬁc alternatives are we testing Newton’s theory ?
Now, to a scientist who is judging his theories, this conclusion is the most obvious exercise
of common sense. We have seen the mathematics of this in some detail in Chapter 4, butall scientists see the same thing intuitively without any mathematics.
For example, if you ask a scientist, ‘How well did the Zilch experiment support the Wilson
theory?’ you may get an answer like this: ‘Well, if you had asked me last week I wouldhave said that it supports the Wilson theory very handsomely; Zilch’s experimental pointslie much closer to Wilson’s predictions than to Watson’s. But, just yesterday, I learned thatthis fellow Woffson has a new theory based on more plausible assumptions, and his curvegoes right through the experimental points. So now I’m afraid I have to say that the Zilchexperiment pretty well demolishes the Wilson theory.’
5.5.1 Digression on alternative hypotheses
In view of this, working scientists will note with dismay that statisticians have developed
ad hoc criteria for accepting or rejecting theories (chi-squared test, etc.) which make no
reference to any alternatives. A practical difﬁculty of this was pointed out by Jeffreys (1939);there is not the slightest use in rejecting any hypothesis H
0unless we can do it in favor of
some deﬁnite alternative H1which better ﬁts the facts.
Of course, we are concerned here with hypotheses which are not themselves statements
of observable fact. If the hypothesis H0is merely that x<y, then a direct, error-free

<<<PAGE 168>>>

136 Part 1 Principles and elementary applications
measurement of xandywhich conﬁrms this inequality constitutes positive proof of the
correctness of the hypothesis, independently of any alternatives. We are considering hy-potheses which might be called ‘scientiﬁc theories’ in that they are suppositions about whatis not observable directly; only some of their consequences – logical or causal – can beobserved by us.
For such hypotheses, Bayes’ theorem tells us this: Unless the observed facts are abso-
lutely impossible on hypothesis H
0, it is meaningless to ask how much those facts tend ‘in
themselves’ to conﬁrm or refute H 0. Not only the mathematics, but also our innate com-
mon sense (if we think about it for a moment) tell us that we have not asked any deﬁnite,well-posed question until we specify the possible alternatives to H
0. Then, as we saw in
Chapter 4, probability theory can tell us how our hypothesis fares relative to the alternatives
that we have speciﬁed ; it does not have the creative imagination to invent new hypotheses
for us.
Of course, as the observed facts approach impossibility on hypothesis H0, we are led to
worry more and more about H0; but mere improbability, however great, cannot in itself be
the reason for doubting H0. We almost noted this after Eq. (5.7); now we are laying stress
on it because it will be essential for our later general formulation of signiﬁcance tests.
Early attempts to devise such tests foundered on the point we are making. Arbuthnot
(1710) noted that in 82 years of demographic data more boys than girls were born in every
year. On the ‘null hypothesis’ H0that the probability for a boy is 1 /2, he considered the
probability for this result to be 2−82=10−24.7(in our measure,−247 db), so small as to
make H0seem to him virtually impossible, and saw in this evidence for ‘Divine Providence’.
He was, apparently, the ﬁrst person to reject a statistical hypothesis on the grounds that itrenders the data improbable. However, we can criticize his reasoning on several grounds.
Firstly, the alternative hypothesis H
1≡‘Divine Providence’ does not seem usable in
a probability calculation because it is not speciﬁc. That is, it does not make any deﬁnitepredictions known to us, and so we cannot assign any probability for the data P(D|H
1)
conditional on H1. (For this same reason, the mere logical denial H1≡H0is unusable as
an alternative.) In fact, it is far from clear why Divine Providence would wish to generatemore boys than girls; indeed, if the number of boys and girls were exactly equal every yearin a large population, that would seem to us much stronger evidence that some supernatural
control mechanism must be at work.
Secondly, on the null hypothesis (independent and equal probability for a boy or girl
at each birth) the probability P(D|H
0) of ﬁnding the observed sequence would have been
just as small whatever the data, so by Arbuthnot’s reasoning the hypothesis would havebeen rejected whatever the data! Without having the probability P(D|H
1) of the data on
the alternative hypothesis andthe prior probabilities of the hypotheses, there is just no
well-posed problem and no rational basis for passing judgment.
Finally, having observed more boys than girls for ten consecutive years, rational inference
might have led Arbuthnot to anticipate it for the 11th year. Thus his hypothesis H0was
not only the numerical value p=1/2; there was also an implicit assumption of logical
independence for different years, of which he was probably unaware. On an hypothesis that

<<<PAGE 169>>>

5 Queer uses for probability theory 137
allows for positive correlations, for example Hex, which assigns an exchangeable sampling
distribution, the probability P(D|Hex) for the aggregated data could be very much greater
than 2−82. Thus, Arbuthnot took a small step in the right direction, but to get a usable
signiﬁcance test required a conceptual understanding of probability theory on a considerablyhigher level, as achieved by Laplace some 100 years later.
Another example occurred when Daniel Bernoulli won a French Academy prize of 1734
with an essay on the orbits of planets, in which he represented the orientation of each orbitby its polar point on the unit sphere and found them so close together as to make it veryunlikely that the present distribution could result by chance. Although he too failed to statea speciﬁc alternative, we are inclined to accept his conclusion today because there seemsto be a very clearly implied null hypothesis H
0of ‘chance’ according to which the points
should appear spread all over the sphere with no tendency to cluster together, and H1of
‘attraction’, which would make them tend to coincide; the evidence rather clearly supported
H1over H0.
Laplace (1812) did a similar analysis on comets, found their polar points much more
scattered than those of the planets, and concluded that comets are not ‘regular members’
of the solar system like the planets. Here we ﬁnally had two fairly well-deﬁned hypothesesbeing compared by a correct application of probability theory.
4
Such tests need not be quantitative. Even when the application is only qualitative, proba-
bility theory is still useful to us in a normative sense; it is the means by which we can detectinconsistencies in our own qualitative reasoning. It tells us immediately what has not beenintuitively obvious to all workers: that alternatives are needed before we have any rationalcriterion for testing hypotheses.
This means that if any signiﬁcance test is to be acceptable to a scientist, we shall need
to examine its rationale to see whether it has, like Daniel Bernoulli’s test, some impliedif unstated alternative hypotheses. Only when such hypotheses are identiﬁed are we ina position to say what the test accomplishes; i.e. what it is testing. But not to keep thereader in suspense: a statisticians’ formal signiﬁcance test can always be interpreted as atest of a speciﬁed hypothesis H
0against a speciﬁed class of alternatives, and thus it is only
a mathematical generalization of our treatment of multiple hypothesis tests in Chapter 4,Eqs. (4.31)–(4.49). However, the orthodox literature, which dealt with composite hypothesesby applying arbitrary ad hockeries instead of probability theory, never perceived this.
5.5.2 Back to Newton
Now we want to formulate a quantitative result about Newton’s theory. In P´ olya’s discussion
of the feat of Leverrier and Adams, once again no speciﬁc alternative to Newton’s theoryis stated; but from the numerical values used (P´ olya, 1954, V ol. II, p. 131) we can infer
that he had in mind a single possible alternative H
1according to which it was known
4It is one of the tragedies of history that Cournot (1843), failing to comprehend Laplace’s rationale, attacked it and reinstated the
errors of Arbuthnot, thereby dealing scientiﬁc inference a setback from which it required a lifetime to recover.

<<<PAGE 170>>>

138 Part 1 Principles and elementary applications
that one more planet existed beyond Uranus, but all directions on the celestial sphere were
considered equally likely. Then, since a cone of angle 1 degree ﬁlls in the sky a solid angle ofabout π/(57.3)
2=10−3steradian, P(N|H1X)/similarequal10−3/4π=1/13 000 is the probability
that Neptune would have been within 1 degree of the predicted position.
Unfortunately, in the calculation no distinction was made between P(N|X) and
P(N|TX); that is, instead of the calculation (5.35) indicated by probability theory, the
likelihood ratio actually calculated by P´ olya was, in our notation,
P(N|TX)
P(N|TX)=P(N|TX)
P(N|H1X). (5.37)
Therefore, according to the analysis in Chapter 4, what P´ olya obtained was not the ratio of
posterior to prior probabilities, but the ratio of posterior to prior odds:
O(N|TX)
O(N|X)=P(N|TX)
P(N|TX)=13 000 . (5.38)
The conclusions are much more satisfactory when we notice this. Whatever prior probability
P(T|X) we assign to Newton’s theory, if H1is the only alternative considered, then veriﬁ-
cation of the prediction increased the evidence for Newton’s theory by 10 log10(13 000)=
41 db.
Actually, if there were a new planet it would be reasonable, in vie w of the aforementioned
investigations of Daniel Bernoulli and Laplace, to adopt a different alternative hypothesis
H2, according to which its orbit would lie in the plane of the ecliptic, as P ´olya again notes
by implication rather than explicit statement. If, on hypothesis H2, all values of longitude
are considered equally likely, we might reduce this to about 10 log10(180)=23 db. In view
of the great uncertainty as to just what the alternative is (i.e. in view of the fact that theproblem has not been deﬁned unambiguously), any value between these extremes seemsmore or less reasonable.
There was a difﬁculty which bothered P´ olya: if the probability of Newton’s theory
were increased by a factor of 13 000, then the prior probability was necessarily lowerthan (1/13 000); but this contradicts common sense, because Newton’s theory was alreadyvery well established before Leverrier was born. P´ olya interprets this in his book as reveal-
ing an inconsistency in Bayes’ theorem, and the danger of trying to apply it numerically.Recognition that we are, in the above numbers, dealing with odds rather than probabilities,removes this objection and makes Bayes’ theorem appear quite satisfactory in describingthe inferences of a scientist.
This is a good example of the way in which objections to the Bayes–Laplace methods
which you ﬁnd in the literature disappear when you look at the problem more carefully. Byan unfortunate slip in the calculation, P´ olya was led to a misunderstanding of how Bayes’
theorem operates. But I am glad to be able to close the discussion of this incident with ahappier personal reminiscence.
In 1956, two years after the appearance of P´ olya’s work, I gave a series of lectures on
these matters at Stanford University, and George P´ olya attended them, sitting in the ﬁrst

<<<PAGE 171>>>

5 Queer uses for probability theory 139
row and paying the most strict attention to everything that was said. By then he understood
this point very well – indeed, whenever a question was raised from the audience, P´ olya
would turn around and give the correct answer, before I could. It was very pleasant to havethat kind of support, and I miss his presence today (George P´ olya died, at the age of 97, in
September 1985).
But the example also shows clearly that, in practice, the situation faced by the scientist
is so complicated that there is little hope of applying Bayes’ theorem to give quantitativeresults about the relative status of theories. Also there is no need to do this, because thereal difﬁculty of the scientist is not in the reasoning process itself; his common sense isquite adequate for that. The real difﬁculty is in learning how to formulate new alternativeswhich better ﬁt the facts. Usually, when one succeeds in doing this, the evidence for thenew theory soon becomes so overwhelming that nobody needs probability theory to tellhim what conclusions to draw.
Exercise 5.4. Our story has a curious sequel. In turn, it was noticed that Neptune was
not following exactly its proper course, and so one naturally assumed that there is stillanother planet causing this. Percival Lowell, by a similar calculation, predicted its orbit,and Clyde Tombaugh proceeded to ﬁnd the new planet (Pluto), although not so close tothe predicted position. But now the story changes: modern data on the motion of Pluto’smoon indicated that the mass of Pluto is too small to have caused the perturbation ofNeptune which motivated Lowell’s calculation. Thus, the discrepancies in the motionsof Neptune and Pluto were unaccounted for. (We are indebted to Dr Brad Schaefer forthis information.) Try to extend our probability analysis to take this new circumstanceinto account; at this point, where did Newton ’s theory stand? For more background
information, see Hoyt (1980) or Whyte (1980). More recently, it appears that the massof Pluto had been estimated wrongly and the discrepancies were after all not real; thenit seems that the status of Newton’s theory should revert to its former one. Discussthis sequence of pieces of information in terms of probability theory. Do we update byBayes’ theorem as each new fact comes in? Or do we just return to the be ginning when
we learn that a previous datum was false?
At present, we have no formal theory at all on the process of ‘optimal hypothesis
formulation’, and we are dependent entirely on the creative imagination of individual per-sons such as Newton, Mendel, Einstein, Wegener, and Crick (1988). So, we would say thatin principle the application of Bayes’ theorem in the above way is perfectly legitimate; but
in practice it is of very little use to a scientist.
However, we should not presume to give quick, glib answers to deep questions. The
question of exactly how scientists do, in practice, pass judgment on their theories, remainscomplex and not well analyzed. Further comments on the validity of Newton’s theory areoffered in our closing Comments, Section 5.9.

<<<PAGE 172>>>

140 Part 1 Principles and elementary applications
5.6 Horse racing and weather forecasting
The preceding examples noted two different features common in problems of inference:
(a) as in the ESP and psychological cases, the information we receive is often not a directproposition like Sin (5.21), but is an indirect claim that Sis true, from some ‘noisy’ source
that is itself not wholly reliable; (b) as in the example of Neptune, there is a long tradition ofwriters who have misapplied Bayes’ theorem and concluded that Bayes’ theorem is at fault.Both features are present simultaneously in a work of the Princeton philosopher Richard C.Jeffrey (1983), hereafter denoted by RCJ to avoid confusion with the Cambridge scholarSir Harold Jeffreys.
RCJ considers the following problem. With only prior information I, we assign a prob-
ability P(A|I) for A. Then we get new information B, and it changes as usual via Bayes’
theorem to
P(A|BI)=P(A|I)P(B|AI)/P(B|I). (5.39)
But then he decides that Bayes’ theorem is not sufﬁciently general, because we often receive
new information that is not certain; perhaps the probability for Bis not unity but, say, q.
To this we would reply: ‘If you do not accept Bas true, then why are you using it in
Bayes’ theorem this way?’ But RCJ follows that long tradition and concludes, not that itis a misapplication of Bayes’ theorem to use uncertain information as in (5.39), but thatBayes’ theorem is itself faulty, and it needs to be generalized to take the uncertainty of new
information into account.
His proposed generalization (denoting the denial of Bby
B) is that the updated probability
forAshould be taken as a weighted average:
P(A)J=qP(A|BI)+(1−q)P(A|BI). (5.40)
But this is an ad hockery that does not follow from the rules of probability theory unless
we take qto be the prior probability P(B|I), just the case that RCJ excludes (for then
P(A)J=P(A|I), and there is no updating).
Since (5.40) conﬂicts with the rules of probability theory, we know that it necessarily
violates one of the desiderata that we discussed in Chapters 1 and 2. The source of the troubleis easy to ﬁnd, because those desiderata tell us where to look. The proposed ‘generalization’(5.40) cannot hold generally because we could learn many different things, all of whichindicate the same probability qforB; but which have different implications for A. Thus
(5.40) violates desideratum (1.39b); it cannot take into account all of the new information,only the part of it that involves (i.e. is relevant to) B.
The analysis of Chapter 2 tells us that, if we are to salvage things and recover a well-posed
problem with a defensible solution, we must not depart in any way from Bayes’ theorem .
Instead, we need to recognize the same thing that we stressed in the ESP example; if Bis not
known with certainty to be true, then Bcould not have been the new information; the actual
information received must have been some proposition Csuch that P(B|CI)=q. But then,
of course, we should be considering Bayes’ theorem conditional on C, rather than B:
P(A|CI)=P(A|I)P(C|AI)/P(C|I). (5.41)

<<<PAGE 173>>>

5 Queer uses for probability theory 141
If we apply it properly, Bayes’ theorem automatically takes the uncertainty of new
information into account. This result can be written, using the product and sum rules ofprobability theory, as
P(A|CI)=P(AB|CI)+P(A
B|CI)=P(A|BCI )P(B|CI)+P(A|BCI )P(B|CI),
(5.42)
and if we deﬁne q≡P(B|CI) to be the updated probability for B, this can be written in
the form
P(A|CI)=qP(A|BCI )+(1−q)P(A|BCI ), (5.43)
which resembles (5.40), but is not in general equal to it, unless we add the restriction that
the probabilities P(A|BCI ) and P(A|BCI ) are to be independent of C. Intuitively, this
would mean that the logic ﬂows thus:
(C→B→A) (5.44)
rather than
(C→A). (5.45)
That is, Cis relevant to Aonly through its intermediate relevance to B(Cis relevant to B
andBis relevant to A).
RCJ shows by example that this logic ﬂow may be present in a real problem, but fails to
note that his proposed solution (5.40) is then the same as the Bayesian result. Without thatlogic ﬂow, (5.40) will be unacceptable in general because it does not take into account allof the new information. The information which is lost is indicated by the lack of an arrowgoing directly ( C→A) in the logic ﬂow diagram (5.45); information in Cwhich is directly
relevant to A, whether or not Bis true.
If we think of the logic ﬂow as something like the ﬂow of light, we might visualize it thus.
At night we receive sunlight only through its intermediate reﬂection from the moon; thiscorresponds to the RCJ solution. But in the daytime we receive light directly from the sun,whether or not the moon is there; this is what the RCJ solution has missed. (In fact, whenwe study the maximum entropy formalism in statistical mechanics and the phenomenon of‘generalized scattering’, we shall ﬁnd that this is more than a loose analogy; the process
of conditional information ﬂow is in almost exact mathematical correspondence with the
Huygens principle of optics.)
Exercise 5.5. We might expect intuitively that when q→1 this difference would
disappear; i.e. P(A|BI)→P(A|CI). Determine whether this is or is not generally
true. If it is, indicate how small 1 −qmust be in order to make the difference practically
negligible. If it is not, illustrate by a verbal scenario the circumstances which can preventthis agreement.

<<<PAGE 174>>>

142 Part 1 Principles and elementary applications
We can illustrate this in a more down-to-earth way by one of RCJ’s own scenarios:
A≡my horse will win the race tomorrow,
B≡the track will be muddy,
I≡whatever I know about my horse and jockey in particular, and about horses,
jockeys, races, and life in general,
and the probability P(A|I) is updated as a result of receiving a weather forecast. Then some
proposition Csuch as:
C≡the TV weather forecaster showed us today’s weather map, quoted some
of the current meteorological data, and then by means unexplainedassigned probability q
/primefor rain tomorrow
is clearly present, but it is not recognized and stated by RCJ. Indeed, to do so would introduce
much new detail, far beyond the gambit of propositions ( A,B) of interest to horse racers.
If we recognize proposition Cexplicitly, then we must recall everything we know about
the process of weather forecasting, what were the particular meteorological data leadingto that forecast, how reliable weather forecasts are in the presence of such data, how theofﬁcially announced probability q
/primeis related to what the forecaster really believes (i.e. what
we think the forecaster perceives his own interest to be), etc.
If the above-deﬁned Cis the new information, then we must consider also, in the light
of all our prior information, how Cmight affect the prospects for the race Athrough other
circumstances than the muddiness Bof the track; perhaps the jockey is blinded by bright
sunlight, perhaps the rival horse runs poorly on cloudy days, whether or not the track is wet.These would be logical relations of the form ( C→A) that (5.40) cannot take into account.
Therefore the full solution must be vastly more complicated than (5.40); but this is, of
course, as it should be. Bayes’ theorem, as always, is only telling us what common sensedoes; in general the updated probability for Amust depend on far more than just the updated
probability qforB.
5.6.1 Discussion
This example illustrates what we have noted before in Chapter 1; that familiar problems
of everyday life may be more complicated than scientiﬁc problems, where we are oftenreasoning about carefully controlled situations. The most familiar problems may be socomplicated – just because the result depends on so many unknown and uncontrolledfactors – that a full Bayesian analysis, although correct in principle, is out of the questionin practice. The cost of the computation is far more than we could hope to win on the horse.
Then we are necessarily in the realm of approximation techniques; but, since we cannot
apply Bayes’ theorem exactly, need we still consider it at all? Yes, because Bayes’ theoremremains the normative principle telling us what we should aim for. Without it, we havenothing to guide our choices and no criterion for judging their success.
It also illustrates what we shall ﬁnd repeatedly in later chapters: that generations of work-
ers in this ﬁeld have not comprehended the fact that Bayes’ theorem is a valid theorem ,

<<<PAGE 175>>>

5 Queer uses for probability theory 143
required by elementary desiderata of rationality and consistency, and have made unbeliev-
ably persistent attempts to replace it by all kinds of intuitive ad hockeries . Of course, we
expect that any sincere intuitive effort will capture bits of the truth; yet all of these dozensof attempts have proved on analysis to be satisfactory only in those cases where they agreewith Bayes’ theorem after all.
We are at a loss, however, to understand what motivates these anti-Bayesian efforts,
because we can see nothing unsatisfactory about Bayes’ theorem, either in its theoreticalfoundations, its intuitive rationale, or its pragmatic results. The writer has devoted some40 years to the analysis of thousands of separate problems by Bayes’ theorem, and isstill being impressed by the beautiful and important results it gives us, often in a fewlines, and far beyond what those ad hockeries can produce. We have yet to ﬁnd a case
where it yields an unsatisfactory result (although the result is sometimes surprising at ﬁrstglance, and it requires some meditation to educate our intuition and see that it is correctafter all).
Needless to say, the cases where we are at ﬁrst surprised are just the ones where Bayes’
theorem is most valuable to us; because those are the cases where intuitive ad hockeries
would never have found the result. Comparing Bayesian analysis with the ad hoc methods
which saturate the literature, whenever there is any disagreement in the ﬁnal conclusions,we have found it easy to exhibit the defect of the ad hockery , just as the analysis of Chapter 2
led us to expect, and as we saw in the above example.
In the past, many man-years of effort were wasted in futile attempts to square the circle;
had Lindemann’s theorem (that πis transcendental) been known and its implications recog-
nized, all of this might have been averted. Likewise, had Cox’s theorems been known, andtheir implications recognized, 100 years ago, many wasted careers might have been turnedinstead to constructive activity. This is our answer to those who have suggested that Cox’stheorems are unimportant, because they only conﬁrm what James Bernoulli and Laplacehad conjectured long before.
Today, we have ﬁve decades of experience conﬁrming what Cox’s theorems tell us. It
is clear that, not only is the quantitative use of the rules of probability theory as extendedlogic the only sound way to conduct inference; it is the failure to follow those rules strictly
that has for many years been leading to unnecessary errors, paradoxes, and controversies.
5.7 Paradoxes of intuition
A famous example of this situation, known as Hempel’s paradox, starts with the premise:
‘A case of an hypothesis supports the hypothesis.’ Then it observes: ‘Now the hypothesisthat all crows are black is logically equivalent to the statement that all non-black things arenon-crows, and this is supported by the observation of a white shoe.’ An incredible amounthas been written about this seemingly innocent argument, which leads to an intolerableconclusion.
The error in the argument is apparent at once when one examines the equations of
probability theory applied to it: the premise, which was not derived from any logical analysis,

<<<PAGE 176>>>

144 Part 1 Principles and elementary applications
is not generally true, and he prevents himself from discovering that fact by trying to judge
support of an hypothesis without considering any alternatives.
Good (1967), in a note entitled ‘The white shoe is a red herring’, demonstrated the error
in the premise by a simple counterexample. In World 1 there are one million birds, of which100 are crows, all black. In World 2 there are two million birds, of which 200 000 are blackcrows and 1 800 000 are white crows. We observe one bird, which proves to be a black crow.Which world are we in?
Evidently, observation of a black crow gives evidence of
10 log
10/parenleftbigg200 000 /2 000 000
100/1 000 000/parenrightbigg
=30 db, (5.46)
or an odds ratio of 1000:1, against the hypothesis that all crows are black; that is, for
World 2 against World 1. Whether an ‘instance of an hypothesis’ does or does notsupport the hypothesis depends on the alternatives being considered and on the priorinformation. We learned this in ﬁnding the error in the reasoning leading to (5.20). But,incredibly, Hempel (1967) proceeded to reject Good’s clear and compelling argumenton the grounds that it was unfair to introduce that background information about Worlds1 and 2.
In the literature there are perhaps 100 ‘paradoxes’ and controversies which are like this,
in that they arise from faulty intuition rather than faulty mathematics. Someone assertsa general principle that seems to him intuitively right. Then, when probability analysisreveals the error, instead of taking this opportunity to educate his intuition, he reacts by
rejecting the probability analysis. We shall see several more examples of this; in particular,
the marginalization paradox in Chapter 15.
As a colleague of the writer once remarked, ‘Philosophers are free to do whatever they
please, because they don’t have to do anything right.’ But a responsible scientist does nothave that freedom; he will not assert the truth of a general principle, and urge others to adoptit, merely on the strength of his own intuition. Some outstanding examples of this error,which are not mere philosophers’ toys like the RCJ tampering with Bayes’ theorem and theHempel paradox, but have been actively harmful to Science and Society, are discussed inChapters 15 and 17.
5.8 Bayesian jurisprudence
It is interesting to apply probability theory in various situations in which we can’t always re-
duce it to numbers very well, but still it shows automatically what kind of information wouldbe relevant to help us do plausible reasoning. Suppose someone in New York City has com-mitted a murder, and you don’t know at ﬁrst who it is, but you know that there are 10 millionpeople in New York City. On the basis of no knowledge but this, e(guilty|X)=−70 db is
the plausibility that any particular person is the guilty one.
How much positive evidence for guilt is necessary before we decide that some man should
be put away? Perhaps +40 db, although your reaction may be that this is not safe enough,

<<<PAGE 177>>>

5 Queer uses for probability theory 145
and the number ought to be higher. If we raise this number we give increased protection to
the innocent, but at the cost of making it more difﬁcult to convict the guilty; and at somepoint the interests of society as a whole cannot be ignored.
For example, if 1000 guilty men are set free, we know from only too much experience
that 200 or 300 of them will proceed immediately to inﬂict still more crimes upon society,and their escaping justice will encourage 100 more to take up crime. So it is clear that thedamage to society as a whole caused by allowing 1000 guilty men to go free, is far greaterthan that caused by falsely convicting one innocent man.
If you have an emotional reaction against this statement, I ask you to think: if you were
a judge, would you rather face one man whom you had convicted falsely; or 100 victims ofcrimes that you could have prevented? Setting the threshold at +40 db will mean, crudely,
that on the average not more than one conviction in 10 000 will be in error; a judge whorequired juries to follow this rule would probably not make one false conviction in a workinglifetime on the bench.
In any event, if we took +40 db starting out from −70 db, this means that in order to
ensure a conviction you would have to produce about 110 db of evidence for the guilt ofthis particular person. Suppose now we learn that this person had a motive. What does thatdo to the plausibility for his guilt? Probability theory says
e(guilty|motive)=e(guilty|X)+10 log
10/bracketleftbiggP(motive|guilty)
P(motive|not guilty)/bracketrightbigg
/similarequal−70−10 log10P(motive|not guilty) ,(5.47)
since P(motive|guilty)/similarequal1, i.e. we consider it quite unlikely that the crime had no mo-
tive at all. Thus, the signiﬁcance of learning that the person had a motive depends al-most entirely on the probability P(motive|not guilty) that an innocent person would also
have a motive.
This evidently agrees with our common sense, if we ponder it for a moment. If the
deceased were kind and loved by all, hardly anyone would have a motive to do him in.Learning that, nevertheless, our suspect didhave a motive, would then be very signiﬁcant
information. If the victim had been an unsavory character , who took great delight in all
sorts of foul deeds, then a great many people would have a motive, and learning that our
suspect was one of them is not so signiﬁcant. The point of this is that we don’t know whatto make of the information that our suspect had a motive, unless we also know somethingabout the character of the deceased. But how many members of juries would realize that,unless it was pointed out to them?
Suppose that a very enlightened judge, with powers not given to judges under present law,
had perceived this fact and, when testimony about the motive was introduced, he directedhis assistants to determine for the jury the number of people in New York City who had a
motive. If this number is N
mthen
P(motive|not guilty)=Nm−1
(number of people in New York) −1/similarequal10−7(Nm−1),(5.48)

<<<PAGE 178>>>

146 Part 1 Principles and elementary applications
and (5.47) reduces, for all practical purposes, to
e(guilty|motive)/similarequal−10 log10(Nm−1). (5.49)
You see that the population of New York has cancelled out of the equation; as soon as we
know the number of people who had a motive, then it doesn’t matter any more how largethe city was. Note that (5.49) continues to say the right thing even when N
mis only 1 or 2.
You can go on this way for a long time, and we think you will ﬁnd it both enlightening and
entertaining to do so. For example, we now learn that the suspect was seen near the sceneof the crime shortly before. From Bayes’ theorem, the signiﬁcance of this depends almostentirely on how many innocent persons were also in the vicinity. If you have ever been toldnot to trust Bayes’ theorem, you should follow a few examples like this a good deal further,and see how infallibly it tells you what information would be relevant, what irrelevant,in plausible reasoning.
5In recent years there has grown up a considerable literature on
Bayesian jurisprudence; for a review with many references, see Vignaux and Robertson(1996).
Even in situations where we would be quite unable to say that numerical values should
be used, Bayes’ theorem still reproduces qualitatively just what your common sense (afterperhaps some meditation) tells you. This is the fact that George P´ olya demonstrated in such
exhaustive detail that the present writer was convinced that the connection must be morethan qualitative.
5.9 Comments
There has been much more discussion of the status of Newton’s theory than we indicated
above. For example, it has been suggested by Charles Misner that we cannot apply a theorywith full conﬁdence until we know its limits of validity – where it fails.
Thus, relativity theory, in showing us the limits of validity of Newtonian mechanics,
also conﬁrmed its accuracy within those limits; so it should increase our conﬁdence inNewtonian theory when applied within its proper domain (velocities small compared withthat of light). Likewise, the ﬁrst law of thermodynamics, in showing us the limits of validityof the caloric theory, also conﬁrmed the accuracy of the caloric theory within its properdomain (processes where heat ﬂows but no work is done). At ﬁrst glance this seems anattractive idea, and perhaps this is the way scientists really should think.
5Note that in these cases we are trying to decide, from scraps of incomplete information, on the truth of an Aristotelian proposition;
whether the defendant did or did not commit some well-deﬁned action. This is the situation – an issue of fact – for which
probability theory as logic is designed. But there are other legal situations quite different; for example, in a medical malpractice
suit it may be that all parties are agreed on the facts as to what the defendant actually did; the issue is whether he did or didnot exercise reasonable judgment. Since there is no ofﬁcial, precise deﬁnition of ‘reasonable judgment’, the issue is not the
truth of an Aristotelian proposition (however, if it were established that he wilfully violated one of our Chapter 1 desiderata of
rationality, we think that most juries would convict him). It has been claimed that probability theory is basically inapplicable tosuch situations, and we are concerned with the partial truth of a non-Aristotelian proposition. We suggest, however, that in such
cases we are not concerned with an issue of truth at all; rather, what is wanted is a value judgment. We shall return to this topic
later (Chapters 13, 18).

<<<PAGE 179>>>

5 Queer uses for probability theory 147
Nevertheless, Misner’s principle contrasts strikingly with the way scientists actually do
think. We know of no case where anyone has avowed that his conﬁdence in a theorywas increased by its being, as we say, ‘overthrown’. Furthermore, we apply the principleof conservation of momentum with full conﬁdence, not because we know its limits ofvalidity, but for just the opposite reason; we do not know of any such limits. Yet scientistsbelieve that the principle of momentum conservation has real content; it is not a meretautology.
Not knowing the answer to this riddle, we pursue it only one step further, with the
observation that if we are trying to judge the validity of Newtonian mechanics, we cannotbe sure that relativity theory showed us all its limitations. It is conceivable, for example,that it may fail not only in the limit of high velocities, but also in that of high accelerations.Indeed, there are theoretical reasons for expecting this; for Newton’s F=maand Einstein’s
E=mc
2can be combined into a perhaps more fundamental statement:
F=(E/c2)a. (5.50)
Why should the force required to accelerate a bundle of energy Edepend on the velocity
of light?
We see a plausible reason at once, if we adopt the – almost surely true – hypothesis that
our allegedly ‘elementary’ particles cannot occupy mere mathematical points in space, butare extended structures of some kind. Then the velocity of light determines how rapidlydifferent parts of the structure can ‘communicate’ with each other. The more quickly allparts can learn that a force is being applied, the more quickly they can all respond to it. Weleave it as an exercise for the reader to show that one can actually derive Eq. (5.50) fromthis premise. (Hint: the force is proportional to the deformation that the particle must sufferbefore all parts of it start to move.)
But this embryonic theory makes further predictions immediately. We would expect that,
when a force is applied suddenly, a short transient response time would be required for theacceleration to reach its Newtonian value. If so, then Newton’s F=mais not an exact
relation, only a ﬁnal steady state condition, approached after the time required for light tocross the structure. It is conceivable that such a prediction could be tested experimentally.
Thus, the issue of our conﬁdence in Newtonian theory is vastly more subtle and complex
than merely citing its past predictive successes and its relationship to relativity theory; itdepends also on our whole theoretical outlook.
It appears to us that actual scientiﬁc practice is guided by instincts that have not yet been
fully recognized, much less analyzed and justiﬁed. We must take into account not only thelogic of science, but also the sociology of science (perhaps also its soteriology). But thisis so complicated that we are not even sure whether the extremely skeptical conservatismwith which new ideas are invariably received is, in the long run, a beneﬁcial stabilizinginﬂuence, or a harmful obstacle to progress.

<<<PAGE 180>>>

148 Part 1 Principles and elementary applications
5.9.1 What is queer?
In this chapter we have examined some applications of probability theory that seem ‘queer’
to us today, in the sense of being ‘off the beaten track’. Any completely new applicationmust presumably pass through such an exploratory phase of queerness. But in many cases,particularly the Bayesian jurisprudence and psychological tests with a more serious purposethan ESP, we think that queer applications of today may become respectable and usefulapplications of tomorrow. Further thought and experience will make us more aware of theproper formulation of a problem – better connected to reality – and then future generationswill come to regard Bayesian analysis as indispensable for discussing it. Now we return tothe many applications that are already advanced beyond the stage of queerness, into that of
respectability and usefulness.

<<<PAGE 181>>>

6
Elementary parameter estimation
A distinction without a difference has been introduced by certain writers
who distinguish ‘Point estimation’, meaning some process of arriving at
an estimate without regard to its precision, from ‘Interval estimation’ inwhich the precision of the estimate is to some extent taken into account.
R. A. Fisher (1956)
Probability theory as logic agrees with Fisher in spirit; that is, it gives us automatically
both point and interval estimates from a single calculation. The distinction commonlymade between hypothesis testing and parameter estimation is considerably greater thanthat which concerned Fisher; yet it too is, from our point of view, not a real difference.
When we have only a small number of discrete hypotheses {H
1,..., Hn}to consider,
we usually want to pick out a speciﬁc one of them as the most likely in that set, in thelight of the prior information and data. The cases n=2 and n=3 were examined in
some detail in Chapter 4, and larger nis in principle a straightforward and rather obvious
generalization.
When the hypotheses become very numerous, however, a different approach seems called
for. A set of discrete hypotheses can always be classiﬁed by assigning one or more numericalindices which identify them, as in H
t(1≤t≤n), and if the hypotheses are very numerous
one can hardly avoid doing this. Then, deciding between the hypotheses Htand estimating
the index tare practically the same thing, and it is a small step to regard the index, rather
than the hypotheses, as the quantity of interest; then we are doing parameter estimation. Weconsider ﬁrst the case where the index remains discrete.
6.1 Inversion of the urn distributions
In Chapter 3 we studied a variety of sampling distributions that arise in drawing from an
urn. There the number Nof balls in the urn, and the number Rof red balls and N−R
white ones, were considered known in the statement of the problem, and we were to make‘pre-data’ inferences about what kind of mix of rred,n−rwhite we were likely to get on
drawing nof them. Now we want to invert this problem, in the way envisaged by Bayes
and Laplace, to the ‘post-data’ problem: the data D≡(n,r) are known, but the contents
149

<<<PAGE 182>>>

150 Part 1 Principles and elementary applications
(N,R) of the urn are not. From the data and our prior information about what is in the urn,
what can we infer about its true contents? It is probably safe to say that every worker inprobability theory is surprised by the results – almost trivial mathematically, yet deep andunexpected conceptually – that one ﬁnds in this inversion. In the following we note someof the surprises already well known in the literature, and add to them.
We found in Eq. (3.22) the sampling distribution for this problem; in our present notation
this is the hypergeometric distribution
p(D|NRI )=h(r|NR,n)=/parenleftbiggN
n/parenrightbigg
−1/parenleftbiggR
r/parenrightbigg/parenleftbiggN−R
n−r/parenrightbigg
, (6.1)
where Inow denotes the prior information, the general statement of the problem as given
above.
6.2 Both NandRunknown
In general, neither NnorRis known initially, and the robot is to estimate both of them. If
we succeed in drawing nballs from the urn, then of course we know deductively that N≥n.
It seems to us intuitively that the data could tell us nothing more about N; how could the
number rof red balls drawn, or the order of drawing, be relevant to N? But this intuition is
using a hidden assumption that we can hardly be aware of until we see the robot’s answerto the question.
The joint posterior probability distribution for NandRis
p(NR|DI)=p(N|I)p(R|NI)p(D|NRI )
p(D|I), (6.2)
in which we have factored the joint prior probability by the product rule: p(NR|I)=
p(N|I)p(R|NI), and the normalizing denominator is a double sum,
p(D|I)=∞/summationdisplay
N=0N/summationdisplay
R=0p(N|I)p(R|NI)p(D|NRI ), (6.3)
in which, of course, the factor p(D|NRI ) is zero when N<n,o rR<r,o rN−R<n−r.
Then the marginal posterior probability for Nalone is
p(N|DI)=N/summationdisplay
R=0p(NR|DI)=p(N|I)/summationtext
Rp(R|NI)p(D|NRI )
p(D|I). (6.4)
We could equally well apply Bayes’ theorem directly:
p(N|DI)=p(N|I)p(D|NI)
p(D|I), (6.5)
and of course (6.4) and (6.5) must agree, by the product and sum rules.
These relations must hold whatever prior information Iwe may have about N,Rthat
is to be expressed by p(NR|I). In principle, this could be arbitrarily complicated, and

<<<PAGE 183>>>

6 Elementary parameter estimation 151
conversion of verbally stated prior information into p(NR|I) is an open-ended problem; you
can always analyze your prior information more deeply. But usually our prior informationis rather simple, and these problems are not difﬁcult mathematically.
Intuition might lead us to expect further that, whatever prior p(N|I) we had assigned,
the data can only truncate the impossible values, leaving the relative probabilities of thepossible values unchanged:
p(N|DI)=/braceleftbiggAp(N|I),ifN≥n,
0, if 0≤N<n,(6.6)
where Ais a normalization constant. Indeed, the rules of probability theory tell us
that this must be true if the data tell us only that N≥nand nothing else about N.F o r
example, if
Z≡N≥n, (6.7)
then
p(Z|NI)=/braceleftbigg1i f n≤N
0i f n>N.(6.8)
Bayes’ theorem reads:
p(N|ZI)=p(N|I)p(Z|NI)
p(Z|I)=/braceleftbiggAp(N|I)i f N≥n
0i f N<n.(6.9)
If the data tell us only that Zis true, then we have (6.6) and the above normalization
constant is A=1/p(Z|I). Bayes’ theorem conﬁrms that if we learn only that N≥n, the
relative probabilities of the possible values of Nare not changed by this information; only
the normalization must be readjusted to compensate for the values N<nthat now have
zero probability. Laplace considered this result intuitively obvious, and took it as a basicprinciple of his theory.
However, the robot tells us in (6.5) that this will not be the case unless p(D|NI)i s
independent of NforN≥n. And, on second thought, we see that (6.6) need not be true
if we have some kind of prior information linking NandR. For example, it is conceivable
that one might know in advance that R<0.06N. Then, necessarily, having observed the
data ( n,r)=(10,6), we would know not only that N≥10, but that N>100. Any prior
information that provides a logical link between NandRmakes the datum rrelevant to
estimating Nafter all. But usually we lack any such prior information, and so estimation
ofNis uninteresting, reducing to the same result (6.6).
From (6.5), the general condition that the data can tell us nothing about N, except to
truncate values less than n, is a nontrivial condition on the prior probability p(R|NI):
p(D|NI)= N/summationdisplay
R=0p(D|NRI )p(R|NI)=/braceleftbiggf(n,r)i f N≥n
0i f N<n,(6.10)

<<<PAGE 184>>>

152 Part 1 Principles and elementary applications
where f(n,r) may depend on the data, but is independent of N. Since we are using the
standard hypergeometric urn sampling distribution (6.1), this is explicitly
N/summationdisplay
R=0/parenleftbiggR
r/parenrightbigg/parenleftbiggN−R
n−r/parenrightbigg
p(R|NI)=f(n,r)/parenleftbiggN
n/parenrightbigg
, (N≥n). (6.11)
This is that hidden assumption that our intuition could hardly have told us about. It is a
kind of discrete integral equation1which the prior p(R|NI) must satisfy as the necessary
and sufﬁcient condition for the data to be uninformative about N. The sum on the left-
hand side is necessarily always zero when N<n, for the ﬁrst binomial coefﬁcient is zero
when R<r, and the second is zero when R≥randN<n. Therefore, the mathematical
constraint on p(R|NI) is only, rather sensibly, that f(n,r) in (6.11) must be independent
ofNwhen N≥n.
In fact, most ‘reasonable’ priors do satisfy this condition, and as a result estimation of N
is relatively uninteresting. Then, factoring the joint posterior distribution (6.2) in the form
p(NR|DI)=p(N|DI)p(R|NDI ), (6.12)
our main concern is with the factor p(R|NDI ), drawing inferences about Ror about the
ratio R/Nwith Nsupposed known. The posterior probability distribution for Ris then, by
Bayes’ theorem,
p(R|DNI )=p(R|NI)p(D|NRI )
p(D|NI). (6.13)
Different choices of the prior probability p(R|NI) will yield many quite different results,
and we now examine a few of them.
6.3 Uniform prior
Consider the state of prior knowledge denoted by I0, in which we are, seemingly, as ignorant
as we could be about Rwhile knowing N: the uniform distribution
p(R|NI0)=/braceleftBigg 1
N+1if 0≤R≤N
0i f R>N.(6.14)
Then a few terms cancel out, and (6.13) reduces to
p(R|DNI 0)=S−1/parenleftbiggR
r/parenrightbigg/parenleftbiggN−R
n−r/parenrightbigg
, (6.15)
1This peculiar name anticipates what we shall ﬁnd later, in connection with marginalization theory; very general conditions of
‘uninformativeness’ are expressed by similar integral equations that the prior for one parameter must satisfy in order to make
the data uninformative about another parameter.

<<<PAGE 185>>>

6 Elementary parameter estimation 153
where Sis a normalization constant. For several purposes, we need the general summation
formula
S≡N/summationdisplay
R=0/parenleftbiggR
r/parenrightbigg/parenleftbiggN−R
n−r/parenrightbigg
=/parenleftbiggN+1
n+1/parenrightbigg
, (6.16)
whereupon the correctly normalized posterior distribution for Ris
p(R|DNI 0)=/parenleftbiggN+1
n+1/parenrightbigg−1/parenleftbiggR
r/parenrightbigg/parenleftbiggN−R
n−r/parenrightbigg
. (6.17)
This is not a hypergeometric distribution like (6.1) because the variable is now R
instead of r.
The prior (6.14) yields, using (6.16),
N/summationdisplay
R=01
N+1/parenleftbiggR
r/parenrightbigg/parenleftbiggN−R
n−r/parenrightbigg
=1
N+1/parenleftbiggN+1
n+1/parenrightbigg
=1
n+1/parenleftbiggN
n/parenrightbigg
, (6.18)
so the integral equation (6.11) is satisﬁed; with this prior the data can tell us nothing about
N, beyond the fact that N≥n.
Let us check (6.17) to see whether it satis ﬁes some obvious common sense requirements.
We see that it vanishes when R<r,o rR>N−n+r, in agreement with what the data
tell us by deductive reasoning. If we have sampled all the balls, n=N, then (6.17) reduces
to Kronecker’s delta, δ(R,r), again agreeing with deductive reasoning. This is another
illustration of the fact that probability theory as extended logic automatically includesdeductive logic as a special case.
If we obtain no data at all, n=r=0, then (6.17) reduces, as it should, to the prior
distribution: p(R|DNI
0)=p(R|NI0)=1/(N+1). If we draw only one ball which proves
to be red, n=r=1, then (6.17) reduces to
p(R|DNI 0)=2R
N(N+1). (6.19)
The vanishing when R=0 again agrees with deductive logic. From (6.1) the sampling
probability p(r=1|n=1,NRI 0)=R/Nthat our one ball would be red is our original
Bernoulli urn result, proportional to R; and with a uniform prior the posterior probability for
Rmust also be proportional to R. The numerical coefﬁcient in (6.19) gives us an inadvertent
derivation of the elementary sum rule,
N/summationdisplay
R=0R=N(N+1)
2. (6.20)
These results are only a few of thousands now known, indicating that probability theory
as extended logic is an exact mathematical system. That is, results derived from correctapplication of our rules without approximation have the property of exact results in any

<<<PAGE 186>>>

154 Part 1 Principles and elementary applications
other area of mathematics: you can subject them to arbitrary extreme conditions and they
continue to make sense.2
What value of Rdoes the robot estimate in general? The most probable value of Ris
found within one unit by setting p(R/prime)=p(R/prime−1) and solving for R/prime. This yields
R/prime=(N+1)r
n, (6.21)
which is to be compared with (3.26) for the peak of the sampling distribution. If R/primeis not an
integer, the most probable value is the next integer below R/prime. The robot anticipates that the
fraction of red balls in the original urn should be about equal to the fraction in the observedsample, just as you and I would from intuition.
For a more reﬁned calculation, let us ﬁnd the mean value, or expectation, of Rover this
posterior distribution:
/angbracketleftR/angbracketright=E(R|DNI
0)=N/summationdisplay
R=0Rp(R|DNI 0). (6.22)
To do the summation, note that
(R+1)/parenleftbiggR
r/parenrightbigg
=(r+1)/parenleftbiggR+1
r+1/parenrightbigg
, (6.23)
and so, using (6.16) again,
/angbracketleftR/angbracketright+1=(r+1)/parenleftbiggN+1
n+1/parenrightbigg−1/parenleftbiggN+2
n+2/parenrightbigg
=(N+2)(r+1)
(n+2). (6.24)
When ( n,r,N) are large, the expectation of Ris very close to the most probable value
(6.21), indicating either a sharply peaked posterior distribution or a symmetric one. Thisresult becomes more signiﬁcant when we ask: ‘What is the expected fraction Fof red balls
left in the urn after this drawing?’ This is
/angbracketleftF/angbracketright=/angbracketleftR/angbracketright−r
N−n=r+1
n+2. (6.25)
6.4 Predictive distributions
Instead of using probability theory to estimate the unobserved contents of the urn, we may
use it as well to predict future observations. We ask a different question: ‘After having drawna sample of rred balls in ndraws, what is the probability that the next one drawn will be
red?’ Deﬁning the propositions:
R
i≡red on the ith draw, 1≤i≤N, (6.26)
2By contrast, the intuitive ad hockeries of current ‘orthodox’ statistics generally give reasonable results within some ‘safe’
domain for which they were invented; but invariably they are found to yield nonsense in some extreme case. This, examined in
Chapter 17, is what one expects of results which are only approximations to an exact theory; as one varies the conditions, the
quality of the approximation varies.

<<<PAGE 187>>>

6 Elementary parameter estimation 155
this is
p(Rn+1|DNI 0)=N/summationdisplay
R=0p(Rn+1R|DNI 0)=/summationdisplay
Rp(Rn+1|RDNI 0)p(R|DNI 0),(6.27)
or
p(Rn+1|DNI 0)=N/summationdisplay
R=0R−r
N−n/parenleftbiggN+1
n+1/parenrightbigg−1/parenleftbiggR
r/parenrightbigg/parenleftbiggN−R
n−r/parenrightbigg
. (6.28)
Using the summation formula (6.16) again, we ﬁnd, after some algebra,
p(Rn+1|DNI 0)=r+1
n+2, (6.29)
the same as (6.25). This agreement is another example of the rule noted before: a probability
is not the same thing as a frequency; but, under quite general conditions, the predictive
probability of an event at a single trial is numerically equal to the expectation of its frequency
in some speciﬁed class of trials.
Equation (6.29) is a famous old result known as Laplace’s rule of succession .I th a s
played a major role in the history of Bayesian inference, and in the controversies overthe nature of induction and inference. We shall ﬁnd it reappearing many times; ﬁnally, in
Chapter 18 we examine it carefully to see how it became controversial, but also how easilythe controversies can be resolved today.
The result (6.29) has a greater generality than would appear from our derivation. Laplace
ﬁrst obtained it, not in consideration of drawing from an urn, but from considering a mixtureof binomial distributions, as we shall do presently in (6.73). The above derivation in termsof urn sampling had been found as early as 1799 (see Zabell, 1989), but became well knownonly through its rediscovery in 1918 by C. D. Broad of Cambridge University, England,and its subsequent emphasis by Wrinch and Jeffreys (1919), W. E. Johnson (1924, 1932),and H. Jeffreys (1939). It was initially a great surprise to ﬁnd that the urn result (6.29) isindependent of N.
But this is only the point estimate; what accuracy does the robot claim for this estimate
ofR? The answer is contained in the same posterior distrib ution (6.17) that gave us (6.29);
we may ﬁnd its variance /angbracketleftR
2/angbracketright−/angbracketleft R/angbracketright2. Extending (6.23), note that
(R+1)(R+2)/parenleftbiggR
r/parenrightbigg
=(r+1)(r+2)/parenleftbiggR+2
r+2/parenrightbigg
. (6.30)
The summation over Ris again simple, yielding
/angbracketleft(R+1)(R+2)/angbracketright=(r+1)(r+2)/parenleftbiggN+1
n+1/parenrightbigg−1/parenleftbiggN+3
n+3/parenrightbigg
=(r+1)(r+2)(N+2)(N+3)
(n+2)(n+3). (6.31)

<<<PAGE 188>>>

156 Part 1 Principles and elementary applications
Then, noting that var( R)=/angbracketleftR2/angbracketright−/angbracketleft R/angbracketright2=/angbracketleft(R+1)2/angbracketright−/angbracketleft (R+1)/angbracketright2and writing for brevity
p=/angbracketleftF/angbracketright=(r+1)/(n+2), from (6.24) and (6.31) we ﬁnd
var(R)=p(1−p)
n+3(N+2)(N−n). (6.32)
Therefore, our (mean) ±(standard deviation) combined point and interval estimate of Ris
(R)est=r+(N−n)p±/radicalbigg
p(1−p)
n+3(N+2)(N−n). (6.33)
The factor ( N−n) inside the square root indicates that, as we would expect, the estimate
becomes more accurate as we sample a larger fraction of the contents of the urn. Indeed,when n=Nthe contents of the urn are known, and (6.33) reduces, as it should, to ( r±0),
in agreement with deductive reasoning.
Looking at (6.33), we note that R−ris the number of red balls remaining in the urn,
andN−nis the total number of balls left in the urn; so an analytically simpler expression
is found if we ask for the (mean) ±(standard deviation) estimate of the fraction of red balls
remaining in the urn after the sample is drawn. This is found to be
(F)
est=(R−r)est
N−n=p±/radicalbigg
p(1−p)
n+3N+2
N−n, 0≤n<N, (6.34)
and this estimate becomes less accurate as we sample a larger portion of the balls. In the
limit N→∞ , this goes into
(F)est=p±/radicalbigg
p(1−p)
n+3, (6.35)
which corresponds to the binomial distribution result. As an application of this, while
preparing this chapter we heard a news report that a ‘random poll’ of 1600 voters wastaken, indicating that 41% of the population favored a certain candidate in the next election,and claiming a±3% margin of error for this result. Let us check the consistency of these
numbers against our theory. To obtain ( F)
est=/angbracketleftF/angbracketright(1±0.03), we require, according to
(6.35), a sample size ngiven by
n+3=1−p
p1
(0.03)2=1−0.41
0.41×1111=1598.9 (6.36)
orn/similarequal1596. The close agreement suggests that the pollsters are using this theory (or at
least giving implied lip service to it in their public announcements).
These results, found with a uniform prior for p(R|NI0) over 0≤R≤N, correspond
very well with our intuitive common sense judgments. Other choices of the prior can affectthe conclusions in ways which often surprise us at ﬁrst glance; then, after some meditation,we see that they were correct after all. Let us put probability theory to a more severe testby considering some increasingly surprising examples.

<<<PAGE 189>>>

6 Elementary parameter estimation 157
6.5 Truncated uniform priors
Suppose our prior information had been different from the above I0; our new prior infor-
mation I1is that we know from the start that 0 <R<N; there is at least one red and one
white ball in the urn. Then the prior (6.14) must be replaced by
p(R|NI1)=/braceleftBigg 1
N−1if 1≤R≤N−1
0 otherwise,(6.37)
and our summation formula (6.16) must be corrected by subtracting the two terms
R=0,R=N. Note that, if R=0, then
/parenleftbiggR
r/parenrightbigg
=/parenleftbiggR+1
r+1/parenrightbigg
=δ(r,0), (6.38)
and, if R=N, then
/parenleftbiggN−R
n−r/parenrightbigg
=δ(r,n), (6.39)
so we have the summation formulas
S=N−1/summationdisplay
R=1/parenleftbiggR
r/parenrightbigg/parenleftbiggN−R
n−r/parenrightbigg
=/parenleftbiggN+1
n+1/parenrightbigg
−/parenleftbiggN
n/parenrightbigg
δ(r,n)−/parenleftbiggN
n/parenrightbigg
δ(r,0), (6.40)
N−1/summationdisplay
R=1/parenleftbiggR+1
r+1/parenrightbigg/parenleftbiggN−R
n−r/parenrightbigg
=/parenleftbiggN+2
n+2/parenrightbigg
−/parenleftbiggN+1
n+1/parenrightbigg
δ(r,n)−/parenleftbiggN
n/parenrightbigg
δ(r,0). (6.41)
What seems surprising at ﬁrst is that, as long as the observed ris in 0 <r<n, the new
terms vanish, and so the previous posterior distribution (6.17) is unchanged:
p(R|DNI 1)=p(R|DNI 0), 0<r<n. (6.42)
Why does the new prior information make no difference? Indeed, it would certainly make
a difference in any form of probability theory that uses only sampling distributions; for thesample space is changed by the new information.
Yet, on meditation, we see that the result (6.42) is correct, for in this case the data tell us
by deductive reasoning that Rcannot be zero or N; so, whether the prior information does
or does not tell us the same thing cannot matter: our state of knowledge about Ris the same
and probability theory as logic so indicates. We discuss this further in Section 6.9.1.
Suppose that our data were r=0; now the sum Sin (6.15) is different:
S=/parenleftbiggN+1
n+1/parenrightbigg
−/parenleftbiggN
n/parenrightbigg
, (6.43)

<<<PAGE 190>>>

158 Part 1 Principles and elementary applications
and in place of (6.17) the posterior probability distribution for Ris found to be, after some
calculation,
p(R|r=0,NI1)=/parenleftbiggN
n+1/parenrightbigg/parenleftbiggN−R
n/parenrightbigg
, 1≤R≤N−1, (6.44)
and zero outside that range. But still, within that range, the relative probabilities of different
values of Rare not changed; we readily verify that the ratio
p(R|r=0,NI1)
p(R|r=0,NI0)=N+1
N−n, 1≤R≤N−1, (6.45)
is independent of R. What has happened here is that the datum r=0 gives no evidence
against the hypothesis that R=0 and some evidence for it; so on prior information I0which
allows this, R=0 is the most probable value. But the prior information I1now makes a
decisive difference; it excludes just that value, and thus forces all the posterior probabilityto be compressed into a smaller range, with an upward adjustment of the normalizationcoefﬁcient. We learn from this example that different priors do not necessarily lead todifferent conclusions; and whether they do or do not can depend on which data set wehappen to get – which is just as it should be.
Exercise 6.1. Find the posterior probability distribution p(R|r=n,NI1) by a deriva-
tion like the above. Then ﬁnd the new (mean) ±(standard deviation) estimate of R
from this distribution, and compare it with the above results from p(R|r=n,NI0).
Explain the difference so that it seems obvious intuitively. Now show how well you
understand this problem by describing in words, without doing the calculation, howthe result would differ if we had prior information that (3 ≤R≤N); i.e. the urn had
initially at least three red balls, but there was no prior restriction on large values.
6.6 A concave prior
The rule of succession, based on the uniform prior p(R|NI)∝const. (0≤R≤N)}, leads
to a perhaps surprising numerical result, that the expected fraction (6.25) of red balls leftin the urn is not the fraction r/nobserved in the sample drawn, but slightly different,
(r+1)/(n+2). What is the reason for this small difference? The following argument is
hardly a derivation, but only a line of free association. Note ﬁrst that Laplace’s rule ofsuccession can be written in the form
r+1
n+2=n(r/n)+2(1/2)
n+2, (6.46)
which exhibits the result as a weighted average of the observed fraction r/nand the prior
expectation 1 /2, the data weighted by the number nof observations, the prior expectation by
2. It seems that the uniform prior carries a weight corresponding to two observations. Thencould that prior be interpreted as a posterior distribution resulting from two observations

<<<PAGE 191>>>

6 Elementary parameter estimation 159
(n,r)=(2,1)? If so, it seems that we must start from a still more uninformative prior than
the uniform one. But is there any such thing as a still more uninformative prior?
Mathematically, this suggests that we try to apply Bayes’ theorem backwards, to ﬁnd
whether there is any prior that would lead to a uniform posterior distribution. Denotethis conjectured, still more primitive, state of ‘pre-prior’ information by I
00. Then Bayes’
theorem would read:
p(R|DI00)=p(R|I00)p(D|RI00)
p(D|I00)=const., 0≤R≤N, (6.47)
and the sampling distribution is still the hypergeometric distribution (6.1), because when
Ris speciﬁed it renders any vague information like I00irrelevant: p(D|RI0)=p(D|RI00).
With the assumed sample, n=2,r=1, the hypergeometric distribution reduces to
h(r=1|N,R,n=2)=R(N−R)
N(N−1), 0≤R≤N, (6.48)
from which we see that there is no pre-prior that yields a constant posterior distribution
over the whole range (0 ≤R≤N); it would be inﬁnite for R=0 and R=N. But we have
just seen that the truncated prior, constant in (1 ≤R≤N−1), yields the same results if
it is known that the urn contains initially at least one red and one white ball. Since ourpresupposed data ( n,r)=(2,1) guarantees this, we see that we have a solution after all.
Consider the prior that emphasizes extreme values:
p(R|I
00)≡A
R(N−R), 1≤R≤N−1, (6.49)
where Astands for a normalization constant, not necessarily the same in all the following
equations. Given new data D≡(n,r), if 1≤r≤n−1 this yields, using (6.1), the posterior
distribution
p(R|DNI 00)=A
R(N−R)/parenleftbiggR
r/parenrightbigg/parenleftbiggN−R
n−r/parenrightbigg
=A
r(n−r)/parenleftbiggR−1
r−1/parenrightbigg/parenleftbiggN−R−1
n−r−1/parenrightbigg
.(6.50)
From (6.16) we may deduce the summation formula
N−1/summationdisplay
r=1/parenleftbiggR−1
r−1/parenrightbigg/parenleftbiggN−R−1
n−r−1/parenrightbigg
=/parenleftbiggN−1
n−1/parenrightbigg
,1≤R≤N−1,
1≤r≤n−1,(6.51)
so the correctly normalized posterior distribution is
p(R|DNI 00)=/parenleftbiggN−1
n−1/parenrightbigg−1/parenleftbiggR−1
r−1/parenrightbigg/parenleftbiggN−R−1
n−r−1/parenrightbigg
,1≤R≤N−1,
1≤r≤n−1,(6.52)
which is to be compared with (6.17). As a check, if n=2,r=1, this reduces to the desired
prior (6.37):
p(R|DNI 00)=p(R|NI1)=1
N−1, 1≤R≤N−1. (6.53)

<<<PAGE 192>>>

160 Part 1 Principles and elementary applications
At this point, we can leave it as an exercise for the reader to complete the analysis for the
concave prior with derivations analogous to (6.22)–(6.35).
Exercise 6.2. Using the general result (6.52), repeat the calculations analogous to
(6.22)–(6.35) and prove three exact results: (a) the integral equation (6.11) is satisﬁed,so (6.6) still holds; (b) for general data compatible with the prior in the sense that0≤n≤N,1≤r≤n−1 (so that the sample drawn includes at least one red and one
white ball), the posterior mean estimated fractions R/Nand ( R−r)/(N−n) are both
equal to the observed fraction in the sample, f=r/n; the estimates now follow the
data exactly so the concave prior (6.49) is given zero weight. Finally, (c) the (mean) ±
(standard deviation) estimate is given by
(R)
est
N=f±/radicalbigg
f(1−f)
n+1/parenleftBig
1−n
N/parenrightBig
, (6.54)
also a simpler result than the analogous (6.33) found previously for the uniform prior.
Exercise 6.3. Now note that if r=0o rr=n, the step (6.50) is not valid. Go back
to the beginning and derive the posterior distribution for these cases. Show that ifwe draw one ball and ﬁnd it not red, the estimated fraction of red in the urn nowdrops from 1 /2 to approximately 1 /log(N) (whereas with the uniform prior it drops
to (r+1)/(n+2)=1/3).
The exercises show that the concave prior gives many results simpler than those of the
uniform one, but has also some near instability properties that become more pronounced withlarge N. Indeed, as N→∞ the concave prior approaches an improper (non-normalizable)
one, which must give absurd answers to some questions, although it still gives reasonableanswers to most questions (those in which the data are so informative that they remove thesingularity associated with the prior).
6.7 The binomial monkey prior
Suppose prior information I
2is that the urn was ﬁlled by a team of monkeys who tossed
balls in at random, in such a way that each ball entering had independently the probability
gof being red. Then our prior for Rwill be the binomial distribution (3.92): in our present
notation,
p(R|NI2)=/parenleftbiggN
R/parenrightbigg
gR(1−g)N−R, 0≤R≤N, (6.55)
and our prior estimate of the number of red balls in the urn will be the (mean) ±(standard
deviation) over this distribution:
(R)est=Ng±/radicalbig
Ng(1−g). (6.56)

<<<PAGE 193>>>

6 Elementary parameter estimation 161
The sum (6.10) is readily evaluated for this prior, with the result that
p(D|NI)=/parenleftbiggn
r/parenrightbigg
gr(1−g)n−r, N≥n. (6.57)
Since this is independent of N, this prior also satisﬁes our integral equation (6.11), so
p(NR|DI2)=p(N|DI2)p(R|NDI 2), (6.58)
in which the ﬁrst factor is the relatively uninteresting standard result (6.6). We are interested
in the factor p(R|NDI 2) in which Nis considered known. We are interested also in the
other factorization
p(NR|DI2)=p(R|DI2)p(N|RDI 2), (6.59)
in which p(R|DI) tells us what we know about R, regardless of N. (Try to guess intuitively
how p(R|DNI ) and p(R|DI) would differ for any I, before seeing the calculations.)
Likewise, the difference between p(N|RDI 2) and p(N|DI2) tells us how much we would
learn about Nif we were to learn the true R; and again our intuition can hardly anticipate
the result of the calculation.
We have set up quite an agenda of calculations to do. Using (6.55) and (6.1), we ﬁnd
p(R|DNI 2)=A/parenleftbiggN
R/parenrightbigg
gR(1−g)N−R/parenleftbiggR
r/parenrightbigg/parenleftbiggN−R
n−r/parenrightbigg
, (6.60)
where Ais another normalization constant. To evaluate it, note that we can rearrange the
binomial coefﬁcients:
/parenleftbiggN
R/parenrightbigg/parenleftbiggR
r/parenrightbigg/parenleftbiggN−R
n−r/parenrightbigg
=/parenleftbiggN
n/parenrightbigg/parenleftbiggn
r/parenrightbigg/parenleftbiggN−n
R−r/parenrightbigg
. (6.61)
Therefore we ﬁnd the normalization by
1=/summationdisplay
Rp(R|DNI 2)=A/parenleftbiggN
n/parenrightbigg/parenleftbiggn
r/parenrightbigg/summationdisplay
R/parenleftbiggN−n
R−r/parenrightbigg
gR(1−g)N−R
=A/parenleftbiggN
n/parenrightbigg/parenleftbiggn
r/parenrightbigg
gr(1−g)n−r, r≤R≤N−n+r,(6.62)
and so our normalized posterior distribution for Ris
p(R|DNI 2)=/parenleftbiggN−n
R−r/parenrightbigg
gR−r(1−g)N−R−n+r, (6.63)
from which we would make the (mean) ±(standard deviation) estimate
(R)est=r+(N−n)g±/radicalbig
g(1−g)(N−n). (6.64)
But the resemblance to (6.33) suggests that we again look at it this way: we estimate the
fraction of red balls left in the urn to be
(R−r)est
N−n=g±/radicalbigg
g(1−g)
N−n. (6.65)

<<<PAGE 194>>>

162 Part 1 Principles and elementary applications
At ﬁrst glance, (6.64) and (6.65) seem to be so much like (6.33) and (6.34) that it was
hardly worth the effort to derive them. But on second glance we notice an astonishingfact: the parameter pin the former equations was determined entirely by the data; while g
in the present ones is determined entirely by the prior information. In fact, (6.65) is exactlythe prior estimate we would have made for the fraction of red balls in any subset of N−n
balls in the urn, without any data at all . It seems that the binomial prior has the magical
property that it nulliﬁes the data! More precisely, with that prior the data can tell us nothingat all about the unsampled balls.
Such a result will hardly commend itself to a survey sampler; the basis of his profession
would be wiped out. Yet the result is correct, and there is no escape from the conclusion:if your prior information about the population is correctly described by the binomial prior,then sampling is futile (it tells you practically nothing about the population) unless yousample practically the whole population.
How can such a thing happen? Comparing the binomial prior with the uniform prior,
one would suppose that the binomial prior, being moderately peaked, expresses more prior
information about the proportion R/Nof red balls; therefore by its use one should be able to
improve his estimates of R. Indeed, we have found this effect, for the uncertainties in (6.64)
and (6.65) are smaller than those in (6.33) and (6.34) by a factor of√
(n+3)/(N+2).
What is intriguing is not the magnitude of the uncertainty, but the fact that (6.34) dependson the data, while (6.65) does not.
It is not surprising that the binomial prior is more informative about the unsampled balls
than are the data of a small sample; but actually it is more informative about them than areany amount of data; even after sampling 99% of the population, we are no wiser about the
remaining 1%.
So what is the invisible strange property of the binomial prior? It is in some sense
so ‘loose’ that it destroys the logical link between different members of the population.But on meditation we see that this is just what was implied by our scenario of the urnbeing ﬁlled by monkeys tossing in balls in such a way that each ball had independently
the probability gof being red. Given that ﬁlling mechanism, then knowing that any given
ball is in fact red, gives one no information whatsoever about any other ball. That is,
P(R
1R2|I)=P(R1|I)P(R2|I). This logical independence in the prior is preserved in the
posterior distribution.
Exercise 6.4. Investigate this apparent ‘law of conservation of logical independence’.
If the propositions: ‘ ith ball is red, 1≤i≤N’ are logically independent in the prior
information, what is the necessary and sufﬁcient condition on the sampling distributionand the data that the factorization property is retained in the posterior distribution:
P(R
1R2|DI)=P(R1|DI)P(R2|DI)?
This sets off another line of deep thought. In conventional probability theory, the binomial
distribution is derived from the premise of causal independence of different tosses. In

<<<PAGE 195>>>

6 Elementary parameter estimation 163
Chapter 3 we found that consistency requires one to reinterpret this as logical independence.
But now, can we reason in the opposite direction? Does the appearance of a binomial
distribution already imply logical independence of the separate events ? If so, then we could
understand the weird result just derived, and anticipate many others like it. We shall return
to these questions in Part 2, after acquiring some more clues.
6.8 Metamorphosis into continuous parameter estimation
As noted in the introduction to this chapter, if our hypotheses become so ‘dense’ that
neighboring hypotheses (i.e. hypotheses with nearly the same values of the index t) are barely
distinguishable in their observable consequences, then, whatever the data, their posteriorprobabilities cannot differ appreciably. So there cannot be one sharply de ﬁned hypothesis
that is strongly favored over all others. Then it may be appropriate and natural to think oftas a continuously variable parameter θ, and to interpret the problem as that of making an
estimate of the parameter θ, and a statement about the accuracy of the estimate.
A common and useful custom is to use Greek letters to denote continuously variable
parameters, Latin letters for discrete indices or data values. We shall adhere to this exceptwhen it would conﬂict with a more deeply entrenched custom.
3
The hypothesis testing problem has thus metamorphosed into a parameter estimation one.
But it can equally well metamorphose back; for the hypothesis that a parameter θlies in a
certain interval a<θ< bis, of course, a compound hypothesis as deﬁned in Chapter 4,
so an interval estimation procedure (i.e. one where we specify the accuracy by givingthe probability that the parameter lies in a given interval) is automatically a compound
hypothesis testing procedure.
Indeed, we followed just this path in Chapter 4 and found ourselves, at Eq. (4.67), doing
what is really parameter estimation. It seemed to us natural to pass from testing simplediscrete hypotheses, to estimating continuous parameters, and ﬁnally to testing compoundhypotheses at Eq. (4.74), because probability theory as logic does this automatically. As inour opening remarks, we do not see parameter estimation and hypothesis testing as funda-mentally different activities – one aspect of the greater unity of probability theory as logic.
But this unity has not seemed at all natural to some others. Indeed, in orthodox statistics
parameter estimation appears very different from hypothesis testing, both mathematicallyand conceptually, largely because it has no satisfactory way to deal with compound hypothe-ses or prior information. We shall see some speciﬁc consequences of this in Chapter 17. Ofcourse, parameters need not be one-dimensional; but let us consider ﬁrst some simple caseswhere they are.
6.9 Estimation with a binomial sampling distribution
We have already seen an example of a binomial estimation problem in Chapter 4, but we
did not note its generality. There are hundreds of real situations in which each time a simple
3Thus for generations the charge on the electron and the velocity of light have been denoted by e,c, respectively. No scientist or
engineer could bring himself to represent them by Greek letters, even when they are the parameters being estimated.

<<<PAGE 196>>>

164 Part 1 Principles and elementary applications
measurement or observation is made, there are only two possible results. The coin will
show either heads or tails, the battery will or will not start the car, the baby will be a boyor a girl, the check will or will not arrive in the mail today, the student will pass or ﬂunkthe examination, etc. As we noted in Chapter 3, the ﬁrst comprehensive sampling theoryanalysis of such an experiment was by James Bernoulli (1713) in terms of drawing ballsfrom an urn, so such experiments are commonly called Bernoulli trials .
Traditionally, for any such binary experiment, we call one of the results, arbitrarily, a
‘success’ and the other a ‘failure’. Generally, our data will be a record of the number ofsuccesses and the number of failures;
4the order in which they occur may or may not be
meaningful, and, if it is meaningful, it may or may not be known, and, if it is known, itmay or may not be relevant to the question we are asking. Presumably, the conditions of theexperiment will tell us whether the order is meaningful or known; and we expect probabilitytheory to tell us whether it is relevant.
For example, if we toss ten coins simultaneously , then we have performed ten Bernoulli
trials, but it is not meaningful to speak of their ‘order’. If we toss one coin 100 timesand record each result, then the order of the results is meaningful and known; but in try-
ing to judge whether the coin is ‘honest’, common sense probably tells us that the or-der is not relevant. If we are observing patient recoveries from a disease and trying tojudge whether resistance to the disease was improved by a new medicine introduced amonth ago, this is much like drawing from an urn whose contents may have changed. In-tuition then tells us that the order in which recoveries and nonrecoveries occur is not onlyhighly relevant, it is the crucial information without which no inference about a change ispossible.
5
To set up the simple general binomial sampling problem, deﬁne
xi≡/braceleftBigg
1 if the ith trial yields success
0 otherwise.(6.66)
Then our data are D≡{x1,..., xn}. The prior information Ispeciﬁes that there is a pa-
rameter θsuch that at each trial we have, independently of anything we know about other
trials, the probability θfor a success, therefore the probability (1 −θ) for a failure. As
discussed before, by ‘independent’ we mean logical independence. There may or may notbe causal independence, depending on further details of Ithat do not matter at the moment.
The sampling distribution is then (mathematically, this is our deﬁnition of the model to be
studied):
p(D|θI)= n/productdisplay
i=1p(xi|θI)=θr(1−θ)n−r, (6.67)
4However, there are important problems involving censored data, to be considered later, in which only the successes can be
recorded (or only the failures), and one does not know how many trials were performed. For example, a highway safety engineerknows from the public record how many lives were lost in spite of his efforts, but not how many were saved because of them.
5Of course, the ﬁnal arbiter of relevance is not our intuition, bu t the equations of probability theory. But, as we shall see later,
judging this can be a tricky business. Whether a given piece of information is or is not relevant depends not only on what questionwe are asking, but also on the totality of all of our other information.

<<<PAGE 197>>>

6 Elementary parameter estimation 165
in which ris the number of successes observed, ( n−r) the number of failures. Then, with
any prior probability density function p(θ|I), we have immediately the posterior pdf
p(θ|DI)=p(θ|I)p(D|θI)/integraltext
dθp(θ|I)p(D|θI)=Ap(θ|I)θr(1−θ)n−r, (6.68)
where Ais a normalizing constant. With a uniform prior for θ,
p(θ|I)=1, 0≤θ≤1, (6.69)
the normalization is determined by an Eulerian integral,
A−1=/integraldisplay1
0dθθr(1−θ)n−r=r!(n−r)!
(n+1)!(6.70)
and the normalized pdf is
p(θ|DI)=(n+1)!
r!(n−r)!θr(1−θ)n−r, (6.71)
identical to Bayes’ original result, noted in Chapter 4, Eq. (4.67). Its moments are
/angbracketleftθm/angbracketright=E(θm|DI)=A/integraldisplay1
0dθθr+m(1−θ)n−r=(n+1)!
(n+m+1)!(r+m)!
r!
=(r+1)(r+2)···(r+m)
(n+2)(n+3)···(n+m+1),(6.72)
leading to the predicti ve probability for success at the next trial of
p≡/angbracketleftθ/angbracketright=/integraldisplay1
0dθθp(θ|DI)=r+1
n+2, (6.73)
in which we see Laplace’s rule of succession in its original derivation. Likewise, the (mean)
±(standard deviation) estimate of θis
(θ)est=/angbracketleftθ/angbracketright±/radicalBig
/angbracketleftθ2/angbracketright−/angbracketleftθ/angbracketright2=p±/radicalbigg
p(1−p)
n+3. (6.74)
Indeed, the continuous results (6.73) and (6.74) must be derivable from the discrete ones
(6.29) and (6.35) by passage to the limit N→∞ ; but since the latter equations are inde-
pendent of N, the limit has no effect.
In this limit the concave pre-prior distribution (6.49) would go into an improper prior
forθ:
A
R(N−R)→dθ
θ(1−θ), (6.75)
for which some sums or integrals would diverge; but that is not the strictly correct method of
calculation. For example, to calculate the posterior expectation of any function f(R/N)i n
the limit of arbitrarily large N, we should take the limit of the ratio /angbracketleftf(R/N)/angbracketright=Num/Den,

<<<PAGE 198>>>

166 Part 1 Principles and elementary applications
where
Num≡N−1/summationdisplay
R=1f(R/N)
R(N−R)p(D|NRI ),
Den≡N−1/summationdisplay
R=11
R(N−R)p(D|NRI ),(6.76)
and, under very general conditions, this limit is well-behaved, leading to useful results. The
limiting improper pre-prior (6.75) was advocated by Haldane (1932) and Jeffreys (1939),in the innocent days before the marginalization paradox, when nobody worried about suchﬁne points. We were almost always lucky in that our integrals converged in the limit, sowe used them directly, thus actually calculating the ratio of the limits rather than the limitof the ratio; but nevertheless getting the right answers. With this ﬁne point now clariﬁed,all this and its obvious generalizations seem perfectly straightforward; however, note the
following point, important for a current controversy.
6.9.1 Digression on optional stopping
We did not include nin the conditioning statements in p(D|θI) because, in the problem
as deﬁned, it is from the data Dthat we learn both nandr. But nothing prevents us from
considering a different problem in which we decide in advance how many trials we shallmake; then it is proper to add nto the prior information and write the sampling probability
asp(D|nθI). Or, we might decide in advance to continue the Bernoulli trials until we have
achieved a certain number rof successes, or a certain log-odds u=log[r/(n−r)]; then it
would be proper to write the sampling probability as p(D|rθI)o r p(D|uθI), and so on.
Does this matter for our conclusions about θ?
In deductive logic (Boolean algebra) it is a triviality that AA=A; if you say: ‘ Ais
true’ twice, this is logically no different from saying it once. This property is retained inprobability theory as logic, since it was one of our basic desiderata that, in the contextof a given problem, propositions with the same truth value are always assigned the sameprobability. In practice this means that there is no need to ensure that the different piecesof information given to the robot are independent; our formalism has automatically theproperty that redundant information is not counted twice.
Thus, in our present problem, the data, as deﬁned, tell us n. Then, since p(n|nθI)=1,
the product rule may be written
p(nrorder|nθI)=p(rorder|nθI)p(n|nθI)=p(rorder|nθI). (6.77)
When something is known already from the prior information, then, whether the data do or
do not tell us the same thing cannot matter; the likelihood function is the same. Likewise,write the product rule as
p(θn|DI)=p(θ|nDI )p(n|DI)=p(n|θDI)p(θ|DI), (6.78)

<<<PAGE 199>>>

6 Elementary parameter estimation 167
or, since p(n|θDI)=p(n|DI)=1,
p(θ|nDI )=p(θ|DI). (6.79)
In this argument we could replace nby any other quantity (such as r,o r( n−r), or u≡
logr/(n−r)) that was known from the data; if any part of the data happens to be included
also in the prior information, then that part is redundant and it cannot affect our ﬁnalconclusions.
Even so, some statisticians (for example, Armitage, 1960) who look only at sampling
distributions, claim that the stopping rule does affect our inference. Apparently, they believe
that if a statistic such as ris not known in advance, then parts of the sample space referring
to false values of rremain relevant to our inferences, even after the true value of rbecomes
known from the data D, although they would not be relevant (they would not even be in
the sample space) if the true value were known before seeing the data. Of course, thatviolates the principle AA=Aof elementary logic; it is astonishing that such a thing could
be controversial in the 20th century.
It is evident that this same comment applies with equal force to any function f(D)o f
the data, whether or not we are using it as an estimator. That is, whether fwas or was not
known in advance can have a major effect on our sample space and sampling distributions;but as redundant information it cannot have any effect on any rational inferences from thedata. Furthermore, inference must depend on the data set that was observed, not on datasets that might have been observed but were not – because merely noting the possibility ofunobserved data sets gives us no information that was not already in the prior information.Although this conclusion might have seemed obvious from the start, it is not recognized
in orthodox statisticians because they do not think in terms of information. We shall see in
Chapter 8 not only some irrational conclusions, but some absolutely spooky consequences(psychokinesis, black magic) this has had, and, in later applications, how much real damagethis has caused.
What if a part of the data set was actually generated by the phenomenon being studied, but
for whatever reason we failed to observe it? This is a major difﬁculty for orthodox statistics,because then the sampling distributions for our estimators are wrong, and the problem mustbe reconsidered from the start. But for us it is only a minor detail, easily taken into account.We show next that probability theory as logic tells us uniquely how to deal with true butunobserved data; they must be relevant in the sense that our conclusions must depend onwhether they were or were not observed; so they have a mathematical status somewhat likethat of a set of nuisance parameters.
6.10 Compound estimation problems
We now consider in some depth a class of problems more complicated in structure, where
more than one process is occurring but not all the results are observable. We want tomake inferences not only about parameters in the model, but about the unobserved data.

<<<PAGE 200>>>

168 Part 1 Principles and elementary applications
The mathematics to be developed next is applicable to a large number of quite different real
problems. To form an idea of the scope of the theory, consider the following scenarios.
(A) In the general population, there is a frequency pat which any given person will contract a certain
disease within the next year; and then another frequency θthat anyone with the disease will die of
it within a year. From the observed variations {c1,c2,...}of deaths from the disease in successive
years (which is a matter of public record), estimate how the incidence of the disease {n1,n2,...}
is changing in the general population (which is not a matter of public record).
(B) Each week, a large number of mosquitos, N, is bred in a stagnant pond near this campus, and we
set up a trap on the campus to catch some of them. Each mosquito lives less than a week, duringwhich there is a frequency pof ﬂying onto the campus, and, once on the campus, a frequency
θof being caught in our trap. We count the numbers {c
1,c2,...}caught each week. From these
data and whatever prior information we have, what can we say about the numbers {n1,n2,...}
on the campus each week, and what can we say about N?
(C) We have a radioactive source (say sodium 22 (22Na), for example) which is emitting particles
of some sort (say, positrons). There is a rate p, in particles per second, at which a radioactive
nucleus sends particles through our counter; and each particle passing through produces countsat the rate θ. From measuring the number {c
1,c2,...}of counts in different seconds, what can
we say about the numbers {n1,n2,...}actually passing through the counter in each second, and
what can we say about the strength of the source?
The common feature in these problems is that we have two ‘binary games’ played in
succession, and we can observe only the outcome of the last one. From this, we are to makethe best inferences we can about the original cause and the intermediate conditions. Thiscould be described also as the problem of trying to recover, in one special case, censoreddata.
We want to show particularly how drastically these problems are changed by various
changes in the prior information. For example, our estimates of the variation in incidenceof a disease are greatly affected, not only by the data, but by our prior information aboutthe process by which one contracts that disease.
6
In our estimates we will want to (1) state the ‘best’ estimate possible on the data and prior
information; and (2) make a statement about the accuracy of the estimate, giving again ourversions of ‘point estimation’ and ‘interval estimation’ about which Fisher commented. Weshall use the language of the radioactive source scenario, but it will be clear enough that thesame arguments and the same calculations apply in many others.
6.11 A simple Bayesian estimate: quantitative prior information
Firstly, we discuss the parameter φ, which a scientist would call the ‘efﬁciency’ of the
counter. By this we mean that, if φis known, then each particle passing through the counter
hasindependently the probability φof making a count. Again we emphasize that this is not
6Of course, in this ﬁrst venture into the following kind of analysis, we shall not take into account all the factors that operate in
the real world, so some of our conclusions may be changed in a more sophisticated analysis. However, nobody would see howto do that unless he had ﬁrst studied this simple introductory example.

<<<PAGE 201>>>

6 Elementary parameter estimation 169
mere causal independence (which surely always holds, as any physicist would assure us);
we mean logical independence, i.e., if φis known, then knowing anything about the number
of counts produced by other particles would tell us nothing more about the probability forthe next particle making a count.
7
We have already stressed the distinction between logical and causal dependence many
times; and now we have another case where failure to understand it could lead to seriouserrors. The point is that causal inﬂuences operate in the same way independently of yourstate of knowledge or mine; thus, if φis not known, then everybody still believes that
successive counts are causally independent. But they are no longer logically independent;
for then knowing the number of counts produced by other particles tells us something aboutφ, and therefore modiﬁes our probability that the next particle will produce a count. The
situation is much like that of sampling with replacement, discussed in Chapter 3, whereeach ball drawn tells us something more about the contents of the urn.
From the independence, the probability that nparticles will produce exactly ccounts
in any speciﬁed order is φ
c(1−φ)n−c, and there are/parenleftbign
c/parenrightbig
possible sequences producing c
counts, so the probability of getting ccounts regardless of order is the binomial distribution
b(c|n,φ)=/parenleftbiggn
c/parenrightbigg
φc(1−φ)n−c, 0≤c≤n. (6.80)
From the standpoint of logical presentation in the real world, however, we have to carry
out a kind of bootstrap operation with regard to the quantity φ; for how could it be known?
Intuitively, you may have no difﬁculty in seeing the procedure you would use to determineφfrom measurements with the counter. But, logically, we need to have the calculation about
to be given before we can justify that procedure. So, for the time being, we’ll just have tosuppose that φis a number gi ven to us by our teacher in assigning us this problem, and ha ve
faith that, in the end, we shall understand how our teacher determined it.
Now let us introduce a quantity rwhich is the probability at which in any one second
that any particular nucleus will emit a particle that passes through the counter. We assumethe number of nuclei Nto be so large and the half-life so long that we need not consider
Nas a variable for this problem. So there are Nnuclei, each of which has independently
the probability rof sending a particle through our counter in any one second. The quantity
ris also, for present purposes, just a number given to us in the statement of the problem,
because we have not yet seen, in terms of probability theory, the line of reasoning by whichwe could convert measurements into a numerical value of r(but again, you see intuitively,
without any hesitation, that ris a way of describing the half-life of the source).
Suppose we were given Nandr; what is the probability, on this evidence, that in any
one second exactly nparticles will pass through the counter? That is the same binomial
7In practice, there is a question of resolving time; if the particles come too close together we may not be able to see the counts as
separate, because the counter experiences a ‘dead time’ after a count, during which it is unable to respond to another particle. We
have disregarded those difﬁculties for this problem and imagined that we have inﬁnitely good resolving time (or, what amounts to
the same thing, that the counting rate is so low that there is negligible probability for missing a count). After we have developedthe theory, the reader will be asked (Exercise 6.5) to generalize it to take these factors into account.

<<<PAGE 202>>>

170 Part 1 Principles and elementary applications
distribution problem, so the answer is
b(n|N,r)=/parenleftbiggN
n/parenrightbigg
rn(1−r)N−n. (6.81)
But in this case there’s a good approximation to the binomial distribution, because the
number Nis enormously large and ris enormously small. In the limit N→∞ ,r→0i n
such a way that Nr→s=const., what happens to (6.81)? To ﬁnd this, write r=s/N,
and pass to the limit N→∞ . Then
N!
(N−n)!rn=N(N−1)···(N−n+1)/parenleftBigs
N/parenrightBign
=sn/parenleftbigg
1−1
N/parenrightbigg/parenleftbigg
1−2
N/parenrightbigg
···/parenleftbigg
1−n−1
N/parenrightbigg
,(6.82)
which goes into snin the limit. Likewise,
(1−r)N−n=/parenleftBig
1−s
N/parenrightBigN−n
→exp{−s}, (6.83)
and so the binomial distribution (6.81) goes over into the simpler Poisson distribution :
p(n|Nr)→p(n|s)=exp{−s}sn
n!, (6.84)
and it will be handy for us to take this limit. The number sis essentially what the experimenter
calls his ‘source strength’, the expectation of the number of particles per second.
Now we have enough ‘formalism’ to start solving useful problems. Suppose we are not
given the number of particles nin the counter, but only the source strength s. What is the
probability, on this evidence, that we shall see exactly ccounts in any one second? Using
our method of resolving the proposition cinto a set of mutually exclusive alternatives, then
applying the sum rule and the product rule:
p(c|φs)=∞/summationdisplay
n=0p(cn|φs)=/summationdisplay
np(c|nφs)p(n|φs)=/summationdisplay
np(c|φn)p(n|s), (6.85)
since p(c|nφs)=p(c|φn); i.e. if we knew the actual number nof particles in the counter,
it would not matter what swas. This is perhaps made clearer by the diagram in Figure 6.1,
rather like the logic ﬂow diagrams of Figure 4.3. In this case, we think of the diagramas indicating not only the logical connections, but also the causal ones; sis the physical
cause which partially determines n; and then nin turn is the physical cause which partially
determines c. To put it another way, scan inﬂuence conly through its intermediate inﬂuence
onn. We saw the same logical situation in the Chapter 5 horse racing example.
snc
Fig. 6.1. The causal inﬂuences.

<<<PAGE 203>>>

6 Elementary parameter estimation 171
Since we have worked out both p(c|φn) and p(n|s), we need only substitute them into
(6.85); after some algebra we have
p(c|φs)=∞/summationdisplay
n=c/bracketleftbiggn!
c!(n−c)!φc(1−φ)n−c/bracketrightbigg/bracketleftbiggexp{−s}sn
n!/bracketrightbigg
=exp{−sφ}(sφ)c
c!.(6.86)
This is again a Poisson distribution with expectation
/angbracketleftc/angbracketright=∞/summationdisplay
c=0cp(c|φs)=sφ. (6.87)
Our result is hardly surprising. We have a Poisson distribution with a mean value which
is the product of the source strength times the efﬁciency of the counter. Without goingthrough the analysis, that is just the estimate of cthat we would make intuitively, although
it is unlikely that anyone could have guessed from intuition that the distribution still has thePoissonian form.
In practice, it is cthat is known, and nthat is unknown. If we knew the source strength s
and also the number of counts c, what would be the probability, on that evidence, that there
were exactly nparticles passing through the counter during that second? This is a problem
which arises all the time in physics laboratories, because we may be using the counter as
a ‘monitor’, and have it set up so that the particles, after going through the counter, theninitiate some other reaction which is the one we’re really studying. It is important to get thebest possible estimates of n, because that is one of the numbers we need in calculating the
cross-section of this other reaction. Bayes’ theorem gives
p(n|φcs)=p(n|s)p(c|nφs)
p(c|φs)=p(n|s)p(c|nφ)
p(c|φs), (6.88)
and all these terms have been found above, so we just have to substitute (6.80) and (6.84)–
(6.86) into (6.88). Some terms cancel, and we are left with:
p(n|φcs)=exp{−s(1−φ)}[s(1−φ)]n−c
(n−c)!. (6.89)
It is interesting that we stillhave a Poisson distribution, now with parameter s(1−φ), but
shifted upward by c; because, of course, ncould not be less than c. The expectation over
this distribution is
/angbracketleftn/angbracketright=/summationdisplay
nnp(n|φcs)=c+s(1−φ). (6.90)
So, now what is the best guess the robot can make as to the number of particles responsible
for those ccounts? Since this is the ﬁrst time we have faced this issue in a serious way, let
us take time for some discussion.

<<<PAGE 204>>>

172 Part 1 Principles and elementary applications
6.11.1 From posterior distribution function to estimate
Given the posterior pdf for some general parameter α, continuous or discrete, what ‘best’
estimate of αshould the robot make, and what accuracy should it claim? There is no one
‘right’ answer; the problem is really one of decision theory which asks, ‘What should wedo?’ This involves value judgments and therefore goes beyond the principles of inference,which ask only ‘What do we know?’ We shall return to this in Chapters 13 and 14, but fornow we give a preliminary discussion adequate for the simple problems being considered.
Laplace (1774) already encountered this problem. The unknown true value of a parameter
isα, and given some data Dand prior information Iwe are to make an estimate α
∗(D,I)
which depends on them in some way. In the jargon of the trade, α∗is called an ‘estimator’,
and nothing prevents us from considering any function of ( D,I) whatsoever as a potential
estimator. But which estimator is best? Our estimate will ha ve an error e=(α∗−α), and
Laplace gave as a criterion that we should make that estimate which minimizes the expected
magnitude|e|. He called this the ‘most advantageous’ method of estimation.
Laplace’s criterion was generally rejected for 150 years in favor of the least squares
method of Gauss and Legendre; we seek the estimate that minimizes the expected squareof the error. In these early works it is not always clear whether this means expected over thesampling pdf for α
∗or over the posterior pdf for α; the distinction was not always recognized,
and the confusion was encouraged by the fact that in some cases considerations of symmetry
lead us to the same ﬁnal conclusion from either. Some of the bad consequences of using
the former (sampling distribution) are noted in Chapter 13. It is clear today that the formerignores all prior information about α, while the latter takes it into account and is therefore
what we want; taking expectations over the posterior pdf for α, the expected squared error
of the estimate is
/angbracketleft(α−α
∗)2/angbracketright=/angbracketleftα2/angbracketright−2α∗/angbracketleftα/angbracketright+α∗2
=(α∗−/angbracketleftα/angbracketright)2+(/angbracketleftα2/angbracketright−/angbracketleftα/angbracketright2).(6.91)
The choice
α∗=/angbracketleftα/angbracketright=/integraldisplay
dααp(α|DI), (6.92)
that is, the posterior mean value, therefore always minimizes the expected square of the
error, over the posterior pdf for α, and the minimum achievable value is the variance of the
posterior pdf. The second term is the expected square of the deviation from the mean:
var(α)≡/angbracketleft(α−/angbracketleftα/angbracketright)2/angbracketright=(/angbracketleftα2/angbracketright−/angbracketleftα/angbracketright2), (6.93)
often miscalled the variance of α; of course, it is really the variance of the probability
distribution that the robot assigns for α. In any event, the robot can do nothing to minimize
it. But the ﬁrst term can be removed entirely by taking as the estimate just the mean valueα
∗=/angbracketleftα/angbracketright, which is the optimal estimator by the mean square error criterion.
Evidently, this result holds generally whatever the form of the posterior distribution
p(α|DI); provided only that /angbracketleftα/angbracketrightand/angbracketleftα2/angbracketrightexist, the mean square error criterion always

<<<PAGE 205>>>

6 Elementary parameter estimation 173
leads to taking the mean value /angbracketleftα/angbracketright(i.e. the ‘center of gravity’ of the posterior distribution)
as the ‘best’ guess. The posterior (mean ±standard deviation) then recommends itself to
us as providing a more or less reasonable statement of what we know and how accuratelywe know it; and it is almost always the easiest to calculate. Furthermore, if the posteriorpdf is sharp and symmetrical, this cannot be very different pragmatically from any otherreasonable estimate. So, in practice, we use this more than any other. In the urn inversionproblems, we simply adopted this procedure without comment.
But this may not be what we really want. We should be aware that there are valid arguments
against the posterior mean, and cases where a different rule would better achieve what wewant. The squared error criterion says that an error twice as great is considered four timesas serious. Therefore, the mean value estimate, in effect, concentrates its attention moststrongly on avoiding the very large (but also very improbable) errors, at the cost of possiblynot doing as well as it might with the far more likely small errors.
Because of this, the posterior mean value estimate is quite sensitive to what happens far
out in the tails of the pdf. If the tails are very unsymmetrical, our estimate could be pulledfar away from the central region where practically all the probability lies and commonsense tells us the parameter is most likely to be. In a similar way, a single very rich manin a poor village would pull the average wealth of the population far away from anythingrepresentative of the real wealth of the people. If we knew this was happening, then thataverage would be a quite irrational estimate of the wealth of any particular person met onthe street.
This concentration on minimizing the large errors leads to another property that we might
consider undesirable. Of course, by ‘large errors’ we mean errors that are large on the scale
of the parameter α. If we redeﬁned our parameter as some nonlinear function λ=λ(α) (for
example, λ=α
3,o rλ=log(α)), an error that is large on the scale of αmight seem small
on the scale of λ, and vice versa. But then the posterior mean estimate
λ∗≡/angbracketleftλ/angbracketright=/integraldisplay
dλλp(λ|DI)=/integraldisplay
dαλ(α)p(α|DI) (6.94)
would not in general satisfy λ∗=λ(α∗). Minimizing the mean square error in αis not the
same thing as minimizing the mean square error in λ(α).
Thus, the posterior mean value estimates lack a certain consistency under parameter
changes. When we change the deﬁnition of a parameter, if we continue to use the meanvalue estimate, then we have changed the criterion of what we mean by a ‘good’ estimate.
Now let us examine Laplace’s original criterion. If we choose an estimator α
+(D,I)b y
the criterion that it minimizes the expected absolute error
E≡/angbracketleft|α+−α|/angbracketright=/integraldisplayα+
−∞dα(α+−α)f(α)+/integraldisplay∞
α+dα(α−α+)f(α), (6.95)
we require
dE
dα+=/integraldisplayα+
−∞dαf(α)−/integraldisplay∞
α+dαf(α)=0, (6.96)

<<<PAGE 206>>>

174 Part 1 Principles and elementary applications
orP(α>α+|DI)=1/2; Laplace’s ‘most advantageous’ estimator is the median of the
posterior pdf.
But what happens now on a change of parameters λ=λ(α)? Suppose that λis strictly a
monotonic increasing function of α(so that αis in turn a single-valued function of λand the
transformation is reversible). Then it is clear from the above equation that the consistencyis restored: λ
+=λ(α+).
More generally, all the percentiles have this invariance property: for example, if α35 is
the 35 percentile value of α:
/integraldisplayα35
−∞dαf(α)=0.35, (6.97)
then we have at once
λ35=λ(α35). (6.98)
Thus if we choose as our point estimate and accuracy claim the median and interquartile
span over the posterior pdf, these statements will have an invariant meaning, independentof how we have deﬁned our parameters. Note that this remains true even when /angbracketleftα/angbracketrightand/angbracketleftα
2/angbracketright
diverge, so the mean square estimator does not exist.
Furthermore, it is clear from their derivation from variational arguments, that the median
estimator considers an error twice as great to be only twice as serious, so it is less sensitiveto what happens far out in the tails of the posterior pdf than is the mean value. In currenttechnical jargon, one says that the median is more robust with respect to tail variations.
Indeed, it is obvious that the median is entirely independent of all variations that do notmove any probability from one side of the median to the other; and an analogous propertyholds for any percentile. One very rich man in a poor village has no effect on the median
wealth of the population.
Robustness, in the general sense that the conclusions are insensitive to small changes in
the sampling distribution or other conditions, is often held to be a desirable property of aninference procedure, and some authors criticize Bayesian methods because they supposethat they lack robustness. However, robustness in the usual sense of the word can alwaysbe achieved merely by throwing away cogent information! It is hard to believe that anyone
could really want this if he were aware of it; but since those with only orthodox trainingdo not think in terms of information content, they do not realize when they are wastinginformation. Evidently, the issue requires a much more careful discussion, to which wereturn later (Chapter 20) in connection with model comparison.
8
In at least some problems, then, Laplace’s ‘most advantageous’ estimates have indeed
two signiﬁcant advantages over the more conventional (mean ±standard deviation). But
8To anticipate our ﬁnal conclusion: robustness with respect to sampling distributions is desirable only when we are not sure of
the correctness of our model. But then a full Bayesian analysis will take into account all the models considered possible andtheir prior probabilities. The result automatically achieves the robustness previously sought in intuitive ad hoc devices; and
some of those devices, such as the ‘jackknife’ and the ‘redescending psi function’ are derived from ﬁrst principles, as ﬁrst-order
approximations to the Bayesian result. The Bayesian analysis of such problems gives us for the ﬁrst time a clear statement ofthe circumstances in which robustness is desirable; and then, because Bayesian analysis never throws away information, it givesus more powerful algorithms for achieving robustness.

<<<PAGE 207>>>

6 Elementary parameter estimation 175
before the days of computers they were prohibitively difﬁcult to calculate numerically, so
the least squares philosophy prevailed as a matter of practical expedience.
Today, the computation problem is relatively trivial, and we can have whatever we want.
It is easy to write computer programs which give us the option of displaying either the ﬁrstand second moments or the quartiles ( x
25,x50,x75), and only the force of long habit makes
us continue to cling to the former.9
Still another principle for estimation is to take the peak ˆ α; or, as it is called, the ‘mode’
of the posterior pdf. If the prior pdf is a constant (or is at least constant in a neighborhoodof this peak and not sufﬁciently greater elsewhere), the result is identical to the ‘maximumlikelihood’ estimate (MLE) α
/primeof orthodox statistics. It is usually attributed to R. A. Fisher,
who coined that name in the 1920s, although Laplace and Gauss used the method routinely100 years earlier without feeling any need to give it a special name other than ‘most probablevalue’. As explained in Chapter 16, Fisher’s ideology would not permit him to call it that.The merits and demerits of the MLE are discussed further in Chapter 13; for the present, weare not concerned with philosophical arguments, but wish only to compare the pragmaticresults of MLE and other procedures.
10This leads to some surprises, as we see next.
We will now return to our original problem of counting particles. At this point, a statistician
of the ‘orthodox’ school of thought pays a visit to our laboratory. We describe the propertiesof the counter to him, and invite him to give us hisbest estimate as to the number of
particles. He will, of course, use maximum likelihood because his textbooks have told himthat (Cram´ er, 1946, p. 498): ‘From a theoretical point of view, the most important general
method of estimation so far known is the method of maximum likelihood.’ His likelihoodfunction is, in our notation, p(c|φn) in its dependence on n. The value of nwhich maximizes
it is found, within one unit, from setting
p(c|φn)
p(c|φ,n−1)=n(1−φ)
n−c=1, (6.99)
or
(n)MLE=c
φ. (6.100)
You may ﬁnd the difference between the two estimates (6.90) and (6.100) rather startling,
particularly if we put in some numbers. Suppose our counter has an efﬁciency of 10%;in other words, φ=0.1, and the source strength is s=100 particles per second, so that
the expected counting rate according to (6.87) is /angbracketleftc/angbracketright=sφ=10 counts per second. But in
this particular second, we got 15 counts. What should we conclude about the number ofparticles?
9In spite of all these considerations, the neat analytical results found in our posterior moments from urn and binomial models,
contrasted with the messy appearance of calculations with percentiles, show that moments have some kind of theoretical
signiﬁcance that percentiles lack. This appears more clearly in Chapter 7.
10One evident pragmatic result is that the MLE fails altogether when the likelihood function has a ﬂat top; then nothing in the data
can give us a reason for preferring any point in that ﬂat top over any other. But this is just the case we have in the ‘generalizedinverse’ problems of current importance in applications; only prior information can resolve the ambiguity.

<<<PAGE 208>>>

176 Part 1 Principles and elementary applications
Probably the ﬁrst answer one would give without thinking is that, if the counter has an
efﬁciency of 10%, then in some sense each count must have been due to about ten particles;so, if there were 15 counts, there must have been about 150 particles. That is, as a matter offact, exactly what the maximum likelihood estimate (6.100) would be in this case. But whatdoes the robot tell us? Well, it says the best estimate by the mean square error criterion isonly
/angbracketleftn/angbracketright=15+100(1−0.1)=15+90=105. (6.101)
More generally, we could write (6.90) this way:
/angbracketleftn/angbracketright=s+(c−/angbracketleftc/angbracketright), (6.102)
so if you see kmore counts than you ‘should have’ in one second, according to the robot
that is evidence for only kmore particles, not 10 k.
This example turned out to be quite surprising to some experimental physicists engaged
in work along these lines. Let’s see if we can reconcile it with our common sense. If wehave an average number of counts of 10 per second with this counter, then we would guess,by rules well known, that a ﬂuctuation in counting rate of something like the square root ofthis,±3, would not be at all surprising, even if the number of incoming particles per second
stayed strictly constant. On the other hand, if the average rate of ﬂow of particles is s=100
per second, the ﬂuctuation in this rate which would not be surprising is±√
100=±10.
But this corresponds to only ±1 in the number of counts.
This shows that we cannot use a counter to measure ﬂuctuations in the rate of arrival of
particles, unless the counter has a very high efﬁciency. If the efﬁciency is high, then we knowthat practically every count corresponds to one particle, and we are reliably measuring thoseﬂuctuations. If the efﬁciency is low and we know that there i sad e ﬁnite, ﬁxed source strength,
then ﬂuctuations in counting rate are much more likely to be due to things happening in thecounter than to actual changes in the rate of arrival of particles.
The same mathematical result, in the disease scenario, means that if a disease is mild
and unlikely to cause death, then variations in the observed number of deaths are not reli-able indicators of variations in the incidence of the disease. If our prior information tellsus that there is a constantly operating basic cause of the disease (such as a contaminatedwater supply), then a large change in the number of deaths from one year to the next isnot evidence of a large change in the number of people having the disease. But if practi-cally everyone who contracts the disease dies immediately, then of course the number ofdeaths tells us very reliably what the incidence of the disease was, whatever the means ofcontracting it.
What caused the difference between the Bayes and maximum likelihood solutions? The
difference is due to the fact that we had prior information contained in this source strength s.
The maximum likelihood estimate simply maximized the probability for getting ccounts,
given nparticles, and that yields 150. In Bayes’ solution, we will multiply this by a prior
probability p(n|s), which represents our knowledge of the antecedent situation, before
maximizing, and we’ll get an entirely different value for the estimate. As we saw in the

<<<PAGE 209>>>

6 Elementary parameter estimation 177
inversion of urn distributions, simple prior information can make a big change in the
conclusions that we draw from a data set.
Exercise 6.5. Generalize the above calculation to take the dead-time effect into ac-
count; that is, if we know that two or more particles incident on the counter within ashort time interval /Delta1tcan produce at most only one count, how is our estimate of n
changed? These effects are important in many practical situations, and there is a vo-luminous literature on the application of probability theory to them (see Bortkiewicz,1898, 1913, and Takacs, 1958).
Now let’s extend this problem a little. We are now going to use Bayes’ theorem in four
problems where there is no quantitative prior information, but only one qualitative fact, andagain see the effect that prior information has on our conclusions.
6.12 Effects of qualitative prior information
The situation is depicted in Figure 6.2. Two robots, which we shall humanize by naming
them Mr Aand Mr B, have different prior information about the source of the particles.
The source is hidden in another room which Mr Aand Mr Bare not allowed to enter.
MrAhas no knowledge at all about the source of particles; for all he knows, it might be an
accelerating machine which is being turned on and off in an arbitrary way, or the other roommight be full of little men who run back and forth, holding ﬁrst one radioactive source, thenanother, up to the exit window. Mr Bhas one additional qualitative fact: he knows that the
source is a radioactive sample of long lifetime, in a ﬁxed position. But he does not know
n1 c1
n2 c2
n3 c3
(a) (b)n1 c1
n2 c2
n3 c3s
Fig. 6.2. (a) The structure of Mr A’s problem; different intervals are logically independent. (b) Mr
B’s logical situation; knowledge of the existence of smakes n2relevant to n1.

<<<PAGE 210>>>

178 Part 1 Principles and elementary applications
anything about its source strength (except, of course, that it is not inﬁnite because, after all,
the laboratory is not being vaporized by its presence; Mr Ais also given assurance that he
will not be vaporized during the experiment). They both know that the counter efﬁciencyis 10%: φ=0.1. Again, we want them to estimate the number of particles passing through
the counter from knowledge of the number of counts. We denote their prior information by
I
A,IB, respectively.
We commence the experiment. During the ﬁrst second, c1=10 counts are registered.
What can Mr Aand Mr Bsay about the number n1of particles? Bayes’ theorem for Mr A
reads
p(n1|φc1IA)=p(n1|IA)p(c1|φn1IA)
p(c1|φIA)=p(n1|IA)p(c1|φn1IA)
p(c1|φIA). (6.103)
The denominator is just a normalizing constant, and could also be written
p(c1|φIA)=/summationdisplay
n1p(c1|φn1IA)p(n1|IA). (6.104)
But now we seem to be stuck, for what is p(n1|IA)? The only information about n1contained
inIAis that n1is not large enough to vaporize the laboratory. How can we assign prior
probabilities on this kind of evidence? This has been a point of controversy for a long time,for in any theory which regards probability as a real physical phenomenon, Mr Ahas no
basis at all for determining the ‘true’ prior probabilities p(n
1|IA).
6.13 Choice of a prior
Now, of course, Mr Ais programmed to recognize that there is no such thing as an
‘objectively true’ probability. As the notation p(n1|IA) indicates, the purpose of assign-
ing a prior is to describe his own state of knowledge IA, and on this he is the ﬁnal authority.
So he does not need to argue the philosophy of it with anyone. We consider in Chapters 11and 12 some of the general formal principles available to him for translating verbal priorinformation into prior probability assignments, but in the present discussion we wish onlyto demonstrate some pragmatic facts, by a prior that represents reasonably the informationthatn
1is not inﬁnite, and that for small n1there is no prior information that would justify
any great variations in p(n1|IA). For example, if as a function of n1the prior p(n1|IA)e x -
hibited features such as oscillations or sudden jumps, that would imply some very detailedprior information about n
1that Mr Adoes not have.
MrA’s prior should, therefore, avoid all such structure; but this is hardly a formal
principle, and so the result is not unique. But it is one of the points to be made fromthis example, noted by H. Jeffreys (1939), that it does not need to be unique because, ina sense, ‘almost any’ prior which is smooth in the region of high likelihood will lead tosubstantially the same ﬁnal conclusions.
11
11We have seen already that, in some circumstances, a prior can make a very large difference in the conclusions; but to do this it
necessarily modulates the likelihood function in the region of its peak, not its tails.

<<<PAGE 211>>>

6 Elementary parameter estimation 179
So Mr Aassigns a uniform prior probability out to some large but ﬁnite number N,
p(n1|IA)=/braceleftbigg1/Nif 0≤n1<N
0i f N≤n1,(6.105)
which seems to represent his state of knowledge tolerably well. The ﬁnite upper bound Nis
an admittedly ad hoc way of representing the fact that the laboratory is not being vaporized.
How large could it be? If Nwere as large as 1060, then not only the laboratory, but our entire
galaxy, would be vaporized by the energy in the beam (indeed, the total number of atoms inour galaxy is of the order of 10
60). So Mr Asurely knows that Nis very much less than that.
Of course, if his ﬁnal conclusions depend strongly on N, then Mr Awill need to analyze
his exact prior information and think more carefully about the value of Nand whether the
abrupt drop in p(n1|IA)a tn1=Nshould be smoothed out. Such careful thinking would
not be wrong, but it turns out to be unnecessary, for it will soon be evident that details of
p(n1|IA) for large n1are irrelevant to Mr A’s conclusions.
6.14 On with the calculation!
Nicely enough, the 1 /Ncancels out of (6.103) and (6.104), and we are left with
p(n1|φc1IA)=/braceleftbiggAp(c1|φn1)i f 0≤n1<N
0i f N≤n1,(6.106)
where Ais a normalization factor:
A−1=N−1/summationdisplay
n1=0p(c1|φn1). (6.107)
We have noted, in (6.100), that, as a function of n1,p(c1|φn1) attains its maximum at
n1=c1/φ(=100, in this problem). For n1φ/greatermuchc1,p(c1|φn1) falls off like nc1
1(1−φ)n1/similarequal
nc1
1exp{−n1φ}. Therefore, the sum (6.107) converges so rapidly that if Nis as large as a few
hundred, there is no appreciable difference between the exact normalization f actor (6.107)
and the sum to inﬁnity.
In view of this, we may as well take advantage of a simpliﬁcation; after applying Bayes’
theorem, pass to the limit N→∞ . But let us be clear about the rationale of this; we pass
to the limit, not because we believe that Nis inﬁnite; we know that it is not. We pass to the
limit rather because we know that this will simplify the calculation without affecting theﬁnal result; after this passage to the limit, all our calculations pertaining to this model canbe performed exactly with the aid of the general summation formula
∞/summationdisplay
m=0/parenleftbiggm+a
m/parenrightbigg
mnxm=/parenleftbigg
xd
dx/parenrightbiggn1
(1−x)a+1, (|x|<1). (6.108)

<<<PAGE 212>>>

180 Part 1 Principles and elementary applications
Thus, writing m=n−c, we replace (6.107) by
A−1/similarequal∞/summationdisplay
n1=0p(c1|φn1)=φc∞/summationdisplay
m=0/parenleftbiggm+c
m/parenrightbigg
(1−φ)m=φc/braceleftbigg1
[1−(1−φ)](c+1)/bracerightbigg
=1
φ.
(6.109)
Exercise 6.6. To better appreciate the quality of this approximation, denote the
‘missing’ terms in (6.107) by
S(N)≡∞/summationdisplay
n1=Np(c1|φn1)( 6 .110)
and show that the fractional discrepancy between (6.107) and (6.109) is about
δ≡S(N)/S(0)/similarequalexp{−Nφ}(Nφ)c1
c1!, ifNφ/greatermuch1. ( 6 .111)
From this, show that in the present case (φ=0.1,c1=10), unless the prior information
can justify an upper limit Nless than about 270, the exact value of N– or indeed, all
details of p(n1|IA) for n1>270 – can make less than one part in 104difference in
MrA’s conclusions. But it is hard to see how anyone could have any serious use for
more than three ﬁgure accuracy in the ﬁnal results; and so this discrepancy would haveno ef fect at all on that ﬁnal result. What happens for n
1≥340 can affect the conclusions
less than one part in 106, and for n1≥400 it is less than one part in 108.
This is typical of the way prior range matters in real problems, and it makes ferocious
arguments over this seem rather silly. It is a valid question of principle, but its pragmaticconsequences are not just negligibly small, but (usually) strictly nil because we are cal-culating only to a ﬁnite number of decimal places. Yet some writers have claimed that afundamental qualitative change in the character of the problem occurs between N=10
10
andN=∞ . The reader may be amused to estimate how much difference this makes in the
ﬁnal numerical results. To how many decimal places would we need to calculate before itmade any difference at all?
Of course, if the prior information should start encroaching on the region n
1<270, it
would then make a difference in the conclusions; but in that case the prior information wasindeed cogent for the question being asked, and this is as it should be. Being thus reassuredand using the approximation (6.109), we obtain the result
p(n
1|φc1IA)=φp(c1|φn1)=/parenleftbiggn1
c1/parenrightbigg
φc1+1(1−φ)n1−c1. (6.112)
So, for Mr A, the most probable value of n1is the same as the maximum likelihood estimate
(ˆn1)A=c1
φ=100, (6.113)

<<<PAGE 213>>>

6 Elementary parameter estimation 181
while the posterior mean value estimate is calculated as follows:
/angbracketleftn1/angbracketrightA−c1=∞/summationdisplay
n1=c1(n1−c1)p(n1|φc1IA)
=φc1+1(1−φ)(c1+1)/summationdisplay
n1/parenleftbiggn1
n1−c1−1/parenrightbigg
(1−φ)n1−c1−1.(6.114)
From (6.108) the sum is equal to
∞/summationdisplay
m=0/parenleftbiggm+c1+1
m/parenrightbigg
(1−φ)m=1
φ2+c1, (6.115)
and we get
/angbracketleftn1/angbracketrightA=c1+(c1+1)1−φ
φ=c1+1−φ
φ=109. (6.116)
Now, how about the other robot, MrB? Does his extra knowledge help him here? He
knows that there is some deﬁnite ﬁxed source strength s. And, because the laboratory is
not being vaporized, he knows that there is some upper limit S0. Suppose that he assigns a
uniform prior probability density for 0 ≤s<S0. Then he will obtain
p(n1|θIB)=/integraldisplay∞
0dsp(n1|s)p(s|θIB)=1
S0/integraldisplayS0
0p(n1|s)ds=1
S0/integraldisplayS0
0dssn1exp{−s}
n1!.
(6.117)
Now, if n1is appreciably less than S0, the upper limit of integration can for all practical
purposes be taken as inﬁnity, and the integral is just unity. So, we have
p(n1|θIB)=p(s|θIB)=1
S0=const., n1<S0. (6.118)
In putting this into Bayes’ theorem with c1=10, the signiﬁcant range of values of n1will
be of the order of 100, and unless the prior information indicates a value of S0lower than
about 300, we will have the same situation as before; Mr B’s extra knowledge didn’t help
him at all, and he comes out with the same posterior distribution and the same estimates:
p(n1|c1IB)=p(n1|φc1IA)=φp(c1|φn1). (6.119)
6.15 The Jeffreys prior
Harold Jeffreys (1939, Chap. 3) proposed a different way of handling this problem. He
suggests that the proper way to express ‘complete ignorance’ of a continuous variableknown to be positive is to assign uniform prior probability to its logarithm; i.e. the priorprobability density is
p(s|I
J)∝1
s, (0≤s<∞). (6.120)

<<<PAGE 214>>>

182 Part 1 Principles and elementary applications
Of course, we cannot normalize this, but that does not stop us from using it. In many
cases, including the present one, it can be used directly because all the integrals involvedconverge. In almost all cases we can approach this prior as the limit of a sequence ofproper (normalizable) priors, with mathematically well-behaved results. If even that doesnot yield a proper posterior distribution, then the robot is warning us that the data are toouninformative about either very large sor very small sto justify any deﬁnite conclusions,
and we need to obtain more evidence before any useful inferences are possible.
Jeffreys justiﬁed (6.120) on the grounds of invariance under certain changes of parame-
ters; i.e. instead of using the parameter s, what prevents us from using t≡s
2,o ru≡s3?
Evidently, to assign a uniform prior probability density to sis not at all the same thing as
assigning a uniform prior probability to t; but if we use the Jeffreys prior, we are saying the
same thing whether we use sor any power smas the parameter.
There is the germ of an important principle here, but it was only recently that the situation
has been fairly well understood. When we take up the theory of transformation groupsin Chapter 12, we will see that the real justiﬁcation of Jeffreys’ rule cannot lie merelyin the fact that the parameter is positive, but that our desideratum of consistency, in thesense that equivalent states of knowledge should be represented by equivalent probabilityassignments, uniquely determines the Jeffreys rule in the case when sis a ‘scale parameter’.
Then, marginalization theory will reinforce this by deriving it Uniquely – without appealingto any principles beyond the basic product and sum rules of probability theory – as the only
prior for a scale parameter that is completely uninformative about other parameters thatmay be in the model.
These arguments and others equally cogent all lead to the same conclusion: the Jeffreys
prior is the only correct way to express complete ignorance of a scale parameter. Thequestion then reduces to whether scan properly be regarded as a scale parameter in this
problem. However, this line of thought has taken us beyond the present topic; in the spiritof our current problem, we shall just put (6.120) to the test and see what results it gives.The calculations are all very easy, and we ﬁnd these results:
p(n
1|IJ)=1
n1, p(c1|IJ)=1
c1, p(n1|φc1IJ)=c1
n1p(c1|φn1). (6.121)
This leads to the most probable and mean value estimates:
(ˆn1)J=c1−1+φ
φ=91,/angbracketleftn1/angbracketrightJ=c
φ=100. (6.122)
The amusing thing emerges that Jeffreys’ prior probability rule just lowers the most probable
and posterior mean value estimates by nine each, bringing the mean value right back to themaximum likelihood estimate!
This comparison is valuable in showing us how little difference there is numerically
between the consequences of different prior probability assignments which are not sharplypeaked, and helps to put arguments about them into proper perspective. We made a ratherdrastic change in the prior probabilities, in a problem where there was really very little

<<<PAGE 215>>>

6 Elementary parameter estimation 183
information contained in the meager data, and it still made less than 10% difference in
the result. This is, as we shall see, small compared with the probable error in the estimatewhich was inevitable in any event. In a more realistic problem where we have more data,the difference would be even smaller.
A useful rule of thumb, illustrated by the comparison of (6.113), (6.116) and (6.122), is
that changing the prior probability p(α|I) for a parameter by one power of αhas in general
about the same effect on our ﬁnal conclusions as does having one more data point. This isbecause the likelihood function generally has a relative width 1 /√
n, and one more power of
αmerely adds an extra small slope in the neighborhood of the maximum, thus shifting the
maximum slightly. Generally, if we have effectively nindependent observations, then the
fractional error in an estimate that was inevitable in any event is 1 /√n, approximately,12
while the fractional change in the estimate due to one more power of αin the prior is
about 1 /n.
In the present case, with ten counts, thus ten independent observations, changing from a
uniform to Jeffreys prior made just under 10% difference. If we had 100 counts, the errorwhich is inevitable in any event would be about 10%, while the difference from the twopriors would be less than 1%.
So, from a pragmatic standpoint, arguments about which prior probabilities correctly
express a state of ‘complete ignorance’, like those over prior ranges, usually amount to
quibbling over pretty small peanuts.
13From the standpoint of principle, however, they are
important and need to be thought about a great deal, as we shall do in Chapter 12 after
becoming familiar with the numerical situation. While the Jeffreys prior is the theoreticallycorrect one, it is in practice a small reﬁnement that makes a difference only in the verysmall sample case. In the past, these issues were argued back and forth endlessly on a foggyphilosophical level, without taking any note of the pragmatic facts of actual performance;that is what we are trying to correct here.
6.16 The point of it all
Now we are ready for the interesting part of this problem. For during the next second, we
seec
2=16 counts. What can Mr Aand Mr Bnow say about the numbers n1,n2of particles
responsible for c1,c2? Well, Mr Ahas no reason to expect any relationship between what
happened in the two time intervals, and so to him the increase in counting rate is evidenceonly of an increase in the number of incident particles. His calculation for the second timeinterval is the same as before, and he will give us the most probable value,
(ˆn
2)A=c2
φ=160, (6.123)
12However, as we shall see later, there are two special cases where the 1 /√nrule fails: if we are trying to estimate the location
of a discontinuity in an otherwise continuous probability distribution, and if different data values are strongly correlated.
13This is most deﬁnitely nottrue if the prior probabilities are to describe a deﬁnite piece of prior knowledge, as the next example
shows.

<<<PAGE 216>>>

184 Part 1 Principles and elementary applications
and his mean value estimate,
/angbracketleftn2/angbracketrightA=c2+1−φ
φ=169. (6.124)
Knowledge of c2doesn’t help him to make any improved estimate of n1, which stays the
same as before.
MrBis in an entirely different position than Mr A; his extra qualitative information
suddenly becomes very important. For knowledge of c2enables him to improve his previous
estimate of n1. Bayes’ theorem now gives
p(n1|φc2c1IB)=p(n1|φc1IB)p(c2|φn1c1IB)
p(c2|φc1IB)=p(n1|φc1IB)p(c2|φn1IB)
p(c2|φc1IB).(6.125)
Again, the denominator is a normalizing constant, which we can ﬁnd by summing the
numerator over n1. We see that the signiﬁcant thing is p(c2|φn1IB). Using our method of
resolving c2into mutually exclusive alternatives, this is
p(c2|φn1IB)=/integraldisplay∞
0dsp(c2s|φn1IB)
=/integraldisplay∞
0dsp(c2|sφn1IB)p(s|φn1IB)
=/integraldisplay∞
0dsp(c2|φsIB)p(s|φn1IB).(6.126)
We have already found p(c2|φsIB) in (6.86), and we need only
p(s|φn1IB)=p(s|φIB)p(n1|φsIB)
p(n1|φIB)=p(n1|φs),ifn1/lessmuchS0, (6.127)
where we have used (6.118). We have found p(n1|s) in (6.84), so we have
p(c2|φn1IB)=/integraldisplay∞
0ds/bracketleftbiggexp{−sφ}(sφ)c2
c2!/bracketrightbigg/bracketleftbiggexp{−s}sn1
n1!/bracketrightbigg
=/parenleftbiggn1+c2
c2/parenrightbiggφc2
(1+φ)n1+c2+1.
(6.128)
Substituting (6.119) and (6.128) into (6.125) and carrying out an easy summation to get the
denominator, the result is ( nota binomial distribution):
p(n1|φc2c1IB)=/parenleftbiggn1+c2
c1+c2/parenrightbigg/parenleftbigg2φ
1+φ/parenrightbiggc1+c2+1/parenleftbigg1−φ
1+φ/parenrightbiggn1−c1
. (6.129)
Note that we could have derived this equally well by direct application of the resolution
method:
p(n1|φc2c1IB)=/integraldisplay∞
0dsp(n1s|φc2c1IB)
=/integraldisplay∞
0dsp(n1|φsc2c1IB)p(s|φc2c1IB)
=/integraldisplay∞
0dsp(n1|φsc1IB)p(s|φc2c1IB).(6.130)

<<<PAGE 217>>>

6 Elementary parameter estimation 185
We have already found p(n1|φsc1IB) in (6.89), and it is easily shown that p(s|φc2c1IB)∝
p(c2|φsIB)p(c1|φsIB), which is therefore given by the Poisson distribution (6.86). This, of
course, leads to the same rather complicated result (6.129); thus providing another – andrather severe – test of the consistency of our rules.
To ﬁnd Mr B’s new most probable value of n
1,w es e t
p(n1|φc2c1IB)
p(n1−1|φc2c1IB)=n1+c2
n1−c11−φ
1+φ=1, (6.131)
or
(ˆn1)B=c1
φ+(c2−c1)1−φ
2φ=c1+c2
2φ+c1−c2
2=127. (6.132)
His new posterior mean value is also readily calculated, and is equal to
/angbracketleftn1/angbracketrightB=c1+1−φ
φ+(c2−c1−1)1−φ
2φ=c1+c2+1−φ
2φ+c1−c2
2=131.5.
(6.133)
Both estimates are considerably raised, and the difference between most probable and mean
value is only half what it was before, suggesting a narrower posterior distrib ution, as we
shall conﬁrm presently. If we want Mr B’s estimates for n2, then from symmetry we just
interchange the subscripts 1 and 2 in the above equations. This gives for his most probableand mean value estimates, respectiv ely,
(ˆn
2)B=133,/angbracketleftn2/angbracketrightB=137.5. (6.134)
Now, can we understand what is happening here? Intuitively, the reason why Mr B’s extra
qualitative prior information makes a difference is that knowledge of both c1andc2enables
him to make a better estimate of the source strength s, which in turn is relevant for estimating
n1. The situation is indicated more clearly by the diagrams in Figure 6.2. By hypothesis, to
MrAeach sequence of events ni→ciis logically independent of the others, so knowledge
of one doesn’t help him in reasoning about any other. In each case he must reason from ci
directly to ni, and no other route is available. But to Mr B, there are two routes available: he
can reason directly from c1ton1as Mr Adoes, as described by p(n1|φc1IA)=p(n1|φc1IB);
but, because of his knowledge that there is a ﬁxed source strength s‘presiding over’ both n1
andn2, he can also reason along the route c2→n2→s→n1. If this were the only route
available to him (i.e. if he didn’t know c1), he would obtain the distribution
p(n1|φc2IB)=/integraldisplay∞
0dsp(n1|s)p(s|c2IB)=φc2+1
c2!(1+φ)c2+1(n1+c2)!
n1!(1+φ)n1, (6.135)
and, comparing the above relations, we see that Mr B’s ﬁnal distribution (6.129) is, except
for normalization, just the product of the ones found by reasoning along his two routes:
p(n1|φc1c2IB)=(const.)×p(n1|φc1IB)p(n1|φc2IB) (6.136)
in consequence of the fact that p(c1c2|φn1)=p(c1|φn1)p(c2|φn1). The information (6.135)
about n1obtained by reasoning along the new route c2→n2→s→n1thus introduces

<<<PAGE 218>>>

186 Part 1 Principles and elementary applications
a ‘correction factor’ in the distribution obtained from the direct route c1→n1, enabling
MrBto improve his estimates.
This suggests that, if Mr Bcould obtain the number of counts in a great many different
seconds, ( c3,c4,..., cm), he would be able to do better and better; and perhaps in the limit
m→∞ his estimate of n1might be as good as the one we found when the source strength
was known exactly. We will check this surmise presently by working out the degree ofreliability of these estimates, and by generalizing these distributions to arbitrary m, from
which we can obtain the asymptotic forms.
6.17 Interval estimation
There is still an essential feature missing in the comparison of Mr Aand Mr Bin our
particle counter problem. We would like to have some measure of the degree of reliabilitywhich they attach to their estimates, especially in view of the fact that their estimates areso different. Clearly, the best way of doing this would be to draw the entire probability
distributions
p(n
1|φc2c1IA) and p(n1|φc2c1IB) (6.137)
and from this make statements of the form, ‘90% of the posterior probability is concentrated
in the interval α< n1<β’. But, for present purposes, we will be content to give the
standard deviations (i.e., square root of the variance as deﬁned in Eq. (6.93)) of the variousdistributions we have found. An inequality due to Tchebycheff then asserts that, if σis the
standard deviation of any probability distribution over n
1, then the amount Pof probability
concentrated between the limits /angbracketleftn1/angbracketright±tσsatisﬁes14
P≥1−1
t2. (6.139)
This tells us nothing when t≤1, but it tells us more and more as tincreases beyond unity.
For example, in any probability distribution with ﬁnite /angbracketleftn/angbracketrightand/angbracketleftn2/angbracketright, at least 3 /4 of the
probability is contained in the interval /angbracketleftn/angbracketright±2σ, and at least 8 /9i si n/angbracketleftn/angbracketright±3σ.
6.18 Calculation of variance
The variances σ2of all the distributions we have found above are readily calculated. In
fact, calculation of any moment of these distributions is easily performed by the generalformula (6.108). For Mr Aand Mr B, and the Jeffreys prior probability distribution, we
14Proof: Let p(x) be a probability density over ( −∞<x<∞),aany real number, and y≡x−/angbracketleftx/angbracketright. Then
a2(1−P)=a2p(|y|>a)=a2/integraldisplay
|y|>adxp(x)≤/integraldisplay
|y|>adxy2p(x)≤/integraldisplay∞
−∞dxy2p(x)=σ2. (6.138)
Writing a=tσ, this is t2(1−P)≤1, the same as Eq. (6.139). This proof includes the discrete cases, since then p(x)i sas u m
of delta-functions. A large collection of useful Tchebycheff-type inequalities is given by I. R. Savage (1961).

<<<PAGE 219>>>

6 Elementary parameter estimation 187
Table 6.1. The effect of prior information on estimates of n 1and n 2.
Problem 1 Problem 2
n1 n1 n2
A most probable 100 100 160
mean±s.d. 109±31 109±31 169±39
B most probable 100 127 133
mean±s.d. 109±31 131.5±25.9 137.5±25.9
Jeffreys most probable 91 121.5 127.5
mean±s.d. 100±30 127±25.4 133±25.4
ﬁnd the variances
var(n1|φc1IA)=(c1+1)(1−φ)
φ2, (6.140)
var(n1|φc2c1IB)=(c1+c2+1)(1−φ2)
4φ2, (6.141)
var(n1|φc1IJ)=c1(1−φ)
φ2, (6.142)
and the variances for n2are found from symmetry.
This has been a rather long discussion, so let’s summarize all our results so far in Table 6.1.
We give, for problem 1 ( c1=10) and problem 2 ( c1=10,c2=16), the most probable
values of the number of particles found by Mr Aand Mr B, and also the (mean value) ±
(standard deviation) estimates. From Table 6.1 we see that Mr B’s extra information not
only has led him to change his estimates considerably from those of Mr A, but it has enabled
him to make an appreciable decrease in his probable error. Even purely qualitative prior
information which has nothing to do with frequencies can greatly alter the conclusions wedraw from a given data set . Now, in virtually every real problem of scientiﬁc inference, we
do have qualitative prior information of more or less the kind supposed here. Therefore,any method of inference which fails to take prior information into account is capable ofmisleading us, in a potentially dangerous way. The fact that it yields a reasonable result in
one problem is no guarantee that it will do so in the next.
It is also of interest to ask how good Mr B’s estimate of n
1would be if he knew only c2;
and therefore had to use the distribution (6.135) representing reasoning along the route c2→
n2→s→n1of Figure 6.2. From (6.135) we ﬁnd the most probable, and the (mean) ±
(standard deviation) estimates
ˆn1=c2
φ=160, (6.143)

<<<PAGE 220>>>

188 Part 1 Principles and elementary applications
mean±s.d.=c2+1
φ±√(c2+1)(φ+1)
φ=170±43.3. (6.144)
In this case, he would obtain a slightly poorer estimate (i.e. a larger probable error) than
MrAeven if the counts c1=c2were the same, because the variance (6.140) for the direct
route contains a factor (1 −φ), which gets replaced by (1 +φ) if we have to reason over
the indirect route. Thus, if the counter has low efﬁciency, the two routes give nearly equalreliability for equal counting rates; but if it has high efﬁciency, φ/similarequal1, then the direct route
c
1→n1is far more reliable. Our common sense will tell us that this is just as it should be.
6.19 Generalization and asymptotic forms
We conjectured above that Mr Bmight be helped a good deal more in his estimate of n1
by acquiring still more data {c3,c4,..., cm}. Let’s investigate that further. The standard
deviation of the distribution (6.89) in which the source strength was known exactly isonly√
s(1−φ)=10.8 for s=130; and from Table 6.1 Mr B’s standard deviation for his
estimate of n1is now about 2.5 times this value. What would happen if we gave him more
and more data from other time intervals, such that his estimate of sapproached 130? To
answer this, note that, if 1 ≤k≤m,w eh a v e :
p(nk|φc1···cmIB)=/integraldisplay∞
0dsp(nks|φc1···cmIB)
=/integraldisplay∞
0dsp(nk|φsckIB)p(s|φc1···cmIB),(6.145)
in which we have put p(nk|φsc1···cmIB)=p(nk|φsckIB) because, from Figure 6.2, if s
is known, then all the ciwith i/negationslash=kare irrelevant for inferences about nk. The second factor
in the integrand of (6.145) can be evaluated by Bayes’ theorem:
p(s|φc1···cmIB)=p(s|φIB)p(c1···cm|φsIB)
p(c1···cm|φIB)
=(const.)×p(s|φIB)p(c1|φsIB)···p(cm|φsIB).(6.146)
Using (6.86) and normalizing, this reduces to
p(s|φc1···cmIB)=(mφ)c+1
c!scexp{−msφ}, (6.147)
where c≡c1+···+ cmis the total number of counts in the mseconds. The mode, mean
and variance of the distribution (6.147) are, respectively,
ˆs=c
mφ,/angbracketlefts/angbracketright=c+1
mφ, var(s)=/angbracketlefts2/angbracketright−/angbracketleft s/angbracketright2=c+1
m2φ2=/angbracketlefts/angbracketright
mφ. (6.148)
So it turns out, as we might have expected, that as m→∞ , the distribution p(s|c1···cm)
becomes sharper and sharper, the most probable and mean value estimates of sget closer

<<<PAGE 221>>>

6 Elementary parameter estimation 189
and closer together, and it appears that in the limit we would have just a delta-function:
p(s|φc1···cmIB)→δ(s−s/prime), (6.149)
where
s/prime≡lim
m→∞c1+c2+···+ cm
mφ. (6.150)
But the limiting form (6.149) was found a bit abruptly, as was James Bernoulli’s ﬁrst limit
theorem. We might like to see in more detail how the limit is approached, in analogy tothe de Moivre–Laplace limit theorem for the binomial (5.10), or the limit (4.72) of the betadistribution.
For example, expanding the logarithm of (6.147) about its peak ˆs=c/mφ, and retaining
only through the quadratic terms, we ﬁnd for the asymptotic formula a Gaussian distribution:
p(s|φc
1···cmIB)→Aexp/braceleftbigg
−c(s−ˆs)2
2ˆs2/bracerightbigg
, (6.151)
which is actually valid for all s, in the sense that the difference between the left-hand side
and right-hand side is small for all s(although their ratio is not close to unity for all s). This
leads to the estimate, as c→∞ ,
(s)est=ˆs/parenleftbigg
1±1√c/parenrightbigg
. (6.152)
Quite generally, posterior distributions go into a Gaussian form as the data increase, because
any function with a single rounded maximum, raised to a higher and higher power, goes intoa Gaussian function. In the next chapter we shall explore the basis of Gaussian distributionsin some depth.
So, in the limit, Mr Bdoes indeed approach exact knowledge of the source strength.
Returning to (6.145), both factors in the integrand are now known from (6.89) and (6.147),and so
p(n
k|φc1···cmIB)=/integraldisplay∞
0dsexp{−s(1−φ)}[s(1−φ)]nk−ck
(nk−ck)!(mφ)c+1
c!scexp{−msφ},
(6.153)
or
p(nk|c1···cmIB)=(nk−ck+c)!
(nk−ck)!c!(mφ)c+1(1−φ)nk−ck
(1+mφ−φ)nk−ck+c+1, (6.154)
which is the promised generalization of (6.135). In the limit m→∞ ,c→∞ ,(c/mφ)→
s/prime=const., this goes into the Poisson distribution
p(nk|c1···cmIB)→exp{−s/prime(1−φ)}
(nk−ck)![s/prime(1−φ)]nk−ck, (6.155)
which is identical to (6.89). We therefore conﬁrm that, given enough additional data, Mr B’s
standard deviation can be reduced from 26 to 10.8, compared with Mr A’s value of 31. For

<<<PAGE 222>>>

190 Part 1 Principles and elementary applications
ﬁnite m, the mean value estimate of nkfrom (6.154) is
/angbracketleftnk/angbracketright=ck+/angbracketlefts/angbracketright(1−φ), (6.156)
where/angbracketlefts/angbracketright=(c+1)/mφis the mean value estimate of sfrom (6.148). Equation (6.156) is
to be compared with (6.90). Likewise, the most probable value of nk, according to (6.154), is
ˆnk=ck+ˆs(1−φ), (6.157)
where ˆsis given by (6.148).
Note that Mr B’s revised estimates in problem 2 still lie within the range of reasonable
error assigned by Mr A. It would be rather disconcerting if this were not the case, as it
would then appear that probability theory is giving Mr Aan over-optimistic picture of
the reliability of his estimates. There is, however, no theorem which guarantees this; forexample, if the counting rate had jumped to c
2=80, then Mr B’s revised estimate of n1
would be far outside Mr A’s limits of reasonable error. But, in this case, Mr B’s common
sense would lead him to doubt the reliability of his prior information IB; we would have
another example like that in Chapter 4, of a problem where one of those ‘something else’alternative hypotheses down at −100 db, which we don’t even bother to formulate until
they are needed, is resurrected by very unexpected new evidence.
Exercise 6.7. The above results were found using the language of the particle counter
scenario. Summarize the ﬁnal conclusions in the language of the disease incidencescenario, as one or two paragraphs of advice for a medical researcher who is trying tojudge whether public health measures are reducing the incidence of a disease in thegeneral population, but has data only on the number of deaths from it. This should, ofcourse, include something about judging under what conditions our model correspondswell to the real world; and what to do if it does not.
Now we turn to a different kind of problem to see some new features that can appear when
we use a sampling distribution that is continuous except at isolated points of discontinuity.
6.20 Rectangular sampling distribution
The following ‘taxicab problem’ has been part of the orally transmitted folklore of this ﬁeld
for several decades, but orthodoxy has no way of dealing with it, and we have never seen itmentioned in the orthodox literature. You are traveling on a night train; on awakening fromsleep, you notice that the train is stopped at some unknown town, and all you can see is ataxicab with the number 27 on it. What is then your guess as to the number Nof taxicabs
in the town, which would in turn give a clue as to the size of the town? Almost everybodyanswers intuitively that there seems to be something about the choice N
est=2×27=54
that recommends itself; but few can offer a convincing rationale for this. The obvious‘model’ that forms in our minds is that there will be Ntaxicabs, numbered, respectively,

<<<PAGE 223>>>

6 Elementary parameter estimation 191
(1,..., N), and, given N, the one we see is equally likely to be any of them. Given that
model, we would then know deductively that N≥27; but, from that point on, our reasoning
depends on our statistical indoctrination.
Here we study a continuous version of the same problem, in which more than one taxi
may be in view, leaving it as an exercise for the reader to write down the parallel solutionto the above taxicab problem, and then state the exact relationship between the continuousand discrete problems. We consider a rectangular sampling distribution in [0 ,α], where
the width αof the distribution is the parameter to be estimated, and ﬁnally suggest further
exercises which will extend what we learn from it.
We have a data set D≡{x
1,..., xn}ofnobservations thought of as ‘drawn from’ this
distribution, urn-wise; that is, each datum xiis assigned independently the pdf
p(xi|αI)=/braceleftbiggα−1if 0≤xi≤α<∞
0 otherwise.(6.158)
Then our entire sampling distribution is
p(D|αI)=/productdisplay
ip(xi|αI)=α−n, 0≤{x1,..., xn}≤α, (6.159)
where for brevity we suppose, in the rest of this section, that when the inequalities following
an equation are not all satisﬁed, the left-hand side is zero. It might seem at ﬁrst glance thatthis situation is too trivial to be worth analyzing; yet, if one does not see in advance exactlyhow every detail of the solution will work itself out, there is always something to be learnedfrom studying it. In probability theory, the most trivial looking problems reveal deep andunexpected things.
The posterior pdf for αis, by Bayes’ theorem,
p(α|DI)=p(α|I)p(D|αI)
p(D|I), (6.160)
where p(α|I) is our prior. Now it is evident that any Bayesian problem with a proper
(normalizable) prior and a bounded likelihood function must lead to a proper, well-behavedposterior distribution, whatever the data – as long as the data do not themselves contradict anyof our other information. If any datum was found to be negative, x
i<0, the model (6.159)
would be known deductively to be wrong (put better, the data contradict the prior information
Ithat led us to choose that model). Then the robot crashes, both (6.159) and (6.160)
vanishing identically. But any data set for which the inequalities in (6.159) are satisﬁed isa possible one according to the model . Must it then yield a reasonable posterior pdf?
Not necessarily! The data could be compatible with the model, but still incompatible
with the other prior information. Consider a proper rectangular prior
p(α|I)=(α
1−α00)−1,α 00≤α≤α1, (6.161)
where α00,α1are ﬁxed numbers satisfying 0 ≤α00≤α1<∞, given to us in the statement
of the problem. If any datum were found to exceed the upper prior bound: xi>α 1, then the
data and the prior information would again be logically contradictory.

<<<PAGE 224>>>

192 Part 1 Principles and elementary applications
But this is just what we anticipated already in Chapters 1 and 2; we are trying to reason
from two pieces of information D,I, each of which may be actually a logical conjunction
of many different propositions. If there is a contradiction hidden anywhere in the totalityof this, there can be no solution (in a set theory context, the set of possibilities that wehave prescribed is the empty set) and the robot crashes, in one way or another. So in thefollowing we suppose that the data are consistent with all the prior information – includingthe prior information that led us to choose this model.
15Then the above rules should yield
the correct and exact answer to the question we have posed.
The denominator of (6.160) is
p(D|I)=/integraldisplay
Rdα(α1−α00)−1α−n, (6.162)
where the region Rof integration must satisfy two conditions:
R≡/braceleftbiggα00≤α≤α1
xmax≤α≤α1/bracerightbigg
(6.163)
andxmax≡max{x1,..., xn}is the greatest datum observed. If xmax≤α00, then in (6.163)
we need only the former condition; the numerical values of the data xiare entirely irrelevant
(although the number nof observations remains relevant). If α00≤xmax, then we need only
the latter inequality; the prior lower bound α00has been superseded by the data, and is
irrelevant to the problem from this point on.
Substituting (6.159), (6.161) and (6.162) into (6.160), the factor ( α1−α00) cancels out,
and if n>1 our general solution reduces to
p(α|DI)=(n−1)α−n
α1−n
0−α1−n
1,α 0≤α≤α1, n>1, (6.164)
where α0≡max(α00,xmax).
6.21 Small samples
Small values of noften present special situations that might be overlooked in a general
derivation. In orthodox statistics, as we shall see in Chapter 17, they can lead to weirdpathological results (like an estimator for a parameter which lies outside the parameterspace, and so is known deductively to be impossible). In any other area of mathematics,when a contradiction like this appears, one concludes at once that an error has been made.But curiously, in the literature of orthodox statistics, such pathologies are never interpreted
as revealing an error in the orthodox reasoning. Instead they are simply passed over; one
proclaims his concern only with large n. But small nproves to be very interesting for us, just
15Of course, in the real world we seldom have prior information that would justify such sharp bounds on xandα, and so such
sharp contradictions would not arise; but that signiﬁes only that we are studying an ideal limiting case. There is nothing strangeabout this; in elementary geometry, our attention is directed ﬁrst to such things as perfect triangles and circles, although no such
things exist in the real world. There, also, we are really studying ideal limiting cases of reality; but what we learn from that study
enables us to deal successfully with thousands of real situations that arise in such diverse ﬁelds as architecture, engineering,astronomy, geodesy, stereochemistry, and the artist’s rules of perspective. It is the same here.

<<<PAGE 225>>>

6 Elementary parameter estimation 193
because of the fact that Bayesian analysis has no pathological, exceptional cases. As long
as we avoid outright logical contradictions in the statement of a problem and use properpriors, the solutions do not break down but continue to make good sense.
It is very instructive to see how Bayesian analysis always manages to accomplish this,
which also makes us aware of a subtle point in practical calculation. Thus, in the presentcase, if n=1, then (6.164) appears indeterminate, reducing to (0 /0). But if we repeat the
derivation from the start for the case n=1, the properly normalized posterior pdf for αis
found to be, instead of (6.164),
p(α|DI)=α
−1
log(α1/α0),α 0≤α≤α1, n=1. (6.165)
The case n=0 can hardly be of any use; nevertheless, Bayes’ theorem still gives the
obviously right answer. For then D= ‘no data at all’, and p(D|αI)=p(D|I)=1; that
is, if we take no data, we shall have no data, whatever the value of α. Then the posterior
distribution (6.160) reduces, as common sense demands, to the prior distribution
p(α|DI)=p(α|I),α 0≤α≤α1, n=0. (6.166)
6.22 Mathematical trickery
Now we see a subtle point: the last two results are contained already in (6.164) without
any need to go back and repeat the derivation from the start. We need to understand the
distinction between the real world problem and the abstract mathematics. Although in the
real problem n is by deﬁnition a non-negative integer, the mathematical expression (6.164)
is well-deﬁned and meaningful when nis any complex number . Furthermore, as long as
α1<∞, it is an entire function of n(that is, bounded and analytic everywhere except
the point at inﬁnity). Now in a purely mathematical derivation we are free to make use ofwhatever analytical properties our functions have, whether or not they would make sensein the real problem. Therefore, since (6.164) can have no singularity at any ﬁnite point, wemay evaluate it at n=1 by taking the limit as n→1. But
n−1
α1−n
0−α1−n
1=n−1
exp{−(n−1) log( α0)}−exp{−(n−1) log( α1)}
=n−1
[1−(n−1) log( α0)+··· ]−[1−(n−1) log( α1)+··· ]
→1
log(α1/α0),(6.167)
leading to (6.165). Likewise, putting n=0 into (6.164), it reduces to (6.166), because
now we have necessarily α0=α00. Even in extreme, degenerate cases, Bayesian analysis
continues to yield the correct results.16And it is evident that all moments and percentiles of
16Under the inﬂuence of early orthodox teaching, the writer became fully convinced of this only after many years of experimen-
tation with hundreds of such cases, and his total failure to produce any pathology as long as the Chapter 2 rules were followedstrictly.

<<<PAGE 226>>>

194 Part 1 Principles and elementary applications
the posterior distribution are also entire functions of n, so they may be calculated once and
for all for all n, taking limiting values whenever the general expression reduces to (0 /0) or
(∞/∞); this will always yield the same result that we obtain by going back to the beginning
and repeating the calculation for that particular nvalue.17
Ifα1<∞, the posterior distribution is conﬁned to a ﬁnite interval, and so it has neces-
sarily moments of all orders. In fact,
/angbracketleftαm/angbracketright=n−1
α1−n
0−α1−n
1/integraldisplayα1
α0dααm−n=n−1
n−m−1α1+m−n
0−α1+m−n
1
α1−n
0−α1−n
1, (6.168)
and when n→1o r m→n−1, we are to take the limit of this expression in the manner
of (6.167), yielding the more explicit forms:
/angbracketleftαm/angbracketright=

αm
1−αm
0
mlog(α1/α0)ifn=1
(n−1) log( α1/α0)
α1−n
0−a1−n
1ifm=n−1.(6.169)
In the above results, the posterior distribution is conﬁned to a ﬁnite region ( a0≤α≤α1)
and there can be no singular result.
Exercise 6.8. Complete this example, ﬁnding explicit values for the estimates of αand
their accuracy. Discuss how these results correspond or fail to correspond to commonsense judgments.
Finally, we leave it as an exercise for the reader to consider what happens as α1→∞
and we pass to an inﬁnite domain.
Exercise 6.9. When α1→∞ , some moments must cease to exist, so some inferences
must cease to be possible; others remain possible. Examine the above equations toﬁnd under what conditions a posterior (mean ±standard deviation) or (median ±
interquartile span) remains possible, considering in particular the case of small n. State
how the results correspond to common sense.
17Recognizing this, we see that, whenever a mathematical expression is an analytic function of some parameter, we can exploit
that fact as a tool for calculation with it, whatever meaning it might have in the original problem. For example, the numbers 2
andπoften appear, and it is often in an expression Q(2) or Q(π) which is an analytic function of the symbol ‘2’ or ‘ π’. Then,
if it is helpful, we are free to replace ‘2’ or ‘ π’b y‘ x’ and evaluate quantities involving Qby such operations as differentiating
with respect to x, or complex integration in the xplane, etc., setting x=2o r x=πat the end; and this is perfectly rigorous.
Once we have distilled the real problem into one of abstract mathematics, our symbols mean whatever we say they mean; thewriter learned this trick from Professor W. W. Hansen of Stanford University, who would throw a class into an uproar when he
evaluated an integral, correctly, by differentiating another integral with respect to π.

<<<PAGE 227>>>

6 Elementary parameter estimation 195
6.23 Comments
The calculations which we have done here with ease – in particular, (6.129) and (6.152) –
cannot be done with any version of probability theory which does not permit the use of theprior and posterior probabilities needed, and consequently does not allow us to integrateout a nuisance parameter with respect to a prior. It appears to us that Mr B’s results are
beyond the reach of orthodox methods. Yet at every stage, probability theory as logic hasfollowed the procedures that are determined uniquely by the basic product and sum rules ofprobability theory; and it has yielded well-behaved, reasonable, and useful results. In somecases, the prior information was absolutely essential, even though it was only qualitative.Later we shall see even more striking examples of this.
It should not be supposed that this recognition of the need to use prior information is a new
disco very. It was emphasized very strongly by Bertrand (1889); he gave several examples,
of which we quote the last (he wrote in very short paragraphs):
The inhabitants of St. Malo [a small French town on the English channel] are convinced; for a
century , in their village, the number of deaths at the time of high tide has been greater than at low
tide. We admit the fact.
On the coast of the English channel there have been more shipwrecks when the wind was from the
northwest than for any other direction. The number of instances being supposed the same and equallyreliably reported, still one will not draw the same conclusions.
While we would be led to accept as a certainty the inﬂuence of the wind on shipwrecks, common
sense demands more evidence before considering it even plausible that the tide inﬂuences the lasthour of the Malouins.
The problems, again, are identical; the impossibility of accepting the same conclusions shows the
necessity of taking into account the prior probability for the cause.
Clearly, Bertrand cannot be counted among those who advocate R. A. Fisher’s maxim: ‘Let
the data speak for themselves!’ which has so dominated statistics in this century. The datacannot speak for themselves; and they never have, in any real problem of inference.
For example, Fisher advocated the method of maximum likelihood for estimating a
parameter; in a sense, this is the value that is indicated most strongly by the data alone.But that takes note of only one of the factors that probability theory (and common sense)requires. For, if we do not supplement the maximum likelihood method with some priorinformation about which hypotheses we shall consider reasonable, then it will always leadus inexorably to favor the ‘sure thing’ hypothesis H
S, according to which every tiny detail
of the data was inevitable; nothing else could possibly have happened. For the data alwayshave a much higher probability (namely p(D|H
S)=1), on HSthan on any other hypothesis;
HSis always the maximum likelihood solution over the class of all hypotheses. Only our
extremely low prior probability for HScan justify our rejecting it.18
18Small children, when asked to account for some observed fact such as the exact shape of a puddle of spilled milk, have a
strong tendency to invent ‘sure thing’ hypotheses; they have not yet acquired the worldly experience that makes educated adults
consider them too unlikely to be considered seriously. But a scientist, who knows that the shape is determined by the laws of
hydrodynamics and has vast computing power available, is no more able than the child to predict that shape, because he lacksthe requisite prior information about the exact initial conditions.

<<<PAGE 228>>>

196 Part 1 Principles and elementary applications
Orthodox practice deals with this in part by the device of specifying a model, which is,
of course, a means of incorporating some prior information about the phenomenon beingobserved. But this is incomplete, deﬁning only the parameter space within which we shallseek that maximum; without a prior probability over that parameter space, we have no wayof incorporating further prior information about the likely values of the parameter, whichwe almost always have and which is often highly cogent for any rational inference. Forexample, although a parameter space may extend formally to inﬁnity, in virtually every realproblem we know in advance that the parameter is enormously unlikely to be outside someﬁnite domain. This information may or may not be crucial, depending on what data set wehappen to get.
As the writer can testify from his student days, steadfast followers of Fisher often inter-
pret ‘Let the data speak for themselves’ as implying that it is reprehensible – a violationof ‘scientiﬁc objectivity’ – to allow one’s self to be inﬂuenced at all by prior informa-tion. It required a few years of experience to perceive, with Bertrand, what a disastrouserror this is in real problems. Fisher was able to manage without mentioning prior in-formation only because, in the problems he chose to work on, he had no very importantprior information anyway, and plenty of data. Had he worked on problems with cogentprior information and sparse data, we think that his ideology would have changed ratherquickly.
Scientists in all ﬁelds see this readily enough – as long as they rely on their own common
sense instead of orthodox teaching. For example, Stephen J. Gould (1989) describes thebewildering variety of soft-bodied animals that lived in early Cambrian times, preservedperfectly in the famous Burgess shale of the Canadian Rockies. Two paleontologists ex-amined the same fossil, named Aysheaia , and arrived at opposite conclusions regarding its
proper taxonomic classiﬁcation. One who followed Fisher’s maxim would be obliged toquestion the competence of one of them; but Gould does not make this error. He concludes(p. 172), ‘We have a reasonably well-controlled psychological experiment here. The datahad not changed, so the reversal of opinion can only record a revised presupposition aboutthe most likely status of Burgess organisms.’
Prior information is essential also for a different reason, if we are trying to make inferences
concerning which mechanism is at work. Fisher would, presumably, insist as strongly asany other scientist that a cause–effect relationship requires a physical mechanism to bring itabout. But as in St Malo, the data alone are silent on this; they do not speak for themselves.
19
Only prior information can tell us whether some hypothesis provides a possible mechanismfor the observed facts, consistent with the known laws of physics. If it does not, then thefact that it accounts well for the data may give it a high likelihood, but cannot give it any
credence. A fantasy that invokes the labors of hordes of little invisible elves and pixiesrunning about to generate the data would have just as high a likelihood; but it would still
have no credence for a scientist.
19Statisticians, even those who profess themselves disciples of Fisher, have been obliged to develop adages about this, such as
‘correlation does not imply causation’. or ‘a good ﬁt is no substitute for a reason’. to discourage the kind of thinking that comes
automatically to small children, and to adults with untrained minds.

<<<PAGE 229>>>

6 Elementary parameter estimation 197
It is not only orthodox statisticians who have denigrated prior information in the
20th century. The fantasy writer H. P. Lovecraft once deﬁned ‘common sense’ as ‘merelya stupid absence of imagination and mental ﬂexibility’. Indeed, it is just the accumulationof unchanging prior information about the world that gives the mature person the mentalstability that rejects arbitrary fantasies (although we may enjoy diversionary reading ofthem).
Today, the question whether our present information does or does not provide credible
evidence for the existence of a causal effect is a major policy issue, arousing bitter polit-ical, commercial, medical, and environmental contention, resounding in courtrooms andlegislative halls.
20Yet cogent prior information – without which the issue cannot possibly
be judged – plays little role in the testimony of ‘expert witnesses’ with orthodox statisticaltraining, because their standard procedures have no place to use it. We note that Bertrand’sclear and correct insight into this appeared the year before Fisher was born; the progress ofscientiﬁc inference has not always been forward.
Thus, this chapter begins and ends with a glance back at Fisher, about whom the reader
may ﬁnd more in Chapter 16.
20For some frightening examples, see Gardner (1957, 1981). Deliberate suppression of inconvenient prior information is also the
main tool of the scientiﬁc charlatans.

<<<PAGE 230>>>

7
The central, Gaussian or normal distribution
My own impression ...is that the mathematical results have outrun their
interpretation and that some simple explanation of the force and meaning
of the celebrated integral ...will one day be found ...which will at once
render useless all the works hitherto written.
Augustus de Morgan (1838)
Here, de Morgan was expressing his bewilderment at the ‘curiously ubiquitous’ success of
methods of inference based on the Gaussian, or normal, ‘error law’ (sampling distribution),even in cases where the law is not at all plausible as a statement of the actual frequenciesof the errors. But the explanation was not forthcoming as quickly as he expected.
In the middle 1950s the writer heard an after -dinner speech by Professor Willy Feller,
in which he roundly denounced the practice of using Gaussian probability distributions
for errors, on the grounds that the frequency distributions of real errors are almost never
Gaussian. Yet in spite of Feller’s disappro val, we continued to use them, and their ubiquitous
success in parameter estimation continued. So, 145 years after de Morgan’s remark, the
situation was still unchanged, and the same surprise was expressed by George Barnard(1983): ‘ Why have we for so long managed with normality assumptions ?’
Today we believe that we can, at last, explain (1) the inevitably ubiquitous use, and
(2) the ubiquitous success, of the Gaussian error law. Once seen, the explanation is indeed
trivially obvious; yet, to the best of our knowledge, it is not recognized in any of the previousliterature of the ﬁeld, because of the universal tendency to think of probability distributionsin terms of frequencies. We cannot understand what is happening until we learn to think of
probability distributions in terms of their demonstrable information content instead of their
imagined (and, as we shall see, irrelevant) frequency connections.
A simple explanation of these properties – stripped of past irrelevancies – has been
achieved only very recently, and this development changed our plans for the present work.We decided that it is so important that it should be inserted at this somewhat early pointin the narrative, even though we must then appeal to some results that are establishedonly later. In the present chapter, then, we survey the historical basis of Gaussian distribu-tions and present a quick preliminary understanding of their functional role in inference.This understanding will then guide us directly – without the usual false starts and blind
198

<<<PAGE 231>>>

7 The central, Gaussian or normal distribution 199
alleys – to the computational procedures which yield the great majority of the useful appli-
cations of probability theory.
7.1 The gravitating phenomenon
We have noted an interesting phenomenon several times in previous chapters; in probability
theory, there seems to be a central, universal distribution
ϕ(x)≡1√
2πexp/braceleftbigg
−x2
2/bracerightbigg
(7.1)
toward which all others gravitate under a very wide variety of different operations – and
which, once attained, remains stable under an even wider variety of operations. The famous‘central limit theorem’ concerns one special case of this. In Chapter 4, we noted thata binomial or beta sampling distribution goes asymptotically into a Gaussian when thenumber of trials becomes large. In Chapter 6 we noted a virtually universal property, thatposterior distributions for parameters go into Gaussian when the number of data valuesincreases.
In physics, these gravitating and stability properties have made this distribution the uni-
versal basis of kinetic theory and statistical mechanics; in biology, it is the natural tool
for discussing population dynamics in ecology and evolution. We cannot doubt that it willbecome equally fundamental in economics, where it already enjoys ubiquitous use, but
somewhat apologetically, as if there were some doubt about its justiﬁcation. We hope to
assist this development by showing that its range of validity for such applications is farwider than is usually supposed.
Figure 7.1 illustrates this distribution. Its general shape is presumably already well known
to the reader, although the numerical values attached to it may not be. The cumulative
−3 −2 −1012 tϕ
0.10.20.30.5
3↓
↓
Fig. 7.1. The central, Gaussian or normal distribution: ϕ(t)=1/√
2πexp(−t2/2).

<<<PAGE 232>>>

200 Part I Principles and elementary applications
Gaussian, deﬁned as
/Phi1(x)≡/integraldisplayx
−∞dtϕ(t),
=/integraldisplay0
−∞dtϕ(t),+/integraldisplayx
0dtϕ(t), (7.2)
=1
2[1+erf(x)],
will be used later in this chapter for solving some problems. Numerical values for this
function are easily calculated using the error function, erf( x).
This distribution is called the Gaussian, or normal, distribution, for historical reasons
discussed below. Both names are inappropriate and misleading today; all the correct con-
notations would be conveyed if we called it, simply, the central distribution of probabil-
ity theory.1We consider ﬁrst three derivations of it that were important historically and
conceptually, because they made us aware of three important properties of the Gaussian
distribution.
7.2 The Herschel–Maxwell derivation
One of the most interesting derivations, from the standpoint of economy of assumptions,
was given by the astronomer John Herschel (1850). He considered the two-dimensional
probability distribution for errors in measuring the position of a star. Let xbe the er-
ror in the longitudinal (east–west) direction and ythe error in the declination (north–
south) direction, and ask for the joint probability distribution ρ(x,y). Herschel made
two postulates (P1, P2) that seemed required intuitively by conditions of geometricalhomogeneity.
(P1) Knowledge of x tells us nothing about y
That is, probabilities of errors in orthogonal directions should be independent; so the unde-
termined distribution should have the functional form
ρ(x,y)dxdy=f(x)dx×f(y)dy. (7.3)
We can write the distribution equally well in polar coordinates r,θdeﬁned by x=rcosθ,
y=rsinθ:
ρ(x,y)dxdy=g(r,θ)rdrdθ. (7.4)
1It is general usage outside probability theory to denote any function of the general form exp {−ax2}as aGaussian function ,a n d
we shall follow this.

<<<PAGE 233>>>

7 The central, Gaussian or normal distribution 201
(P2) This probability should be independent of the angle: g (r,θ)=g(r)
Then (7.3) and (7.4) yield the functional equation
f(x)f(y)=g/parenleftbig/radicalbig
x2+y2/parenrightbig
, (7.5)
and, setting y=0, this reduces to g(x)=f(x)f(0), so (7.5) becomes the functional
equation
log/bracketleftbiggf(x)
f(0)/bracketrightbigg
+log/bracketleftbiggf(y)
f(0)/bracketrightbigg
=log/bracketleftBigg
f(/radicalbig
x2+y2)
f(0)/bracketrightBigg
. (7.6)
But the general solution of this is obvious; a function of xplus a function of yis a function
only of x2+y2. The only possibility is that log[ f(x)/f(0)]=ax2. We have a normalizable
probability only if ais negative, and then normalization determines f(0); so the general
solution can only have the form
f(x)=/radicalbiggα
πexp/braceleftbig
−αx2/bracerightbig
,α > 0, (7.7)
with one undetermined parameter. The only two-dimensional probability density satisfying
Herschel’s invariance conditions is a circular symmetric Gaussian:
ρ(x,y)=α
πexp/braceleftbig
−α(x2+y2)/bracerightbig
. (7.8)
Ten years later, James Clerk Maxwell (1860) gave a three-dimensional version of this same
argument to ﬁnd the probability distribution ρ(vx,vy,vz)∝exp{−α(v2
x+v2
y+v2
z)}for
velocities of molecules in a gas, which has become well known to physicists as the ‘Maxwell-ian velocity distribution law’ fundamental to kinetic theory and statistical mechanics.
The Herschel–Maxwell argument is particularly beautiful because two qualitative con-
ditions, incompatible in general, become compatible for just one quantitative distribution,which they therefore uniquely determine. Einstein (1905a,b) used the same kind of argumentto deduce the Lorentz transformation law from his two qualitative postulates of relativitytheory.
2
The Herschel–Maxwell derivation is economical also in that it does not actually make any
use of probability theory; only geometrical invariance properties which could be appliedequally well in other contexts. Gaussian functions are unique objects in their own right, forpurely mathematical reasons. But now we give a famous derivation that makes explicit useof probabilistic intuition.
2These are: (1) the laws of physics take the same form for all moving observers; and (2) the velocity of light has the same constant
numerical value for all such observers. These are also contradictory in general, but become compatible for one particularquantitative law of transformation of space and time to a moving coordinate system.

<<<PAGE 234>>>

202 Part I Principles and elementary applications
7.3 The Gauss derivation
We estimate a location parameter θfrom ( n+1) observations ( x0,..., xn) by maximum
likelihood. If the sampling distribution factors: p(x0,..., xn|θ)=f(x0|θ)···f(xn|θ), the
likelihood equation is
n/summationdisplay
i=0∂
∂θlogf(xi|θ)=0, (7.9)
or, writing
logf(x|θ)=g(θ−x)=g(u), (7.10)
the maximum likelihood estimate ˆθwill satisfy
/summationdisplay
ig/prime(ˆθ−xi)=0. (7.11)
Now, intuition may suggest to us that the estimate ought to be also the arithmetic mean of
the observations:
ˆθ=¯x=1
n+1n/summationdisplay
i=0xi, (7.12)
but (7.11) and (7.12) are in general incompatible ((7.12) is not a root of (7.11)). Nevertheless,
consider a possible sample, in which only one observation x0is nonzero: if in (7.12) we put
x0=(n+1)u, x1=x2=···= xn=0, (−∞<u<∞), (7.13)
then ˆθ=u,ˆθ−x0=−nu, whereupon eqn. (7.11) becomes g/prime(−nu)+ng/prime(u)=0,
n=1,2,3,.... The case n=1 tells us that g/prime(u) must be an antisymmetric function:
g/prime(−u)=−g/prime(u), so this reduces to
g/prime(nu)=ng/prime(u), (−∞<u<∞),n=1,2,3,.... (7.14)
Evidently, the only possibility is a linear function:
g/prime(u)=au, g(u)=1
2au2+b. (7.15)
Converting back by (7.10), a normalizable distribution again requires that abe negative,
and normalization then determines the constant b. The sampling distribution must have
the form
f(x|θ)=/radicalbiggα
2πexp/braceleftbigg
−1
2α(x−θ)2/bracerightbigg
(0<α<∞). (7.16)
Since (7.16) was derived assuming the special sample (7.13), we have shown thus far only
that (7.16) is a necessary condition for the equality of maximum likelihood estimate andsample mean. Conversely, if (7.16) is satisﬁed, then the likelihood equation (7.9) alwayshas the unique solution (7.12); and so (7.16) is the necessary and sufﬁcient condition forthis agreement. The only freedom is the unspeciﬁed scale parameter α.

<<<PAGE 235>>>

7 The central, Gaussian or normal distribution 203
7.4 Historical importance of Gauss’s result
This derivation was given by Gauss (1809), as little more than a passing remark in a work
concerned with astronomy. It might have gone unnoticed but for the fact that Laplace saw itsmerit and the following year published a large work calling attention to it and demonstratingthe many useful properties of (7.16) as a sampling distribution. Ever since, it has been calledthe ‘Gaussian distribution’.
Why was the Gauss derivation so sensational in effect? Because it put an end to a long –
and, it seems to us today, scandalous – psychological hang up suffered by some of thegreatest mathematicians of the time. The distribution (7.16) had been found in a more orless accidental way already by de Moivre (1733), who did not appreciate its signiﬁcanceand made no use of it. Throughout the 18th century, it would have been of great valueto astronomers faced constantly with the problem of making the best estimates from dis-crepant observations; yet the greatest minds failed to see it. Worse, even the qualitative factunderlying data analysis – cancellation of errors by averaging of data – was not perceivedby so great a mathematician as Leonhard Euler.
Euler (1749), trying to resolve the ‘Great Inequality of Jupiter and Saturn’, found himself
with what was at the time a monstrous problem (described brieﬂy in our closing Comments,Section 7.27). To determine how the longitudes of Jupiter and Saturn had varied over longtimes, he made 75 observations over a 164 year period (1582–1745), and eight orbitalparameters to estimate from them.
Today, a desk-top microcomputer could solve this problem by an algorithm to be given
in Chapter 19, and print out the best estimates of the eight parameters and their accuracies,in about one minute (the main computational job is the inversion of an (8 ×8) matrix).
Euler failed to solve it, but not because of the magnitude of this computation; he failedeven to comprehend the principle needed to solve it. Instead of seeing that by combiningmany observations their errors tend to cancel, he thought that this would only ‘multiply theerrors’ and make things worse. In other words, Euler concentrated his attention entirely onthe worst possible thing that could happen, as if it were certain to happen – which makeshim perhaps the ﬁrst really devout believer in Murphy’s Law.
3
Yet, practical people, with experience in actual data taking, had long perceived that this
worst possible thing does nothappen. On the contrary, averaging our observations has
the great advantage that the errors tend to cancel each other.4Hipparchus, in the second
century bc, estimated the precession of the equinoxes by averaging measurements on several
stars. In the late 16th century, taking the average of several observations was the routineprocedure of Tycho Brahe. Long before it had any formal theoretical justiﬁcation frommathematicians, intuition had told observational astronomers that this averaging of datawas the right thing to do.
Some 30 years after Euler’s effort, another competent mathematician, Daniel Bernoulli
(1777), still could not comprehend the procedure. Bernoulli supposes that an archer is
3‘If anything cango wrong, it willgo wrong.’
4If positive and negative errors are equally likely, then the probability that ten errors all have the same sign is (0 .5)9/similarequal0.002.

<<<PAGE 236>>>

204 Part I Principles and elementary applications
shooting at a vertical line drawn on a target, and asks how many shots land in various
vertical bands on either side of it:
Now is it not self-evident that the hits must be assumed to be thicker and more numerous on any given
band the nearer this is to the mark? If all the places on the vertical plane, whatever their distance fromthe mark, were equally liable to be hit, the most skillful shot would have no advantage over a blindman. That, however, is the tacit assertion of those who use the common rule (the arithmetic mean) inestimating the value of various discrepant observations, when they treat them all indiscriminately. Inthis way, therefore, the degree of probability of any given deviation could be determined to some extenta posteriori , since there is no doubt that, for a large number of shots, the probability is proportional
to the number of shots which hit a band situated at a given distance from the mark.
We see that Daniel Bernoulli (1777), like his uncle James Bernoulli (1713), saw clearly
the distinction between probability and frequency. In this respect, his understanding ex-ceeded that of John Venn 100 years later, and Jerzy Neyman 200 years later. Yet he failscompletely to understand the basis for taking the arithmetic mean of the observationsas an estimate of the true ‘mark’. He takes it for granted (although a short calculation,which he was easily capable of doing, would have taught him otherwise) that, if the ob-servations are given equal weight in calculating the average, then one must be assigningequal probability to all errors, however great. Presumably, others made intuitive guesseslike this, unchecked by calculation, making this part of the folklore of the time. Thenone can appreciate how astonishing it was when Gauss, 32 years later, proved that the
condition
(maximum likelihood estimate) =(arithmetic mean) (7.17)
uniquely determines the Gaussian error law, not the uniform one.
In the meantime, Laplace (1783) had investigated this law as a limiting form of the
binomial distribution, derived its main properties, and suggested that it was so importantthat it ought to be tabulated; yet, lacking the above property demonstrated by Gauss, he stillfailed to see that it was the natural error law (the Herschel derivation was still 77 years in thefuture). Laplace persisted in trying to use the form f(x)∝exp{−a|x|}, which caused no end
of analytical difﬁculties. But he did understand the qualitative principle that combinationof observations improves the accuracy of estimates, and this was enough to enable him tosolve, in 1787, the problem of Jupiter and Saturn, on which the greatest minds had beenstruggling since before he was born.
Twenty-two years later, when Laplace saw the Gauss derivation, he understood it all in a
ﬂash – doubtless mentally kicked himself for not seeing it before – and hastened (Laplace,1810, 1812) to give the central limit theorem and the full solution to the general problemof reduction of observations, which is still how we analyze it today. Not until the timeof Einstein did such a simple mathematical argument again have such a great effect onscientiﬁc practice.

<<<PAGE 237>>>

7 The central, Gaussian or normal distribution 205
7.5 The Landon derivation
A derivation of the Gaussian distribution that gives us a very lively picture of the process by
which a Gaussian frequency distribution is built up in Nature was given in 1941 by VernonD. Landon, an electrical engineer studying properties of noise in communication circuits.We give a generalization of his argument, in our current terminology and notation.
The argument was suggested by the empirical observation that the variability of the
electrical noise voltage v(t) observed in a circuit at time tseems always to have the same
general properties, even though it occurs at many different levels (say, mean square values)corresponding to different temperatures, ampliﬁcations, impedance levels, and even differ-ent kinds of sources – natural, astrophysical, or man-made by many different devices suchas vacuum tubes, neon signs, capacitors, resistors made of many different materials, etc.Previously, engineers had tried to characterize the noise generated by different sources in
terms of some ‘statistic’ such as the ratio of peak to RMS (root mean square) value, which
it was thought might identify its origin. Landon recognized that these attempts had failed,and that the samples of electrical noise produced by widely different sources ‘ ...cannot be
distinguished one from the other by any known test’.
5
Landon reasoned that if this frequency distribution of noise voltage is so universal, then
it must be better determined theoretically than empirically. To account for this universalitybut for magnitude, he visualized not a single distribution for the voltage at any given time,but a hierarchy of distributions p(v|σ) characterized by a single scale parameter σ
2, which
we shall take to be the expected square of the noise voltage. The stability seems to implythat, if the noise level σ
2is increased by adding a small increment of voltage, the probability
distribution still has the same functional form, but is only moved up the hierarchy to thenew value of σ. He discovered that for only one functional form of p(v|σ) will this be true.
Suppose the noise voltage vis assigned the probability distribution p(v|σ). Then it
is incremented by a small extra contribution /epsilon1, becoming v
/prime=v+/epsilon1, where /epsilon1is small
compared with σ, and has a probability distribution q(/epsilon1)d/epsilon1, independent of p(v|σ). Given
a speciﬁc /epsilon1, the probability for the new noise voltage to have the value v/primewould be just the
previous probability that vshould have the value ( v/prime−/epsilon1). Thus, by the product and sum
rules of probability theory, the new probability distribution is the convolution
f(v/prime)=/integraldisplay
d/epsilon1p(v/prime−/epsilon1|σ)q(/epsilon1). (7.18)
Expanding this in powers of the small quantity /epsilon1and dropping the prime, we have
f(v)=p(v|σ)−∂p(v|σ)
∂v/integraldisplay
d/epsilon1/epsilon1q(/epsilon1)+1
2∂2p(v|σ)
∂v2/integraldisplay
d/epsilon1/epsilon12q(/epsilon1)+···, (7.19)
5This universal, stable type of noise was called ‘grass’ because that is what it looks like on an oscilloscope. To the ear, it sounds
like a smooth hissing without any discernible pitch; today this is familiar to everyone because it is what we hear when a television
receiver is tuned to an unused channel. Then the automatic gain control turns the gain up to the maximum, and both the hissing
sound and the ﬂickering ‘snow’ on the screen are the greatly ampliﬁed noise generated by random thermal motion of electrons
in the antenna according to the Nyquist law noted below.

<<<PAGE 238>>>

206 Part I Principles and elementary applications
or, now writing for brevity p≡p(v|σ),
f(v)=p−/angbracketleft/epsilon1/angbracketright∂p
∂v+1
2/angbracketleft/epsilon12/angbracketright∂2p
∂v2+···. (7.20)
This shows the general form of the expansion; but now we assume that the increment is
as likely to be positive as negative:6/angbracketleft/epsilon1/angbracketright=0. At the same time, the expectation of v2is
increased to σ2+/angbracketleft/epsilon12/angbracketright, so Landon’s invariance property requires that f(v) should be equal
also to
f(v)=p+/angbracketleft/epsilon12/angbracketright∂p
∂σ2. (7.21)
Comparing (7.20) and (7.21), we have the condition for this invariance:
∂p
∂σ2=1
2∂2p
∂v2. (7.22)
But this is a well-known differential equation (the ‘diffusion equation’), whose solution
with the obvious initial condition p(v|σ=0)=δ(v)i s
p(v|σ)=1√
2πσ2exp/braceleftbigg
−v2
2σ2/bracerightbigg
, (7.23)
the standard Gaussian distribution. By minor changes in the wording, the above math-
ematical argument can be interpreted either as calculating a probability distribution, or
asestimating a frequency distribution; in 1941 nobody except Harold Jeffreys and John
Maynard Keynes took note of such distinctions. As we shall see, this is, in spirit, an incre-mental version of the central limit theorem; instead of adding up all the small contributions atonce, it takes them into account one at a time, requiring that at each step the new probabilitydistribution has the same functional form (to second order in /epsilon1).
This is just the process by which noise is produced in Nature – by addition of many
small increments, one at a time (for example, collisions of individual electrons with atoms,each collision radiating another tiny pulse of electromagnetic waves, whose sum is theobserved noise). Once a Gaussian form is attained, it is preserved; this process can bestopped at any point, and the resulting ﬁnal distribution still has the Gaussian form. Whatis at ﬁrst surprising is that this stable form is independent of the distributions q(/epsilon1)o ft h e
small increments; that is why the noise from different sources could not be distinguishedby any test known in 1941.
7
Today we can go further and recognize that the reason for this independence was that only
the second moment /angbracketleft/epsilon12/angbracketrightof the increments mattered for the updated point distribution (that
6If the small increments all had a systematic component in the same direction, one would build up a large ‘DC’ noise voltage,
which is manifestly not the present situation. But the resulting solution might have other applications; see Exercise 7.1.
7Landon’s original derivation concerned only a special case of this, in which q(/epsilon1)=[π√
a2−/epsilon12]−1,|/epsilon1|<a, corresponding to
an added sinusoid of amplitude aand unknown phase. But the important thing was his idea of the derivation, which anyone
can generalize once it is grasped. In essence he had discovered independently, in the expansion (7.20), what is now called theFokker–Planck equation of statistical mechanics, a powerful method which we shall use later to show how a nonequilibriumprobability distribution relaxes into an equilibrium one. It is now known to have a deep meaning, in terms of continuallyremaximized entropy.

<<<PAGE 239>>>

7 The central, Gaussian or normal distribution 207
is, the probability distribution for the voltage at a given time that we were seeking). Even the
magnitude of the second moment did not matter for the functional form; it determined onlyhow far up the σ
2hierarchy we moved. But if we ask a more detailed question, involving
time-dependent correlation functions, then noise samples from different sources are nolonger indistinguishable. The second-order correlations of the form /angbracketleft/epsilon1(t)/epsilon1(t
/prime)/angbracketrightare related
to the power spectrum of the noise through the Wiener–Khinchin theorem, which was justin the process of being discovered in 1941; they give information about the duration in timeof the small increments. But if we go to fourth-order correlations /angbracketleft/epsilon1(t
1)/epsilon1(t2)/epsilon1(t3)/epsilon1(t4)/angbracketrightwe
obtain still more detailed information, different for different sources, even though they allhave the same Gaussian point distribution and the same power spectrum.
8
Exercise 7.1. The above derivation established the result to order /angbracketleft/epsilon12/angbracketright. Now suppose
that we add nsuch small increments, bringing the variance up to σ2+n/angbracketleft/epsilon12/angbracketright. Show
that in the limit n→∞ ,/angbracketleft/epsilon12/angbracketright→ 0,n/angbracketleft/epsilon12/angbracketright→ const., the Gaussian distribution (7.23)
becomes exact (the higher terms in the expansion (7.19) become vanishingly smallcompared with the terms in /angbracketleft/epsilon1
2/angbracketright).
Exercise 7.2. Repeat the above derivation without assuming that /angbracketleft/epsilon1/angbracketright=0 in (7.20).
The resulting differential equation is a Fokker–Planck equation. Show that there is nowa superimposed steady drift, the solutions having the form exp {−(v−aσ
2)2/2σ2}.
Suggest a possible useful application of this result.Hint: σ
2andvmay be given other interpretations, such as time and distance.
7.6 Why the ubiquitous use of Gaussian distributions?
We started this chapter by noting the surprise of de Morgan and Barnard at the great and
ubiquitous success that is achieved in inference – particularly, in parameter estimation –through the use of Gaussian sampling distributions, and the reluctance of Feller to believethat such success was possible. It is surprising that to understand this mystery requires
almost no mathematics – only a conceptual reorientation toward the idea of probabilitytheory as logic.
Let us think in terms of the information that is conveyed by our equations. Whether
or not the long-run frequency distribution of errors is in fact Gaussian is almost never
8Recognition of this invalidates many na¨ ıve arguments by physicists who try to prove that ‘Maxwell demons’ are impossible by
assuming that thermal radiation has a universal character, making it impossible to distinguish the source of the radiation. Butonly the second-order correlations are universal; a demon who perceives fourth-order correlations in thermal radiation is far
from blind about the details of his surroundings. Indeed, the famous Hanbury Brown–Twiss interferometer (1956), invokes just
such a fourth-order demon, in space instead of time and observing /angbracketleft/epsilon1
2(x1)/epsilon12(x2)/angbracketrightto measure the angular diameters of stars.
Conventional arguments against Maxwell demons are logically ﬂawed and prove nothing.

<<<PAGE 240>>>

208 Part I Principles and elementary applications
known empirically; what the scientist knows about them (from past experience or from
theory) is almost always simply their general magnitude. For example, today most accurateexperiments in physics take data electronically, and a physicist usually knows the meansquare error of those measurements because it is related to the temperature by the well-known Nyquist thermal ﬂuctuation law.
9But he seldom knows any other property of the
noise. If he assigns the ﬁrst two moments of a noise probability distribution to agree with suchinformation, but has no further information and therefore imposes no further constraints,then a Gaussian distribution ﬁt to those moments will, according to the principle of maximumentropy as discussed in Chapter 11, represent most honestly his state of knowledge aboutthe noise.
But we must stress a point of logic concerning this. It represents most honestly the
physicist’s state of knowledge about the particular samples of noise for which he had data .
This never includes the noise in the measurement which he is about to make! If we supposethat knowledge about some past samples of noise applies also to the speciﬁc sample of noisethat we are about to encounter, then we are making an inductive inference that might ormight not be justiﬁed; and honesty requires that we recognize this. Then past noise samplesare relevant for predicting future noise only through those aspects that we believe shouldbe reproducible in the future.
In practice, common sense usually tells us that any observed ﬁne details of past noise
are irrelevant for predicting ﬁne details of future noise, but that coarser features, such aspast mean square values, may be expected reasonably to persist, and thus be relevant forpredicting future mean square values. Then our probability assignment for future noiseshould make use only of those coarse features of past noise which we believe to have
this persistence. That is, it should have maximum entropy subject to the constraints of
the coarse features that we retain because we expect them to be reproducible. Probabilitytheory becomes a much more powerful reasoning tool when guided by a little commonsense judgment of this kind about the real world, as expressed in our choice of a model andassignment of prior probabilities.
Thus we shall ﬁnd in studying maximum entropy below that, when we use a Gaussian
sampling distribution for the noise, we are in effect telling the robot: ‘The only thing I knowabout the noise is its ﬁrst two moments, so please take that into account in assigning your
probability distribution, but be careful notto assume anything else about the noise.’ We
shall see presently how well the robot obeys this instruction.
10
9A circuit element of resistance R(ω) ohms at angular frequency ωdevelops across its terminals in a small frequency band
/Delta1ω=2π/Delta1fa ﬂuctuating mean square open-circuit voltage V2=4kT R/Delta1f, where fis the frequency in hertz (cycles per
second), k≡1.38×10−23joule/degree is Boltzmann’s constant, and Tis the Kelvin temperature. Thus it can deliver to
another circuit element the maximum noise power P=V2/4R=kT/Delta1f. At room temperature, T=300 K, this is about
4×10−15watt/megahertz bandwidth. Any signal of lower intensity than this will be lost in the thermal noise and cannot be
recovered, ordinarily, by any amount of ampliﬁcation. But prior information about the kind of signal to be expected will stillenable a Bayesian computer program to extract weaker signals, as the work of Bretthorst (1988) demonstrates. We study this
in Part 2.
10If we have further pieces of information about the noise, such as a fourth moment or an upper bound, the robot can take these
into account also by assigning generalized Gaussian – that is, general maximum entropy – noise probability distributions.Examples of the use of fourth-moment constraints in economics and physical chemistry are given by Gray and Gubbins (1984)
and Zellner (1988).

<<<PAGE 241>>>

7 The central, Gaussian or normal distribution 209
This does not mean that the full frequency distribution of the past noise is to be ig-
nored if it happens to be known. Probability theory as logic does not conﬂict with con-ventional orthodox theory if we actually have the information (that is, perfect knowledgeof limiting frequencies, and no other information) that orthodox theory presupposes; butit continues to operate using whatever information we have. In the vast majority of realproblems we lack this frequency information but have other information (such as meansquare value, digitizing interval, power spectrum of the noise); and a correct probabilityanalysis readily takes this into account, by using the technical apparatus that orthodoxylacks.
Exercise 7.3. Suppose that the long-run frequency distribution of the noise has been
found empirically to be the function f(e) (never mind how one could actually obtain that
information), and that we have no other information about the noise. Show, by reasoninglike that leading to (4.55) and using Laplace’s Rule of Succession (6.73), that, in thelimit of a very large amount of frequency data, our probability distribution for the noise
becomes numerically equal to the observed frequency distribution: p(e|I)→f(e).
This is what Daniel Bernoulli conjectured in Section 7.4. But state very carefully theexact conditions for this to be true.
In other ﬁelds, such as analysis of economic data, knowledge of the noise may be more
crude, consisting of its approximate general magnitude and nothing else. But for reasonsnoted below (the central limit theorem), we still have good reasons to expect a Gaussian
functional form; so a Gaussian distribution ﬁt to that magnitude is still a good representationof one’s state of knowledge. If even that knowledge is lacking, we still have good reasonto expect the Gaussian functional form, so a sampling distribution with σan undetermined
nuisance parameter to be estimated from the data is an appropriate and useful startingpoint. Indeed, as Bretthorst (1988) demonstrates, this is often the safest procedure, evenin a physics experiment, because the noise may not be the theoretically well understoodNyquist noise. No source has ever been found which generates noise below the Nyquistvalue – and from the second law of thermodynamics we do not expect to ﬁnd such a source,because the Nyquist law is only the low-frequency limit of the Planck black-body radiationlaw – but a defective apparatus may generate noise far above the Nyquist value. One canstill conduct the experiment with such an apparatus, taking into account the greater noisemagnitude; but, of course, a wise experimenter who knows that this is happening will tryto improve his apparatus before proceeding.
We shall ﬁnd, in the central limit theorem, still another strong justiﬁcation for using
Gaussian error distributions. But if the Gaussian law is nearly always a good representationof our state of knowledge about the errors in our speciﬁc data set , it follows that inferences
made from it are nearly always the best ones that could have been made from the informationthat we actually have.

<<<PAGE 242>>>

210 Part I Principles and elementary applications
Now, as we note presently, the data give us a great deal of information about the noise,
not usually recognized. But Bayes’ theorem automatically takes into account whatevercan be inferred about the noise from the data; to the best of our knowledge, this has notbeen recognized in the previous literature. Therefore Bayesian inferences using a Gaussiansampling distribution could be improved upon only by one who had additional informationabout the actual errors in his speciﬁc data set, beyond its ﬁrst two moments and beyond what
is known from the data .
For this reason, whether our inferences are successful or not, unless such extra information
is at hand, there is no justiﬁcation for adopting a different error law; and, indeed, noprinciple to tell us which different one to adopt. This explains the ubiquitous use. Since thetime of Gauss and Laplace, the great majority of all inference procedures with continuousprobability distributions have been conducted – necessarily and properly – with Gaussiansampling distributions. Those who disapproved of this, whatever the grounds for theirobjection, have been unable to offer any alternative that was not subject to a worse objection;so, already in the time of de Morgan, some 25 years after the work of Laplace, use of the
Gaussian rule had become ubiquitous by default, and this continues today.
Recognition of this considerably simpliﬁes our expositions of Bayesian inference; 95%
of our analysis can be conducted with a Gaussian sampling distribution, and only in specialcircumstances (unusual prior information such as that the errors are pure digitizing errors orthat there is an upper bound to the possible error magnitude) is there any reason for adoptinga different one. But even in those special circumstances, the Gaussian analysis usually leadsto ﬁnal conclusions so near to the exact ones that the difference is hardly worth the extraeffort.
It is now clear that the most ubiquitous reason for using the Gaussian sampling distribution
is not that the error frequencies are known to be – or assumed to be – Gaussian, but ratherbecause those frequencies are unknown . One sees what a totally different outlook this is
than that of Feller and Barnard; ‘normality’ was not an assumption of physical fact at all.
It was a valid description of our state of knowledge. In most cases, had we done anything
different, we would be making an unjustiﬁed, gratuitous assumption (violating one of ourChapter 1 desiderata of rationality). But this still does not explain why the procedure is sosuccessful.
7.7 Why the ubiquitous success?
By ‘ubiquitous success’ we mean that, for nearly two centuries, the Gaussian sampling
distribution has continued to be, in almost all problems, much easier to use and to yieldbetter results (more accurate parameter estimates) than any alternative sampling distributionthat anyone has been able to suggest. To explain this requires that analysis that de Morganpredicted would one day be found. But why did it require so long to ﬁnd that analysis?
As a start toward answering this, note that we are going to use some function of the data
as our estimate; then, whether our present inference – here and now – is or is not successful,
depends entirely on what that function is, and on the actual errors that are present in the

<<<PAGE 243>>>

7 The central, Gaussian or normal distribution 211
one speciﬁc data set that we are analyzing . Therefore to explain its success requires that we
examine that speciﬁc data set. The frequency distribution of errors in other data sets that wemight have got but did not – and which we are therefore not analyzing – is irrelevant, unless(a) it is actually known, not merely imagined; (b) it tells us something about the errors inour speciﬁc data set that we would not know otherwise.
We have never seen a real problem in which these conditions were met; those who em-
phasized frequencies most strongly merely assumed them without pointing to any actual
measurement. They persisted in trying to justify the Gaussian distribution in terms of as-sumed frequencies in imaginary data sets that have never been observed; thus they continuedto dwell on fantasies instead of the information that was actually relevant to the inference;and so we understand why the y were unable to ﬁnd any explanation of the success of that
distribution.
Thus, Feller, thinking exclusively in terms of sampling distributions for estimators,
thought that, unless our sampling distribution for the e
icorrectly represented the actual
frequencies of errors, our estimates would be in some way unsatisfactory; in exactly what
way seems never to have been stated by Feller or anyone else. Now there is a closely related
truth here: If our estimator is a given, ﬁxed function of the data, then the actual variability
of the estimate in the long-run over all possible data sets, is indeed determined by the actual
long-run frequency distribution of the errors, if such a thing exists .
But does it follow that our assigned sampling distribution must be equal to that frequency
distribution in order to get satisfactory estimates? To the best of our knowledge, orthodoxy
has never attempted to give any such demonstration, or even recognized the need for it. But
this makes us aware of another, equally serious, difﬁculty.
7.8 What estimator should we use?
In estimating a parameter µfrom data D, the orthodoxian would almost surely use the
maximum likelihood estimator; that is, the value of µfor which p(D|µ) is a maximum.
If the prior information is unimportant (that is, if the prior probability density p(µ|I)i s
essentially constant over the region of high likelihood), the Bayesian might do this also.But is there any proof that the maximum likelihood estimator yields the most accurateestimates? Might not the estimates of µbe made still better in the long-run (i.e., more
closely concentrated about the true value µ
0) by a different choice of estimator? This
question also remains open; there are two big gaps in the logic here.
More fundamental than the logical gaps is the conceptual disorientation; the scenario
envisaged by Feller is not the real problem facing a scientist. As John Maynard Keynes(1921) emphasized long ago, his job is not to fantasize about an imaginary ‘long-run’which will never be realized, but to estimate the parameters in the one real case before him,from the one real data set that he actually has.
11
11Curiously, in that same after-dinner speech, Feller also railed against those who fail to distinguish between the long-run and the
individual case, yet it appears to us that it was Feller who failed to make that distinction properly. He would judge the merit of

<<<PAGE 244>>>

212 Part I Principles and elementary applications
To raise these issues is not mere nitpicking; let us show that in general there actually is
a better estimator, by the long-run sampling theory criterion, than the maximum likelihoodestimator. As we have just seen, Gauss proved that the condition
(maximum likelihood estimator) =(arithmetic mean of the observations) (7.24)
uniquely determines the Gaussian sampling distribution. Therefore, if our sampling distri-
bution is not Gaussian, these two estimators are different. Then, which is better?
Almost all sampling distributions used are of the ‘independent, identically distributed’
(iid) form:
p(x
1···xn|µI)=n/productdisplay
i=1f(xi−µ). (7.25)
Bayesian analysis has the theoretical principles needed to determine the optimal estimate
for each data set whatever the sampling distribution; it will lead us to make the posteriormean estimate as the one that minimizes the expected square of the error, the posteriormedian as the one that minimizes the absolute error, etc. If the sampling distribution isnot Gaussian, the estimator proves typically to be a linear combination of the observations(µ)
est=/summationtextwiyi,b u t with variable weighting coefﬁcients widepending on the data conﬁg-
uration (yi−yj), 1≤i,j≤n. Thus the estimate is, in general, a nonlinear function of the
observations.12
In contrast, consider a typical real problem from the orthodox viewpoint which has no
prior probabilities or loss functions. We are trying to estimate a location parameter µ, and our
data Dconsist of nobservations: D={y1,..., yn}. But they have errors that vary in a way
that is uncontrolled by the experimenter and unpredictable from his state of knowledge.13
In the following we denote the unknown true value by µ0, and use µas a general running
variable. Then our model is
an individual case inference by its imagined long-run properties. But it is not only possible, but common as soon as we depart
from Gaussian sampling distributions, that an estimator which is proved to be as good as can be obtained, as judged by its
long-run success over all data sets, may nevertheless be very poor for our particular data set and should not be used for it. Then
the sampling distribution for any particular estimator (i.e. any particular function f(y1···yn) of the data) becomes irrelevant
because with different data sets we shall use different estimators . Thus, to suppose that a procedure that works satisfactorily with
Gaussian distributions should be used also with others, can lead one to be badly mistaken in more than one way. This introducesus to the phenomena of sufﬁciency and ancillarity, pointed out by R. A. Fisher in the 1930s and discussed in Chapter 8. But it
is now known that Bayes’ theorem automatically detects these situations and does the right thing here, choosing for each data
set the optimal estimator for that data set . In other words, the correct solution to the difﬁculties pointed out by Fisher is just to
return to the original Bayesian analysis of Laplace and Jeffreys, that Fisher thought to be wrong.
12The reader may ﬁnd it instructive to verify this in detail for the simple looking Cauchy sampling distribution
p(yi|µI)=1
π/bracketleftbigg1
1+(yi−µ)2/bracketrightbigg
(7.26)
for which the nonlinear functions are surprisingly complicated.
13This does not mean that they are ‘not determined by anything’ as is so often implied by those suffering from the mind projection
fallacy; it means only that they are not determined by any circumstances that the experimenter is controlling or observing.
Whether the determining factors could or could not be observed in principle is irrelevant to the present problem, which is to
reason as best we can in the state of knowledge that we have speciﬁed.

<<<PAGE 245>>>

7 The central, Gaussian or normal distribution 213
yi=µ0+ei, (1≤i≤n), (7.27)
where eiis the actual error in the ith measurement. Now, if we assign an independent
Gaussian sampling distribution for the errors ei=yi−µ0:
p(D|µ0σI)=/parenleftbigg1
2πσ2/parenrightbiggn/2
exp/braceleftbigg
−/summationtext(yi−µ0)2
2σ2/bracerightbigg
, (7.28)
we have
n/summationdisplay
i=1(yi−µ0)2=n[(µ0−y)2+s2], (7.29)
where
y≡1
n/summationdisplay
yi=µ0+e, s2≡y2−y2=e2−e2(7.30)
are the only properties of the data that appear in the likelihood function. Thus the conse-
quence of assigning the Gaussian error distribution is that only the ﬁrst two moments of
the data are going to be used for inferences about µ0(and about σ, if it is unknown). They
are called the sufﬁcient statistics . From (7.30) it follows that only the ﬁrst two moments of
the noise values{e1,..., en},
e=1
n/summationdisplay
iei, e2=1
n/summationdisplay
ie2
i, (7.31)
can matter for the error in our estimate. We have, in a sense, the simplest possible connection
between the errors in our data and the error in our estimate.
If we estimate µby the arithmetic mean of the observations, the actual error we shall
make in the estimate is the average of the individual errors in our speciﬁc data set:14
/Delta1≡y−µ0=e. (7.32)
Note that eis not an average over any probability distribution; it is the average of the
actual errors, and this result holds however the actual errors eiare distributed. For example,
whether a histogram of the eiclosely resembles the assigned Gaussian (7.28) or whether
all of the error happens to be in e1does not matter in the least; (7.32) remains correct.
7.9 Error cancellation
An important reason for the success of the Gaussian sampling distribution lies in its relation
to the aforementioned error cancellation phenomenon. Suppose we estimate µby some
linear combination of the data values:
(µ)est=n/summationdisplay
i=1wiyi, (7.33)
14Of course, probability theory tells us that this is the best estimate we can make if, as supposed, the only information we have
aboutµcomes from this one data set. If we have other information (previous data sets, other prior information) we should take
it into account; but then we are considering a different problem.

<<<PAGE 246>>>

214 Part I Principles and elementary applications
where the weighting coefﬁcients wiare real numbers satisfying/summationtextwi=1,wi≥0, 1≤
i≤n. Then with the model (7.27), the square of the error we shall make in our estimate is
/Delta12=[(µ)est−µ0]2=/parenleftBigg/summationdisplay
iwiei/parenrightBigg2
=n/summationdisplay
i,j=1wiwjeiej, (7.34)
and the expectation of this over whatever sampling distribution we have assigned is
/angbracketleft/Delta12/angbracketright=/summationdisplay
i,jwiwj/angbracketlefteiej/angbracketright. (7.35)
But if we have assigned identical and independent probabilities to each eiseparately, as is
almost always supposed, then /angbracketlefteiej/angbracketright=σ2δij, and so
/angbracketleft/Delta12/angbracketright=σ2/summationdisplay
iw2
i. (7.36)
Now set wi=n−1+qi, where the{qi}are real numbers constrained only by/summationtextwi=1, or/summationtextqi=0. The expected square of the error is then
/angbracketleft/Delta12/angbracketright=σ2/summationdisplay
i/parenleftbigg1
n2+2qi
n+q2
i/parenrightbigg
=σ2/parenleftBigg
1
n+/summationdisplay
iq2
i/parenrightBigg
, (7.37)
from which it is evident that /angbracketleft/Delta12/angbracketrightreaches its absolute minimum
/angbracketleft/Delta12/angbracketrightmin=σ2
n(7.38)
if and only if all qi=0. We have the result that uniform weighting, wi=1/n, leading to
the arithmetic mean of the observations as our estimate, achieves a smaller expected squareof the error than any other; in other words, it affords the maximum possible opportunity forthat error cancellation to take place. Note that the result is independent of what samplingdistribution p(e
i|I) we use for the individual errors. But highly cogent prior information
aboutµ(that is, the prior density p(µ|I) varies greatly within the high likelihood region)
would lead us to modify this somewhat.
If we have no important prior information, use of the Gaussian sampling distribution
automatically leads us to estimate µby the arithmetic mean of the observations; and Gauss
proved that the Gaussian distribution is the only one which does this. Therefore, amongall sampling distributions which estimate µby the arithmetic mean of the observations,
the Gaussian distribution is uniquely determined as the one that gives maximum errorcancellation.
This ﬁnally makes it very clear why the Gaussian sampling distribution has enjoyed that
ubiquitous success over the years compared with others, fulﬁlling de Morgan’s prediction:
When we assign an independent Gaussian sampling distribution to additive noise, what we achieve is
not that the error frequencies are correctly represented, but that those frequencies are made irrelevantto the inference, in two respects. (1) All other aspects of the noise beyond
eande2contribute nothing
to the numerical value or the accuracy of our estimates. (2) Our estimate is more accurate than that

<<<PAGE 247>>>

7 The central, Gaussian or normal distribution 215
from any other sampling distribution that estimates a location parameter by a linear combination of
the observations, because it has the maximum possible error cancellation.
Exercise 7.4. More generally, one could contemplate a sampling distribution
p(e1,..., en|I) which assigns different marginal distributions p(ei|I) to the different
ei, and allows arbitrary correlations between different ei. Then the covariance matrix
Cij≡/angbracketlefteiej/angbracketrightis a general n×npositive deﬁnite matrix. In this case, prove that the
minimum/angbracketleft/Delta12/angbracketrightis achieved by the weighting coefﬁcients
wi=/summationdisplay
jKij//summationdisplay
ijKij, (7.39)
where K=C−1is the inverse covariance matrix; and that the minimum achievable
/angbracketleft/Delta12/angbracketrightis then
/angbracketleft/Delta12/angbracketrightmin=/parenleftBigg/summationdisplay
ijKij/parenrightBigg−1
. (7.40)
In the case Cij=σ2δij, this reduces to the previous result (7.38).
In view o f the discovery of de Groot and Goel (1980) that ‘Only normal distributions
have linear posterior expectations’, it may be that we are discussing an empty case. Weneed the solution to another mathematical problem: ‘What is the most general samplingdistribution that estimates a location parameter by a linear function of the observations? ’
The work of de Groot and Goel suggests, but in our view does not prove, that the answeris again a Gaussian distribution. Note that we are considering two different problems here,(7.38) is the ‘risk’, or expected, square of the error over the sampling distribution; whilede Groot and Goel were considering expectations over the posterior distribution.
7.10 The near irrelevance of sampling frequency distributions
Another way of looking at this is helpful. As we have seen before, in a repetitive situation the
probability of any event is usually the same as its expected frequency (using, of course, thesame basic probability distribution for both). Then, given a sampling distribution f(y|θ), it
tells us that/integraltext
Rdyf(y|θ) is the expected frequency, before the data are known of the event
y∈R.
But if, as always supposed in elementary parameter estimation, the parameters are held
ﬁxed throughout the taking of a data set, then the variability of the data is also, necessarily ,
the variability of the actual errors in that data set. If we have deﬁned our model to havethe form y
i=f(xi)+ei, in which the noise is additive, then the exact distribution of the
errors is known from the data to within a uniform translation: ei−ej=yi−yj. We know
from the data ythat the exact error in the ith observation has the form ei=yi−e0, where

<<<PAGE 248>>>

216 Part I Principles and elementary applications
e0is an unknown constant. Whether the frequency distribution of the errors does or does
not have the Gaussian functional form is known from the data . Then what use remains for
the sampling distribution, which in orthodox theory yields only the prior expectations ofthe error frequencies? Whatever form of frequency distribution we might have expectedbefore seeing the data, is rendered irrelevant by the information in the data! What remainssigniﬁcant for inference is the likelihood function – how the probability of the observeddata set varies with the parameters θ.
Although all these results are mathematically trivial, we stress their nontrivial conse-
quences by repeating them in different words. A Gaussian distribution has a far deeperconnection with the arithmetic mean than that shown by Gauss. If we assign the indepen-dent Gaussian error distribution, then the error in our estimate is always the arithmetic meanof the true errors in our data set; and whether the frequency distribution of those errors isor is not Gaussian is totally irrelevant. Any error vector {e
1,..., en}with the same ﬁrst
moment ewill lead us to the same estimate of µ; and any error vector with the same ﬁrst
two moments will lead us to the same estimates of both µandσand the same accuracy
claims, whatever the frequency distributions of the individual errors . This is a large part of
the answer to de Morgan, Feller, and Barnard.
This makes it clear that what matters to us functionally – that is, what determines the
actual error of our estimate – is not whether the Gaussian error law correctly describesthe limiting frequency distribution of the errors; but rather whether that error law correctlydescribes our prior information about the actual errors in our data set. If it does, then the
above calculations are the best we can do with the information we have; and there is nothingmore to be said.
The only case where we should – or indeed, could – do anything different is when we have
additional prior information about the errors beyond their ﬁrst two moments. For example,if we know that they are simple digitizing errors with digitizing interval δ, then we know that
there is a rigid upper bound to the magnitude of any error: |e
i|≤δ/2. Then if δ<σ , use of
the appropriate truncated sampling distribution instead of the Gaussian (7.28) will almostsurely lead to more accurate estimates of µ. This kind of prior information can be very
helpful (although it complicates the analytical solution, this is no deterrent to a computer),and we consider a problem of this type in Section 7.17.
Closer to the present issue, in what sense and under what conditions does the Gaussian
error law ‘correctly describe’ our information about the errors?
7.11 The remarkable efﬁciency of information transfer
Again, we anticipate a few results from later chapters in order to obtain a quick, pre-
liminary view of what is happening, which will improve our judgment in setting upreal problems. The noise probability distribution p(e|αβ) which has maximum entropy
H=−/integraltext
dep(e) log p(e) subject to the constraints of prescribed expectations
/angbracketlefte/angbracketright=α,/angbracketlefte
2/angbracketright=α2+β2, (7.41)

<<<PAGE 249>>>

7 The central, Gaussian or normal distribution 217
in which the brackets /angbracketleft/angbracketrightnow denote averages over the probability distribution p(e|αβ), is
the Gaussian
p(e|αβ)=1/radicalbig
2πβ2exp/braceleftbigg
−(e−α)2
2β2/bracerightbigg
. (7.42)
So a state of prior information which leads us to prescribe the expected ﬁrst and second
moments of the noise – and nothing else – uniquely determines the Gaussian distribution.Then it is eminently satisfactory that this leads to inferences that depend on the noise onlythrough the ﬁrst and second moments of the actual errors. When we assign error probabilitiesby the principle of maximum entropy, the only properties of the errors that are used in our
Bayesian inference are the properties about which we speciﬁed some prior information .
This is a very important second part of that answer.
In this example, we have stumbled for the ﬁrst time onto a fundamental feature of prob-
ability theory as logic: if we assign probabilities to represent our information, then circum-
stances about which we have no information, are not used in our subsequent inferences. But
it is not only true of this example; we shall ﬁnd when we study maximum entropy that itis a general theorem that any sampling distribution assigned by maximum entropy leads toBayesian inferences that depend only on the information that we incorporated as constraintsin the entropy maximization.
15
Put differently, our rules for extended logic automatically use all the information that we
have, and avoid assuming information that we do not have. Indeed, our Chapter 1 desiderata
require this. In spite of its extremely simple formal structure in the product and sum rules,
probability theory as logic has a remarkable sophistication in applications. It perceivesinstantly what generations of statisticians and probabilists failed to see; for a probabilitycalculation to have a useful and reliable function in the real world, it is by no means requiredthat the probabilities have any relation to frequencies.
16
Once this is pointed out, it seems obvious that circumstances about which we have no
information cannot be of any use to us in inference. Rules for inference which fail to
recognize this and try to introduce such quantities as error frequencies into the calculationasad hoc assumptions, even when we have no information about them, are claiming, in
effect, to get something for nothing (in fact, they are injecting arbitrary – and thereforealmost certainly false – information). Such devices may be usable in some small class ofproblems; but they are guaranteed to yield wrong and/or misleading conclusions if appliedoutside that class.
On the other hand, probability theory as logic is always safe and conservative, in the
following sense: it always spreads the probability out over the full range of conditions
15Technically (Chapter 8), the class of sampling distributions which have sufﬁcient statistics is precisely the class generated by the
maximum entropy principle; and the resulting sufﬁcient statistics are precisely the constraints which determined that maximumentropy distribution.
16This is not to say that probabilities are forbidden to have any relation to frequencies; the point is rather that whether they do
or do not depends on the problem, and probability theory as logic works equally well in either case. We shall see, in the work
of Galton below, an example where a clear frequency connection is present, and analysis of the general conditions for this will
appear in Chapter 9.

<<<PAGE 250>>>

218 Part I Principles and elementary applications
allowed by the information used; our basic desiderata require this. Thus it always yields the
conclusions that are justiﬁed by the information which was put into it . The robot can return
vague estimates if we give it vague or incomplete information; but then it warns us of that
fact by returning posterior distributions so wide that they still include the true value of theparameter . It cannot actually mislead us – in the sense of assigning a high probability to a
false conclusion – unless we have given it false information.
For example, if we assign a sampling distribution which supposes the errors to be far
smaller than the actual errors, then we have put false information into the problem, and theconsequence will be, not necessarily bad estimates of parameters, but false claims about theaccuracy of those estimates and – often more serious – the robot can hallucinate, artifactsof the noise being misinterpreted as real effects. As de Morgan (1872, p. 113) put it, thisis the error of ‘attributing to the motion of the moon in her orbit all the tremors which shegets from a shaky telescope’.
Conversely, if we use a sampling distribution which supposes the errors to be much larger
than the actual errors, the result is not necessarily bad estimates, but overly conservative
accuracy claims for them and – often more serious – blunt perception, failing to recognize
effects that are real, by dismissing them as part of the noise. This would be the oppositeerror of attributing to a shaky telescope the real and highly important deviation of the moonfrom her expected orbit. If we use a sampling distribution that reﬂects the true averageerrors and the true mean square errors, we have the maximum protection against both ofthese extremes of misperception, steering the safest possible middle course between them.These properties are demonstrated in detail later.
7.12 Other sampling distributions
Once we understand the reasons for the success of Gaussian inference, we can also see
very rare special circumstances where a different sampling distribution would better ex-press our state of knowledge. For example, if we know that the errors are being generatedby the unavoidable and uncontrollable rotation of some small object, in such a way thatwhen it is at angle θ, the error is e=αcosθbut the actual angle is unknown, a little
analysis shows that the prior probability assignment p(e|I)=(π√
α2−e2)−1,e2<α2,
correctly describes our state of knowledge about the error. Therefore it should be usedinstead of the Gaussian distribution; since it has a sharp upper bound, it may yield ap-preciably better estimates than would the Gaussian – even if αis unknown and must
therefore be estimated from the data (or perhaps it is the parameter of interest to beestimated).
Or, if the error is known to have the form e=αtanθbutθis unknown, we ﬁnd that the
prior probability is the Cauchy distribution p(e|I)=π
−1α/(α2+e2). Although this case
is rare, we shall ﬁnd it an instructive exercise to analyze inference with a Cauchy samplingdistribution, because qualitatively different things can happen. Orthodoxy regards this as ‘apathological, exceptional case’ as one referee put it, but it causes no difﬁculty in Bayesiananalysis, which enables us to understand it.

<<<PAGE 251>>>

7 The central, Gaussian or normal distribution 219
7.13 Nuisance parameters as safety devices
As an example of this principle, if we do not have actual knowledge about the magnitude σ
of our errors, then it could be dangerous folly to assume some arbitrary value; the wisestand safest procedure is to adopt a model which honestly acknowledges our ignorance byallowing for various possible values of σ; we should assign a prior p(σ|I) which indicates
the range of values that σmight reasonably have, consistent with our prior information.
Then in the Bayesian analysis we shall ﬁnd ﬁrst the joint posterior pdf for both parameters:
p(µσ|DI)=p(µσ|I)p(D|µσI)
p(D|I). (7.43)
But now notice how the product rule rearranges this:
p(µσ|DI)=p(σ|I)p(µ|σI)p(D|σI)p(µ|σDI)
p(D|I)p(µ|σI)=p(µ|σDI)p(σ|DI). (7.44)
So, if we now integrate out σas a nuisance parameter, we obtain the marginal posterior pdf
forµalone in the form:
p(µ|DI)=/integraldisplay
dσp(µ|σDI)p(σ|DI), (7.45)
a weighted average of the pdfs p(µ|σDI) for all possible values of σ, weighted according
to the marginal posterior pdf p(σ|DI) forσ, which represents everything we know about σ.
Thus when we integrate out a nuisance parameter, we are not throwing away any infor-
mation relevant to the parameters we keep; on the contrary, probability theory automatically
estimates the nuisance parameter for us from all the available evidence, and takes that infor-
mation fully into account in the marginal posterior pdf for the interesting parameters (butit does this in such a slick, efﬁcient way that one may not realize that this is happening,and think that he is losing something). In the limit where the data are able to determine thetrue value σ=σ
0very accurately, p(σ|DI)→δ(σ−σ0) and p(µ|DI)→p(µ|σ0DI);
the theory yields, as it should, the same conclusions that we would have if the true valuewere known from the start.
This is just one example illustrating that, as noted above, whatever question we ask,
probability theory as logic automatically takes into account all the possibilities allowed
by our model and our information. Then, of course, the onus is on us to choose a model
wisely so that the robot is given the freedom to estimate for itself, from the totality of its
information, any parameter that we do not know. If we fail to recognize the existence of
a parameter which is uninteresting but nevertheless affects our data – and so leave it outof the model – then the robot is crippled and cannot return the optimal inferences to us.The marginalization paradox, discussed in Chapter 15, and the data pooling paradox ofChapter 8, exhibit some of the things that can happen then; the robot’s conclusions are stillthe best ones that could have been made from the information we gave it , but they are not
the ones that simple common sense would make, using extra information that we failed togive it.

<<<PAGE 252>>>

220 Part I Principles and elementary applications
In practice, we ﬁnd that recognition of a relevant, but unknown and uninteresting, param-
eter by including it in the model and then integrating it out again as a nuisance parameter,can greatly improve our ability to extract the information we want from our data – often byorders of magnitude. By this means we are forewarning the robot about a possible disturbingcomplication, putting it on the lookout for it; and the rules of probability theory then leadthe robot to make the optimal allowance for it.
This point is extremely important in some current problems of estimating environmental
hazards or the safety of new machines, drugs or food additives, where inattention to all of therelevant prior information that scientists have about the phenomenon – and therefore failureto include that information in the model and prior probabilities – can cause the danger to begrossly overestimated or underestimated. For example, from knowledge of the engineeringdesign of a machine, one knows a great deal about its possible failure modes and theirconsequences, that could not be obtained from any feasible amount of reliability testing by‘random experiments’. Likewise, from knowledge of the chemical nature of a food additive,one knows a great deal about its physiological effects that could not be obtained from any
feasible amount of mere toxicity tests.
Of course, this is not to say that reliability tests and toxicity tests should not be carried
out; the point is rather that random experiments are very inefﬁcient ways of obtaininginformation (we learn, so to speak, only like the square root of the number of trials), andrational conclusions cannot be drawn from them unless the equally cogent – often farmore cogent – prior information is also taken into account. We saw some examples of thisphenomenon in Chapter 6, (6.123)–(6.144). The real function of the random experimentis to guard against completely unexpected bad effects, about which our prior information
gave us no warning.
7.14 More general properties
Although the Gauss derivation was of the greatest historical importance, it does not satisfy us
today because it depends on intuition; whymust the ‘best’ estimate of a location parameter
be a linear function of the observations? Evidently, in view of the Gauss derivation, if ourassigned sampling distribution is not Gaussian, the best estimate of the location parameterwillnotbe the sample mean. It could have a wide variety of other functional forms; then,
under what circumstances, is Laplace’s prescription the one to use?
We have just seen the cogent pragmatic advantages of using a Gaussian sampling distribu-
tion. Today, anticipating a little from later chapters, we would say that its unique theoreticalposition derives not from the Gauss argument, but rather from four mathematical stabilityproperties, which have fundamentally nothing to do with probability theory or inference,and a ﬁfth, which has everything to do with them, but was not discovered until the mid-20thcentury:
(A) Any smooth function with a single rounded maximum, if raised to higher and higher powers,
goes into a Gaussian function. We saw this in Chapter 6.
(B) The product of two Gaussian functions is another Gaussian function.

<<<PAGE 253>>>

7 The central, Gaussian or normal distribution 221
(C) The convolution of two Gaussian functions is another Gaussian function.
(D) The Fourier transform of a Gaussian function is another Gaussian function.
(E) A Gaussian probability distribution has higher entropy than any other with the same variance;
therefore any operation on a probability distribution which discards information, but conserves
variance, leads us inexorably closer to a Gaussian. The central limit theorem, derived below, is
the best known example of this, in which the operation being performed is convolution.
Properties (A) and (E) explain why a Gaussian form is approached more and more closely
by various operations; properties (B), (C) and (D) explain why that form, once attained, ispreserved.
7.15 Convolution of Gaussians
The convolution property (C) is shown as follows. Expanding now the notation
17of (7.1)
ϕ(x−µ|σ)≡1
σϕ/parenleftbiggx−µ
σ/parenrightbigg
=/radicalbigg
1
2πσ2exp/braceleftbigg
−(x−µ)2
2σ2/bracerightbigg
=/radicalbiggw
2πexp/braceleftBig
−w
2(x−µ)2/bracerightBig
(7.46)
in which we introduce the ‘weight’ w≡1/σ2for convenience, the product of two such
functions is
ϕ(x−µ1|σ1)ϕ(y−x−µ2|σ2)=1
2πσ1σ2exp/braceleftBigg
−1
2/bracketleftBigg/parenleftbiggx−µ1
σ1/parenrightbigg2
+/parenleftbiggy−x−µ2
σ2/parenrightbigg2/bracketrightBigg/bracerightBigg
;
(7.47)
but we bring out the dependence on xby rearranging the quadratic form:
/parenleftbiggx−µ1
σ1/parenrightbigg2
+/parenleftbiggy−x−µ2
σ2/parenrightbigg2
=(w1+w2)(x−ˆx)2+w1w2
w1+w2(y−µ1−µ2)2,
(7.48)
where ˆx≡(w1µ1+w2y−w2µ2)/(w1+w2). The product is still a Gaussian with respect
tox; on integrating out xwe have the convolution law:
/integraldisplay∞
−∞dxϕ(x−µ1|σ1)ϕ(y−x−µ2|σ2)=ϕ(y−µ|σ), (7.49)
where µ≡µ1+µ2,σ2≡σ2
1+σ2
2. Two Gaussians convolve to make another Gaussian,
the means µand variances σ2being additive. Presently we shall see some important appli-
cations that require only the single convolution formula (7.49). Now we turn to the famoustheorem, which results from repeated convolutions.
17This notation is not quite inconsistent, since ϕ( ) and ϕ(|) are different functional symbols.

<<<PAGE 254>>>

222 Part I Principles and elementary applications
7.16 The central limit theorem
The question whether non-Gaussian distributions also have parameters additive under con-
volution leads us to the notion of cumulants discussed in Appendix C. The reader who has
not yet studied this should do so now.
Editor’s Exercise 7.5. Jaynes never actually derived the central limit theorem in this
section; rather he is deriving the only known exception to the central limit theorem. InAppendix C he comes close to deriving the central limit theorem. Deﬁning
φ(α)=/integraldisplay
∞
−∞f(x)e x p{iαx}, (7.50)
and a repeated convolution gives
hn(y)=f∗f∗f∗···∗ f=1
2π/integraldisplay∞
−∞dyφ(y)nexp{−iαy}, (7.51)
[φ(α)]n=exp/braceleftbigg
n/parenleftbigg
C0+αC1−α2C2
2+···/parenrightbigg/bracerightbigg
, (7.52)
where the cumulants, Cn, are deﬁned in Appendix C. If cumulants higher than C2are
ignored, one obtains
hn(y)≈1
2π/integraldisplay∞
−∞dαexp/braceleftbigg
inα/angbracketleftx/angbracketright−nσ2α2
2−iαy/bracerightbigg
,
=1
2π/integraldisplay∞
−∞dαexp/braceleftbigg
−nσ2α2
2/bracerightbigg
exp{−iα(n/angbracketleftx/angbracketright−y)}, (7.53)
=1√
2πnσ2exp/braceleftbigg
−(y−n/angbracketleftx/angbracketrightx)2
2nσ2/bracerightbigg
,
and this completes the derivation of the central limit theory. What are the conditions un-
der which this is a good approximation? Is this derivation valid when one is computingthe ratios of probabilities?
If the functions fi(x) to which we apply that theory are probability distributions, then they
are necessarily non-negative and normalized: fi(x)≥0,/integraltext
dxfi(x)=1. Then the zeroth
moments are all Zi=1, and the Fourier transforms
Fi(α)≡/integraldisplay∞
−∞dxfi(x)e x p{iαx} (7.54)

<<<PAGE 255>>>

7 The central, Gaussian or normal distribution 223
are absolutely convergent for real α. Note that all this remains true if the fiare discontinuous,
or contain delta-functions; therefore the following derivation will apply equally well to thecontinuous or discrete case or any mixture of them.
18
Consider two variables to which are assigned probability distributions conditional on
some information I:
f1(x1)=p(x1|I), f2(x2)=p(x2|I). (7.55)
We want the probability distribution f(y) for the sum y=x1+x2. Evidently, the cumulative
probability density for yis
P(y/prime≤y|I)=/integraldisplay∞
−∞dx1f1(x1)/integraldisplayy−x1
−∞dx2f2(x2), (7.56)
where we integrated over the region Rdeﬁned by ( x1+x2≤y). Then the probability
density for yis
f(y)=/bracketleftbiggd
dyP(y/prime≤y|I)/bracketrightbigg
y=y/prime=/integraldisplay
dx1f1(x1)f2(y−x1), (7.57)
just the convolution, denoted by f(y)=f1∗f2in Appendix C. Then the probability density
for the variable z=y+x3is
g(z)=/integraldisplay
dyf(y)f3(z−y)=f1∗f2∗f3 (7.58)
and so on by induction: the probability density for the sum y=x1+···+ xnofnvariables
is the multiple convolution hn(y)=f1∗···∗ fn.
In Appendix C we found that convolution in the xspace corresponds to simple multipli-
cation in the Fourier transform space: introducing the characteristic function forfk(x)
ϕk(α)≡/angbracketleftexp{iαx}/angbracketright=/integraldisplay∞
−∞dxfk(x)e x p{iαx} (7.59)
and the inverse Fourier transform
fk(x)=1
2π/integraldisplay∞
−∞dαϕ k(α)e x p{−iαx}, (7.60)
we ﬁnd that the probability density for the sum of nvariables xiis
hn(q)=1
2π/integraldisplay
dαϕ 1(α)···ϕn(α)e x p{−iαq}, (7.61)
or, if the probability distributions fi(x) are all the same,
hn(q)=1
2π/integraldisplay
dα[ϕ(α)]nexp{−iαq}. (7.62)
18At this point, the reader who has been taught to distrust or disbelieve in delta-functions must unlearn that by reading Appendix B
on the concept of a ‘function’. This is explained also by Lighthill (1957) and Dyson (1958). Without the free use of delta-
functions and other generalized functions, real applications of Fourier analysis are in an almost helpless, crippled conditioncompared with what can be done by using them.

<<<PAGE 256>>>

224 Part I Principles and elementary applications
The probability density for the arithmetic mean ¯x=q/nis evidently, from (7.62),
p(¯x)=nhn(n¯x)=n
2π/integraldisplay
dα[ϕ(α)e x p{−iα¯x}]n. (7.63)
It is easy to prove that there is only one probability distribution with this property. If the
probability distribution p(x|I) for a single observation xhas the characteristic function
ϕ(α)=/integraldisplay
dxp(x|I)e x p{iαx}, (7.64)
then the one for the average of nobservations, ¯x=n−1/summationtextxi, has a characteristic function
of the form ϕn(n−1α). The necessary and sufﬁcient condition that xand¯xhave the same
probability distribution is therefore that ϕ(α) satisfy the functional equation ϕn(n−1α)=
ϕ(α). Now, substituting α/prime=n−1α, and recognizing that one dummy argument is as good
as another, one obtains
nlogϕ(α)=logϕ(nα),−∞<α<∞, n=1,2,3,.... (7.65)
Evidently, this requires a linear relation on the positive real line:
logϕ(α)=Cα, 0≤α<∞, (7.66)
where Cis some complex number. Writing C=−k+iθ, the most general solution satis-
fying the reality condition ϕ(−α)=ϕ∗(α)i s
ϕ(α)=exp{iαθ−k|α|},−∞<θ<∞, 0<k<∞, (7.67)
which yields
p(x|I)=1
2π/integraldisplay∞
−∞dαexp{−k|α|}exp{iα(θ−x)}=1
π/bracketleftbiggk
k2+(x−θ)2/bracketrightbigg
, (7.68)
the Cauchy distribution with median θ, quartiles θ±k. Now we turn to some important
applications of the above mathematical results.
7.17 Accuracy of computations
As a useful application of the central limit theorem, consider a computer programmer
deciding on the accuracy to be used in a program. This is always a matter of compromisebetween misleading, inaccurate results on the one hand, and wasting computation facilitieswith more accuracy than needed on the other.
Of course, it is better to err on the side of a little more accuracy than really needed. Never-
theless, it is foolish (and very common) to tie up a large facility with a huge computation todouble precision (16 decimal places) or even higher, when the user has no use for anythinglike that accuracy in the ﬁnal result. The computation might have been done in less time butwith the same result on a desktop microcomputer, had it been programmed for an accuracythat is reasonable for the problem.

<<<PAGE 257>>>

7 The central, Gaussian or normal distribution 225
Programmers can speed up and simplify their creations by heeding what the central limit
theorem tells us. In probability calculations we seldom have any serious need for more thanthree-ﬁgure accuracy in our ﬁnal results, so we shall be well on the safe side if we strive toget four-ﬁgure accuracy reliably in our computations.
As a simple example, suppose we are computing the sum
S≡
N/summationdisplay
n=1an (7.69)
ofNterms an, each one positive and of order unity. To achieve a given accuracy in the sum,
what accuracy do we need in the indi vidual terms?
Our computation program or lookup table necessarily gives each andigitized to some
smallest increment /epsilon1,so this will be actually the true value plus some error en.I fw e
have anto six decimal digits, then /epsilon1=10−6; if we have it to 16 binary digits, then
/epsilon1=2−16=1/65 536. The error in any one entry is in the range ( −/epsilon1/2<en≤/epsilon1/2), and
in adding Nsuch terms the maximum possible error is N/epsilon1/2. Then it might be thought that
the programmer should ensure that this is acceptably small.
But if Nis large, this maximum error is enormously unlikely; this is just the point that
Euler failed to see. The individual errors are almost certain to be positive and negativeroughly equally often, giving a high degree of mutual cancellation, so that the net error
should tend to grow only as√
N.
The central limit theorem tells us what is essentially a simple combinatorial fact, that
out of all conceivable error vectors {e1,..., eN}that could be generated, the overwhelming
majority have about the same degree of cancellation, which is the reason for the√
Nrule.
If we consider each individual error equally likely to be anywhere in ( −/epsilon1/2,/epsilon1/2), this
corresponds to a rectangular probability distribution on that interval, leading to an expectedsquare error per datum of
1
/epsilon1/integraldisplay/epsilon1/2
−/epsilon1/2dxx2=/epsilon12
12. (7.70)
Then by the central limit theorem the probability distribution for the sum Swill tend to a
Gaussian with a variance N/epsilon12/12, while Sis approximately N.I fNis large so that the
central limit theorem is accurate, then the probability that the magnitude of the net error
will exceed /epsilon1√
N,which is√
12=3.46standard deviations, is about
2[1−/Phi1(3.46)]/similarequal0.0006, (7.71)
where /Phi1(x) is the cumulative normal distribution. One will almost never observe an error
that great. Since /Phi1(2.58)=0.995, there is about a 1% chance that the net error magnitude
will exceed 0 .74/epsilon1√
N=2.58 standard deviations.
Therefore if we strive, not for certainty, but for 99% or greater probability, that our sum S
is correct to four ﬁgures, this indicates the value of /epsilon1that can be tolerated in our algorithm

<<<PAGE 258>>>

226 Part I Principles and elementary applications
or lookup table. We require 0 .74/epsilon1√
N≤10−4N,o r
/epsilon1≤1.35×10−4√
N. (7.72)
The perhaps surprising result is that if we are adding N=100 roughly equal terms, to
achieve a virtual certainty of four-ﬁgure accuracy in the sum we require only three-ﬁgureaccuracy in the individual terms! Under favorable conditions, the mutual cancellation phe-nomenon can be effective far beyond Euler’s dreams. Thus we can get by with a consider-ably shorter computation for the individual terms, or a smaller lookup table, than might besupposed.
This simple calculation can be greatly generalized, as indicated by Exercise 7.5. But
we note an important proviso to be investigated in Exercise 7.6; this holds only when theindividual errors e
nare logically independent. Given /epsilon1in advance, if knowing e1then tells
us anything about any other en, then there are correlations in our probability assignment
to errors, the central limit theorem no longer applies, and a different analysis is required.Fortunately, this is almost never a serious limitation in practice because the individual
a
nare determined by some continuously variable algorithm and differ among themselves
by amounts large compared with /epsilon1, making it impossible to determine any eigiven any
other ej.
Exercise 7.6. Suppose that we are to evaluate a Fourier series S(θ)=/summationtextansinnθ.
Now the individual terms vary in magnitude and are themselves both positive andnegative. In order to achieve four-ﬁgure accuracy in S(θ) with high probability, what
accuracy do we now require in the individual values of a
nand sin nθ?
Exercise 7.7. Show that if there is a positive correlation in the probabilities assigned
to the ei, then the error in the sum may be much greater than indicated by the central
limit theorem. Try to make a more sophisticated probability analysis taking correlationsinto account, which would be helpful to a computer programmer who has some kind ofinformation about mutual properties of errors leading to such correlations, but is stillstriving for the greatest efﬁciency for a given accuracy.
The literature of orthodox statistics contains some quite different recommendations than
ours concerning accuracy of numerical calculations. For example, the textbook of McClaveand Benson (1988, p. 99) considers calculation of a sample standard deviation sofn=
50 observations{x
1,..., xn}from that of s2=x2−x2. McClave and Benson state that:
‘You should retain twice as many decimal places in s2as you want in s. For example, if

<<<PAGE 259>>>

7 The central, Gaussian or normal distribution 227
you want to calculate sto the nearest hundredth, you should calculate s2to the nearest
ten-thousandth.’ When we studied calculus (admittedly many years ago) it was generallythought that small increments are related by δ(s
2)=2sδs,o rδs/s=(1/2)δ(s2)/s2. So, if
s2is calculated to four signiﬁcant ﬁgures, this determines snot to two signiﬁcant ﬁgures,
but to somewhat better than four. But, in any event, McClave and Benson’s practice ofinserting a gratuitous extra factor n/(n−1) in the symbol which they denote by ‘ s
2’ makes
a joke of any pretense of four-ﬁgure accuracy in either when n=100.
7.18 Galton’s discovery
The single convolution formula (7.49) led to one of the most important applications of
probability theory in biology. Although from our present standpoint (7.49) is only a straight-forward integration formula, which we may write for present purposes in the form
/integraldisplay
∞
−∞dxϕ(x|σ1)ϕ(y−ax|σ2)=ϕ(y|σ), (7.73)
where we have made the scale changes x→ax,σ1→aσ1, and so now
σ=/radicalBig
a2σ2
1+σ2
2, (7.74)
it became in the hands of Francis Galton (1886) a major revelation about the mechanism of
biological variation and stability.19We use the conventional language of that time, which
did not distinguish between the notions of probability and frequency, using the wordsinterchangeably. But this is not a serious matter because his data were, in fact, frequencies,and, as we shall see in Chapter 9, strict application of probability theory as logic would thenlead to probability distributions that are substantially equal to the frequency distributions
(exactly equal in the limit where we have an arbitrarily large amount of frequency dataand no other relevant prior information). Consider, for example, the frequency distributionof heights hof adult males in the population of England. Galton found that this could be
represented fairly well by a Gaussian
ϕ(h−µ|σ)dh=ϕ/parenleftbiggh−µ
σ/parenrightbiggdh
σ(7.75)
withµ=68.1 inches, σ=2.6 inches. Then he investigated whether children of tall parents
tend to be tall, etc. To keep the number of variables equal to two, in spite of the fact thateach person has two parents, he determined that the average height of men was about 1.08times that of women, and deﬁned a person’s ‘midparent’ as an imaginary being of height
h
mid≡1
2(hfather+1.08hmother ). (7.76)
19A photograph of Galton, with more details of his work and a short biographical sketch, may be found in Stigler (1986c). His
autobiography (Galton, 1908) has additional details.

<<<PAGE 260>>>

228 Part I Principles and elementary applications
He collected data on 928 adults born of 205 midparents and found, as expected, that children
of tall parents do indeed tend to be tall, etc., but that children of tall parents still show aspread in heights, although less than the spread ( ±σ) of the entire population.
If the children of each selected group of parents still spread in height, why does the spread
in height of the entire population not increase continually from one generation to the next?Because of the phenomenon of ‘reversion’; the children of tall parents tend to be taller thanthe average person, but less tall than their parents. Likewise, children of short parents aregenerally shorter than the average person, but taller than their parents. If the population asa whole is to be stable, this ‘systematic’ tendency to revert back to the mean of the entirepopulation must exactly balance the ‘random’ tendency to spreading. Behind the smoothfacade of a constant overall distribution of heights, an intricate little time-dependent gameof selection, drift, and spreading is taking place constantly.
In fact, Galton (with some help from mathematicians) could predict the necessary rate
of reversion theoretically, and verify it from his data. If x≡(h−µ) is the deviation from
the mean height of the midparents, let the population as a whole have a height distribution
ϕ(x|σ
1), while the sub-population of midparents of height ( x+µ) tend to produce children
of height ( y+µ) with a frequency distribution ϕ[(y−ax)|σ2]. Then the height distribution
of the next generation will be given by (7.73). If the population as a whole is to be stable,it is necessary that σ=σ
1, or the reversion rate must be
a=±/radicalBigg
1−σ2
2
σ2
1, (7.77)
which shows that aneed not be positive; if tall parents tended to ‘compensate’ by producing
unusually short children, this would bring about an alternation from one generation to thenext, but there would still be equilibrium for the population as a whole.
We see that equilibrium is not possible if |a|>1; the population would explode. Al-
though (7.73) is true for all a, equilibrium would then require σ
2
2<0. The boundary of
stability is reached at σ2=0,|a|=1; then each sub-population breeds true, and what-
ever initial distribution of heights happened to exist would be maintained thereafter. Aneconomist might call the condition a=1 a ‘unit root’ situation; there is no reversion and no
spreading.
20
Of course, this analysis is in several obvious respects an oversimpliﬁed model of what
happens in actual human societies. But that involves only touching up of details; Galton’sanalysis was, historically, of the greatest importance in giving us a general understandingof the kind of processes at work. For this, its freedom from nonessential details was a majormerit.
20It is a currently popular theory among some economists that many economic processes, such as the stock market, are very
close to the unit root behavior, so that the effects of momentary external perturbations like wars and droughts tend to persist
instead of being corrected. There is no doubt that phenomena like this exist, at least in some cases; in the 1930s John Maynard
Keynes noted what he called ‘the stickiness of prices and wages’. For a discussion of this from a Bayesian viewpoint, see Sims(1988).

<<<PAGE 261>>>

7 The central, Gaussian or normal distribution 229
Exercise 7.8. Galton’s device of the midparent was only to reduce the computational
burden, which would otherwise have been prohibitive in the 1880s, by reducing theproblem to a two-variable one (midparent and children). But today computing poweris so plentiful and cheap that one can easily analyze the real four-variable problem, inwhich the heights of father, mother, son, and daughter are all taken into account. Refor-mulate Galton’s problem to take advantage of this; what hypotheses about spreading andreversion might be considered and tested today? As a class project, one might collectnew data (perhaps on faster-breeding creatures like fruit-ﬂies) and write the computerprogram to analyze them and estimate the new spreading and reversion coefﬁcients.Would you expect a similar program to apply to plants? Some have objected that thisproblem is too biological for a physics class, and too mathematical for a biology class;we suggest that, in a course dedicated to scientiﬁc inference in general, the class shouldinclude both physicists and biologists, working together.
Twenty years later this same phenomenon of selection, drift, and spreading underlying
equilibrium was perceived independently by Einstein (1905a,b) in physics. The steadythermal Boltzmann distribution for molecules at temperature Tto have energy Eis
exp{−E/kT}. Being exponential in energies E=u+(mv
2/2), where u(x) is potential
energy, this is Gaussian in particle velocities v. This generates a time-dependent drift in po-
sition; a particle which is at position xat time t=0 has at time tthe conditional probability
to be at yof
p(y|xt)∝exp/braceleftbigg
−(y−x)2
4Dt/bracerightbigg
(7.78)
from random drift alone, but this is countered by a steady drift effect of external forces
F=−∇ u, corresponding to Galton’s reversion rate.
Although the details are quite different, Galton’s equation (7.77) is the logical equivalent
of Einstein’s relation D=λkTconnecting diffusion coefﬁcient D, representing random
spreading of particles, with the temperature Tand the mobility λ(velocity per unit force)
representing the systematic reversion rate counteracting the diffusion. Both express thecondition for equilibrium as a balance between a ‘random spreading’ tendency, and asystematic counter-drift that holds it in check.
7.19 Population dynamics and Darwinian evolution
Galton’s type of analysis can explain much more than biological equilibrium. Suppose the
reversion rate does not satisfy (7.77). Then the height distribution in the population will notbe static, but will change slowly. Or, if short people tend to have fewer children than do tall

<<<PAGE 262>>>

230 Part I Principles and elementary applications
people, then the average height of the population will drift slowly upward.21Do we have
here the mechanism for Darwinian evolution? The question could hardly go unasked, sinceFrancis Galton was a cousin of Charles Darwin.
A new feature of probability theory has appeared here that is not evident in the works of
Laplace and Gauss. Being astronomers, their interests were in learning facts of astronomy,and telescopes were only a tool toward that end. The vagaries of telescopes themselveswere for them only ‘errors of observation’ whose effects were to be eliminated as much aspossible; and so the sampling distribution was called by them an ‘error law’.
But a telescope maker might see it differently. For him, the errors it produces are the
objects of interest to study, and a star is only a convenient ﬁxed object on which to focus hisinstrument for the purpose of determining those errors. Thus a given data set might servetwo entirely different purposes; one man’s ‘noise’ is another man’s ‘signal’.
But then, in any science, the ‘noise’ might prove to be not merely something to get
rid of, but the essential phenomenon of interest. It seems curious (at least, to a physicist)that this was ﬁrst seen clearly not in physics, but in biology. In the late 19th centurymany biologists saw it as the major task confronting them to conﬁrm Darwin’s theory byexhibiting the detailed mechanism by which evolution takes place. For this purpose, the
journal Biometrika was founded by Karl Pearson and Walter Frank Raphael Weldon, in
1901. It started (V olume 1, page 1) with an editorial setting forth the journal’s program, inwhich Weldon wrote:
The starting point of Darwin’s theory of evolution is precisely the existence of those differences
between individual members of a race or species which morphologists for the most part rightlyneglect. The ﬁrst condition necessary, in order that a process of Natural Selection may begin amonga race, or species, is the existence of differences among its members; and the ﬁrst step in an enquiryinto the possible effect of a selective process upon any character of a race must be an estimate of thefrequency with which individuals, exhibiting any degree of abnormality with respect to that character,occur.
Weldon had here reached a very important level of understanding. Morphologists, thinking
rather like astronomers, considered individual variations as only ‘noise’ whose effects mustbe eliminated by averaging, in order to get at the signiﬁcant ‘real’ properties of the species asa whole. Weldon, learning well from the example of Galton, saw it in just the opposite light;those individual variations are the engine that drives the process of evolutionary change ,
which will be reﬂected eventually in changes in the morphologists ’ averages. Indeed, without
individual variations, the mechanism of natural selection has nothing to operate on. So, todemonstrate the mechanism of evolution at its source, and not merely the ﬁnal result, it isthe frequency distribution of individual variations that must be studied.
21It is well known that, in developed nations, the average height of the population has, in fact, drifted upward by a substantial
amount in the past 200 years. This is commonly attributed to better nutrition in childhood; but it is worth noting that if tall
people tended to have more or longer-lived children than did short people for sociological reasons, the same average drift in
height would be observed, having nothing to do with nutrition. This would be true Darwinian evolution, powered by individualvariations. It appears to us that more research is needed to decide on the real cause of this upward drift.

<<<PAGE 263>>>

7 The central, Gaussian or normal distribution 231
Of course, at that time scientists had no conception of the physical mechanism of muta-
tions induced by radioactivity (much less by errors in DNA replication), and they expectedthat evolution would be found to take place gradually, via nearly continuous changes.
22
Nevertheless, the program of studying the individual variations would be the correct oneto ﬁnd the fundamental mechanism of evolution, whatever form it took. The scenario issomewhat like the following.
7.20 Evolution of humming-birds and ﬂowers
Consider a population of humming-birds in which the ‘noise’ consists of a distribution of
different beak lengths. The survival of birds is largely a matter of ﬁnding enough food; abird that ﬁnds itself with the mutation of an unusually long beak will be able to extractnectar from deeper ﬂowers. If such ﬂowers are available it will be able to nourish itself andits babies better than others because it has a food supply not available to other birds; sothe long-beak mutation will survive and become a greater portion of the bird population, in
more or less the way Darwin imagined.
But this inﬂuence works in two directions; a bird is inadvertently fertilizing ﬂowers
by carrying a few grains of pollen from one to the next. A ﬂower that happens to havethe mutation of being unusually deep will ﬁnd itself sought out preferentially by long-beaked birds because they need not compete with other birds for it. Therefore its pollenwill be carried systematically to other ﬂowers of the same species and mutation where itis effective, instead of being wasted on the wrong species. As the number of long-beakedbirds increases, deep ﬂowers thus have an increasing survival advantage, ensuring that theirmutation is present in an increasing proportion of the ﬂower population; this in turn givesa still greater advantage to long-beaked birds, and so on. We have a positive feedbacksituation.
Over millions of years, this back-and-forth reinforcement of mutations goes through
hundreds of cycles, resulting eventually in a symbiosis so specialized – a particular speciesof bird and a particular species of ﬂower that seem designed speciﬁcally for each other –that it appears to be a miraculous proof of a guiding purpose in Nature, at least to those
who do not think as deeply as did Darwin and Galton.
23Yet short-beaked birds do not
die out, because birds patronizing deep ﬂowers leave the shallow ﬂowers for them. Byitself, the process would tend to an equilibrium distribution of populations of short- andlong-beaked birds, coupled to distributions of shallow and deep ﬂowers. But if they breed
22The necessity for evolution to be particulate (by discrete steps) was perceived later by several people, including Fisher (1930b).
Evolutionary theory taking this into account, and discarding the Lamarckian notion of inheritance of acquired characteristics,is often called neo-Darwinism . However, the discrete steps are usually small, so Darwin’s notion of ‘gradualism’ remains quite
good pragmatically.
23The unquestioned belief in such a purpose pervades even producers of biological research products who might be expectedto know better. In 1993 there appeared in biological trade journals a full-page ad with a large color photograph of a feedinghumming-bird and the text: ‘ Speciﬁc purpose. The sharply curved bill of the white-tipped sickle-billed humming-bird is
speciﬁcally adapted to probe the delicate tubular ﬂowers of heliconia plants for the nectar on which the creature survives.’ Then
this is twisted somehow into a plug for a particular brand of DNA polymerase – said to be produced for an equally speciﬁcpurpose. This seems to us a dangerous line of argument; since the bird bills do not, in fact, have a speciﬁc purpose, whatbecomes of the alleged purpose of the polymerase?

<<<PAGE 264>>>

232 Part I Principles and elementary applications
independently, over long periods other mutations will take place independently in the two
types, and eventually they would be considered as belonging to two different species.
As noted, the role of ‘noise’ as the mechanism driving a slow change in a system was
perceived independently by Einstein (of course, he knew about Darwin’s theory, but wethink it highly unlikely that he would have known about the work of Galton or Weldon inSwitzerland in 1905). ‘Random’ thermal ﬂuctuations caused by motion of individual atomsare not merely ‘noise’ to be averaged out in our predictions of mass behavior; they are the
engine that drives irreversible processes in physics , and eventually brings about thermal
equilibrium. Today this is expressed very speciﬁcally in the many ‘ﬂuctuation-dissipationtheorems’ of statistical mechanics, which we derive in generality from the maximum entropyprinciple in Chapter 11. They generalize the results of Galton and Einstein. The aforemen-tioned Nyquist ﬂuctuation law was, historically, the ﬁrst such theorem to be discovered inphysics.
The visions of Weldon and Einstein represented such a major advance in thinking that
today, some 100 years later, many have not yet comprehended them or appreciated their
signiﬁcance in either biology or physics. We still have biologists
24who try to account for
evolution by a quite unnecessary appeal to the second law of thermodynamics, and physi-cists
25who try to account for the second law by appealing to quite unnecessary modi ﬁcations
in the equations of motion. The operative mechanism of evolution is surely Darwin’s originalprinciple of natural selection, and any effects of the second law can only hinder it.
26
Natural selection is a process entirely different from the second law of thermodynamics.
The purposeful intervention of man can suspend or reverse natural selection – as we observein wars, medical practice, and dog breeding – but it can hardly affect the second law.Furthermore, as Stephen J. Gould has emphasized, the second law always follows the samecourse, but evolution in Nature does not. Whether a given mutation makes a creature betteradapted or less adapted to its environment depends on the environment. A mutation thatcauses a creature to lose body heat more rapidly would be beneﬁcial in Brazil but fatalin Finland; and so the same actual sequence of mutations can result in entirely different
24For example, see Weber, Depew and Smith (1988). Here the trouble is that the second law of thermodynamics goes in the wrong
direction; if the second law were the driving principle, evolution would proceed inexorably back to the primordial soup, which
has a much higher entropy than would any collection of living creatures that might be made from the same atoms. This is easily
seen as follows. What is the difference between a gram of living matter and a gram of primordial soup made of the same atoms?Evidently, it is that the living matter is far from thermal equilibrium, and it is obeying thousands of additional constraints on
the possible reactions and spatial distribution of atoms (from cell walls, osmotic pressures, etc.) that the primordial soup is notobeying. But removing a constraint always has the effect of making a larger phase space available, thus increasing the entropy.The primordial soup represents the thermal equilibrium, resulting from removal of all the biological constraints; indeed, our
present chemical thermodynamics is based on (derivable from) the Gibbs principle that thermal equilibrium is the macrostate
of maximum entropy subject to only the physical constraints (energy, volume, mole numbers).
25Several writers have thought that Liouville’s theorem (conservation of phase volume in classical mechanics or unitarity of timedevelopment in quantum theory) is in conﬂict with the second law. On the contrary, in Jaynes (1963b, 1965) we demonstratethat, far from being in conﬂict, the second law is an immediate elementary consequence of Liouville’s theorem, and in Jaynes
(1989) we give a simple application of this to biology: calculation of the maximum theoretical efﬁciency of a muscle.
26This is not to say that natural selection is the only process at work; random drift is still an operative cause of evolution
with or without subsequent selection. Presumably, this is the reason for the fantastic color patterns of such birds as parrots,which surely have no survival value; the black bird is even more successful at surviving. For an extensive discussion of the
evidence and later research efforts by many experts, see the massive three-volume work Evolution After Darwin (Tax, 1960)
produced to mark the centenary of the publication of Darwin’s Origin of Species , or the more informal work of Dawkins
(1987).

<<<PAGE 265>>>

7 The central, Gaussian or normal distribution 233
creatures in different environments – each appearing to be adapting purposefully to its
surroundings.
7.21 Application to economics
The remarkable – almost exact – analogy between the processes that bring about equilibrium
in physics and in biology surely has other important implications, particularly for theoriesof equilibrium and stability in economics, not yet exploited. It seems likely, for example,that the ‘turbulence’ of individual variations in economic behavior is the engine that drivesmacroeconomic change in the direction of the equilibrium envisaged by Adam Smith. Theexistence of this turbulence was recognized by John Maynard Keynes (1936), who calledit ‘animal spirits’ which cause people to behave erratically; but he did not see in this theactual cause that prevents stagnation and keeps the economy on the move.
In the next level of understanding we see that Adam Smith’s equilibrium is never actually
attained in the real world because of what a physicist would call ‘external perturbations’,and what an economist would call ‘exogenous variables’ which vary on the same timescale. That is, wars, droughts, taxes, tariffs, bank reserve requirements, discount rates andother disturbances come and go on about the same time scale as would the approach toequilibrium in a perfectly ‘calm’ society.
The effect of small disturbances may be far greater than one might expect merely from
the ‘unit root’ hypothesis noted above. If small individual decisions (like whether to buya new car or open a savings account instead) take place independently, their effects on the
macroeconomy should average out according to the√
Nrule, to show only small ripples
with no discernible periodicity. But seemingly slight inﬂuences (like a month of bad weatheror a 1% change in the interest rate) might persuade many to do this a little sooner or later thanthey would otherwise. That is, a very slight inﬂuence may be able to pull many seeminglyindependent agents into phase with each other so they generate large organized wavesinstead of small ripples.
Such a phase-locked wave, once started, can itself become a major inﬂuence on other
individual decisions (of buyers, retailers, and manufacturers), and if these secondary in-ﬂuences are in the proper phase with the original ones, we could have a positive feedback
situation; the wave may grow and perpetuate itself by mutual reinforcement, as did the
humming-birds and ﬂowers. Thus, one can see why a macroeconomy may be inherentlyunstable for reasons that have nothing to do with capitalism or socialism. Classical equi-librium theory may fail not just because there is no ‘restoring force’ to bring the systemback to equilibrium; relatively small fortuitous events may set up a big wave that goes in-stead into an oscillating limit cycle – perhaps we are seeing this in business cycles. To stopthe oscillations and move back toward the equilibrium predicted by classical theory, themacroeconomy would be dependent on the erratic behavior of individual people, spreadingthe phases out again. Contrarians may be necessary for a stable economy!
As we see it, these are the basic reasons why economic data are very difﬁcult to interpret;
even if relevant and believable data were easy to gather, the rules of the game and the

<<<PAGE 266>>>

234 Part I Principles and elementary applications
conditions of play are changing constantly. But we think that important progress can still
be made by exploiting what is now known about entropy and probability theory as toolsof logic. In particular, the conditions for instability should be predictable from this kind ofanalysis, just as they are in physics, meteorology, and engineering. A very wise governmentmight be able to make and enforce regulations that prevent phase locking – just as it nowprevents wild swings in the stock market by suspending trading. We are not about to runout of important things to do in theoretical economics.
7.22 The great inequality of Jupiter and Saturn
An outstanding problem for 18th century science was noted by Edmund Halley in 1676.
Observation showed that the mean motion of Jupiter (30.35 deg/yr) was slowly accelerating,that of Saturn (12.22 deg/yr) decelerating. But this was not just a curiosity for astronomers;it meant that Jupiter was drifting closer to the Sun, Saturn farther away. If this trend wereto continue indeﬁnitely, then eventually Jupiter would fall into the Sun, carrying with it the
Earth and all the other inner planets. This seemed to prophesy the end of the world – and
in a manner strikingly like the prophesies of the Bible.
Understandably , this situation was of more than ordinary interest, and to more people
than astronomers. Its resolution called forth some of the greatest mathematical efforts of
18th century savants, either to conﬁrm the coming end; or preferably to show how theNewtonian laws would eventually put a stop to the drift of Jupiter and save us.
Euler, Lagrange, and Lambert made heroic attacks on the problem without solving it. We
noted above how Euler was stopped by a mass of overdetermined equations; 75 simultaneousbut inconsistent equations for eight unknown orbital parameters. If the equations were all
consistent, he could choose any eight of them and solve (this would still involve inversion
of an 8×8 matrix), and the result would be the same whatever eight he chose. But the
observations all had unknown errors of measurement, and so there were
/parenleftbigg75
8/parenrightbigg
/similarequal1.69×10
10(7.79)
possible choices; i.e. over 16 billion different sets of estimates for the parameters, with
apparently nothing to choose between them.27At this point, Euler managed to extract
reasonably good estimates of two of the unknowns (already an advance over previous
knowledge), and simply gave up on the others. For this work (Euler, 1749), he won the
French Academy of Sciences prize.
The problem was ﬁnally solved in 1787 by one who was born that same year. Laplace
(1749–1827) ‘saved the world’ by using probability theory to estimate the parametersaccurately enough to show that the drift of Jupiter was not secular after all; the observations
27Our algorithm for this in Chapter 19, Eqs. (19.24) and (19.37), actually calculates a weighted average over all these billions of
estimates; but in a manner so efﬁcient that one is unaware that all this is happening. What probability theory determines for
us – and what Euler and Daniel Bernoulli never comprehended – is the optimal weighting coefﬁcients in this average, leading
to the greatest possible reliability for the estimate and the accuracy claims.

<<<PAGE 267>>>

7 The central, Gaussian or normal distribution 235
at hand had covered only a fraction of a cycle of an oscillation with a period of about
880 years. This is caused by an ‘accidental’ near resonance in their orbital periods:
2×(period of Saturn)/similarequal5×(period of Jupiter) . (7.80)
Indeed, from the above mean motion data we have
2×360
12.22=58.92 yr, 5×360
30.35=59.32 yr. (7.81)
In the time of Halley, their difference was only about 0 .66% and decreasing.
So, long before it became a danger to us, Jupiter indeed reversed its drift – just as
Laplace had predicted – and it is returning to its old orbit. Presumably, Jupiter and Saturn
have repeated this seesaw game several million times since the solar system was formed.
The ﬁrst half-cycle of this oscillation to be observed by man will be completed in about theyear 2012.
7.23 Resolution of distributions into Gaussians
The tendency of probability distributions to gravitate to the Gaussian form suggests that
we might view the appearance of a Gaussian, or ‘normal’, frequency distribution as looseevidence (but far from proof) that some kind of equilibrium has been reached. This view is
also consistent with (but by no means required by) the results of Galton and Einstein. In theﬁrst attempts to apply probability theory in the biological and social sciences (for example,Quetelet, 1835, 1869), serious errors were made through supposing ﬁrstly that the appear-ance of a normal distribution in data indicates that one is sampling from a homogeneouspopulation, and secondly that any departure from normality indicates an inhomogeneityin need of explanation. By resolving a non-normal distribution into Gaussians, Queteletthought that one would be discovering the different sub-species, or varieties, that werepresent in the population. If this were true reliably, we would indeed have a powerful toolfor research in many different ﬁelds. But later study showed that the situation is not thatsimple.
We have just seen how one aspect of it was corrected ﬁnally by Galton (1886), in showing
that a normal frequency distribution by no means proves homogeneity; from (7.73), a
Gaussian of width σcan arise inhomogeneously – and in many different ways – from
the overlapping of narrower Gaussian distributions of various widths σ
1,σ2. But those
subpopulations are in general merely mathematical artifacts like the sine waves in a Fouriertransform; they have no individual signiﬁcance for the phenomenon unless one can showthat a particular set of subpopulations has a real existence and plays a real part in themechanism underlying stability and change. Galton was able to show this from his data bymeasuring those widths.
The second assumption, that non-normal distributions can be resolved into Gaussian
subdistributions, turns out to be not actually wrong (e xcept in a nitpicking mathematical
sense); but without extra prior information it is ambiguous in what it tells us about the
phenomenon.

<<<PAGE 268>>>

236 Part I Principles and elementary applications
We have here an interesting problem, with many useful applications: is a non-Gaussian
distribution explainable as a mixture of Gaussian ones? Put mathematically, if an observeddata histogram is well described by a distribution g(y), can we ﬁnd a mixing function
f(x)≥0 such that g(y) is seen as a mixture of Gaussians:
/integraldisplay
dxϕ(y−x|σ)f(x)=g(y),−∞≤ y≤∞. (7.82)
Neither Quetelet nor Galton was able to solve this problem, and today we understand why.
Mathematically, does this integral equation have solutions, or unique solutions? It appearsfrom (7.73) that we cannot expect unique solutions in general, for, in the case of Gaussian
g(y), many different mixtures (many different choices of a,σ
1,σ2) will all lead to the same
g(y). But perhaps if we specify the width σof the Gaussian kernel in (7.82) there is a unique
solution for f(x).
Solution of such integral equations is rather subtle mathematically. We give two argu-
ments: the ﬁrst depends on the properties of Hermite polynomials and yields a class of exactsolutions; the second appeals to Fourier transforms and yields an understanding of the moregeneral situation.
7.24 Hermite polynomial solutions
The rescaled Hermite polynomials R
n(x) may be deﬁned by the displacement of a Gaussian
distribution ϕ(x), which gives the generating function
ϕ(x−a)
ϕ(x)=exp{xa−a2/2}=∞/summationdisplay
n=0Rn(x)an
n!, (7.83)
or, solving for Rn, we have the Rodriguez form
Rn(x)=dn
dan/bracketleftBig
exp{xa−a2/2}/bracketrightBig
a=0=(−1)nexp{x2/2}dn
dxnexp{−x2/2}. (7.84)
The ﬁrst few of these polynomials are: R0=1,R1=x,R2=x2−1,R3=x3−3x,R4=
x4−6x2+3. The conventional Hermite polynomials Hn(x) differ only in scaling: Hn(x)=
2n/2Rn(x√
2).
Multiplying (7.83) by ϕ(x)e x p{xb−b2/2}and integrating out x, we have the orthogo-
nality relation
/integraldisplay∞
−∞dxR m(x)Rn(x)ϕ(x)=n!δmn, (7.85)
and in consequence these polynomials have the remarkable property that convolution with
a Gaussian function reduces simply to
/integraldisplay∞
−∞dxϕ(y−x)Rn(x)=yn. (7.86)

<<<PAGE 269>>>

7 The central, Gaussian or normal distribution 237
Therefore, if g(y) is represented by a power series,
g(y)=/summationdisplay
nanyn, (7.87)
we have immediately a formal solution of (7.82):
f(x)=/summationdisplay
nanσnRn/parenleftBigx
σ/parenrightBig
. (7.88)
Since the coefﬁcient of xninRn(x) is unity, the expansions (7.87) and (7.88) converge
equally well. So, if g(y) is any polynomial or entire function (i.e. one representable by a
power series (7.87) with inﬁnite radius of convergence), the integral equation has the uniquesolution (7.88).
We can see the solution (7.88) a little more explicitly if we invoke the expansion of R
n,
deducible from (7.83) by expanding exp {xa−a2/2}in a power series in x:
Rn/parenleftBigx
σ/parenrightBig
=M/summationdisplay
m=0(−1)m n!
2mm!(n−2m)!/parenleftBigx
σ/parenrightBign−2m
, (7.89)
where M=(n−1)/2i fnis odd, M=n/2i fnis even. Then, noting that
n!
(n−2m)!/parenleftBigx
σ/parenrightBign−2m
=σ2m−nd2m
dx2mxn, (7.90)
we have the formal expansion
f(x)=∞/summationdisplay
m=0(−1)mσ2m
2mm!d2m
dx2mg(x)=g(x)−σ2
2d2g(x)
dx2+σ4
8d4g(x)
dx4−···. (7.91)
An analytic function is differentiable any number of times, and if g(x) is an entire function
this will converge to the unique solution. If g(x) is a very smooth function, it converges
very rapidly, so the ﬁrst two or three terms of (7.91) are already a good approximation to thesolution. This gives us some insight into the workings of the integral equation; as σ→0,
the solution (7.91) relaxes into f(x)→g(x), as it should. The ﬁrst two terms of (7.91) are
what would be called, in image reconstruction, ‘edge detection’; for small σthe solution
goes into this. The larger σ, the more the higher-order derivatives matter; that is, the more
ﬁne details of the structure of g(y) contribute to the solution. Intuitively, the broader the
Gaussian kernel, the more difﬁcult it is to represent ﬁne structure of g(y) in terms of that
kernel.
Evidently, we could continue this line of thought with much more analytical work, and
it might seem that the problem is all but solved; but now the subtlety starts. Solutions like(7.88) and (7.91), although formally correct in a mathematical sense, ignore some facts ofthe real world; is f(x) non-negative when g(y) is? Is the solution stable, a small change
ing(y) inducing only a small change in f(x)? What if g(x) is not an entire function but is
piecewise continuous; for example, rectangular?

<<<PAGE 270>>>

238 Part I Principles and elementary applications
7.25 Fourier transform relations
For some insight into these questions, let us look at the integral equation from the Fourier
transform viewpoint. Taking the transform of (7.82) according to
F(k)≡/integraldisplay∞
−∞dxf(x)e x p{ikx}, (7.92)
(7.82) reduces to
exp/braceleftbigg
−k2σ2
2/bracerightbigg
F(k)=G(k), (7.93)
which illustrates that the Fourier transform of a Gaussian function is another Gaussian
function, and shows us at once the difﬁculty of ﬁnding more general solutions than (7.88).Ifg(y) is piecewise continuous, then, as k→∞ , from the Riemann–Lebesgue lemma G(k)
will fall off only as 1 /k. Then F(k) must blow up violently, like exp {+k
2σ2/2}/k, and one
shudders to think what the function f(x) must look like (inﬁnitely violent oscillations of
inﬁnitely high frequency?) If g(y) is continuous, but has discontinuous ﬁrst derivatives like
a triangular distribution, then G(k) falls off as k−2, and we are in a situation about as bad.
Evidently, if g(y) has a discontinuity in any derivative, there is no solution f(x) that would
be acceptable in the physical problem. This is evident also from (7.91); the formal solutionwould degenerate into inﬁnitely high derivatives of a delta-function.
In order that we can interpret g(y) as a mixture of possible Gaussians, f(x) must be non-
negative. But we must allow the possibility that the f(x) sought is a sum of delta-functions;
indeed, to resolve g(y) into a discrete mixture of Gaussians g(y)=/summationtexta
jϕ(x−xj)w a s
thereal goal of Quetelet and Galton. If this could be achieved uniquely , their interpretation
might be valid. Then F(k) does not fall off at all as k→±∞ ,s oG(k) must fall off as
exp{−k2σ2/2}. In short, in order to be resolvable into Gaussians of width σwith positive
mixture function f(x), the function g(y) must itself be at least as smooth as a Gaussian of
width σ. This is a formal difﬁculty.
There is a more serious practical difﬁculty. If g(y) is a function determined only empiri-
cally, we do not have it in the form of an analytic function; we have only a ﬁnite number ofapproximate values g
iat discrete points yi. We can ﬁnd many analytic functions which ap-
pear to be good approximations to the empirical one. But because of the instability evident
in (7.88) and (7.91) they will lead to greatly different ﬁnal results f(x). Without a stabil-
ity property and a criterion for choosing that smooth function, we really have no deﬁnitesolution in the sense of inversion of an integral equation.
28
In other words, ﬁnding the appropriate mixture f(x) to account for an empirically deter-
mined distribution g(y) is not a conventional mathematical problem of inversion; it is itself
a problem of inference, requiring the apparatus of probability theory . In this way, a problem
in probability theory can generate a hierarchy of subproblems, each involving probabilitytheory again but on a different level.
28For other discussions of the problem, see Andrews and Mallows (1974) and Titterington, Smith and Makov (1985).

<<<PAGE 271>>>

7 The central, Gaussian or normal distribution 239
7.26 There is hope after all
Following up the idea in Section 7.2.5, the original goal of Quetelet has now been very
nearly realized by analysis of the integral equation as a problem of Bayesian inferenceinstead of mathematical inversion; and useful examples of analysis of real data by this havenow been found. Sivia and Carlile (1992) report the successful resolution of noisy data intoas many as nine different Gaussian components, representing molecular excitation lines, bya Bayesian computer program.
29
It is hardly surprising that Quetelet and Galton could not solve this problem in the 19th
century; but it is very surprising that today many scientists, engineers, and mathematiciansstill fail to see the distinction between inversion and inference, and struggle with problemslike this that have no deductive solutions, only inferential ones. The problem is, however,very common in current applications; it is kno wn as a ‘generalized inverse’ problem, and
today we can give unique and useful inferential solutions to such problems by specifying the(essential, but hitherto unmentioned) prior information to be used, converting an ill-posedproblem into a straightforward Bayesian exercise.
This suggests another interesting mathematical problem; for a given entire function g(y),
over what range of σis the solution (7.88) non-negative? There are some evident clues: when
σ→0, we have ϕ(x−y|σ)→δ(x−y) and so, as noted above, f(x)→g(x); so, for σ
sufﬁciently small, f(x) will be non-negative if g(y) is. But when σ→∞ the Gaussians
in (7.82) become very broad and smooth; so, if f(x) is non-negative, the integral in (7.82)
must be at least as broad. Thus, when g(y) has detailed structure on a scale smaller than σ,
there can be no solution with non-negative f(x); and it is not obvious whether there can be
any solution at all.
Exercise 7.9. From the above arguments one would conjecture that there will be
some upper bound σmaxsuch that the solution f(x) is non-negative when and only
when 0≤σ<σ max. It will be some functional σmax[g(y)] of g(y). Prove or disprove
this conjecture; if it is true, give a verbal argument by which we could have seen thiswithout calculation; if it is false, give a speciﬁc counter-example showing why.Hint. It appears that (7.91) might be useful in this endeavor.
29We noted in Chapter 1 that most of the computer programs used in this ﬁeld are only intuitive ad hoc devices that make no use
of the principles of probability theory; therefore in general they are usable in some restricted domain, but they fail to extract all
the relevant information from the data and are subject to both the errors of hallucination and blunt perception. One commercial
program for resolution into Gaussians or other functions simply reverts to empirical curve ﬁtting. It is advertised ( Scientiﬁc
Computing , July 1993, p. 15) with a provocative message, which depicts two scientists with the same data curve showing two
peaks; by hand drawing one could resolve it very crudely into two Gaussians. The ad proclaims: ‘Dr Smith found two peaks ....
Using [our program] Dr Jones found three peaks...’. Guess who got the grant? We are encouraged to think that we can extract
money from the Government by ﬁrst allowing the software company to extract $500 from us for this program, whose outputwould indeed be tolerable for noiseless data. But it would surely degenerate quickly into dangerous, unstable nonsense as the
noise level increases. The problem is not, basically, one of inversion or curve ﬁtting; it is a problem of inference . A Bayesian
inference program like those of Bretthorst (1988) will continue to return the best resolution possible from the data and themodel, without instability, whatever the noise level. If the noise level becomes so high as to make the data useless, the Bayesianestimates just relax back into the prior estimates, as they should.

<<<PAGE 272>>>

240 Part I Principles and elementary applications
This suggests that the original goal of Quetelet and Galton was ambiguous; any sufﬁ-
ciently smooth non-Gaussian distribution may be generated by many different superposi-tions of different Gaussians of different widths. Therefore a given set of subpopulations,even if found mathematically, would have little biological signiﬁcance unless there wereadditional prior information pointing to Gaussians of that particular width σas having a
‘real’ existence and playing some active role in the phenomena. Of course, this caveat ap-
plies equally to the aforementioned Bayesian solution; but Sivia and Carlile did have thatprior information.
7.27 Comments
7.27.1 Terminology again
As we are obliged to point out so often, this ﬁeld seems to be cursed more than any other
with bad and misleading terminology which seems impossible to eradicate. The electricalengineers have solved this problem very effectively; every few years, an ofﬁcial committeeissues a revised standard terminology, which is then enforced by editors of their journals
(witness the meek acceptance of the change from ‘megacycles’ to ‘megahertz’ which was
accomplished almost overnight a few years ago).
In probability theory there is no central authority with the power to bring about dozens
of needed reforms, and it would be self-defeating for any one author to try to do this by
himself; he would only turn away readers. But we can offer tentative suggestions in thehope that others may see merit in them.
The literature gives conﬂicting evidence about the origin of the term ‘normal distribution’.
Karl Pearson (1920) claimed to have introduced it ‘many years ago’, in order to avoid an olddispute over priority between Gauss and Legendre; but he gives no reference. Hilary Seal(1967) attributes it instead to Galton; but again fails to give a reference, so it would requirea new historical study to decide this. However, the term had long been associated with thegeneral topic: given a linear model y=Xβ+e, where the vector yand the matrix Xare
known, the vector of parameters βand the noise vector eunknown, Gauss (1823) called
the system of equations X
/primeXˆβ=X/primey, which give the least squares parameter estimates
ˆβ, the ‘normal equations ’, and the ellipsoid of constant probability density was called the
‘normal surface’. It appears that somehow the name was transferred from the equations tothe sampling distribution that leads to those equations.
Presumably, Gauss meant ‘normal’ in its mathematical sense of ‘perpendicular’, express-
ing the geometric meaning of those equations. The minimum distance from a point (theestimate) to a plane (the constraint) is the length of the perpendicular. But, as Pearsonhimself observes, the term ‘normal distribution’ is a bad one because the common col-loquial meaning of ‘normal’ is standard orsane, implying a value judgment. This leads
many to think – consciously or subconsciously – that all other distributions are in some wayabnormal.
Actually, i t is quite the other way; it is the so-called ‘normal’ distribution that is abnormal
in the sense that it has many unique properties not possessed by any other. Almost all of our

<<<PAGE 273>>>

7 The central, Gaussian or normal distribution 241
experience in inference has been with this abnormal distribution, and much of the folklore
that we must counter here was acquired as a result. For decades, workers in statisticalinference have been misled, by that abnormal experience, into thinking that methods suchas conﬁdence intervals, that happen to work satisfactorily with this distribution, shouldwork as well with others.
The alternative name ‘Gaussian distribution’ is equally bad for a different reason, although
there is no mystery about its origin. Stigler (1980) sees it as a general law of eponymy that no
discovery is named for its original discoverer . Our terminology is in excellent compliance
with this law, since the fundamental nature of this distribution and its main properties werenoted by Laplace when Gauss was six years old; and the distribution itself had been found byde Moivre before Laplace was born. But, as we noted, the distribution became popularizedby the work of Gauss (1809), who gave a derivation of it that was simpler than previousones and seemed very compelling intuitively at the time. This is the derivation that we gaveabove, Eq. (7.16), and which resulted in his name becoming attached to it.
The term ‘central distribution’ would avoid both of these objections while conveying
a correct impression; it is the ﬁnal ‘stable’ or ‘equilibrium’ distribution toward whichall others gravitate under a wide variety of operations (large number limit, convolution,stochastic transformation, etc.), and which, once attained, is maintained through an evengreater variety of transformations, some of which are still unknown to statisticians becausethey have not yet come up in their problems.
For example, in the 1870s Ludwig Boltzmann gave a compelling, although heuristic, ar-
gument indicating that collisions in a gas tend to bring about a ‘Maxwellian’, or Gaussian,frequency distribution for velocities. Then Kennard (1938, Chap. 3) showed that this dis-tribution, once attained, is maintained automatically, without any help from collisions, asthe molecules move about, constantly changing their velocities, in any conservative forceﬁeld (that is, forces f(x) derivable from a potential φ(x) by gradients: f(x)=−∇ φ(x)).
Thus, this distribution has stability properties considerably beyond anything yet utilized bystatisticians, or yet demonstrated in the present work.
While venturing to use the term ‘central distribution’ in a cautious, tentative way, we
continue to use also the bad but traditional terms, preferring ‘Gaussian’ for two reasons.Ancient questions of priority are no longer of interest; far more important today, ‘Gaussian’
does not imply any value judgment. Use of emotionally loaded terms appears to us amajor cause of the confusion in this ﬁeld, causing workers to adhere to principles withnoble-sounding names like ‘unbiased’ or ‘admissible’ or ‘uniformly most powerful’, inspite of the nonsensical results they can yield in practice. But also, we are writing foran audience that includes both statisticians and scientists. Everybody understands what‘Gaussian distribution’ means; but only statisticians are familiar with the term ‘normaldistribution’.
The fundamental Boltzmann distribution of statistical mechanics, exponential in energies,
is of course Gaussian or Maxwellian in particle velocities. The general central tendencyof probability distributions toward this ﬁnal form is now seen as a consequence of theirmaximum entropy properties (Chapter 11). If a probability distribution is subjected to some

<<<PAGE 274>>>

242 Part I Principles and elementary applications
transformation that discards information but leaves certain quantities invariant, then, under
very general conditions, if the transformation is repeated, the distribution tends to the onewith maximum entropy, subject to the constraints of those conserved quantities.
This brings us to the term ‘central limit theorem’, which we have derived as a special case
of the phenomenon just noted – the behavior of probability distributions under repeatedconvolutions, which conserve ﬁrst and second moments. This name was introduced byGeorge P´ olya (1920), with the intention that the adjective ‘central’ was to modify the
noun ‘theorem’; i.e. it is the limit theorem which is central to probability theory . Almost
universally, students today think that ‘central’ modiﬁes ‘limit’, so that it is instead a theoremabout a ‘ central limit ’, whatever that means.
30
In view of the equilibrium phenomenon, it appears that P´ olya’s choice of words was after
all fortunate in a way that he did not foresee. Our suggested terminology takes advantage ofthis; looked at in this way, the terms ‘central distribution’ and ‘central limit theorem’ bothconvey the right connotations to one hearing them for the ﬁrst time. One can read ‘centrallimit’ as meaning a limit toward a central distribution, and will be invoking just the rightintuitive picture.
30The confusion does not occur in the original German, where P´ olya’s words were: ¨Uber den zentralen Grenzwertsatz der
Wahrscheinlichkeitsrechnung , an interesting example where the German habit of inventing compound words removes an
ambiguity in the literal English rendering.

<<<PAGE 275>>>

8
Sufﬁciency, ancillarity, and all that
In the preceding ﬁve chapters we have examined the use of probability theory in problems
that, although technically elementary, illustrated a fairly good sample of typical currentapplications. Now we are in a position to look back over these examples and note someinteresting features that the y have brought to light. It is useful to understand these features,
for tactical reasons. Many times in the past when one tried to conduct inference by applyingintuitive ad hoc devices instead of probability theory, they would not work acceptably
unless some special circumstances were present, and others absent. Thus they were of
major theoretical importance in orthodox statistics.
None of the material of the present chapter, however, is really needed in our applications;
for us, these are incidental details that take care of themselves as long as we obey the rules.
That is, if we merely apply the rules derived in Chapter 2, strictly and consistently in every
problem, they lead us to do the right thing and arrive at the optimal inferences for thatproblem automatically, without our having to take any special note of these things. Forus, they have rather a ‘general cultural value’ in helping us to understand better the innerworkings of probability theory. One can see much more clearly why it is necessary to obeythe Chapter 2 rules, and the predictable consequences of failure to do so.
8.1 Sufﬁciency
In our examples of parameter estimation, probability theory sometimes does not seem to use
all the data that we offer it. In Chapter 6, when we estimated the parameter θof a binomial
distribution from data on ntrials, the posterior pdf for θdepended on the data only through
the number nof trials and the number rof successes; all information about the order in
which success and failure occurred was ignored.
With a rectangular sampling distribution in α≤x≤β, the joint posterior pdf for α, β
used only the extreme data values ( x
min,xmax) and ignored the intermediate data.
Likewise, in Chapter 7, with a Gaussian sampling distribution and a data set D≡
{x1,..., xn}, the posterior pdf for the parameters µ, σ depended on the data only through
nand their ﬁrst two moments ( ¯x,x2). The ( n−2) other properties of the data convey a
great deal of additional information of some kind; yet our use of probability theory ignoredthem.
243

<<<PAGE 276>>>

244 Part 1 Principles and elementary applications
Is probability theory failing to do all it could here? No, the proofs of Chapter 2 have
precluded that possibility; the rules being used are the only ones that can yield uniqueanswers while agreeing with the qualitative desiderata of rationality and consistency. Itseems, then, that the unused parts of the data must be irrelevant to the question we are
asking.
1But can probability theory itself conﬁrm this conjecture for us in a more direct way?
This introduces us to a quite subtle theoretical point about inference. Special cases of
the phenomenon were noted by Laplace (1812, 1824 edn, Supp. V). It was generalized andgiven its present name 100 years later by Fisher (1922), and its signiﬁcance for Bayesianinference was noted by H. Jeffreys (1939). Additional understanding of its role in inferencewas achieved only recently, in the resolution of the ‘marginalization paradox’ discussed inChapter 15.
If certain aspects of the data are not used when they are known, then presumably it would
not matter (we should come to the same ﬁnal conclusion) if they were unknown. Thus, ifthe posterior pdf for a parameter θis found to depend on the data D={x
1,..., xn}only
through a function r(x1,..., xn) (call it‘property R’), then it seems plausible that given r
alone we should be able to draw the same inferences about θ. This would conﬁrm that the
unused parts of the data were indeed irrelevant in the sense just conjectured.
With a sampling density function p(x1...xn|θ) and prior p(θ|I)=f(θ), the posterior
pdf using all the data is
p(θ|DI)=h(θ|D)=f(θ)p(x1...xn|θ)/integraltext
dθ/primef(θ/prime)p(x1...xn|θ/prime). (8.1)
Note that we are not assuming independent or exchangeable sampling here; the sampling
pdf need not factor in the form p(x1...xn|θ)=/Pi1ip(xi|θ) and the marginal probabilities
p(xi|θ)=ki(xi,θ) and p(xj|θ)=kj(xj,θ) need not be the same function. Now carry
out a change of variables ( x1,..., xn)→(y1,..., yn) in the sample space Sx, such that
y1=r(x1,..., xn), and choose ( y2,..., yn) so that the Jacobian
J=∂(y1,..., yn)
∂(x1,..., xn)(8.2)
is bounded and nonvanishing everywhere on Sx. Then the change of variables is a 1:1
mapping of Sxonto Sy, and the sampling density
g(y1,..., yn|θ)=J−1p(x1...xn|θ) (8.3)
may be used just as well as p(x1...xn|θ) in the posterior pdf:
h(θ|D)=f(θ)g(y1,..., yn|θ)/integraltext
dθ/primef(θ/prime)g(y1,..., yn|θ/prime)(8.4)
since the Jacobian, being independent of θ, cancels out.
Then property R is the statement that for all θ∈Sθ, (8.4) is independent of ( y2,..., yn).
Writing this condition out as derivatives set to zero, we ﬁnd that it deﬁnes a set of n−1
1Of course, when we say that some information is ‘irrelevant’ we mean only that we don’t need it for our present purpose ;i t
might be crucially important for some other purpose that we shall have tomorrow.

<<<PAGE 277>>>

8 Sufﬁciency, ancillarity, and all that 245
simultaneous integral equations (actually, only orthogonality conditions) that the prior f(θ)
must satisfy:
/integraldisplay
Sθdθ/primeKi(θ,θ/prime)f(θ/prime)=0/braceleftBigg
θ∈Sθ
2≤i≤n/bracerightBigg
, (8.5)
where the ith kernel is
Ki(θ,θ/prime)≡g(y|θ)∂g(y|θ/prime)
∂yi−g(y|θ/prime)∂g(y|θ)
∂yi, (8.6)
and we used the abbreviation y≡(y1,..., yn), etc. It is antisymmetric: Ki(θ,θ/prime)=
−Ki(θ/prime,θ).
8.2 Fisher sufﬁciency
If (8.5) holds only for some particular prior f(θ), then Ki(θ,θ/prime) need not vanish; in its
dependence on θ/primeit needs only to be orthogonal to that particular function. But if (8.5)
is to hold for all f(θ), as Fisher (1922) required by implication – by failing to mention
f(θ) – then Ki(θ,θ/prime) must be orthogonal to a complete set of functions f(θ/prime); thus zero
almost everywhere for (2 ≤i≤n). Noting that the kernel may be written in the form
Ki(θ,θ/prime)=g(y|θ)g(y|θ/prime)∂
∂yilog/bracketleftbiggg(y|θ/prime)
g(y|θ)/bracketrightbigg
, (8.7)
this condition may be stated as: given any ( θ,θ/prime), then for all possible samples (that is, all
values of{y1,..., yn;θ;θ/prime}for which g(y|θ)g(y|θ/prime)/negationslash=0), the ratio [ g(y|θ/prime)/g(y|θ)] must
be independent of the components ( y2,..., yn). Thus to achieve property R independently
of the prior, g(y|θ) must have the functional form
g(y1,..., yn|θ)=q(y1|θ)m(y2,..., yn). (8.8)
Integrating ( y2,..., yn) out of (8.8), we see that the function denoted by q(y1|θ) is, to within
a normalization constant, the marginal sampling pdf for y1.
Transforming back to the original variables, Fisher sufﬁciency requires that the sampling
pdf has the form
p(x1...xn|θ)=p(r|θ)b(x1,..., xn), (8.9)
where p(r|θ) is the marginal sampling density for r(x1,..., xn).
Equation (8.9) was given by Fisher (1922). If a sampling distribution factors in the manner
(8.8), (8.9), then the sampling pdf for ( y2,..., yn) is independent of θ. This being the case,
he felt intuitively that the values of ( y2,..., yn) can convey no information about θ; full
information should be conveyed by the single quantity r, which he then termed a sufﬁcient
statistic . But Fisher’s reasoning was only a conjecture referring to a sampling theory context.
We do not see how it could be proved in that limited context, which did not use the conceptsof prior and posterior probabilities.

<<<PAGE 278>>>

246 Part 1 Principles and elementary applications
Probability theory as logic can demonstrate this property directly without any need for
conjecture. Indeed, using (8.9) in (8.1), the function b(x) cancels out, and we ﬁnd immedi-
ately the relation
h(θ|D)∝f(θ)p(r|θ). (8.10)
Thus, if (8.10) holds, then r(x1,..., xn) is a sufﬁcient statistic in the sense of Fisher, and in
Bayesian inference with the assumed model (8.1), knowledge of the single quantity rdoes
indeed tell us everything about θthat is contained in the full data set ( x1,..., xn); and this
will be true for all priors f(θ).
The idea generalizes at once to more variables. Thus, if the sampling distribution factors in
the form g(y1,..., yn|θ)=h(y1,y2|θ)m(y3,..., yn), we would say that y1(x1,..., xn) and
y2(x1,..., xn) are jointly sufﬁcient statistics for θand, in this, θcould be multidimensional.
If there are two parameters θ1,θ2such that there is a coordinate system {yi}in which
g(y1,..., yn|θ1θ2)=h(y1|θ1)k(y2|θ2)m(y3,..., yn), (8.11)
then y1(x1,..., xn) is a sufﬁcient statistic for θ1, and y2is a sufﬁcient statistic for θ2; and
so on.
8.2.1 Examples
Our discussion of the Gaussian distribution in Chapter 7 has already demonstrated that
it has sufﬁcient statistics [Eqs. (7.25)–(7.30)]. If the data D={y1,..., yn}consist of n
independent observations yi, then the sampling distribution with mean and variance µ,σ2
could be written as
p(D|µσI)=/parenleftbigg1
2πσ2/parenrightbiggn/2
exp/braceleftBig
−n
2σ2[(µ−y)2+s2]/bracerightBig
, (8.12)
where y,s2are the observed sample mean and variance, Eq. (7.29). Since these are the only
properties of the data that appear in the sampling distribution (8.12) – and therefore are theonly properties of the data that occur in the joint posterior distribution p(µσ|DI) – they
are jointly sufﬁcient statistics for estimation of µ,σ. The test for sufﬁciency via Bayes’
theorem is often easier to carry out than is the test for factorization (8.11), although of
course they amount to the same thing.
Let us examine sufﬁciency for the separate parameters. If σis known, then we would
ﬁnd the posterior distribution for µalone:
p(µ|σDI)=Ap(µ|I)p(D|µσI)
/integraltext
dµp(µ|I)p(D|µI), (8.13)
p(x1...xn|µσI)=Aexp/braceleftBigg
−1
σ2n/summationdisplay
i=1(xi−µ)2/bracerightBigg
,
(8.1)
=Aexp/braceleftbigg
−ns2
2σ2/bracerightbigg
×exp/braceleftBig
−n
2σ2(x−µ)2/bracerightBig
,

<<<PAGE 279>>>

8 Sufﬁciency, ancillarity, and all that 247
where
x≡1
nn/summationdisplay
i=1xi, x2≡1
n/summationdisplay
ix2
i, s2≡x2−x2, (8.15)
p(µ|σDI)∝p(u|I)e x p/braceleftBig
−n
2σ2(x−µ)/bracerightBig
(8.16)
are the sample mean, mean square, and variance, respectively. Since now the factor
exp{−ns2/2s2}appears in both numerator and denominator, it cancels out.
Likewise, if µis known, then the posterior pdf for σalone is found to be
p(σ|µDI)∝p(σ|I)σ−nexp/braceleftBig
−n
2σ2(x2−2µx+µ2)/bracerightBig
. (8.17)
Fisher sufﬁciency was of major importance in orthodox (non-Bayesian) statistics, because it
had so few criteria for choosing an estimator. It had, moreover, a fundamental status lackingin other criteria because, for the ﬁrst time, the notion of information appeared in orthodox
thinking. If a sufﬁcient statistic for θexists, it is hard to justify using any other for inference
about θ. From a Bayesian standpoint one would be, deliberately, throwing away some of
the information in the data that is relevant to the problem.
2
8.2.2 The Blackwell–Rao theorem
Arguments in terms of information content had almost no currency in orthodox theory, but a
theorem given by D. Blackwell and C. R. Rao in the 1940s did establish a kind of theoretical
justiﬁcation for the use of sufﬁcient statistics in orthodox terms. Let r(x1,..., xn) be a Fisher
sufﬁcient statistic for θ, and let β(x1,..., xn) be any proposed estimator for θ. By (8.9) the
joint pdf for the data conditional on r:
p(x1...xn|rθ)=b(x)p(r|xθ)=b(x)δ(r−r(x)) (8.18)
is independent of θ. Then the conditional expectation
β0(r)≡/angbracketleftβ|rθ/angbracketright=E(β|rθ) (8.19)
is also independent of θ,s oβ0is a function only of the xi, and so is itself a conceivable
estimator for θ, which depends on the observations only through the sufﬁcient statistic:
β0=E(β|r). The theorem is then that the ‘quadratic risk’
R(θ,β)≡E[(β−θ)2|θ]=/integraldisplay
dx1···dxn[β(x1,..., xn)−θ]2(8.20)
satisﬁes the inequality
R(θ,β 0)≤R(θ,β), (8.21)
2This rather vague statement becomes a deﬁnite theorem when we learn that, if we measure information in terms of entropy, then
zero information loss in going from the full data set Dto a statistic ris equivalent to sufﬁciency of r. The beginnings of this
appeared long ago, in the Pitman–Koopman theorem (Koopman, 1936; Pitman, 1936); we give a modern version in Chapter 11.

<<<PAGE 280>>>

248 Part 1 Principles and elementary applications
for all θ.I fR(θ,β) is bounded, there is equality if and only if β0=β; that is, if βitself
depends on the data only through the sufﬁcient statistic r.
In other words, given any estimator βforθ, if a sufﬁcient statistic rexists, then we
can ﬁnd another estimator β0that achieves a lower or equal risk and depends only on r.
Thus the best estimator we can ﬁnd by the criterion of quadratic risk can always be chosenso that it depends on the data only through r. A proof is given by de Groot (1975, 1986
edn, p. 373); the orthodox notion of risk is discussed further in Chapters 13 and 14. Butif a sufﬁcient statistic does not exist, orthodox estimation theory is in real trouble becauseit wastes information; no single estimator can take note of all the relevant information inthe data.
The Blackwell–Rao argument is not compelling to a Bayesian, because the criterion of risk
is a purely sampling theory notion that ignores prior information. But Bayesians have a farbetter justiﬁcation for using sufﬁcient statistics; it is straightforward mathematics, evidentfrom (8.9) and (8.10) that, if a sufﬁcient statistic exists, Bayes’ theorem will lead us to itautomatically , without our having to take any particular note of the idea. Indeed, far more is
true: from the proofs of Chapter 2, Bayes’ theorem will lead us to the optimal inferences,
3
whether or not a sufﬁcient statistic exists. So, in Bayesian inference, sufﬁciency is a validconcept; but it is not a fundamental theoretical consideration, only a pleasant convenienceaffecting the amount of computation but not the quality of the inference.
We have seen that sufﬁcient statistics exist for the binomial, rectangular, and Gaussian
sampling distributions. But consider the Cauchy distribution
p(x
1...xn|θI)=n/productdisplay
i=11
π1
1+(xi−θ)2. (8.22)
This does not factor in the manner (8.9), and so there is no sufﬁcient statistic. With a Cauchy
sampling distribution, it appears that no part of the data is irrelevant; every scrap of it isused in Bayesian inference, and it makes a difference in our inferences about θ(that is, in
details of the posterior pdf for θ). Then there can be no satisfactory orthodox estimator for
θ; a single function conveys only one piece of information concerning the data, and misses
(n−1) others, all of which are relevant and used by Bayesian methods.
8.3 Generalized sufﬁciency
What Fisher could not have realized, because of his failure to use priors, is that the proviso
for all priors is essential here. Fisher sufﬁciency, Eq. (8.9), is the strong condition necessary
to achieve property R independently of the prior. But what was realized only recently isthat property R may hold under weaker conditions that depend on which prior we assign.Thus, the notion of sufﬁciency, which originated in the Bayesian considerations of Laplace,actually has a wider meaning in Bayesian inference than in sampling theory.
3That is, optimal in the aforementioned sense that no other procedure can yield unique results while agreeing with our desiderata
of rationality.

<<<PAGE 281>>>

8 Sufﬁciency, ancillarity, and all that 249
To see this, note that, since the integral equations (8.5) are linear, we may think in terms
of linear vector spaces. Let the class of all priors span a function space (Hilbert space) Hof
functions on the parameter space Sθ. If property R holds only for some subclass of priors
f(θ)∈H/primethat span a subspace H/prime⊂H, then in (8.5) it is required only that the projection
ofKi(θ,θ/prime) onto that subspace vanishes. Then Ki(θ,θ/prime) may be an arbitrary function on
the complementary function space ( H−H/prime) of functions orthogonal to H/prime.
This new understanding is that, for some priors, it is possible to have ‘effective sufﬁcient
statistics’, even though a sufﬁcient statistic in the sense of Fisher does not exist. Givenany speciﬁed function r(x
1,..., xn) and sampling density p(x1...xn|θ), this determines a
kernel Ki(θ,θ/prime) which we may construct by (8.6). If this kernel is incomplete (i.e. as ( θ,θ/prime,i)
vary over their range, the kernel, thought of as a set of functions of θ/primeparameterized by
(θ,i), does not span the entire function space H), then the set of simultaneous integral
equations (8.5) has nonvanishing solutions f(θ). If there are non-negative solutions, they
will determine a subclass of priors f(θ) for which rwould play the role of a sufﬁcient
statistic.
Then the possibility seems open that, for different priors, different functions r(x1,..., xn)
of the data may take on the role of sufﬁcient statistics. This means that use of a particular
prior may make certain particular aspects of the data irrelevant. Then a dif ferent prior may
make different aspects of the data irrelevant . One who is not prepared for this may think
that a contradiction or paradox has been found.
This phenomenon is mysterious only for those who think of probability in terms of
frequencies; as soon as we think of probability distributions as carriers of information
the reason for it suddenly seems trivial and obvious. It really amounts to no more thanthe principle of Boolean algebra AA=A; redundant information is not counted twice. A
piece of information in the prior makes a difference in our conclusions only when it tells ussomething that the data do not tell us. Conversely, a piece of information in the data makes adifference in our conclusions only when it tells us something that the prior information doesnot. Any information that is conveyed by both is redundant, and can be removed from eitherone without affecting our conclusions. Thus in Bayesian inference a prior can make someaspect of the data irrelevant simply by conveying some information that is also in the data.
But is this new freedom expressing trivialities, or potentially useful new capabilities for
Bayesian inference, which Fisher and Jeffreys never suspected? To show that we are notjust speculating about an empty case, note that we have already seen an extreme exampleof this phenomenon, in the strange properties that use of the binomial monkey prior had inurn sampling (Chapter 6); it made all of the data irrelevant, although with other priors allof the data were relevant.
8.4 Sufﬁciency plus nuisance parameters
In Section 8.2, the parameter θmight have been multidimensional, and the same general
arguments would go through in the same way. The question becomes much deeper if wenow suppose that there are two parameters θ,ηin the problem, but we are not interested

<<<PAGE 282>>>

250 Part 1 Principles and elementary applications
inη, so for us the question of sufﬁciency concerns only the marginal posterior pdf for θ.
Factoring the prior p(θη|I)=f(θ)g(η|θ), we may write the desired posterior pdf as
h(θ|D)=/integraltext
dηp(θη)f(x1,..., xn|θη)/integraltext/integraltext
dθdηp(θη)f(x1,..., xn|θη)=f(θ)F(x1,..., xn|θ)/integraltext
dθf(θ)F(x1,..., xn|θ), (8.23)
where
F(x1,..., xn|θ)≡/integraldisplay
dηp(η|θI)f(x1,..., xn|θ,η). (8.24)
Since this has the same mathematical form as (8.1), the steps (8.5)–(8.9) may be repeated
and the same result must follow; given any speciﬁed p(η|θI) for which the integral (8.24)
converges, if we then ﬁnd that the marginal distribution for θhas property R for all priors
f(θ), then F(x1,..., xn|θ) must factorize in the form
F(x1,..., xn|θ)=F∗(r|θ)B(x1,..., xn). (8.25)
But the situation is entirely different because F(x1,..., xn|θ) no longer has the meaning of
a sampling density, being a different function for different priors p(η|θI). Now{F,F∗,B}
are all functionals of p(η|θI).4Thus the presence of nuisance parameters changes the
details, but the general phenomenon of sufﬁciency is retained.
8.5 The likelihood principle
In applying Bayes’ theorem, the posterior pdf for a parameter θis always a product of
a prior p(θ|I) and a likelihood function L(θ)∝p(D|θI); the only place where the data
appear is in the latter. Therefore it is manifest that
Within the context of the speciﬁed model , the likelihood function L(θ) from data D
contains all the information about θthat is contained in D.
For us, this is an immediate and mathematically trivial consequence of the product rule of
probability theory, and is no more to be questioned than the multiplication table. Put differ-ently, two data sets D,D
/primethat lead to the same likelihood function to within normalization:
L(θ)=aL/prime(θ), where ‘ a’ is a constant independent of θ, have just the same import for any
inferences about θ, whether it be point estimation, interval estimation, or hypothesis testing.
But for those who think of a probability distribution as a physical phenomenon arising from‘randomness’ rather than a carrier of incomplete information, the above quoted statement –since it involves only the sampling distribution – has a meaning independent of the productrule and Bayes’ theorem. They call it the ‘likelihood principle’, and its status as a validprinciple of inference has been the subject of long controversy, still continuing today.
An elementary argument for the principle, given by George Barnard (1947), is that
irrelevant data ought to cancel out of our inferences. He stated it thus: Suppose that in
4In orthodox statistics, F∗(r|θ) would be interpreted as the sampling density to be expected in a compound experiment in which
θis held ﬁxed but ηis varied at random from one trial to the next, according to the distribution p(η|θI).

<<<PAGE 283>>>

8 Sufﬁciency, ancillarity, and all that 251
addition to obtaining the data Dwe ﬂip a coin and record the result Z=HorT. Then the
sampling probability for all our data becomes, as Barnard would have written it,
p(DZ|θ)=p(D|θ)p(Z). (8.26)
Then he reasoned that, obviously, the result of a coin ﬂip can tell us nothing more about
the parameter θbeyond what the data Dhave to say; and so inference about θbased on
DZought to be exactly the same as inference based on Dalone. From this he drew the
conclusion that constant factors in the likelihood must be irrelevant to inferences; that is,inferences about θmay depend only on the ratios of likelihoods for different values:
L
1
L2=p(DZ|θ1I)
p(DZ|θ2I)=p(D|θ1I)
p(D|θ2I), (8.27)
which are the same whether Zis or is not included. This is commonly held to be the ﬁrst
statement of the likelihood principle by an orthodox statistician. It is just what we consideredobvious already back in Chapter 4, when we noted that a likelihood is not a probabilitybecause its normalization is arbitrary. But not all orthodoxians found Barnard’s argumentconvincing.
Alan Birnbaum (1962) gave the ﬁrst attempted proof of the lik elihood principle to be
generally accepted by orthodox statisticians. From the enthusiastic discussion following
his paper, we see that many regarded this as a major historical event in statistics. He againappeals to coin tossing, but in a different way, through the principle of Fisher suf ﬁciency
plus a ‘conditionality principle’ which appeared to him more primitive:
Conditionality principle
Suppose we can estimate θfrom either of two experiments, E
1andE2. If we ﬂip a coin
to decide which to do, then the information we get about θshould depend only on the
experiment that was actually performed. That is, recognition of an experiment that mighthave been performed, but was not, cannot tell us anything about θ.
But Birnbaum’s argument was not accepted by all orthodox statisticians, and Birnbaum
himself seems to have had later doubts. One can criticize the conditionality principle byasking: ‘How did you choose the experiments E
1,E2?’ Presumably, they were chosen with
some knowledge of their properties. For example, we may know that one kind of experimentmay be very good for small θ, a different one for large θ. Suppose that both E
1andE2are
most accurate for small θand that there is a third experiment E3which is accurate for large
θ. We assume that we chose E1andE2, and the coin ﬂip chose E1. Then the fact that the coin
ﬂip did not choose E2need not make recognition of E2irrelevant to the inference; the very
fact that we included it in our enumeration of experiments worth considering implies someprior knowledge favoring small θ.
In any event, Kempthorne and Folks (1971) and Fraser (1980) continued to attack the
likelihood principle and deny its validity. From his failure to attack it when he was attacking
almost every other principle of inference, we may infer that R. A. Fisher probably accepted

<<<PAGE 284>>>

252 Part 1 Principles and elementary applications
the likelihood principle, although his own procedures did not respect it. But he continued to
denounce the use of Bayes’ theorem on other ideological grounds. For further discussion,see A.W. F. Edwards (1974), or Berger and Wolpert (1988). The issue becomes even morecomplex and confusing in connection with the notion of ancillarity, discussed below.
Orthodoxy is obliged to violate the likelihood principle for three different reasons: (1) its
central dogma that ‘The merit of an estimator is determined by its long-run samplingproperties’, which makes no reference to the likelihood function; (2) its secondary dogmathat the accuracy of an estimate is determined by the width of the sampling distribution forthe estimator, which again takes note of the likelihood principle; and (3) procedures in which‘randomization’ is held to generate the probability distribution used in the inference ! These
are still being taught, and defended vigorously, by people who do not seem to comprehendthat their conclusions are then determined, not by the relevant evidence in the data, butby irrelevant artifacts of the randomization. In Chapter 17 we shall examine the so-called‘randomization tests’ of orthodoxy and see how Bayesian analysis deals with the sameproblems.
Indeed, even coin ﬂip arguments cannot be accepted unconditionally if they are to be
taken literally; particularly by a physicist who is aware of all the complicated things thathappen in real coin ﬂips, as described in Chapter 10. If there is any logical connectionbetween θand the coin, so that knowing θwould tell us anything about the coin ﬂip, then
knowing the result of the coin ﬂip must tell us something about θ. For example, if we are
measuring a gravitational ﬁeld by the period of a pendulum, but the coin is tossed in thatsame gravitational ﬁeld, there is a clear logical connection. Both Barnard’s argument andBirnbaum’s conditionality principle contain an implicit hidden assumption that this is notthe case. Presumably, they would reply that, without saying so explicitly, they really meant‘coin ﬂip’ in a more abstract sense of some binary experiment totally detached from θand
the means of measuring it. But then, the onus was on them to deﬁne exactly what that binaryexperiment was, and they never did this.
In our view, this line of thought takes us off into an inﬁnite regress of irrelevancies;
in our system, the likelihood principle is already proved as an immediate consequence ofthe product rule of probability theory, independently of all considerations of coin ﬂips orany other auxiliary experiment. But for those who ignore Cox’s theorems, ad hoc devices
continue to take precedence over the rules of probability theory, and there is a faction inorthodoxy that still militantly denies the validity of the likelihood principle.
It is important to note that the likelihood principle, like the likelihood function, refers
only to the context of a speciﬁed model which is not being questioned ; seen in a wider
context, it may or may not contain all the information in the data that we need to makethe best estimate of θ, or to decide whether to take more data or stop the experiment now.
Is there additional external evidence that the apparatus is deteriorating? Or, is there reasonto suspect that our model may not be correct? Perhaps a new parameter λis needed. But
to claim that the need for additional information like this is a refutation of the likelihoodprinciple, is only to display a misunderstanding of what the likelihood principle is; it is a‘local’ principle, not a ‘global’ one.

<<<PAGE 285>>>

8 Sufﬁciency, ancillarity, and all that 253
8.6 Ancillarity
Consider estimation of a location parameter θfrom a sampling distribution p(x|θI)=
f(x−θ|I).5Fisher (1934) perceived a strange difﬁculty with orthodox procedures. Choos-
ing some function of the data θ∗(x1,..., xn) as our estimator, two different data sets might
yield the same estimate for θ, yet have very different conﬁgurations (such as range, fourth
central moments, etc.), and must leave us in a very different state of knowledge concern-ingθ. In particular, it seemed that a very broad range and a sharply clustered one might lead
us to the same actual estimate, but they ought to yield very different conclusions as to theaccuracy of that estimate. Yet if we hold that the accuracy of an estimate is determined bythe width of the sampling distribution for the estimator, one is obliged to conclude that allestimates from a given estimator have the same accuracy, regardless of the conﬁguration ofthe sample.
Fisher’s proposed remedy was not to question the orthodox reasoning which caused this
anomaly, but rather to invent still another ad hockery to patch it up: use sampling distributions
conditional on some ‘ancillary’ statistic z(x
1,..., xn) that gives some information about
the data conﬁguration that is not contained in the estimator. In general, a single statisticcannot describe the data conﬁguration fully; this could require as many as ( n−1) ancillary
statistics. But Fisher could not always supply them; often they do not exist, because he also
demanded that the sampling distribution p(z|θI)=p(z|I) for an ancillary statistic must be
independent of θ. We do not know Fisher’s private reason for imposing this independence,
but from a Bayesian viewpoint we can see easily what it accomplishes.
The conditional sampling distribution for the data that Fisher would use is then p(D|zθI).
In orthodox statistics, this changed sampling distribution can in general lead to differentconclusions about θ. But we process this by Bayes’ theorem:
p(D|zθI)=p(zD|θI)
p(z|θI)=p(D|θI)p(z|DθI)
p(z|θI). (8.28)
Now if z=z(D) is a function only of the data, then p(z|DθI) is just a delta-function δ[z−
z(D)]; so, if p(z|θI) is independent of θ, the conditioned sampling distribution p(D|zθI)
has the same θdependence (that is, it yields the same likelihood function) as does the
unconditional sampling distribution p(D|θI). Put differently, from a Bayesian standpoint
what Fisher’s procedure accomplishes is nothing at all; the likelihood L(θ) is unchanged, so
any method of inference – whether for point estimation, interval estimation, or hypothesistesting – that respects the likelihood principle will lead to just the same inferences about θ,
whether or not we condition on an ancillary statistic. Indeed, in Bayesian analysis, if zis
a function only of the data, then the value of zis known from the data, so it is redundant
information; whether it is or is not included also in the prior information cannot matter.This is, again, just the principle AA=Aof elementary logic that we are obliged to stress
so often because orthodoxy does not seem to comprehend its implications.
5For example, if the mean of a set of samples is used as the estimator, then, given a set of samples, the observed variation of the
mean is called the sampling distribution of the mean.

<<<PAGE 286>>>

254 Part 1 Principles and elementary applications
The fact that Fisher obtained different estimates, depending on whether he did or did not
condition on ancillary statistics, indicates only that his unconditioned procedure violatedthe likelihood principle. On the other hand, if we condition on a quantity Zthat is not just
a function of the data, then Zconveys additional information that is not in the data; and we
must expect that in general this willalter our inferences about θ.
Orthodoxy, when asked for the accuracy of the estimate, departs from the likelihood
principle a second time by appealing not to any property of the likelihood function from ourdata set, but rather to the width of the sampling distribution for the estimator – a property ofthat imaginary collection of data sets that one thought might have been observed but werenot. For us, adhering to the likelihood principle, it is the width of the likelihood function,from the one data set that we actually have, that tells us the accuracy of the estimate fromthat data set; imaginary data sets that were not seen are irrelevant to the question we areasking.
6Thus, for a Bayesian the question of ancillarity never comes up at all; we proceed
directly from the statement of the problem to the solution that obeys the likelihood principle.
8.7 Generalized ancillary information
Now let us take a broader view of the notion of ancillary information, as referring not to
Fisher ancillarity (in which the ancillary statistic zis part of the data), but to any additional
quantity Zthat we do not consider part of the prior information or the data. As before, we
deﬁne
θ=parameters (interesting or uninteresting)
E=e1,..., en, noise
D=d1,..., dn,data
di=f(tiθ)+ei,model .(8.29)
But now we add
Z=z1,..., zm ancillary data . (8.30)
We want to estimate θfrom the posterior pdf, p(θ|DZI ), and direct application of Bayes’
theorem gives
p(θ|DZI )=p(θ|I)p(DZ|θI)
p(DZ|I), (8.31)
in which Zappears as part of the data. But now we suppose that Zhas, by itself, no direct
relevance to θ:
p(θ|ZI)=p(θ|I). (8.32)
This is the essence of what Fisher meant by the term ‘ancillary’, although his ideology did
not permit him to state it this way (since he admitted only sampling distributions, he was
6The width of the sampling distribution for the estimator is the answer to a very different question: How would the estimates vary
over the class of all different data sets that we think might have been seen?

<<<PAGE 287>>>

8 Sufﬁciency, ancillarity, and all that 255
obliged to deﬁne all properties in terms of sampling distributions). He would say instead
that ancillary data have a sampling distribution independent of θ:
p(Z|θI)=p(Z|I), (8.33)
which he would interpret as: θexerts no causal physical inﬂuence on Z. But from the
product rule,
p(θZ|I)=p(θ|ZI)p(Z|I)=p(Z|θI)p(θ|I), (8.34)
we see that from the standpoint of probability theory as logic, (8.32) and (8.33) are equiva-
lent; either implies the other. Expanding the likelihood ratio by the product rule and using(8.33),
p(DZ|θI)
p(DZ|I)=p(D|θZI)
p(D|ZI). (8.35)
Then, in view of (8.32), we can rewrite (8.31) equally well as
p(θ|DZI )=p(θ|ZI)p(D|θZI)
p(D|ZI), (8.36)
and now the generalized ancillary information appears to be part of the prior information.
A peculiar property of generalized ancillary information is that the relationship between
θandZis a reciprocal one; had we been interested in estimating Zbut knew θ, then θ
would appear as a ‘generalized ancillary statistic’. To see this most clearly, note that thedeﬁnitions (8.32) and (8.33) of an ancillary statistic are equivalent to the factorization:
p(θZ|I)=p(θ|I)p(Z|I). (8.37)
Now recall how we handled this before, when our likelihood was only
L
0(θ)∝p(D|θI). (8.38)
Because of the model equation (8.29), if θis known, then the probability of getting any
datum diis just the probability that the noise would have made up the difference:
ei=di−f(ti,θ). (8.39)
So if the prior pdf for the noise is a function
p(E|θI)=u(e1,..., en,θ)=u({ei},θ) (8.40)
we have
p(D|θI)=u({di−f(ti,θ)},θ), (8.41)
the same function of {di−f(ti,θ)}. In the special case of a white Gaussian noise pdf
independent of θ, this led to Eq. (7.28).
Our new likelihood function (8.35) can be dealt with in the same way, only in place of
(8.41) we shall have a different noise pdf, conditional on Z. Thus the effect of ancillary

<<<PAGE 288>>>

256 Part 1 Principles and elementary applications
data is simply to update the original noise pdf:
p(E|θI)→p(E|θZI), (8.42)
and in general ancillary data that have any relevance to the noise will affect our estimates
of all parameters through this changed estimate of the noise.
In (8.40)–(8.42) we have included θin the conditioning statement to the right of the
vertical stroke to indicate the most general case. But in all the cases examined in theorthodox literature, knowledge of θwould not be relevant to estimating the noise, so what
they actually did was the replacement
p(E|I)→p(E|ZI) (8.43)
instead of (8.42).
Also, in the cases we have analyzed, this updating is naturally re garded as arising from
a joint sampling distribution, which is a function
p(DZ|I)=w(e
1,..., en,z1,..., zm). (8.44)
The previous noise pdf (8.40) is then a marginal distribution of (8.44):
p(D|I)=u(e1···en)=/integraldisplay
dz1···dzmw(e1,..., en,z1,..., zm), (8.45)
the prior pdf for the ancillary data is another marginal distribution:
p(Z|I)=/integraldisplay
de1···denw(e1,..., en,z1,..., zm), (8.46)
and the conditional distribution is
p(D|ZI)=p(DZ|I)
p(Z|I)=w(ei,zj)
v(zj). (8.47)
Fisher’s original application, and the ironic lesson it had for the relation of Bayesian and sam-
pling theory methods, is explained in the Comments at the end of this chapter, Section 8.12.
8.8 Asymptotic likelihood: Fisher information
Given a data set D≡{x1,..., xn}, the log likelihood is
1
nlogL(θ)=1
nn/summationdisplay
i=1logp(xi|θ). (8.48)
What happens to this function as we accumulate more and more data? The usual assumption
is that, as n→∞ , the sampling distribution p(x|θ) is actually equal to the limiting relative
frequencies of the various data values xi. We know of no case where one could actually
know this to be true in the real world; so the following heuristic argument is all that is

<<<PAGE 289>>>

8 Sufﬁciency, ancillarity, and all that 257
justiﬁed. If this assumption were true, then we would have asymptotically, as n→∞ ,
1
nlogL(θ)→/integraldisplay
dxp(x|θ0) log p(x|θ), (8.49)
where θ0is the ‘true’ value, presumed unknown. Denoting the entropy of the ‘true’ den-
sity by
H0=−/integraldisplay
dxp(x|θ0) log p(x|θ0), (8.50)
we have for the asymptotic likelihood function
1
nlogL(θ)+H0=/integraldisplay
dxp(x|θ0) log/bracketleftbiggp(x|θ)
p(x|θ0)/bracketrightbigg
≤0, (8.51)
where, letting q≡p(x|θ0)/p(x|θ), we used the fact that, for positive real q,w eh a v e
log(q)≤q−1,with equality if and only if q=1. Thus we have equality in (8.51) if and
only if p(x|θ)=p(x|θ0) for allxfor which p(x|θ0)>0. But if two different values θ,θ0
of the parameter lead to identical sampling distributions, then they are confounded: the data
cannot distinguish between them. If the parameter is always ‘identiﬁed’, in the sense that
different values of θalways lead to different sampling distributions for the data, then we
have equality in (8.51) if and only if θ=θ0, so the asymptotic likelihood function L(θ)
reaches its maximum at the unique point θ=θ0.
Supposing the parameter multidimensional: θ≡{θ1,...,θ m}and expanding about this
maximum, we have
logp(x|θ)=logp(x|θ0)−1
2m/summationdisplay
i,j=1∂2logp(x|θ)
∂θi∂θjδθiδθj (8.52)
or
1
nlog/bracketleftbiggL(θ)
L(θ0)/bracketrightbigg
=−1
2/summationdisplay
ijIijδθiδθj, (8.53)
where
Iij≡/integraldisplay
dnxp(x|θ0)∂2logp(x|θ)
∂θi∂θj(8.54)
is called the Fisher information matrix . It is a useful measure of the ‘resolving power’ of the
experiment; that is, considering two close values θ,θ/prime, how big must the separation |θ−θ/prime|
be in order that the experiment can distinguish between them?
8.9 Combining evidence from different sources
We all know that there are good and bad experiments. The latter accumulate in vain. Whether there are
a hundred or a thousand, one single piece of work by a real master – by a Pasteur, for example – willbe sufﬁcient to sweep them into oblivion.
Henri Poincar ´e (1904, p. 141)

<<<PAGE 290>>>

258 Part 1 Principles and elementary applications
We all feel intuitively that the totality of evidence from a number of experiments ought to
enable better inferences about a parameter than does the evidence of any one experiment.But intuition is not powerful enough to tell us when this is valid. One might think na¨ ıvely
that if we have 25 experiments, each yielding conclusions with an accuracy of ±10%, then
by averaging them we get an accuracy of ±10/√
25=±2%. This seems to be supposed by
a method currently in use in psychology and sociology, called meta-analysis (Hedges andOlkin, 1985). Probability theory as logic shows clearly how and under what circumstancesit is safe to combine this evidence.
The classical example showing the error of uncritical reasoning here is the old fable about
the height of the Emperor of China. Supposing that each person in China surely knows theheight of the Emperor to an accuracy of at least ±1 meter; if there are N=1 000 000 000
inhabitants, then it seems that we could determine his height to an accuracy at least asgood as
1
√
1 000 000 000m=3×10−5m=0.03 mm , (8.55)
merely by asking each person’s opinion and averaging the results.
The absurdity of the conclusion tells us rather forcefully that the√
Nrule is not always
valid, even when the separate data values are causally independent; it is essential that theybelogically independent. In this case, we know that the vast majority of the inhabitants
of China have never seen the Emperor; yet they have been discussing the Emperor amongthemselves, and some kind of mental image of him has evolved as folklore. Then, knowledgeof the answer given by one does tell us something about the answer likely to be given byanother, so they are not logically independent. Indeed, folklore has almost surely generateda systematic error, which survives the averaging; thus the above estimate would tell ussomething about the folklore, but almost nothing about the Emperor.
We could put it roughly as follows:
error in estimate=S±R
√
N, (8.56)
where Sis the common systematic error in each datum, Ris the RMS ‘random’ error in the
individual data values. Uninformed opinions, even though they may agree well among them-selves, are nearly worthless as evidence. Therefore sound scientiﬁc inference demands that,when this is a possibility, we use a form of probability theory (i.e., a probabilistic model)which is sophisticated enough to detect this situation and make allowances for it.
As a start on this, (8.56) gives us a crude but useful rule of thumb; it shows that, unless
weknow that the systematic error is less than about one-third of the random error, we
cannot be sure that the average of one million data values is any more accurate or reliablethan the average of ten. As Henri Poincar´ e put it: ‘The physicist is persuaded that one
good measurement is worth many bad ones.’ Indeed, this has been well recognized byexperimental physicists for generations; but warnings about it are conspicuously missing

<<<PAGE 291>>>

8 Sufﬁciency, ancillarity, and all that 259
from textbooks written by statisticians, and so it is not sufﬁciently recognized in the ‘soft’
sciences whose practitioners are educated from those textbooks.
Let us investigate this more carefully using probability theory as logic. Firstly we recall
the chain consistency property of Bayes’ theorem. Suppose we seek to judge the truth ofsome hypothesis H, and we have two experiments which yield data sets A,B, respectively.
With prior information I, from the ﬁrst we would conclude
p(H|AI)=p(H|I)p(A|HI)
p(A|I). (8.57)
Then this serves as the prior probability when we obtain the new data B:
p(H|ABI )=p(H|AI)p(B|AHI )
p(B|AI)=p(H|I)p(A|HI)p(B|AHI )
p(A|I)p(B|AI). (8.58)
But
p(A|HI)p(B|AHI )=p(AB|HI)
p(A|I)p(B|AI)=p(AB|I),(8.59)
so (8.58) reduces to
p(H|ABI )=p(H|I)p(AB|HI)
p(AB|I), (8.60)
which is just what we would have found had we used the total evidence C=ABin a single
application of Bayes’ theorem. This is the chain consistency property. We see from this thatit is valid to combine the evidence from several experiments if:
(1) the prior information Iis the same in all;
(2) the prior for each experiment includes also the results of the earlier ones.
To study one condition a time, let us leave it as an exercise for the reader to examine the
effect of violating (1), and suppose for now that we obey (1) but not (2), but we have fromthe second experiment alone the conclusion
p(H|BI)=p(H|I)p(B|HI)
p(B|I). (8.61)
Is it possible to combine the conclusions (8.57) and (8.61) of the two experiments into a
single more reliable conclusion? It is evident from (8.58) that this cannot be done in general;it is not possible to obtain p(H|ABI ) as a function of the form
p(H|ABI )=f[p(H|AI),p(H|BI)], (8.62)
because this requires information not contained in either of the arguments of that function.
But if it is true that p(B|AHI )=p(B|HI), then from the product rule written in the form
p(AB|I)=p(A|BHI )p(B|HI)=p(B|AHI )p(A|HI), (8.63)

<<<PAGE 292>>>

260 Part 1 Principles and elementary applications
Table 8.1. Experiment A.
Failures Successes Success (%)
Old 16 519 4343 20.8 ±0.28
New 742 122 14.1 ±1.10
Table 8.2. Experiment B.
Failures Successes Success (%)
Old 3876 14 488 78.9 ±0.30
New 1233 3907 76.0 ±0.60
it follows that p(A|BHI )=p(A|HI), and this will work. For this, the data sets A,Bmust
be logically independent in the sense that, given HandI,knowing either data set would
tell us nothing about the other .
If we do have this logical independence, then it is valid to combine the results of the
experiments in the above na¨ ıve way, and we will in general improve our inferences by so
doing. Meta-analysis, applied without regard to these necessary conditions, can be utterly
misleading.
At this point, we are beginning to see the kind of dangerous nonsense that can be produced
by those who fail to distinguish between causal independence and logical independence.
But the situation is still more subtle and dangerous; suppose one tried to circumvent this
by pooling all the data before analyzing them; that is, using (8.60). Let us see what couldhappen to us.
8.10 Pooling the data
The following data are real, but the circumstances were more complicated than supposed
in the following scenario. Patients were given either of two treatments, the old one and anew one, and the number of successes (recoveries) and failures (deaths) were recorded. Inexperiment A the data were as given in Table 8.1. In which the entries in the last column areof the form 100×[p±√
p(1−p)/n], indicating the standard deviation to be expected
from binomial sampling. Experiment B, conducted two years later, yielded the data givenin Table 8.2. In each experiment, the old treatment appeared slightly but signiﬁcantly better(that is, the differences in pwere greater than the standard deviations). The results were
very discouraging to the researchers.
But then one of them had a brilliant idea: let us pool the data, simply adding up in
the manner 4343+14 488=18 831, etc. Then we have the contingency table, Table 8.3.
Now the new treatment appears much better with overwhelmingly high signiﬁcance (thedifference is over 20 times the sum of the standard deviations)! They eagerly publish this

<<<PAGE 293>>>

8 Sufﬁciency, ancillarity, and all that 261
Table 8.3. Pooled data.
Failures Successes Success (%)
Old 20 395 18 831 48.0 ±0.25
New 1975 4029 67.1 ±0.61
gratifying conclusion, presenting only the pooled data; and become (for a short time) famous
as great discoverers.
How is such an anomaly possible with such innocent looking data? How can two data
sets, each supporting the same conclusion, support the opposite conclusion when pooled?Let the reader, before proceeding, ponder these tables and form your own opinion of whatis happening.
The point is that an extra parameter is clearly present. Both treatments yielded much
better results two years later. This unexpected fact is, evidently, far more important than therelatively small differences in the treatments. Nothing in the data per se tells us the reason
for this (better control over procedures, selection of promising patients for testing, etc.) andonly prior information about further circumstances of the tests can suggest a reason.
Pooling the data under these conditions introduces a very misleading bias; the new
treatment appears better simply because, in the second experiment, six times as manypatients were given the new treatment, while fewer were given the old one. The correctconclusion from these data is that the old treatment remains noticeably better than the newone; but another factor is present that is vastly more important than the treatment.
We conclude from this example that pooling the data to estimate a parameter θis not
permissible if the separate experiments involve other parameters ( α, β, . . . ) which can be
different in different experiments. In (8.61)–(8.63) we supposed (by failing to mention them)that no such parameters were present, but real experiments almost always have nuisanceparameters which are eliminated separately in drawing conclusions.
In summary, the meta-analysis procedure is not necessarily wrong; but when applied
without regard to these necessary qualiﬁcations it can lead to disaster. But we do not seehow anybody could have found all these qualiﬁcations by intuition alone. Without theBayesian analysis there is almost no chance that one could apply meta-analysis safely; thesafe procedure is not to mention meta-analysis at all as if it were a new principle, but simplyto apply probability theory with strict adherence to our Chapter 2 rules . Whenever meta-
analysis is appropriate, the full Bayesian procedure automatically reduces to meta-analysis.
8.10.1 Fine-grained propositions
One objection that has been raised to probability theory as logic notes a supposed technical
difﬁculty in setting up problems. In fact, many seem to be perplexed by it, so let us examinethe problem and its resolution.

<<<PAGE 294>>>

262 Part 1 Principles and elementary applications
The Venn diagram mentality, noted at the end of Chapter 2, supposes that every probability
must be expressed as an additive measure on some set; or, equivalently, that every propositionto which we assign a probability must be resolved into a disjunction of elementary ‘atomic’propositions. Carrying this supposition over into the Bayesian ﬁeld has led some to rejectBayesian methods on the grounds that, in order to assign a meaningful prior probabilityto some proposition such as W≡the dog walks, we would be obliged to resolve it into a
disjunction W=W
1+W2+··· of every conceivable subproposition about how the dog
does this, such as
W1≡ﬁrst it moves the right forepaw, then the left hindleg, then . . .
W2≡ﬁrst it moves the right forepaw, then the right hindleg, then. . .
...
This can be done in any number of different ways, and there is no principle that tells
us which resolution is ‘right’. Having deﬁned these subpropositions somehow, there isno evident element of symmetry that could tell us which ones should be assigned equalprior probabilities. Even the professed Bayesian L. J. Savage (1954, 1961, 1962) raisedthis objection, and thought that it made it impossible to assign priors by the principle ofindifference. Curiously, those who reasoned this way seem never to have been concernedabout how the orthodox probabilist is to deﬁne his‘universal set’ of atomic propositions,
which performs for him the same function as would that inﬁnitely ﬁne-grained resolutionof the dog’s movements.
8.11 Sam’s broken thermometer
If Sam, in analyzing his data to test his pet theory, wants to entertain the possibility that his
thermometer is broken, does he need to enumerate every conceivable way in which it couldbe broken? The answer is not intuitively obvious at ﬁrst glance, so let
A≡Sam’s pet theory,
H
o≡the thermometer is working properly,
Hi≡the thermometer is broken in the ith way, 1≤i≤n,
where, perhaps, n=1000. Then, although
p(A|DH 0I)=p(A|H0I)p(D|AH 0I)
p(D|H0I)(8.64)
is the Bayesian calculation Sam would like to do, it seems that honesty compels him to note
1000 other possibilities {H1,..., Hn}, and so he must do the calculation
p(A|DI)=n/summationdisplay
i=0p(AH i|DI)=p(A|H0DI)p(H0|I)+n/summationdisplay
i=1p(A|HiDI)p(Hi|DI).
(8.65)

<<<PAGE 295>>>

8 Sufﬁciency, ancillarity, and all that 263
Now expand the last term by Bayes’ theorem:
p(A|HiDI)=p(A|HiI)p(D|AH iI)
p(D|HiI)(8.66)
p(Hi|DI)=p(Hi|I)p(D|HiI)
p(D|I). (8.67)
Presumably, knowing the condition of his thermometer does not in itself tell Sam anything
about the status of his pet theory, so
p(A|HiI)=p(A|I), 0≤i≤n. (8.68)
But if he knew the thermometer was broken, then the data would tell him nothing about his
pet theory (all this is supposed to be contained in the prior information I):
p(A|HiDI)=p(A|HiI)=p(A|I), 1≤i≤n. (8.69)
Then from (8.66), (8.68) and (8.69) we have
p(D|AH iI)=p(D|HiI), 1≤i≤n. (8.70)
That is, if he knows the thermometer is broken, and as a result the data can tell him nothing
about his pet theory, then his probability of getting those data cannot depend on whether
his pet theory is true. Then (8.65) reduces to
p(A|DI)=p(A|I)
p(D|I)/bracketleftBigg
p(D|AH 0I)p(H0I)+n/summationdisplay
i=1p(D|HiI)p(Hi|I)/bracketrightBigg
. (8.71)
From this, we see that if the different ways of being broken do not in themselves tell him
different things about the data,
p(D|HiI)=p(D|H1I), 1≤i≤n, (8.72)
then enumeration of the ndifferent ways of being broken is unnecessary; the calculation
reduces to ﬁnding the likelihood
L≡p(D|AH 0I)p(H0|I)+p(D|H1I)[1−p(H0|I)] (8.73)
and only the total probability of being brok en,
p(H0|I)=n/summationdisplay
i=1p(Hi|I)=1−p(H0|I), (8.74)
is relevant. Sam does not need to enumerate 1000 possibilities. But if p(D|HiI) can depend
oni, then the sum in (8.71) should be over those Hithat lead to different p(D|HiI). That
is, information contained in the variations of p(D|HiI) would be relevant to his inference,
and so they should be taken into account in a full calculation.

<<<PAGE 296>>>

264 Part 1 Principles and elementary applications
Contemplating this argument, common sense now tells us that this conclusion should
have been ‘obvious’ from the start. Quite generally, enumeration of a large number of ‘ﬁne-grained’ propositions and assigning prior probabilities to all of them is necessary only ifthe breakdown into those ﬁne details contains information relevant to the question beingasked. If they do not, then only the disjunction of all of the propositions is relevant to ourproblem, and we need only assign a prior probability directly to it.
In practice, this means that in a real problem there will be some natural end to the process
of introducing ﬁner and ﬁner subpropositions; not because it is wrong to introduce them,but because it is unnecessary and it contributes nothing to the solution of the problem. Thedifﬁculty feared by Savage does not arise in real problems; and this is one of the manyreasons why our policy of assigning probabilities on ﬁnite sets succeeds in the real world.
8.12 Comments
There are still a number of interesting special circumstances, less important technically but
calling for short discussions.
Trying to conduct inference by inventing intuitive ad hoc devices instead of applying
probability theory has become such a deeply ingrained habit among those with con ventional
training that, even after seeing the Cox theorems and the applications of probability theory
as logic, many fail to appreciate what has been shown, and persist in trying to improve theresults – without acquiring any more information – by adding further ad hoc devices to the
rules of probability theory. We offer here three observations intended to discourage suchefforts, by noting what information is and is not contained in our equations.
8.12.1 The fallacy of sample re-use
Richard Cox’s theorems show that, given certain data and prior information D,I,a n y
procedure which leads to a different conclusion than that of Bayes’ theorem, will necessarilyviolate some very elementary desideratum of consistency and rationality. This implies that asingle application of Bayes’ theorem with given D,Iwill extract all the information that is
inD,I, relevant to the question being asked. Furthermore, we have already stressed that, if
we apply probability theory correctly, there is no need to check whether the different piecesof information used are logically independent; any redundant information will cancel outand will not be used twice.
7
The feeling persists that, somehow, using the same data again in some other procedure
might extract still more information from Dthat Bayes’ theorem has missed the ﬁrst time,
and thus improve our ultimate inferences from D. Since there is no end to the conceivable
arbitrary devices that might be invented, we see no way to prove once and for all that nosuch attempt will succeed, other than pointing to Cox’s theorems. But for any particulardevice we can always ﬁnd a direct proof that it will not work; that is, the device cannot
7Indeed, this is a property of any algorithm, in or out of probability theory, which can be derived from a constrained variational
principle, because adding a new constraint cannot change the solution if the old solution already satisﬁed that constraint.

<<<PAGE 297>>>

8 Sufﬁciency, ancillarity, and all that 265
change our conclusions unless it also violates one of our Chapter 2 desiderata of rationality.
We consider one commonly encountered example.
Having applied Bayes’ theorem with given D,Ito ﬁnd the posterior probability
p(θ|DI)=p(θ|I)p(D|θI)
p(D|I)(8.75)
for some parameter θ, suppose we decide to introduce some additional evidence E. Then
another application of Bayes’ theorem updates that conclusion to
p(θ|EDI )=p(θ|DI)p(E|θDI)
p(E|DI), (8.76)
so the necessary and sufﬁcient condition that the new information will change our conclu-
sions is that, on some region of the parameter space of positive measure, the likelihood ratio
in (8.76) differs from unity:
p(E|θDI)/negationslash=p(E|DI). (8.77)
But if the evidence Ewas something already implied by the data and prior information,
then
p(E|θDI)=p(E|DI)=1, (8.78)
and Bayes’ theorem conﬁrms that re-using redundant information cannot change the results.
This is really only the principle of elementary logic: AA=A.
There is a famous case in which it appeared at ﬁrst glance that one actually did get
important improvement in this way; this leads us to recognize that the meaning of ‘logical
independence’ is subtle and crucial. Suppose we take E=D; we simply use the same data
set twice. But we act as if the second Dwere logically independent of the ﬁrst D; that is,
although they are the same data, let us call them D∗the second time we use them. Then we
simply ignore the fact that DandD∗are actually one and the same data set, and instead of
(8.76)–(8.78) we take, in violation of the rules of probability theory,
p(D∗|DI)=p(D∗|I) and p(D∗|θDI)=p(D∗|θI). (8.79)
Then the likelihood ratio in (8.76) is the same as in the ﬁrst application of Bayes’ theo-
rem, (8.75). We have squared the likelihood function, thus achieving a sharper posteriordistribution with apparently more accurate estimate of θ!
It is evident that a fraud is being perpetrated here; by the same argument we could re-use
the same data any number of times, thus raising the likelihood function to an arbitrarilyhigh power, and seemingly getting arbitrarily accurate estimates of θ– all from the same
original data set Dwhich might consist of only one or two observations.
If we actually had two different data sets D,D
∗which were logically independent ,i n
the sense that knowing one would tell us nothing about the other – but which happenedto be numerically identical – then indeed (8.79) would be valid, and the correct likelihoodfunction from the two data sets would be the square of the likelihood from one of them.

<<<PAGE 298>>>

266 Part 1 Principles and elementary applications
Therefore the fraudulent procedure is, in effect, claiming to have twice as many observations
as we really have. One can ﬁnd this procedure actually used and advocated in the literature,in the guise of a ‘data dependent prior’ (Akaike, 1980). This is also close to the topic of‘meta-analysis’ discussed earlier, where ludicrous errors can result from failure to perceivethe logical dependence of different data sets which are causally independent.
The most egregious example of attempted sample re-use is in the aforementioned ‘ran-
domization tests’, in which every one of the n! permutations of the data is thought to
contain new evidence relevant to the problem! We examine this astonishing view and itsconsequences in Chapter 17.
8.12.2 A folk theorem
In ordinary algebra, suppose that we have a number of unknowns {x
1,..., xn}in some
domain Xto be determined, and are given the values of mfunctions of them:
y1=f1(x1,..., xn)
y2=f2(x1,..., xn)
...
ym=fm(x1,..., xn).(8.80)
Ifm=nand the Jacobian ∂(y1,..., yn)/∂(x1,..., xn) is not zero, then we can in principle
solve for the xiuniquely. But if m<nthe system is underdetermined; one cannot ﬁnd all
thexibecause the information is insufﬁcient.
It appears that this well-known theorem of algebra has metamorphosed into a popular
folk theorem of probability theory. Many authors state, as if it were an evident truth, thatfrom mobservations one cannot estimate more than mparameters. Authors with the widest
divergence of viewpoints in other matters seem to be agreed on this. Therefore we almosthesitate to point out the obvious; that nothing in probability theory places any such limitationon us. In probability theory, as our data tend to zero, the effect is not that fewer and fewerparameters can be estimated; given a single observation, nothing prevents us from estimatinga million different parameters. What happens as our data tend to zero is that those estimatesjust relax back to the prior estimates, as common sense tells us they must.
There may still be a grain of truth in this, however, if we consider a slightly different
scenario; instead of varying the amount of data for a ﬁxed number of parameters, supposewe vary the number of parameters for a ﬁxed amount of data. Then does the accuracy ofour estimate of one parameter depend on how many other parameters we are estimating?We note verbally what one ﬁnds, leaving it as an exercise for the reader to write down thedetailed equations. The answer depends on how the sampling distributions change as weadd new parameters; are the posterior pdfs for the parameters independent? If so, then ourestimate of one parameter cannot depend on how many others are present.
But if in adding new parameters they all get correlated in the posterior pdf, then the
estimate of one parameter θmight be greatly degraded by the presence of others (uncertainty
in the values of the other parameters could then ‘leak over’ and contribute to the uncertainty

<<<PAGE 299>>>

8 Sufﬁciency, ancillarity, and all that 267
inθ). In that case, it may be that some function of the parameters can be estimated more
accurately than can any one of them. For example, if two parameters have a high negativecorrelation in the posterior pdf, then their sum can be estimated much more accurately thancan their difference.
8All these subtleties are lost on orthodox statistics, which does not
recognize even the concept of correlations in a posterior pdf.
8.12.3 Effect of prior information
As we noted above, it is obvious, from the general principle of non-use of redundant
information AA=A, that our data make a difference only when they tell us something
that our prior information does not. It should be (but apparently is not) equally obvious thatprior information makes a difference only when it tells us something that the data do not.Therefore, whether our prior information is or is not important can depend on which data
set we get. For example, suppose we are estimating a general parameter θ, and we know
in advance that θ< 6. If the data lead to a negligible likelihood in the region θ> 6, then
that prior information has no effect on our conclusions. Only if the data alone would haveindicated appreciable likelihood in θ> 6 does the prior information matter.
But consider the opposite extreme: if the data placed practically all the likelihood in the
region θ> 6, then the prior information would have overwhelming importance and the robot
would be led to an estimate very nearly θ
∗=6, determined almost entirely by the prior
information. But in that case the evidence of the data strongly contradicts the prior infor-mation, and we would become skeptical about the correctness of the prior information,the model, or the data. This is another case where astonishing new information may causeresurrection of alternative hypotheses that we always have lurking somewhere in our minds.
The robot, by design, has no creative imagination and always believes literally what we
tell it; and so, if we fail to tell it about any alternative hypotheses, it will continue to giveus the best estimates based on unquestioning acceptance of the hypothesis space that wegave it – right up to the point where the data and the prior information become logicallycontradictory – at which point, as noted at the end of Chapter 2, the robot crashes.
In principle, a single data point could determine accurate values of a million parameters.
For example, if a function f(x
1,x2,...) of one million variables takes on the value√
2 only
at a single point, and we learn that f=√
2 exactly, then we have determined one million
variables exactly. Or, if a single parameter is determined to an accuracy of 12 decimal digits,a simple mapping can convert this into estimates of six parameters to two digits each. Butthis gets us into the subject of ‘algorithmic complexity’, which is not our present topic.
8.12.4 Clever tricks and gamesmanship
Two very different attitudes toward the technical workings of mathematics are found in the
literature. In 1761, Leonhard Euler complained about isolated results which ‘are not based
8We shall see this in Chapter 18, in the theory of seasonal adjustment in economics. The phenomenon is demonstrated and
discussed in detail in Jaynes (1985e); conventional non-Bayesian seasonal adjustment loses important information here.

<<<PAGE 300>>>

268 Part 1 Principles and elementary applications
on a systematic method’ and therefore whose ‘inner grounds seem to be hidden’. Yet in the
20th century, writers as diverse in viewpoint as Feller and de Finetti are agreed in consideringcomputation of a result by direct application of the systematic rules of probability theoryas dull and unimaginative, and revel in the ﬁnding of some isolated clever trick by whichone can see the answer to a problem without any calculation.
For example, Peter and Paul toss a coin alternately starting with Peter, and the one who
ﬁrst tosses ‘heads’ wins. What are the probabilities p,p
/primefor Peter or Paul to win? The
direct, systematic computation would sum (1 /2)nover the odd and even integers:
p=∞/summationdisplay
n=01
22n+1=2
3, p/prime=∞/summationdisplay
n=11
22n=1
3. (8.81)
The clever trick notes instead that Paul will ﬁnd himself in Peter’s shoes if Peter fails to
win on the ﬁrst toss: ergo,p/prime=p/2, so p=2/3,p/prime=1/3.
Feller’s perception was so keen that in virtually every problem he was able to see a clever
trick; and then gave only the clever trick. So his readers get the impression that:
(1) probability theory has no systematic methods; it is a collection of isolated, unrelated clever tricks,
each of which works on one problem but not on the next one;
(2) Feller was possessed of superhuman cleverness;(3) only a person with such cleverness can hope to ﬁnd new useful results in probability theory.
Indeed, clever tricks do have an aesthetic quality that we all appreciate at once. But we
doubt whether Feller, or anyone else, was able to see those tricks on ﬁrst looking at theproblem.
We solve a problem for the ﬁrst time by that (perhaps dull to some) direct calculation
applying our systematic rules. After seeing the solution, we may contemplate it and see a
clever trick that would have led us to the answer much more quickly. Then, of course, wehave the opportunity for gamesmanship by showing others only the clever trick, scorningto mention the base means by which we ﬁrst found the answer. But while this may give aboost to our ego, it does not help anyone else.
Therefore we shall continue expounding the systematic calculation methods, because
they are the only ones which are guaranteed to ﬁnd the solution. Also, we try to emphasizegeneral mathematical techniques which will work not only on our present problem, but on
hundreds of others. We do this even if the current problem is so simple that it does not
require those general techniques. Thus we develop the very powerful algorithms involvinggroup invariance, partition functions, entropy, and Bayes’ theorem, that do not appear at allin Feller’s work. For us, as for Euler, these are the solid meat of the subject, which make itunnecessary to discover a different new clever trick for each new problem.
We learned this policy from the example of George P´ olya. For a century, mathematicians
had been, seemingly, doing their best to conceal the fact that they were ﬁnding their theoremsﬁrst by the base methods of plausible conjecture, and only afterward ﬁnding the ‘clever trick’of an effortless, rigorous proof. P´ olya (1954) gave away the secret in his Mathematics and
Plausible Reasoning , which was a major stimulus for the present work.

<<<PAGE 301>>>

8 Sufﬁciency, ancillarity, and all that 269
Clever tricks are always pleasant diversions, and useful in a temporary way, when we want
only to convince someone as quickly as possible. Also, they can be valuable in understandinga result; having found a solution by tedious calculation, if we can then see a simple wayof looking at it that would have led to the same result in a few lines, this is almost sure togive us a greater conﬁdence in the correctness of the result, and an intuitive understandingof how to generalize it. We point this out many times in the present work. But the road tosuccess in probability theory goes ﬁrst through mastery of the general, systematic methodsof permanent value. For a teacher, therefore, maturity is largely a matter of overcoming theurge to gamesmanship.

<<<PAGE 302>>>

9
Repetitive experiments: probability and frequency
The essence of the present theory is that no probability, direct, prior, or
posterior, is simply a frequenc y.
H. Jeffreys (1939)
We have developed probability theory as a generalized logic of plausible inference which
should apply, in principle, to any situation where we do not have enough information topermit deductive reasoning. We have seen it applied successfully in simple prototype exam-ples of nearly all the current problems of inference, including sampling theory, hypothesistesting, and parameter estimation.
Most of probability theory, however, as treated in the past 100 years, has conﬁned attention
to a special case of this, in which one tries to predict the results of, or draw inferences
from, some experiment that can be repeated indeﬁnitely under what appear to be identicalconditions; but which nevertheless persists in giving different results on different trials.
Indeed, virtually all application-oriented expositions deﬁne probability as meaning ‘limiting
frequency in independent repetitions of a random experiment’ rather than as an element oflogic. The mathematically oriented often deﬁne it more abstractly, merely as an additivemeasure, without any speciﬁc connection to the real world. However, when they turn toapplications, they too tend to think of probability in terms of frequency. It is important thatwe understand the exact relationship between these conventional treatments and the theorybeing developed here.
Some of these relationships have been seen already; in the preceding ﬁve chapters we
have shown that probability theory as logic can be applied consistently in many problemsof inference that do not ﬁt into the frequentist preconceptions, and so would be consideredbeyond the scope of probability theory. Evidently, the problems that can be solved byfrequentist probability theory form a subclass of those that are amenable to probabilitytheory as logic, but it is not yet clear just what that subclass is. In the present chapter weseek to clarify this, with some surprising results, including a better understanding of therole of induction in science.
There are also many problems where the attempt to use frequentist probability theory in
inference leads to nonsense or disaster. We postpone examination of this pathology to laterchapters, particularly Chapter 17.
270

<<<PAGE 303>>>

9 Repetitive experiments: probability and frequency 271
9.1 Physical experiments
Our ﬁrst example of such a repetitive experiment appeared in Chapter 3, where we consid-
ered sampling with replacement from an urn, and noted that even there great complicationsarise. But we managed to muddle our way through them by the conceptual device of‘randomization’ which, although ill-deﬁned, had enough intuitive force to overcome thefundamental lack of logical justiﬁcation.
Now we want to consider general repetitive experiments where there need not be any
resemblance to drawing from an urn, and for which those complications may be far greaterand more diverse than they were for the urn. But at least we know that any such experimentis subject to physical law. If it consists of tossing a coin or die, it will surely conformto the laws of Newtonian mechanics, well known for 300 years. If it consists of giving anew medicine to a variety of patients, the principles of biochemistry and physiology, only
partially understood at present, surely determine the possible effects that can be observed.
An experiment in high-energy elementary particle physics is subject to physical laws aboutwhich we are about equally ignorant; but even here well-established general principles(conservation of charge, angular momentum, etc.) restrict the possibilities.
Clearly, competent inferences about any such experiment must take into account whatever
is currently known concerning the physical laws that apply to the situation. Generally, thisknowledge will determine the ‘model’ that we prescribe in the statement of the problem.If one fails to take account of the real physical situation and the known physical laws that
apply, then the most impeccably rigorous mathematics from that point on will not guardagainst producing nonsense or worse. The literature gives much testimony to this.
In any repeatable experiment or measurement, some relevant factors are the same at
each trial (whether or not the experimenter is consciously trying to hold them constant –
or is even consciously aware of them), and some vary in a way not under the control ofthe experimenter. Those factors that are the same (whether from the experimenter’s goodcontrol of conditions or from his failure to inﬂuence them at all) are called systematic .
Those factors which vary in an uncontrolled way are often called random , a term which we
shall usually avoid, because in current English usage it carries some very wrong con-notations.
1We should call them, rather, irreproducible by the experimental technique
used. They might become reproducible by an improved technique; indeed, the progress
of all areas of experimental science involves the continual development of more power-ful techniques that exert ﬁner control over conditions, making more effects reproducible.Once a phenomenon becomes reproducible, as has happened in molecular biology, itemerges from the cloud of speculation and fantasy to become a respectable part of ‘hard’science.
In this chapter we examine in detail how our robot reasons about a repetitive experiment.
Our aim is to ﬁnd the logical relations between the information it has and the kind of
1To many, the term ‘random’ signiﬁes on the one hand lack of physical determination of the individual results, but, at the same
time, operation of a physically real ‘propensity’ rigidly ﬁxing long-run frequencies. Naturally, such a self-contradictory view
of things gives rise to endless conceptual difﬁculties and confusion throughout the literature of every ﬁeld that uses probabilitytheory. We note some typical examples in Chapter 10, where we confront this idea of ‘randomness’ with the laws of physics.

<<<PAGE 304>>>

272 Part 1 Principles and elementary applications
predictions it is able to make. Let our experiment consist of ntrials, with mpossible
results at each trial; if it consists of tossing a coin, then m=2; for a die, m=6. If we are
administering a vaccine to a sequence of patients, then mis the number of distinguishable
reactions to the treatment, nis the number of patients, etc.
At this point, one would say, conventionally, something like: ‘Each trial is capable of
giving any one of mpossible results, so in ntrials there are N=mndifferent conceivable
outcomes.’ However, the exact meaning of this is not clear: is it a statement or an assumptionof physical fact, or only a description of the robot’s information? The content and range ofvalidity of what we are doing depends on the answer.
The number mmay be regarded, always, as a description of the state of knowledge in
which we conduct a probability analysis; but this may or may not correspond to the numberof real possibilities actually existing in Nature. On examining a cubical die, we feel ratherconﬁdent in taking m=6; but in general we cannot know in advance how many different
results are possible. Some of the most important problems of inference are of the ‘CharlesDarwin’ type.
Exercise 9.1. When Charles Darwin ﬁrst landed on the Galapagos Islands in
September 1835, he had no idea how many different species of plants he wouldﬁnd there. Having examined n=122 specimens, and ﬁnding that they can be clas-
siﬁed into m=19 different species, what is the probability that there are still more
species, as yet unobserved? At what point does one decide to stop collecting speci-
mens because it is unlikely that anything more will be learned? This problem is muchlike that of the sequential test of Chapter 4, although we are now asking a different
question. It requires judgment about the real world in setting up the mathematical
model (that is, in the prior information used in choosing the appropriate hypothesisspace), but persons with reasonably good judgment will be led to substantially the sameconclusions.
In general, then, far from being a kno wn physical fact, the number mshould be understood
to be simply the number of results per trial that we shall take into account in the present
calculation . Then it is perhaps being stated most defensibly if we say that when we specify
mwe are deﬁning a tentative working hypothesis , whose consequences we want to learn.
In any event, we are concerned with two different sample spaces; the space Sfor a single
trial, consisting of mpoints, and the extension space
Sn=S⊗S⊗···⊗ S, (9.1)
the direct product of ncopies of S, which is the sample space for the experiment as a
whole. For clarity, we use the word ‘result’ for a single trial referring to space S, while
‘outcome’ refers to the experiment as a whole, deﬁned on space Sn. Thus, one outcome
consists of the enumeration of nresults (including their order if the experiment is conducted

<<<PAGE 305>>>

9 Repetitive experiments: probability and frequency 273
in such a way that an order is deﬁned). Then we may say that the number of results being
considered in the present calculation ism, while the number of outcomes being considered
isN=mn.
Denote the result of the ith trial by ri(1≤ri≤m,1≤i≤n). Then any outcome of
the experiment can be indicated by specifying the numbers {r1,..., rn}, which constitute a
conceivable data set D. Since the different outcomes are mutually exclusive and exhaustive,
if our robot is given any information Iabout the experiment, the most general probability
assignment it can make is a function of the ri:
P(D|I)=p(r1...rn) (9.2)
satisfying the sums over all possible data sets
m/summationdisplay
r1=1m/summationdisplay
r2=1···m/summationdisplay
rn=1p(r1...rn)=1. (9.3)
As a convenience, since the riare non-negative integers, we may regard them as digits
(modulo m ) in a number Rexpressed in the base mnumber system; 0≤R≤N−1.
Our robot, however poorly informed it may be about the real world, is an accomplishedmanipulator of numbers, so we may instruct it to communicate with us in the base mnumber
system instead of the decimal (base ten) system that you and I were trained to use becauseof an anatomical peculiarity of humans.
For example, suppose that our experiment consists of tossing a die four times; there are
m=6 possible results at each trial, and N=6
4=1296 possible outcomes for the experi-
ment, which can be indexed (1 to 1296). Then to indicate the outcome that is designated asnumber 836 in the decimal system, the robot notes that
836=(3×6
3)+(5×62)+(1×61)+(2×60) (9.4)
and so, in the base six system the robot displays this as outcome number 3512.
Unknown to the robot, this has a deeper meaning to you and me; for us, this represents
the outcome in which the ﬁrst toss gave three spots up, the second gave ﬁve spots, the thirdgave one spot, and the fourth toss gave two spots (since in the base six system the individualdigits r
ihave meaning only modulo 6, the display 5024 ≡5624 represents an outcome in
which the second toss yielded six spots up).
More generally, for an experiment with mpossible results at each trial, repeated ntimes,
we communicate with the robot in the base mnumber system, whereupon each number
displayed will have exactly ndigits, and for us the ith digit will represent, modulo m , the
result of the ith trial. By this device we trick our robot into taking instructions and giving
its conclusions in a format which has for us an entirely different meaning. We can now askthe robot for its predictions on any question we care to ask about the digits in the displaynumber, and this will never betray to the robot that it is really making predictions abouta repetitive physical experiment (for the robot, by construction as discussed in Chapter 4,always accepts what we tell it as the literal truth).

<<<PAGE 306>>>

274 Part 1 Principles and elementary applications
With the conceptual problem deﬁned as carefully as we know how to do, we may turn
ﬁnally to the actual calculations. We noted in the discussion following Eq. (2.86) that,depending on details of the information I, many different probability assignments (9.2)
might be appropriate; consider ﬁrst the obvious simplest case of all.
9.2 The poorly informed robot
Suppose we tell the robot only that there are Npossibilities, and give no other information.
That is, the robot is not only ignorant about the relevant physical laws; it is not even toldthat the full experiment consists of nrepetitions of a simpler one. For it, the situation is as
if there were only a single trial, with Npossible results, the ‘mechanism’ being completely
unknown.
At this point, you might object that we have withheld from the robot some very important
information that must be of crucial importance for rational inferences about the experiment;and so we have. Nevertheless, it is important that we understand the surprising consequences
of neglecting that information.
What meaningful predictions about the experiment could the robot possibly make, when
it is in such a primitive state of ignorance that it does not even know that there is anyrepetitive experiment involved? Actually, the poorly informed robot is fa r from helpless;
although it is hopelessly na¨ ıve in some respects, nevertheless it is already able to make
a surprisingly large number of correct predictions for purely combinatorial reasons (thisshould give us some respect for the cogency of multiplicity factors, which can mask a lotof ignorance).
Let us see ﬁrst just what those poorly informed predictions are; then we can give the
robot additional pertinent pieces of information and see how its predictions are revised as itcomes to know more and more about the real physical experiment. In this way we can followthe robot’s education step by step, until it reaches a level of sophistication comparable to(in some cases, exceeding) that displayed by real scientists and statisticians discussing realexperiments.
Denote this initial state of ignorance (the robot knows only the number Nof possible
outcomes and nothing else) by I
0. The principle of indifference (2.95) then applies; the
robot’s ‘sample space’ or ‘hypothesis space’ consists of N=mndiscrete points, and to
each it assigns probability N−1. Any proposition Athat is deﬁned to be true on a subset
S/prime⊂Snand false on the complementary subset Sn−S/primewill, by the rule (2.99), then be
assigned the probability
P(A|I0)=M(n,A)
N, (9.5)
where M(n,A) is the multiplicity of A(number of points of Snon which Ais true). This
trivial looking result summarizes everything the robot can say on the prior information I0,
and it illustrates again that, whenever they are relevant to the problem, connections betweenprobability and frequency appear automatically, as mathematical consequences of our rules.

<<<PAGE 307>>>

9 Repetitive experiments: probability and frequency 275
Consider ntosses of a die, m=6; the probability (9.2) of any completely speciﬁed
outcome is
p(r1...rn|I0)=1
6n, 1≤ri≤6,1≤i≤n. (9.6)
Then what is the probability that the ﬁrst toss gives three spots, regardless of what hap-
pens later? We ask the robot for the probability that the ﬁrst digit r1=3. Then the 6n−1
propositions
A(r2,..., rn)≡r1=3 and the remaining digits are r2,..., rn (9.7)
are mutually exclusive, and so (2.85) applies:
P(r1=3|I0)=6/summationdisplay
r2=1···6/summationdisplay
rn=1p(3r2...rn|I0)
=6n−1p(r1...rn|I0)
=1/6.(9.8)
(Note that ‘ r1=3’ is a proposition, so by our notational rules in Appendix B we are allowed
to put it in a formal probability symbol with capital P.) But by symmetry, if we had asked for
the probability that any speciﬁed ( ith) toss gives any speciﬁed ( kth) result, the calculation
would have been the same:
P(ri=k|I0)=1/6, 1≤k≤6,1≤i≤n. (9.9)
Now, what is the probability that the ﬁrst toss gives kspots, and the second gives jspots?
The robot’s calculation is just like the above; the results of the remaining tosses comprise
6n−2mutually exclusive possibilities, and so
P(r1=k,r2=j|I0)=6/summationdisplay
r3=1···6/summationdisplay
rn=1p(k,j,r3...rn|I0)
=6n−2p(r1...rn|I0)=1/62
=1/36,(9.10)
and by symmetry the answer would have been the same for any two different tosses. Simi-
larly, the robot will tell us that the probability for any speciﬁed outcome at any three differenttosses is
p(r
irjrk|I0)=1/63=1/216, (9.11)
and so on!
Let us now try to educate the robot. Suppose we give it the additional information that,
to you and me, means that the ﬁrst toss gave three spots. But we tell this to the robot in theform: out of the originally possible Noutcomes, the correct one belongs to the subclass
for which the ﬁrst digit is r
1=3. With this additional information, what probability will
it now assign to the proposition r2=j? This conditional probability is determined by the

<<<PAGE 308>>>

276 Part 1 Principles and elementary applications
product rule (2.63):
p(r2|r1I0)=p(r1r2|I0)
p(r1|I0), (9.12)
or, using (9.9) and (9.10),
p(r2|r1I0)=1/36
1/6=1/6=p(r2|I0). (9.13)
The robot’s prediction is unchanged. If we tell it the result of the ﬁrst two tosses and ask
for its predictions about the third, we have from (9.11) the same result:
p(r3|r1r2I0)=p(r3r1r2|I0)
p(r1r2|I0)=1/216
1/36=1/6=p(r3|I0). (9.14)
We can continue in this way, and will ﬁnd that if we tell the robot the results of any number
of tosses, this will have no ef fect at all on its predictions for the remaining ones. It appears
that the robot is in such a profound state of ignorance I0that it cannot be educated. However,
if it does not respond to one kind of instruction, perhaps it will respond to another. But ﬁrstwe need to understand the cause of the difﬁculty.
9.3 Induction
In what way does the robot’s behavior surprise us? Its reasoning here is different from the
way you and I would reason, in that the robot does not seem to learn from the past. If wewere told that the ﬁrst dozen digits were all 3, you and I would take the hint and start placingour bets on 3 for the next digit. But the poorly informed robot does not take the hint, nomatter how many times it is given.
More generally, if you or I could perceive any regular pattern in the previous results, we
would more or less expect it to continue; this is the reasoning process called induction . The
robot does not yet see how to reason inductively. However, the robot must do all thingsquantitatively, and you and I would have to admit that we are not certain whether theregularity will continue. It only seems somewhat likely, but our intuition does not tell ushow likely. So our intuition, as in Chapters 1 and 2, gives us only a qualitative ‘sense ofdirection’ in which we feel the robot’s quantitative reasoning ought to go.
Note that what we are calling induction is a very different process from what is called,
confusingly, ‘mathematical induction’. The latter is a rigorous deductive process, and we
are not concerned with it here.
The problem of ‘justifying induction’ has been a difﬁcult one for the conventional formu-
lations of probability theory, and the nemesis of some philosophers beginning with DavidHume (1739, 1777) in the 18th century. For example, the philosopher Karl Popper (1974)has gone so far as to ﬂatly deny the possibility of induction. He asked the rhetorical ques-tion: ‘Are we rationally justiﬁed in reasoning from repeated instances of which we haveexperience to instances of which we have no experience?’ This is, quite literally, the poorlyinformed robot speaking to us, and wanting us to answer ‘ No!’ But we want to show that

<<<PAGE 309>>>

9 Repetitive experiments: probability and frequency 277
a better informed robot will answer: ‘Yes, if we have prior information providing a log-
ical connection between the different trials’ and give speciﬁc circumstances that enableinduction to be made.
The difﬁculty has seemed particularly acute in the theory of survey sampling, which
corresponds closely to our equations above. Having questioned 1000 people and found that672 of them favor proposition Ain the next election, by what right do the pollsters jump to
the conclusion that about 67 ±3% of the millions not surveyed also favor proposition A?
For the poorly informed robot (and, apparently, for Popper too), learning the opinions ofany number of persons tells it nothing about the opinions of anyone else.
The same logical problem appears in many other scenarios. In physics, suppose we
measured the energies of 1000 atoms, and found that 672 of them were in excited states,the rest in the ground state. Do we have any right to conclude that about 67% of the 10
23
other atoms not measured are also in excited states? Or, 1000 cancer patients were given anew treatment and 672 of them recovered; then in what sense is one justiﬁed in predictingthat this treatment will also lead to recovery in about 67% of future patients? On prior
information I
0, there is no justiﬁcation at all for such inferences.
As these examples show, the problem of logical justiﬁcation of induction (i.e., of clarifying
the exact meaning of the statements, and the exact sense in which they can be supported by
logical analysis) is important as well as difﬁcult.
9.4 Are there general inductive rules?
What is shown by (9.13) and (9.14) is that, on the information I0, the results of different
tosses are, logically, completely independent propositions; giving the robot any informationwhatsoever about the results of speciﬁed tosses tells it nothing relevant to any other toss.The reason for this was stressed above: the robot does not yet know that the successive digits{r
1,r2,...}represent successive repetitions of the same experiment. It can be educated out
of this state only by giving it some kind of information that has relevance to all tosses; forexample, if we tell it something, however slight, about some property – physical or logical –that is common to all trials.
Perhaps, then, we might learn by introspection: What is that extra ‘hidden’ information,
common to all trials, that you and I are using, unconsciously, when we do inductive reason-ing? Then we might try giving this hidden information to the robot (i.e., incorporate it intoour equations).
A very little introspection is enough to make us aware that there is no one piece of hidden
information; there are many different kinds. Indeed, the inductive reasoning that we all dovaries widely, even for identical data, as our prior knowledge about the experiment varies.Sometimes we ‘take the hint’ immediately, and sometimes we are as slow to do it as thepoorly informed robot.
For example, suppose the data are that the ﬁrst three tosses of a coin have all yielded
‘heads’: D=H
1H2H3. What is our intuitive probability P(H4|DI) for heads on the fourth
toss? This depends very much on what that prior information Iis. On prior information

<<<PAGE 310>>>

278 Part 1 Principles and elementary applications
I0the answer is always p(H4|DI0)=1/2, whatever the data. Two other possibili-
ties are:
I1≡We have been allowed to examine the coin carefully and observe the tossing. We
know that the coin has a head and a tail and is perfectly symmetrical, with its centerof gravity in the right place, and we saw nothing peculiar in the way it was tossed.
I
2≡We were not allowed to examine the coin, and we are very dubious about the
‘honesty’ of either the coin or the tosser.
On information I1, our intuition will probably tell us that the prior evidence of the symmetry
of the coin far outweighs the evidence of three tosses; so we shall ignore the data and againassign P(H
4|DI1)=1/2.
But on information I2we would consider the data to have some cogency: we would feel
that the fact of three heads and no tails constitutes some evidence (although certainly not
proof) that some systematic inﬂuence is at work favoring heads, and so we would assign
P(H4|DI2)>1/2. Then we would be doing real inductive reasoning.
Now we seem to be facing a paradox. For I1represents a great deal more information
than does I2; yet it is P(H4|DI1) that agrees with the poorly informed robot! In fact,
it is easy to see that all our inferences based on I1agree with those of the poorly in-
formed robot, as long as the prior evidence of symmetry outweighs the evidence of thedata.
This is only an example of something that we have surely noted many times in other
contexts. The fact that one person has far greater knowledge than another does not mean
that they necessarily disagree; an idiot might guess the same truth that a scholar laboredfor years to discover. All the same, it does call for some deep thought to understand why
knowledge of perfect symmetry could leave us making the same inferences as does the
poorly informed robot.
As a start on this, note that we would not be able to assign any deﬁnite numerical value
toP(H
4|DI2) until that vague information I2is speciﬁed much more clearly. For example,
consider the extreme case:
I3≡We know that the coin is a trick one, that has either two heads or two tails; but we do not
know which.
Then we would, of course, assign P(H4|DI3)=1; in this state of prior knowledge, the
evidence of a single toss is already conclusive. It is not possible to take the hint any morestrongly than this.
As a second clue, note that our robot did seem, at ﬁrst glance, to be doing induc-
tive reasoning of a kind back in Chapter 3; for example in (3.14), where we examinedthe hypergeometric distribution. But on second glance it was doing ‘reverse induction’;the more red balls that had been drawn, the lower its probability for red in the future.And this reverse induction disappeared when we went on to the limit of the binomialdistribution.

<<<PAGE 311>>>

9 Repetitive experiments: probability and frequency 279
But you and I could also be persuaded to do reverse induction in coin tossing. Consider
the prior information:
I4≡The coin has a concealed inner mechanism that constrains it to give exactly 50 heads
and 50 tails in the next 100 tosses.
On this prior information, we would say that tossing the coin is, for the next 100 times,
equivalent to drawing from an urn that contains initially 50 red balls and 50 white ones.We could then use the product rule as in (9.12) but with the hypergeometric distribution
h(r|N,M,n) of (3.22):
P(H
4|DI4)=h(4|100,50,4)
h(3|100,50,3)=0.05873
0.12121=0.4845<1
2. (9.15)
But in this case it is easier to reason it out directly: P(H4|DI4)=(M−3)/(N−3)=
47/97=0.4845.
The great variety of different conclusions that we have found from the same data makes
it clear that there can be no such thing as a single universal inductive rule and, in viewof the unlimited variety of different kinds of conceivable prior information, makes it seemdubious that there could exist even a classiﬁcation of all inductive rules by some system ofparameters.
Nevertheless, such a classiﬁcation was attempted by the philosopher R. Carnap (1891–
1970), who found (Carnap, 1952) a continuum of rules identiﬁed by a single parameter λ
(0<λ<∞). But ironically, Carnap’s rules turned out to be identical with those given,
on the basis of entirely different reasoning, by Laplace in the 18th century (the ‘rule ofsuccession’ and its generalizations) that had been rejected as metaphysical nonsense bystatisticians and philosophers.
2
Laplace was not considering the general problem of induction, but was only ﬁnding the
consequences of a certain type of prior information, so the fact that he did not obtain everyconceivable inductive rule never arose and would have been of no concern to him. In themeantime, superior analyses of Laplace’s problem had been given by W. E. Johnson (1932),de Finetti (1937) and Harold Jeffreys (1939), of which Carnap seemed unaware.
Carnap was seeking the general inductive rule (i.e., the rule by which, given the record
of past results, one can make the best possible prediction of future ones). But he suffered
from one of the standard occupational diseases of philosophers; his exposition wandersoff into abstract symbolic logic without ever considering a speciﬁc real example. So henever rises to the level of seeing that different inductive rules correspond to different prior
information . It seems to us obvious, from arguments like the above, that this is the primary
fact controlling induction, without which the problem cannot even be stated, much lesssolved; there is no ‘general inductive rule’. Yet neither the term ‘prior information’ nor theconcept ever appears in Carnap’s exposition.
2Carnap (1952, p. 35), like Venn (1866), claims that Laplace’s rule is inconsistent (in spite of the fact that it is identical with his
own rule); we examine these claims in Chapter 18 and ﬁnd, in agreement with Fisher (1956), that they have misapplied Laplace’srule by ignoring the necessary conditions required for its derivation.

<<<PAGE 312>>>

280 Part 1 Principles and elementary applications
This should give a good idea of the level of confusion that exists in this ﬁeld, and the
reason for it; conventional frequentist probability theory simply ignores prior informationand – just for that reason – it is helpless to account for induction. Fortunately, probabilitytheory as logic is able to deal with the full problem.
9.5 Multiplicity factors
In spite of the formal simplicity of (9.5), the actual numerical evaluation of P(A|I
0) for a
complicated proposition Amay involve immense combinatorial calculations. For example,
suppose we toss a die twelve times. The number of conceivable outcomes is
612=2.18×109, (9.16)
which is about equal to the number of minutes since the Great Pyramid was built. The
geologists and astrophysicists tell us that the age of the universe is of the order of 1010
years, or 3×1017seconds. Thus, in 30 tosses of a die, the number of possible outcomes
(630=2.21×1023) is about equal to the number of microseconds in the age of the universe.
Yet we shall be particularly interested in evaluating quantities like (9.5) pertaining to afamous experiment involving 20 000 tosses of a die!
It is true that we are concerned with ﬁnite sets; but they can be rather large and we
need to learn how to calculate on them. An exact calculation will generally involve in-tricate number-theoretic details (such as whether nis a prime number, whether it is
odd or even, etc.), and may require many different analytical expressions for differentn. While we could make some further progress by elementary methods, any real facil-
ity in these calculations requires some more sophisticated mathematical techniques. Wedigress to collect some of the basic mathematical facts needed for them. These weregiven, for the most part, by Laplace, J. Willard Gibbs, and Claude Shannon. In view ofthe large numbers, there turn out to be extremely good approximations which are easy tocalculate.
A large class of problems may be ﬁt into the following scheme, for which we can indicate
the exact calculation that should, in principle, be done. Let {g
1,g2,..., gm}be any set of
mﬁnite real numbers. For concreteness, one may think of gjas the ‘value’ or the ‘gain’ of
observing the jth result in any trial (perhaps the number of pennies we win whenever that
result occurs), but the following considerations are independent of whatever meaning weattach to the{g
j}, with the proviso that they are additive; i.e., sums such as g1+g2are to
be, like sums of pennies, meaningful to us. We could, equally well, make it more abstractby saying simply that we are concerned with predicting linear functions of the n
j. The total
amount of Ggenerated by the experiment is then
G=n/summationdisplay
i=1g(ri)=m/summationdisplay
j=1njgj, (9.17)

<<<PAGE 313>>>

9 Repetitive experiments: probability and frequency 281
where the sample number njis the number of times the jth result occurred. If we ask the
robot for the probability for obtaining this amount, it will answer, from (9.5),
p(G|n,I0)=f(G|n,I0)=M(n,G)
N, (9.18)
where N=mnandM(n,G) is the multiplicity of the event G; i.e., the number of different
outcomes which yield the value G(we now indicate in it also the number of trials n– to the
robot, the number of digits needed to deﬁne an outcome – because we want to allow this tovary). Many probabilities are determined by this multiplicity factor, in its dependence on n
andG.
9.6 Partition function algorithms
Expanding M(n,G) according to the result of the nth trial gives the recursion relation
M(n,G)= m/summationdisplay
j=1M(n−1,G−gj). (9.19)
For small n, a computer could apply this ntimes for direct evaluation of M(n,G), but this
would be impractical for very large n. Equation (9.19) is a linear difference equation with
constant coefﬁcients in both nandG, so it must have elementary solutions of exponential
form:
exp{αn+λG}. (9.20)
On substitution into (9.19), we ﬁnd that this is a solution of the difference equation if αand
λare related by
exp{α}=Z(λ)≡m/summationdisplay
j=1exp{−λgj}. (9.21)
The function Z(λ) is called the partition function , and it will have a fundamental importance
throughout all of probability theory. An arbitrary superposition of such elementary solutions:
H(n,G)=/integraldisplay
dλZn(λ)e x p{λG}h(λ) (9.22)
is, from linearity, a formal solution of (9.19). However, the true M(n,G) also satisﬁes
the initial condition M(0,G)=δ(G,0), and is deﬁned only for certain discrete values of
G=/summationtextnjgj, the values that are possible results of ntrials. Further elaboration of (9.22)
leads to analytical methods of calculation that will be used in the advanced applications inthe later chapters; but for the present let us note the remarkable things that can be done justwith algebraic methods.
Equation (9.22) has the form of an inverse Laplace transform. To ﬁnd the discrete Laplace
transform of M(n,G) multiply M(n,G)b ye x p{−λG}and sum over all possible values

<<<PAGE 314>>>

282 Part 1 Principles and elementary applications
ofG. This sum contains a contribution from every possible outcome of the experiment, and
so it can be expressed equally well as a sum over all possible sample numbers:
/summationdisplay
Gexp{−λG}M(n,G)=/summationdisplay
nj∈UW(n1,..., nm)e x p/braceleftBig
−λ/summationdisplay
njgj/bracerightBig
, (9.23)
where the multinomial coefﬁcient
W(n1,..., nm)≡n!
n1!···nm!(9.24)
is the number of outcomes which lead to the sample numbers {nj}.I fxnj
j=exp{−njgj}
then exp{−/summationtextm
jnjgj}=xn1
1xn2
2...xnmm. The multinomial expansion is deﬁned by
(x1+···+ xm)n=/summationdisplay
nj∈UW(n1,..., nm)xn1
1...xnm
m. (9.25)
In (9.23) we sum over the ‘universal set’ U, deﬁned by
/braceleftbig
U:nj≥0,m/summationdisplay
j=1nj=n/bracerightbig
, (9.26)
which consists of all possible sample numbers in ntrials. But, comparing (9.23) with (9.25),
this is just
/summationdisplay
Gexp{−λG}M(n,G)=Zn(λ). (9.27)
Equation (9.27) says that the number of ways M(n,G) in which a particular value Gcan be
realized is just the coefﬁcient of exp {−λG}inZn(λ); in other words, Z(λ) raised to the nth
power displays the exact way in which all the possible outcomes in ntrials are partitioned
among the possible values of G, which indicates why the name ‘partition function’ is
appropriate.
9.6.1 Solution by inspection
In some simple problems, this observation gives us the solution by mere inspection of Zn(λ).
For example, if we make the choice
gj≡δ(j,1), (9.28)
then the total Gis just the ﬁrst sample number:
G=/summationdisplay
jnjgj=n1. (9.29)
The partition function (9.21) is then
Z(λ)=exp{−λ}+m−1 (9.30)

<<<PAGE 315>>>

9 Repetitive experiments: probability and frequency 283
and, from Newton’s binomial expansion,
Zn(λ)=n/summationdisplay
s=0/parenleftbiggn
s/parenrightbigg
exp{−λs}(m−1)n−s. (9.31)
M(n,G)=M(n,n1) is then the coefﬁcient of exp {−λn1}in this expression:
M(n,G)=M(n,n1)=/parenleftbiggn
n1/parenrightbigg
(m−1)n−n1. (9.32)
In this simple case, the counting could have been done also as: M(n,n1)=(number of
ways of choosing n1trials out of n)×(number of ways of allocating the remaining m−1
trial results to the remaining n−n1trials). However, the partition function method works
just as well in more complicated problems; and even in this example the partition functionmethod, once understood, is easier to use.
In the choice (9.28) we separated off the trial result j=1 for special attention. More
generally, suppose we separate the mtrial results comprising the sample space Sarbitrarily
into a subset S
/primecontaining sof them, and the complementary subset S/primeconsisting of the
(m−s) remaining ones, where 1 <s<m. Call any result in the subset S/primea ‘success’, any
inS/primea ‘failure’. Then we replace (9.28) by
gj=/braceleftBigg
1 j∈S/prime
0 otherwise ,(9.33)
and (9.29)–(9.32) are generalized as follows. Gis now the total number of successes, called
traditionally r:
G=m/summationdisplay
j=1njgj≡r, (9.34)
and the partition function now becomes
Z(λ)=sexp{−λ}+m−s, (9.35)
from which
Zn(λ)=n/summationdisplay
r=0/parenleftbiggn
r/parenrightbigg
srexp{−λr}(m−s)n−r, (9.36)
and so the coefﬁcient of exp {−λr}is
M(n,G)=M(n,r)=/parenleftbiggn
r/parenrightbigg
sr(m−s)n−r. (9.37)
From (9.18), the poorly informed robot’s probability for rsuccesses is therefore
P(G=r|I0)=/parenleftbiggn
r/parenrightbigg
pr(1−p)n−r, 0≤r≤n, (9.38)

<<<PAGE 316>>>

284 Part 1 Principles and elementary applications
where p=s/m. But this is just the binomial distribution b(r|n,p), whose derivation cost
us so much conceptual agonizing in Chapter 3. There we found the binomial distribution(3.86) as the limiting form in drawing from an inﬁnitely large urn, and again as a randomizedapproximate form (3.92) in drawing with replacement from a ﬁnite urn; but in neither casewas it exact for a ﬁnite urn. Now we have found a case where the binomial distributionarises for a different reason, and it is exact for a ﬁnite sample space.
This quantitative exactness is a consequence of our making the problem more abstract;
there is now, in the prior information I
0, no mention of complicated physical properties
such as those of urns, balls, and hands reaching in. But more important, and surprising, issimply the qualitative fact that the binomial distribution, ostensibly arising out of repeatedsampling, has appeared in the inferences of a robot so poorly informed that it does noteven have the concept of repetitions! In other words, the binomial distribution has an exactcombinatorial basis, completely independent of the notion of ‘repetitive sampling’.
This gives us a clue toward understanding how the poorly informed robot functions. In
conventional probability theory, starting with James Bernoulli (1713), the binomial distri-bution has always been derived from the postulate that the probability for any result is to bethe same at each trial, strictly independent of what happens at any other trial . But, as we
have noted already, that is exactly what the poorly informed robot would say – not out of itsknowledge of the physical conditions of the experiment, but out of its complete ignorance
of what is happening.
Now we could go through many other derivations and we would ﬁnd that this agreement
persists: the poorly informed robot will ﬁnd not only the binomial but also its generalization,the multinomial distribution, as combinatorial theorems.
Exercise 9.2. Derive the multinomial distribution found in Chapter 3, Eq. (3.77), as
a generalization or extension of our derivation of (9.38).
Then all the usual probability distributions of sampling theory (Poisson, gamma, Gaussian,chi-squared, etc.) will follow as limiting forms of these. All the results that conventionalprobability theory has been obtaining from the frequency deﬁnition, and the assumption ofstrict independence of different trials, are just what the poorly informed robot would ﬁnd inthe same problems. In other words, frequentist probability theory is, functionally, just the
reasoning of the poorly informed robot .
Then, since the poorly informed robot is unable to do inductive reasoning, we begin to
understand why conventional probability theory has trouble with it. Until we learn how tointroduce some kind of logical connection between the results of different trials, the resultsof any trials cannot tell us anything about any other trial, and it will be impossible to ‘takethe hint’.
Frequentist probability theory seems to be stuck with independent trials because it lays
great stress on limit theorems, and examination of them shows that their derivation depends

<<<PAGE 317>>>

9 Repetitive experiments: probability and frequency 285
entirely on the strict independence of different trials. The slightest positive correlation
between the results of different trials will render those theorems qualitatively wrong. Indeed,without that strict independence, not only limit theorems, but virtually all of the samplingdistributions for estimators, on which orthodox statistics depends, would be incorrect.
Here the poorly informed robot would seem to have the tactical advantage; for all those
limit theorems and sampling distributions for estimators are valid exactly on informa-tion I
0. There is another important difference; in conventional probability theory that
‘independence’ is held to mean causal physical independence; but how is one to judgethis as a property of the real world? We have seen no discussion of this in the orthodoxliterature. To the robot it means logical independence, a stronger condition, but one thatmakes its calculations cleaner and simpler.
Solution by inspection of Z
n(λ) has the merit that it yields exact results. However, only
relatively simple problems can be solved in this way. We now note a much more powerfulalgebraic method.
9.7 Entropy algorithms
We return to the problem of calculating multiplicities as in (9.18)–(9.37), but in a little
more general formulation. Consider a proposition A(n
1,..., nm) which is a function of the
sample numbers nj; it is deﬁned to be true when ( n1,..., nm) are in some subset R∈U,
where Uis the universal set (9.26), and false when they are in the complementary set
R=U−R.I fAis linear in the nj, then it is the same as our Gin (9.17). The multiplicity
ofA(number of outcomes for which it is true) is
M(n,A)=/summationdisplay
nj∈RW(n1,..., nm), (9.39)
where the multinomial coefﬁcient Wwas deﬁned in (9.24).
How many terms T(n,m) are in the sum (9.39)? This is a well-known combinatorial
problem for which the reader will easily ﬁnd the solution3
T(n,m)=/parenleftbiggn+m−1
n/parenrightbigg
=(n+m−1)!
n!(m−1)!, (9.40)
and we note that, as n→∞ ,
T(n,m)∼nm−1
(m−1)!. (9.41)
The number of terms grows as a ﬁnite [( m−1)th] power of n(as can be seen intuitively
by thinking of the njas Cartesian coordinates in an m-dimensional space and noting the
geometrical meaning of the conditions (9.26) deﬁning U). Denote the greatest term in the
3Physicists will recognize T(n,m) as the ‘Bose–Einstein multiplicity factor’ of statistical mechanics (the number of linearly
independent quantum states which can be generated by putting nBose–Einstein particles into msingle-particle states). Finding
T(n,m) is the same combinatorial problem.

<<<PAGE 318>>>

286 Part 1 Principles and elementary applications
region Rby
Wmax≡Max RW(n1,..., nm). (9.42)
Then the sum (9.39) cannot be less than Wmax, and the number of terms in (9.39) cannot be
greater than T(n,m), so
Wmax≤M(n,A)≤WmaxT(n,m) (9.43)
or
1
nlog(Wmax)≤1
nlogM(n,A)≤1
nlog(Wmax)+1
nlogT(n,m). (9.44)
But as n→∞ , from (9.41), we have
1
nlogT(n,m)→0, (9.45)
and so
1
nlogM(n,A)→1
nlog(Wmax). (9.46)
The multinomial coefﬁcient Wgrows so rapidly with nthat in the limit the single maximum
term in the sum (9.39) dominates it. The logarithm of Tgrows less rapidly than n,s oi nt h e
limit it makes no difference in (9.44).
Then how does log( W/n) behave in the limit? The limit we want is the one in which the
sample frequencies fj=nj/ntend to constants; in other words, the limit as n→∞ of
1
nlog/bracketleftbiggn!
(nf1)!···(nfm)!/bracketrightbigg
(9.47)
as the fjare held constant. But, from the Stirling asymptotic approximation,
log(n!)∼nlog(n)−n+log√
2πn+O/parenleftbigg1
n/parenrightbigg
, (9.48)
we ﬁnd that, in the limit, log( W/n) tends to a ﬁnite constant value independent of n:
1
nlog(W)→H≡−m/summationdisplay
j=1fjlog(fj), (9.49)
which is just what we call the entropy of the frequency distribution {f1,..., fm}.W eh a v e
the result that, for very large n, if the sample frequencies fjtend to constants, the multiplicity
ofAgoes into a surprisingly simple expression:
M(n,A)∼exp{nH}, (9.50)
in the sense that the ratio of the two sides in (9.50) tends to unity (although their difference
does not tend to zero; but they are both growing so rapidly that this makes no percentagedifference in the limit). From (9.46) it is understood that in (9.50) the frequencies f
j=nj/n
to be used in Hare the ones which maximize Hover the region Rfor which Ais deﬁned.

<<<PAGE 319>>>

9 Repetitive experiments: probability and frequency 287
We now see what was not evident before; that this multiplicity is to be found by determining
thefrequency distribution{f1,..., fm}which has maximum entropy subject to whatever
constraints deﬁne R.4
It requires some thought and analysis to appreciate what we have in (9.50). Note ﬁrst
that we now have the means to complete the calculations which require explicit valuesfor the multiplicities M(n,G). Before proceeding to calculate the entropy, let us note
brieﬂy how this will go. If Ais linear in the n
j, then the multiplicity (9.50) is also equal
asymptotically to
M(n,G)=exp{nH}, (9.51)
and so the probability for realizing the total Gis, from (9.18) ,
p(G|n,I0)=m−nexp{nH}=exp{−n(H0−H)}, (9.52)
where H0=log(m) is the absolute maximum of the entropy, derived below in (9.74). Often,
the quantity most directly relevant is not the entropy, but the difference between the entropyand its maximum possible value; this is a direct measure of how strong are the constraints R.
For many purposes it would have been better if entropy had been deﬁned as that difference;but the historical precedence would be very hard to change now. In any event, (9.52) hassome deep intuitive meaning that we develop in later chapters.
Let us note the effect of acquiring new information; now we learn that a speciﬁed trial
yielded the amount g
j. This new information changes the multiplicity of Abecause now
the remaining ( n−1) trials must have yielded the total amount ( G−gj), and the number
of ways this could happen is M(n−1,G−gj). Also, the frequencies are slightly changed,
because one trial that yielded gjis now absent from the counting. Instead of fk=nk/nin
(9.18), we now have the frequencies {f/prime
1,..., f/prime
m}, where
f/prime
k=nk−δjk
n−1, 1≤k≤m, (9.53)
or writing f/prime
k=fk+δfk, the change is
δfk=fk−δjk
n−1, (9.54)
which is exact; as a check, note that/summationtextf/prime
k=1 and/summationtextδfk=0, as it should be.
This small change in frequencies induces a small change in the entropy; writing the new
value as H/prime=H+δH,w eﬁ n d
δH=/summationdisplay
k∂H
∂fkδfk+O/parenleftbigg1
n2/parenrightbigg
=/bracketleftbiggH+log(fj)
n−1/bracketrightbigg
+O/parenleftbigg1
n2/parenrightbigg
, (9.55)
4We now also see that, not only is the notion of entropy inherent in probability theory independently of the work of Shannon, the
maximum entropy principle is also, at least in this case, derivable directly from the rules of probability theory without additional
assumptions.

<<<PAGE 320>>>

288 Part 1 Principles and elementary applications
and so
H/prime=nH+log(fj)
n−1+O/parenleftbigg1
n2/parenrightbigg
. (9.56)
Then the new multiplicity is, asymptotically,
M(n−1,G−gj)=exp{(n−1)H/prime}= fjexp{nH}/bracketleftbigg
1+O/parenleftbigg1
n/parenrightbigg/bracketrightbigg
. (9.57)
The asymptotic forms of multiplicity are astonishingly simple compared with the exact
expressions. This means that, contrary to ﬁrst appearances when we noted the enormoussize of the extension set S
n, the large nlimit is by far the easiest thing to calculate when
we have the right mathematical machinery. Indeed, the set Snhas disappeared from our
considerations; the remaining problem is to calculate the fkthat maximize the entropy
(9.49) over the domain R. But this is a problem that is solved on the sample space Sof a
single trial!
The probability for getting the total gain Gis changed from (9.52) to
p(G|ri=j,nI0)=M(n−1,G−gj)
mn−1, (9.58)
and, given only I0, the prior probability for the event ri=jis, from (9.5),
p(ri=j|nI0)=1
m. (9.59)
This gives us everything we need to apply Bayes’ theorem conditional on G:
p(ri=j|GnI 0)=p(ri=j|nI0)p(G|ri=j,nI0)
p(G|nI0), (9.60)
or
p(ri=j|GnI 0)=1
m[M(n−1,G−gj)/mn−1]
[M(n,G)/mn]=M(n−1,G−gj)
M(n,G)=fj.(9.61)
Knowledge of Gtherefore changes the robot’s probability for the jth result from the uniform
prior probability 1 /mto the observed frequency fjof that result. Intuition might have
expected this connection between probability and frequency to appear eventually, but itmay seem surprising that this requires only that the total Gbe known. Note, however,
that specifying Gdetermines the maximum entropy frequency distribution {f
1,..., fm},
so there is no paradox here.
Exercise 9.3. Extend this result to derive the joint probability
p(ri=j,rs=t|GnI 0)=M(n−2,G−gj−gt)/M(n,G) (9.62)
as a ratio of multiplicities and give the resulting probability. Are the trials still inde-
pendent, or does knowledge of Ginduce correlations between different trials?

<<<PAGE 321>>>

9 Repetitive experiments: probability and frequency 289
These results show the gratifyingly simple and reasonable things that the poorly informed
robot can do. In conventional frequentist probability theory, these connections are onlypostulated arbitrarily; the poorly informed robot derives them as consequences of the rulesof probability theory.
Now we return to the problem of carrying out the entropy maximization to obtain explicit
expressions for the entropies Hand frequencies f
j.
9.8 Another way of looking at it
The following observation gives us a better intuitive understanding of the partition function
method. Unfortunately, it is only a number -theoretic trick, useless in practice. From (9.28)
and (9.29) we see that the multiplicity of ways in which the total Gcan be realized can be
written as
M(n,G)=/summationdisplay
{nj}W(n1,..., nm), (9.63)
where we are to sum over all sets of non-negative integers {nj}satisfying
/summationdisplay
nj=n,/summationdisplay
njgj=G. (9.64)
Let{nj}and{n/prime
j}be two such different sets which yield the same total:/summationtextnjgj=/summationtextn/prime
jgj=
G. Then it follows that
m/summationdisplay
j=1kjgj=0, (9.65)
where by hypothesis the integers kj≡nj−n/prime
jcannot all be zero.
Two numbers f,gare said to be incommensurable if their ratio is not a rational number;
i.e., if ( f/g) cannot be written as ( r/s), where randsare integers (but, of course, any
ratio may be thus approximated arbitrarily close by choosing r,slarge enough). Likewise,
we shall call the numbers ( g1,..., gm)jointly incommensurable if no one of them can be
written as a linear combination of the others with rational coef ﬁcients. But if this is so, then
(9.65) implies that all kj=0:
nj=n/prime
j, 1≤j≤m, (9.66)
so if the{g1,..., gm}are jointly incommensurable, then in principle the solution is im-
mediate; for then a given value of G=/summationtextnjgjcan be realized by only one set of sample
numbers nj; i.e., if Gis speciﬁed exactly, this determines the exact values of all the {nj}.
Then we have only one term in (9.63):
M(n,G)=W(n1,..., nm) (9.67)
and
M(n−1,G−gj)=W(n/prime
1,..., n/prime
m), (9.68)

<<<PAGE 322>>>

290 Part 1 Principles and elementary applications
where, necessarily, n/prime
i=ni−δij. Then the exact result (9.61) reduces to
p(rk=j|GnI 0)=W(n/prime
1,..., n/prime
m)
W(n1,..., nm)=(n−1)!
n!nj!
(nj−1)!=nj
n. (9.69)
In this case the result could have been found in a different way: whenever by any means the
robot knows the sample number nj(i.e., the number of digits {r1,..., rn}equal to j)b u t
does not know at which trials the jth result occurred (i.e., which digits are equal to j), it
can apply James Bernoulli’s rule (9.18) directly:
P(rk=j|njI0)=nj
(total number of digits). (9.70)
Again, the probability for any proposition Ais equal to the frequency with which it is true in
the relevant set of equally possible hypotheses. So again, our robot, even if poorly informed,
is nevertheless producing the standard results that current conventional treatments all assure
us are correct. Conventional writers appear to regard this as a kind of law of physics; butwe need not invoke any ‘law’ to account for the fact that a measured frequency oftenapproximates an assigned probability (to a relative accuracy something like 1 /√
n, where n
is the number of trials). If the information used to assign that probability includes all of thesystematic effects at work in the real experiment, then the great majority of all things thatcould happen in the experiment correspond to frequencies remaining in such a shrinking
interval; this is simply a combinatorial theorem, which in essence was given already by
de Moivre and Laplace in the 18th century, in their asymptotic formula. In virtually all
of current probability theory this strong connection between probability and frequency istaken for granted for all probabilities, but without any explanation of the mechanism that
produces it; for us, this connection is only a special case.
9.9 Entropy maximization
The above derivation (9.50) of M(n,A) is valid for a proposition Athat is deﬁned by some
arbitrary function of the sample numbers n
j. In general, one might need many different
algorithms for this maximization. But in the case A=G, where we are concerned with a
linear function G=/summationtextnjgj, the domain Ris deﬁned by specifying just the average ofG
over the ntrials:
G=G
n=m/summationdisplay
j=1fjgj, (9.71)
which is also an average over the frequency distribution. Then the maximization problem
has a solution that was given once and for all by J. Willard Gibbs (1902) in his work onstatistical mechanics.
It required another lifetime for Gibbs’ algorithm to be generally appreciated; for 75 years
it was rejected and attacked by some because, for those who thought of probability as a

<<<PAGE 323>>>

9 Repetitive experiments: probability and frequency 291
real physical phenomenon, it appeared arbitrary. Only through the work of Claude Shannon
(1948) was it possible to understand what the Gibbs’ algorithm was accomplishing. Thiswas pointed out ﬁrst in Jaynes (1957a) in suggesting a new interpretation of statisticalmechanics (as an example of logical inference rather than as a physical theory), and this ledrather quickly to a generalization of Gibbs’ equilibrium theory to nonequilibrium statisticalmechanics.
In Chapter 11 we set down the complete mathematical apparatus generated by the max-
imum entropy principle; for the present it will be sufﬁcient to give the solution for the caseat hand. An inequality given by Gibbs leads to an elegant solution to our maximizationproblem.
Let{f
1,..., fm}be any possible frequency distribution on mpoints, satisfying ( fj≥0,/summationtext
jfj=1), and let{u1,..., um}be any other frequency distribution satisfying the same
conditions. Then using the fact that on the positive real line log( x)≤(x−1) with equality
if and only if x=1, we have
m/summationdisplay
j=1fjlog/parenleftbigguj
fj/parenrightbigg
≤0, (9.72)
with equality if and only if fj=ujfor all j. In this we recognize the entropy expression
(9.49), so the Gibbs inequality becomes
H(f1,..., fm)≤−m/summationdisplay
j=1fjlog(uj), (9.73)
from which various conclusions can be drawn. Making the choice uj=1/mfor all j,i t
becomes
H≤log(m), (9.74)
so the maximum possible value of His log( m), attained if and only if fjis the uniform
distribution fj=1/mfor all j. Now make the choice
uj=exp/braceleftbig
−λgj/bracerightbig
Z(λ), (9.75)
where the normalizing factor Z(λ) is just the partition function (9.21). Choose the constant
λso that some speciﬁed average G=/summationtextujgjis attained; we shall see presently how to do
this. The Gibbs inequality becomes
H≤/summationdisplay
fjgj+logZ(λ). (9.76)
Now let fjvary over the class of all frequency distributions that yield the wanted average
(9.71). The right-hand side of (9.76) remains constant, and Hattains its maximum value
onR:
Hmax=G+log(Z), (9.77)

<<<PAGE 324>>>

292 Part 1 Principles and elementary applications
if and only if fj=uj. It remains only to choose λso that the average value Gis realized.
But it is evident from (9.75) that
G=−∂
log(Z)∂λ, (9.78)
so this is to be solved for λ. It is easy to see that this has only one real root (on the real axis,
the right-hand side of (9.78) is a continuous, strictly decreasing monotonic function of λ),
so the solution is unique.
We have just derived the ‘Gibbs canonical ensemble’ formalism, which in quantum
statistics is able to determine all equilibrium thermodynamic properties of a closed system(that is, no particles enter it or leave it); but now its generality far be yond that application
is evident.
9.10 Probability and frequency
In our terminology, a probability is something that we assign, in order to represent a state of
knowledge, or that we calculate from previously assigned probabilities according to the rulesof probability theory. A frequency is a factual property of the real world that we measure
orestimate. The phrase ‘estimating a probability ’i sjust as much a logical incongruity as
‘assigning a frequency’ or ‘drawing a square circle’.
The fundamental, inescapable distinction between probability and frequency lies in this
relati vity principle: probabilities change when we change our state of knowledge; frequen-
cies do not. It follows that the probability p(E) that we assign to an event Ecan be equal
to its frequency f(E) only for certain particular states of knowledge. Intuitively, one would
expect this to be the case when the only information we have about Econsists of its
observed frequency; and the mathematical rules of probability theory conﬁrm this in thefollowing way.
We note the two most familiar connections between probability and frequency. Under the
assumption of exchangeability and certain other prior information (Jaynes, 1968), the rulefor translating an observed frequency in a binary experiment into an assigned probability isLaplace’s rule of succession. We ha ve encountered this already in Chapter 6 in connection
with urn sampling, and we analyze it in detail in Chapter 18. Under the assumption of
independence, the rule for translating an assigned probability into an estimated frequencyis James Bernoulli’s weak law of large numbers (or, to get an error estimate, the de Moivre–Laplace limit theorem).
However, many other connections exist. They are contained, for example, in the principle
of maximum entropy (Chapter 11), the principle of transformation groups (Chapter 12), andin the theory of ﬂuctuations in exchangeable sequences (Jaynes, 1978).
If anyone wished to research this matter, we think he could ﬁnd a dozen logically distinct
connections between probability and frequency that have appeared in various applications.But these connections always appear automatically, whenever they are relevant to the prob-lem, as mathematical consequences of probability theory as logic; there is never any need

<<<PAGE 325>>>

9 Repetitive experiments: probability and frequency 293
to deﬁne a probability as a frequency. Indeed, Bayesian theory may justiﬁably claim to use
the notion of frequency more effectively than does the ‘frequency’ theory. For the latteradmits only one kind of connection between probability and frequency, and has trouble incases where a different connection is appropriate.
R. A. Fisher, J. Neyman, R. von Mises, W. Feller, and L. J. Savage denied vehemently that
probability theory is an extension of logic, and accused Laplace and Jeffreys of committingmetaphysical nonsense for thinking that it is. It seems to us that, if Mr Awishes to study
properties of frequencies in random experiments and publish the results for all to see andteach them to the next generation, he has every right to do so, and we wish him everysuccess. But in turn Mr Bhas an equal right to study problems of logical inference that
have no necessary connection with frequencies or random experiments, and to publish hisconclusions and teach them. The world has ample room for both.
Then why should there be such unending conﬂict, unresolved after over a century of bitter
debate? Why cannot both coexist in peace? What we have never been able to comprehend isthis: If Mr Awants to talk about frequencies, then why can ’t he just use the word ‘frequency’?
Why does he insist on appropriating the word ‘probability’ and using it in a sense that ﬂiesin the face of both historical precedent and the common colloquial meaning of that word?By this practice he guarantees that his meaning will be misunderstood by almost everyreader who does not belong to his inner circle clique. It seems to us that he would ﬁnd iteasy – and very much in his own self-interest – to avoid these constant misunderstandings,simply by saying what he means. (H. Cram´ er (1946) did this fairly often, although not with
100% reliability, so his work is today easier to read and comprehend.)
Of course, von Mises, Feller, Fisher, and Neyman would not be in full agreement among
themselves on anything. Nevertheless, whenever any of them uses the word ‘probability’,if we merely substitute the word ‘frequency’ we shall go a long way toward clearing up theconfusion by producing a statement that means more nearly what they had in mind.
We think it is obvious that the vast majority of the real problems of science fall into
MrB’s category, and therefore, in the future, science will be obliged to turn more and
more toward his viewpoint and results. Furthermore, Mr B’s use of the word ‘probability’
as expressing human information enjoys not only the historical precedent going back toJames Bernoulli (1713), but it is also closer to the modern colloquial meaning of theword.
9.11 Signiﬁcance tests
The rather subtle interplay between the notions of probability and frequency appears again
in the topic of signiﬁcance tests, or ‘tests of goodness of ﬁt’. In Chapter 5 we discussedsuch problems as assessing the validity of Newtonian celestial mechanics, and noted thatorthodox signiﬁcance tests purport to accept and reject hypotheses without consideringany alternatives. Then we demonstrated why we cannot say how the observed facts affectthe status of some hypothesis Huntil we state the speciﬁc alternative(s) against which
His to be tested. Common sense tells all scientists that a given piece of observational

<<<PAGE 326>>>

294 Part 1 Principles and elementary applications
evidence Emight demolish Newton’s theory, or elevate it to certainty, or anything in
between. It depends entirely on this: against which alternative(s) is it being tested? Bayes’theorem sends us the same message; for example, suppose we wish to consider only twohypotheses, HandH
/prime. Then on any data Dand prior information I, we must always have
P(H|DI)+P(H/prime|DI)=1, and in terms of our logarithmic measure of plausibility in
decibels as discussed in Chapter 4, Bayes’ theorem becomes
e(H|DI)=e(H|I)+10 log10/bracketleftbiggP(D|H)
P(D|H/prime)/bracketrightbigg
, (9.79)
which we might describe in words by saying that ‘Data Dsupports hypothesis Hrelative to
H/primeby 10 log10[P(D|H)/P(D|H/prime)] decibels’. The phrase ‘ relative to H/prime’ is essential here,
because relative to some other alternative H/prime/primethe change in evidence, [ e(H|DI)−e(H|I)],
might be entirely different; it does not make sense to ask how much the observed facts tend‘in themselves’ to support or refute H(except, of course, when data Dare impossible on
hypothesis H, so deductive reasoning can take over).
Now as long as we talk only in these generalities, our common sense readily assents to
this need for alternatives. But if we consider speciﬁc problems, we may have some doubts.For example, in the particle counter problem of Chapter 6 we had a case (known source
strength and counter efﬁciency s,φ) where the probability for getting ccounts in any one
second is a Poisson distribution with mean value λ=sφ:
p(c|sφ)=exp{−λ}λ
c
c!, 0≤c≤∞. (9.80)
Although it wasn’t necessary for the problem we were considering then, we can still ask:
What can we infer from this about the relative frequencies with which we would see c
counts if we repeat the measurement in many different seconds, with the resulting datasetD≡{c
1,c2,..., cn}? If the assigned probability for any particular event (say the event
c=12) is independently equal to
p=exp{−λ}λ12
12!(9.81)
at each trial, then the probability that the event will occur exactly rtimes in ntrials is the
binomial distribution (9.38):
b(r|n,p)=/parenleftbiggn
r/parenrightbigg
pr(1−p)n−r. (9.82)

<<<PAGE 327>>>

9 Repetitive experiments: probability and frequency 295
There are several ways of calculating the moments of this distribution; one, easy to remem-
ber, is that the ﬁrst moment is
/angbracketleftr/angbracketright=E(r)
=n/summationdisplay
r=0rb(r|n,p)
=/bracketleftBigg
pd
dp/summationdisplay
r/parenleftbiggn
r/parenrightbigg
prq(n−r)/bracketrightBigg
q=1−p
=/parenleftbigg
pd
dp/parenrightbigg
×(p+q)n
=np;(9.83)
likewise,
/angbracketleftr2/angbracketright=/parenleftbigg
pd
dp/parenrightbigg2
(p+q)n=np+n(n−1)p2,
/angbracketleftr3/angbracketright=/parenleftbigg
pd
dp/parenrightbigg3
(p+q)n=np+2n(n−1)p2+n(n−1)(n−2)p3,(9.84)
and so on! For each higher moment we merely apply the operator ( pd/dp) one more time,
setting p+q=1 at the end.
Our (mean)±(standard deviation) estimate, over the sampling distribution, of ris then
(r)est=/angbracketleftr/angbracketright±/radicalbig
/angbracketleftr2/angbracketright−/angbracketleft r/angbracketright2
=np±/radicalbig
np(1−p),(9.85)
and our estimate of the frequency f=r/nwith which the event c=12 will occur in n
trials, is
(f)est=p±/radicalbigg
p(1−p)
n. (9.86)
These relations and their generalizations give the most commonly encountered connection
between probability and frequency; it is the original connection given by James Bernoulli(1713).
In the ‘long run’, therefore, we expect that the actual frequencies of various counts will be
distributed in a manner approximating the Poisson distribution (9.80) to within the tolerancesindicated by (9.86). Now we can perform the experiment, and the experimental frequencieseither will or will not resemble the predicted values. If, by the time we have observed a fewthousand counts, the observed frequencies are wildly different from a Poisson distribution(i.e. far outside the limits (9.86)), our intuition will tell us that the arguments which led to thePoisson prediction must be wrong; either the functional form of (9.80), or the independenceat different trials, must not represent the real conditions in which the experiment was done.

<<<PAGE 328>>>

296 Part 1 Principles and elementary applications
Yet we have not said anything about any alternatives! Is our intuitive common sense wrong
here, or is there some way we can reconcile it with probability theory? The question isnot about probability theory but about psychology; it concerns what our intuition is doinghere.
9.11.1 Implied alternatives
Let’s look again at (9.79). No matter what H
/primeis, we must have p(D|H/prime)≤1, and therefore
a statement which is independent of any alternative hypotheses is
e(H|DI)≥e(H|I)+10 log10p(D|H)=e(H|I)−ψ∞, (9.87)
where
ψ∞≡−10 log10p(D|H)≥0. (9.88)
Thus, there is no possible alternative which data D could support, relative to H, by more
thanψ∞decibels .
This suggests the solution to our paradox: in judging the amount of agreement between
theory and observation, the proper question to ask is not, ‘How well do data Dsupport
hypothesis H?’ without mentioning any alternatives. A much better question is, ‘Are there
any alternatives H/primewhich data Dwould support relative to H, and how much support is
possible?’ Probability theory can give no meaningful answer to the ﬁrst question becauseit is not well-posed; but it can give a very deﬁnite (quantitative and unambiguous) answerto the second.
We might be tempted to conclude that the proper criterion of ‘goodness of ﬁt’ is simply
ψ
∞; or what amounts to the same thing, just the probability p(D|H). This is not so, however,
as the following argument shows. As we noted at the end of Chapter 6, after we have obtained
D, it is always possible to invent a strange, ‘sure thing’ hypothesis HSaccording to which
every detail of Dwas inevitable: p(D|HS)=1, and HSwill always be supported relative to
Hby exactly ψ∞decibels. Let us see what this implies. Suppose we toss a die n=10 000
times and record the detailed results. Then, on the hypothesis H≡‘the die is honest’, each
of the 6npossible outcomes has probability 6−n,o r
ψ∞=10 log10(6n)=77 815 db . (9.89)
No matter what we observe in the 10 000 tosses, there is always an hypothesis HSthat
will be supported relative to Hby this enormous amount. If, after observing 10 000
tosses, we still believe the die is honest, it can be only because we considered theprior probability for H
Sto be even lower than −77 815 db. Otherwise, we are reasoning
inconsistently.
This is, if startling, all quite correct. The prior probability for HSwas indeed much lower
than 6−n, simply because there were 6ndifferent ‘sure thing’ hypotheses which were all
on the same footing before we observed the data D. But it is obvious that in practice we

<<<PAGE 329>>>

9 Repetitive experiments: probability and frequency 297
don’t want to bother with HS; even though it is supported by the data more than any other,
its prior probability is so low that we know in advance that we are not going to accept itanyway.
In practice, we are not interested in comparing Hto all conceivable alternatives, but only
to all those in some restricted class /Omega1, consisting of hypotheses which we consider in some
sense ‘reasonable’. Let us note one example (by far the most common and useful one) of atest relative to such a restricted class of alternatives.
Consider again the above experiment which has mpossible results{A
1,..., Am}at each
trial. Deﬁne the quantities
xi≡k, ifAkis true at the ith trial; (9.90)
thus, each xican take on independently the values 1 ,2,..., m. Now we wish to take into
account only the hypotheses belonging to the ‘Bernoulli class’ Bmin which there are m
possible results at each trial and the probabilities of the Akon successive repetitions of
the experiment are considered independent and stationary; thus, when His in Bm, the
probability conditional on Hof any speciﬁc sequence {x1,..., xn}of observations has the
form
p(x1...xn|H)=pn1
1...pnm
m, (9.91)
where nkis the above sample number. To every hypothesis in Bmthere corresponds a set
of numbers{p1...pm}such that pk≥0,/summationtext
kpk=1, and for our present purposes these
numbers completely characterize the hypothesis. Conversely, every such set of numbersdeﬁnes an hypothesis belonging to the Bernoulli class B
m.
Now we note an important lemma, given by J. Willard Gibbs (1902). Letting x=nk/npk,
and using the fact that on the positive real line log( x)≥(1−x−1) with equality if and only
ifx=1, we ﬁnd at once that
m/summationdisplay
k=1nklog/parenleftbiggnk
npk/parenrightbigg
≥0, (9.92)
with equality if and only if pk=nk/nfor all k. This inequality is the same as
logp(x1...xn|H)≤nm/summationdisplay
k=1fklog(fk), (9.93)
where fk=nk/nis the observed frequency of result Ak. The right-hand side of (9.88)
depends only on the observed sample D, so if we consider various hypotheses {H1,H2,...}
inBm, the quantity (9.88) gives us a measure of how well the different hypotheses ﬁt the
data; the nearer to equality, the better the ﬁt.
For convenience in numerical work, we express (9.88) in decibel units as in Chapter 4:
ψB≡10m/summationdisplay
k=1nklog10/parenleftbiggnk
npk/parenrightbigg
. (9.94)

<<<PAGE 330>>>

298 Part 1 Principles and elementary applications
To see the meaning of ψB, suppose we apply Bayes’ theorem in the form of (9.79). Only
two hypotheses, H={p1,..., pm}andH/prime={p/prime
1,..., p/prime
m}are being considered. Let the
values of ψBaccording to HandH/primebeψB,ψ/prime
B, respectively. Then Bayes’ theorem reads
e(H|x1...xn)=e(H|I)+10 log10/bracketleftbiggp(x1...xn|H)
p(x1...xn|H/prime)/bracketrightbigg
=e(H|I)+ψ/prime
B−ψB.(9.95)
Now we can always ﬁnd an hypothesis H/primeinBmfor which p/prime
k=nk/n, and so ψ/prime
B=0;
therefore ψBhas the following meaning:
Given an hypothesis Hand the observed data D≡{x1,..., xn}, compute ψBfrom
(9.94). Then, given any ψin the range 0≤ψ≤ψB, it is possible to ﬁnd an alternative
hypothesis H/primeinBmsuch that the data support H/primerelative to Hbyψdecibels. There is
noH/primeinBmwhich is supported relative to Hby more than ψBdecibels.
Thus, although ψBmakes no reference to any speciﬁc alternative, it is nevertheless exactly
the appropriate measure of ‘goodness of ﬁt’ relative to the class B mof Bernoulli alternatives .
It searches out Bmand locates the best alternative in that class.
Now we can understand the seeming paradox with which our discussion of signi ﬁcance
tests started; the ψ-test is just the quantitative version of what our intuition has been,
unconsciously, doing. We have already noted in Chapter 5, Section 5.4, that natural selectionin exactly the sense of Darwin would tend to evolve creatures that reason in a Bayesian way
because of its survival value.
We can also interpret ψ
Bin this manner: we may regard the observed results {x1,..., xn}
as a ‘message’ consisting of nsymbols chosen from an alphabet of mletters. On each repe-
tition of the experiment, Nature transmits to us one more letter of the message. How muchinformation is transmitted by this message under the Bernoulli probability assignment?Note that
ψ
B=10nm/summationdisplay
k=1fklog10(fk/pk) (9.96)
with fk=nk/n. Thus, (−ψB/n) is the entropy per symbol H(f;p) of the observed mes-
sage distribution{f1,..., fm}relative to the ‘expected distribution’ {p1,..., pm}. This
shows that the notion of entropy was always inherent in probability theory; independentlyof Shannon’s theorems, entropy or some monotonic function of entropy appears automat-ically in the equations of anyone who is willing to use Bayes’ theorem for hypothesistesting.
Historically, a different criterion was introduced by Karl Pearson early in the 20th century.
We expect that, if hypothesis His true, then n
kwill be close to npk, in the sense that the
difference|nk−npk|will grow with nonly as√n. Call this ‘condition A’. Then using the
expansion log( x)=(x−1)−(x−1)2/2+··· , we ﬁnd that
m/summationdisplay
k=1nklog/bracketleftbiggnk
npk/bracketrightbigg
=1
2/summationdisplay
k(nk−npk)2
npk+O/parenleftbigg1√n/parenrightbigg
, (9.97)

<<<PAGE 331>>>

9 Repetitive experiments: probability and frequency 299
the quantity designated as O(1/√n) tending to zero as indicated provided that the observed
sample does in fact satisfy condition A. The quantity
χ2≡m/summationdisplay
k=1(nk−npk)2
npk=n/summationdisplay
k(fk−pk)2
pk(9.98)
is thus very nearly proportional to ψBif the sample frequencies are close to the expected
values:
ψB=[10 log10(e)]×1
2χ2+O/parenleftbigg1√n/parenrightbigg
=4.343χ2+O/parenleftbigg1√n/parenrightbigg
. (9.99)
Pearson suggested that χ2be used as a criterion of ‘goodness of ﬁt’, and this has led to the
‘chi-squared test’, one of the most used techniques of orthodox statistics. Before describingthe test, we examine its theoretical basis and suitability as a criterion. Evidently, χ
2≥0,
with equality if and only if the observed frequencies agree exactly with those expectedif the hypothesis is true. So, larger values of χ
2correspond to greater deviation between
prediction and observation, and too large a value of χ2should lead us to doubt the truth of the
hypothesis. But these qualitative properties are possessed also by ψBand by any number of
other quantities we could deﬁne. We have seen how probability theory determines directlythe theoretical basis, and precise quantitative meaning, of ψ
B; so we ask whether there exists
any connected theoretical argument pointing to χ2as the optimal measure of goodness of
ﬁt, by some well-deﬁned criterion.
The results of a search for this connected argument are disappointing. Scanning a
number of orthodox textbooks, we ﬁnd that χ2is usually introduced as a straight deus
ex machina ; but Cram´ er (1946) does attempt to prepare the way for the idea, in these
words:
It will then be in conformity with the general principle of least squares to adopt as measure of deviation
an expression of the form/summationtextci(ni/n−pi)2where the coefﬁcients cimay be chosen more or less
arbitrarily. It was shown by K. Pearson that if we take ci=n/pi, we shall obtain a deviation measure
with particularly simple properties.
In other words, χ2is adopted, not because it is demonstrated to have good performance by
any criterion, but only because it has simple properties!
We have seen that in some cases χ2is nearly a multiple of ψB, and then they must, of
course, lead to essentially the same conclusions. But let us try to understand the quanti-tative difference in these criteria by a technique introduced in Jaynes (1976), which we
borrowed from Galileo. Galileo’s telescope was able to reveal the moons of Jupiter becauseit could magnify what was too small to be perceived by the unaided eye, up to the point
where it could be seen by everybody. Likewise, we often ﬁnd a quantitative difference in theBayesian and orthodox results, so small that our common sense is unable to pass judgmenton which result is preferable. But when this happens, we can ﬁnd some extreme case wherethe difference is magniﬁed to the point where common sense cantell us which method is
giving sensible results, and which is not.

<<<PAGE 332>>>

300 Part 1 Principles and elementary applications
As an example of this magniﬁcation technique, we compare ψBandχ2to see which is
the more reasonable criterion of goodness of ﬁt.
9.12 Comparison of psi and chi-squared
A coin toss can give three different results: (1) heads, (2) tails, (3) it may stand on edge if
it is sufﬁciently thick. Suppose that Mr A’s knowledge of the thick English pound coin is
such that he assigns probabilities p1=p2=0.499, p3=0.002 to these cases. We are in
communication with Mr Bon the planet Mars, who has never seen a coin and doesn’t have
the slightest idea what a coin is. So, when told that there are three possible results at eachtrial, and nothing more, he can only assign equal probabilities, p
/prime
1=p/prime
2=p/prime
3=1/3.
Now we want to test Mr A’s hypothesis against Mr B’s by doing a ‘random’ experiment.
We toss the coin 29 times and observe the results ( n1=n2=14,n3=1). Then if we use
theψcriterion, we would have for the two hypotheses
ψA=10/bracketleftbigg
28 log10/parenleftbigg14
29×0.499/parenrightbigg
+log10/parenleftbigg1
29×0.002/parenrightbigg/bracketrightbigg
=8.34 db,
ψB=10/bracketleftbigg
28 log10/parenleftbigg14×3
29/parenrightbigg
+log10/parenleftbigg3
29/parenrightbigg/bracketrightbigg
=35.19 db.(9.100)
From this experiment, Mr Blearns two things: (a) that there is another hypothesis about the
coin that is 35.2 db better than his (this corresponds to odds of over 3 300:1), and so, unlesshe can justify an extremely low prior probability for that alternative, he cannot reasonablyadhere to his ﬁrst hypothesis; and (b) that Mr A’s hypothesis is better than his by some
26.8 db, and in fact is within about 8 db of the best hypothesis in the Bernoulli class B
3.
Here the ψtest tells us pretty much what our common sense does.
Suppose that the man on Mars knew only about orthodox statistical principles as usually
taught; and therefore believed that χ2was the proper criterion of goodness of ﬁt. He would
ﬁnd that
χ2
A=2(14−29×0.499)2
29×0.499+(1−29×0.002)2
29×0.002
=15.33,
χ2
B=2(14−29×0.333)2
29×0.333+(1−29×0.333)2
29×0.333
=11.66,(9.101)
and he would report back delightedly: ‘My hypothesis, by the accepted statistical test, is
shown to be slightly preferable to yours!’
Many persons trained to use χ2will ﬁnd this comparison startling, and will try immedi-
ately to ﬁnd the error in our numerical work above. We have here still another fulﬁlment of

<<<PAGE 333>>>

9 Repetitive experiments: probability and frequency 301
what Cox’s theorems predict. The ψcriterion is exactly derivable from the rules of prob-
ability theory; therefore any criterion which is only an approximation to it must containeither an inconsistency or a qualitative violation of common sense, which can be exhibitedby producing special cases.
We can learn an important lesson about the practical use of χ
2by looking more closely
at what is happening here. On hypothesis A, the ‘expected’ number of heads or tails in 29
tosses was np1=14.471. The actual observed number must be an integer, and we supposed
that in each case it was the closest possible integer, namely 14. Yet this small discrepancybetween expected and observed sample numbers, in a sense the smallest it could possiblybe, nevertheless had an enormous effect on χ
2. The spook lies in the fact that χ2
Aturned out
so much larger than seems reasonable; there is nothing surprising about the other numericalvalues. Evidently, it is the last term in χ
2
A, which refers to the fact the coin stood on edge once
in 29 tosses, that is causing the trouble. On hypothesis A, the probability that this would
happen exactly rtimes in ntosses is our binomial distribution (9.57), and with n=29,
p=0.002, we ﬁnd that the probability for seeing the coin on edge one or more times in
29 trials is 1−b(0|n,p)=1−0.99829=1/17.73; i.e. the fact that we saw it even once is
a bit unexpected, and constitutes some evidence against A. But this amount of evidence is
certainly not overwhelming; if our travel guide tells us that London has fog, on the average,
one day in 18, we are hardly astonished to see fog on the day we arrive. Yet this contributes
an amount 15.30, almost all of the value of χ2
A=15.33.
It is the (1 /pi) weighting factor in the summand of χ2that causes this anomaly. Because
of it, the χ2criterion essentially concentrates its attention on the extremely unlikely possi-
bilities if the hypothesis contains them; and the slightest discrepancy between expected and
observed sample number for the unlikely events grotesquely over-penalizes the hypothesis.Theψ-test also contains this effect, but in a much milder form, the 1 /p
iterm appearing
only in the logarithm.
To see this effect more clearly, suppose now that the experiment had yielded instead the
results n1=14,n2=15,n3=0. Evidently, by either the χ2orψcriterion, this ought to
make hypothesis Alook better, Bworse, than in the ﬁrst example. Repeating the calculations,
we now ﬁnd
ψA=0.30 db χ2
A=0.0925
ψB=51.2d b χ2
B=14.55.(9.102)
You see that by far the greatest relative change was in χ2
A; both criteria now agree that
hypothesis Ais far superior to B, as far as this experiment indicates.
This shows what can happen through uncritical use of χ2. Professor Qbelieves in ex-
trasensory perception, and undertakes to prove it to us poor benighted, intransigent doubters.So he plays card games. As in Chapter 5, on the ‘null hypothesis’ that only chance is operat-ing, it is extremely unlikely that the subject will guess many cards correctly. But Professor Q
is determined to avoid the tactical errors of his predecessors, and is alert to the phenomenonof deception hypotheses discussed in Chapter 5; so he averts that possibility by making

<<<PAGE 334>>>

302 Part 1 Principles and elementary applications
videotape recordings of every detail of the experiments. The ﬁrst few hundred times he
plays, the results are disappointing; but these are readily explained away on the groundsthat the subject is not in a ‘receptive’ mood. Of course, the tapes recording these experimentsare erased.
One day, providence smiles on Professor Q; the subject comes through handsomely and
he has the incontrovertible record of it. Immediately he calls in the statisticians, the mathe-maticians, the notary publics, and the newspaper reporters. An extremely improbable eventhas at last occurred; and χ
2is enormous. Now he can publish the results and assert: ‘The
validity of the data is certiﬁed by reputable, disinterested persons, the statistical analysis hasbeen under the supervision of recognized statisticians, the calculations have been checkedby competent mathematicians. By the accepted statistical test, the null hypothesis has beendecisively rejected.’ And everything he has said is absolutely true!
Moral
For testing hypotheses involving moderately large probabilities, which agree moderately
well with observation, it will not make much difference whether we use ψorχ
2. But for
testing hypotheses involving extremely unlikely events, we had better use ψ; or life might
become too exciting for us.
9.13 The chi-squared test
Now we examine brieﬂy the chi-squared test as done in practice. We have the so-called ‘null
hypothesis’ Hto be tested, and no alternative is stated. The null hypothesis predicts certain
relative frequencies {f1,..., fm}and corresponding sample numbers nk=nfk, where nis
the number of trials. We observe the actual sample numbers {n1,..., nm}. But if the nkare
very small, we group categories together, so that each nkis at least, say, ﬁve. For example,
in a case with m=6, if the observed sample numbers were {6,11,14,7,3,2}we would
group the last two categories together, making it a problem with m=5 distinguishable
results per trial, with sample numbers {6,11,14,7,5}, and null hypothesis Hwhich assigns
probabilities{p1,p2,p3,p4,p5+p6}. We then calculate the observed value of χ2:
χ2
obs=m/summationdisplay
k=1(nk−npk)2
npk(9.103)
as our measure of deviation of observation from prediction. Evidently, it is very unlikely that
we would ﬁnd χ2
obs=0 even if the null hypothesis is true. So, goes the orthodox reasoning,
we should calculate the probability that χ2would have various values, and reject Hif the
probability P(χ2
obs) of ﬁnding a deviation as great as or greater than χ2
obsis sufﬁciently
small; this is the ‘tail area’ criterion, and one usually takes 5% (that is, P(χ2
obs)=0.05) as
the threshold of rejection.
Now the nkare integers, so χ2is capable of taking on only a discrete set of numerical
values, at most ( n+m−1)!/n!(m−1)! different values if the pkare all different and

<<<PAGE 335>>>

9 Repetitive experiments: probability and frequency 303
incommensurable. Therefore, the exact χ2distribution is necessarily discrete and deﬁned
at only a ﬁnite number of points. However, for sufﬁciently large n, the number and density
of points becomes so large that we may approximate the true χ2distribution by a continuous
one. The ‘simple property’ referred to by Cram´ er is then the fact, at ﬁrst glance surprising,
that, in the limit of large n, we obtain a universal distribution law: the sampling probability
thatχ2will lie in the interval d( χ2)i s
g(χ2)d(χ2)=χf−2
2f/2(f/2−1)!exp/braceleftbigg
−1
2χ2/bracerightbigg
d(χ2), (9.104)
where fis called the ‘number of degrees of freedom’ of the distribution. If the null hypoth-
esisHis completely speciﬁed (i.e., if it contains no variable parameters), then f=m−1,
where mis the number of categories used in the sum of (9.98). But if Hcontains unspeciﬁed
parameters which must be estimated from the data, we take f=m−1−r, where ris the
number of parameters estimated.5
We readily calculate the expectation and variance over this distribution: /angbracketleftχ2/angbracketright= f,
var(χ2)=2f, so the (mean)±(standard deviation) estimate of the χ2that we expect
to see is just
/parenleftbig
χ2/parenrightbig
est=f±/radicalbig
2f. (9.105)
The reason usually given for grouping categories for which the sample numbers are small,
is that the approximation (9.104) would otherwise be bad. But grouping inevitably throwsaway some of the relevant information in the data, and there is never any reason to do thiswhen using the exact ψ.
The probability that we would see a deviation as great as or greater than χ
2
obsis then
P(χ2
obs)=/integraldisplay∞
χ2
obsd(χ2)g(χ2)=/integraldisplay∞
qobsdqqk
k!exp{−q}, (9.106)
where q≡(1/2)χ2,k≡(f−2)/2. If P(χ2
obs)<0.05, we reject the null hypothesis at the
5% ‘signiﬁcance level’. Tables of χ2for which P=0.01, 0.05, 0.10, 0.50, for various
numbers of degrees of freedom, are given in most orthodox textbooks and collections ofstatistical tables (for example, Crow, Davis, and Maxﬁeld, 1960).
Note the traditional procedure here; we chose some basically arbitrary signiﬁcance level,
then reported only whether the null hypothesis was or was not rejected at that level. Evidentlythis doesn’t tell us very much about the real import of the data; if you tell me that thehypothesis was rejected at the 5% level, then I can’t tell from that whether it would havebeen rejected at the 1%, or 2%, level. If you tell me that it was not rejected at the 5%level, then I don’t know whether it would have been rejected at the 10%, or 20%, level. Theorthodox statistician would tell us far more about what the data really indicate if he wouldreport instead the signiﬁcance level P (χ
2)at which the null hypothesis is just barely rejected ;
for then we know what the verdict would be at all levels. This is the practice of reporting
5The need for this correction was perceived by the young R. A. Fisher but not comprehended by Karl Pearson; and this set off
the ﬁrst of their ﬁerce controversies, described in Chapter 16.

<<<PAGE 336>>>

304 Part 1 Principles and elementary applications
so-called ‘ P-values’, a major improvement over the original custom. Unfortunately, the
orthodox χ2and other tables are still so constructed that you cannot use them to report the
conclusions in this more informative way, because they give numerical values only at suchwidely separated values of the signiﬁcance level that interpolation is not possible.
How does one ﬁnd numerical P-values without using the chi-squared tables? Writing
q=q
0+t, (9.106) becomes
P=/integraldisplay∞
0dt(q0+t)k
k!exp{−(q0+t)}
=1
k!m/summationdisplay
k=0/parenleftbiggm
k/parenrightbigg/integraldisplay∞
0dtqk
0tm−kexp{−(q0+t)}
=m/summationdisplay
k=0exp{−q0}qk
0
k!.(9.107)
But this is just the cumulative Poisson distribution and easily computed.
If you use the ψ-test instead, however, you don’t need any tables. The evidential meaning
of the sample is then described simply by the numerical value ofψ, and not by a further
arbitrary construct such as tail areas. Of course, the numerical value of ψdoesn’t in itself tell
you whether to reject the hypothesis (although we could, with just as much justiﬁcation as inthe chi-squared test, prescribe some deﬁnite ‘level’ at which to reject). From the Bayesianpoint of view, there is simply no use in rejecting any hypothesis unless we can replaceit with a deﬁnite alternative known to be better; and, obviously, whether this is justiﬁedmust depend not only on ψ, but also on the prior probability for the alternative and on the
consequences of making wrong decisions. Common sense tells us that this is, necessarily,a problem not just of inference, but of decision theory.
In spite of the vast difference in viewpoints, there is not necessarily much difference
in the actual conclusions reached. For example, as the number of degrees of freedom f
increases, the orthodox statistician will accept a higher value of χ
2(roughly proportional to
f, as (9.105) indicates) on the grounds that such a high value is quite likely to occur if the
hypothesis is true; but the Bayesian, who will reject it only in favor of a deﬁnite alternative,must also accept a proportionally higher value of ψ, because the number of reasonable
alternatives is increasing exponentially with f, and the prior probability for any one of
them is correspondingly decreasing. So, in either case we end up rejecting the hypothesisifψorχ
2exceeds some critical limit, with an enormous difference in the philosophy of
how we choose that limit, but not necessarily a big difference in its actual location.
For many more details about chi-squared, see Lancaster (1969); and for some curious
views that Bayesian methods fail to give proper signiﬁcance tests, see Box and Tiao (1973).
9.14 Generalization
Although the point is not made in the orthodox literature, which does not mention alternatives
at all, we see from the preceding section that χ2is not a measure of goodness of ﬁt relative

<<<PAGE 337>>>

9 Repetitive experiments: probability and frequency 305
to all conceivable alternatives, but only relative to those in the same Bernoulli class. Until
this is recognized, one really does not know what the χ2-test is testing.
The procedure by which we constructed the ψ-test generalizes at once to the rule for
constructing the exact test which compares the null hypothesis to any well-deﬁned class C
of alternatives. Just write Bayes’ theorem describing the effect of data Don the relative
plausibility of two hypotheses H1,H2in that class, in the form
e(H1|DI)−e(H2|DI)=ψ2−ψ1, (9.108)
where ψidepends only on the data and Hiis non-negative over C, and vanishes for some
HiinC. Then we can always ﬁnd an H2inCfor which ψ2=0, and so we have constructed
the appropriate ψ1which measures goodness of ﬁt relative to the class of alternatives C,
and has the same meaning as that deﬁned after (9.95). ψ1is the maximum amount by which
any hypothesis in Ccan be supported relative to H1by the data D.
Thus, if we want a Bayesian test that is exact but operates in a similar way to orthodox
signiﬁcance tests, it can be produced quite easily. But we shall see in Chapter 17 thata different vie wpoint has advantages; the format of orthodox signi ﬁcance tests can be
replaced, as was done already by Laplace, by a parameter estimation procedure, whichyields even more useful information.
Anscombe (1963) held it to be a weakness of the Bayesian method that we had to
introduce a speciﬁc class of alternatives. We have answered that sufﬁciently here and in
Chapters 4 and 5. We would hold it to be a great merit of the Bayesian approach that itforces us to recognize these essential features of inference, which have not been apparent
to all orthodox statisticians. Our discussion of signiﬁcance tests is a good example of what,
we suggest, is the general situation; if an orthodox method is usable in some problem, thenthe Bayesian approach to inference supplies the missing theoretical basis for it, and usuallyimprovements on it. Any signiﬁcance test is only a slight variant of our multiple hypothesistesting procedures given in Chapter 4.
9.15 Halley’s mortality table
An early example of the use of observed frequencies as probabilities, in a more useful
and digniﬁed context than gambling, and by a procedure that is so nearly correct that wecould not improve on it appreciably today, was provided by the astronomer Edmund Halley(1656–1742) of ‘Halley’s Comet’ fame. Interested in many things besides astronomy, healso prepared in 1693 the ﬁrst modern mortality table. Let us dwell a moment on the detailsof this work because of its great historical interest.
The subject does not quite start with Halley, however. In England, due presumably to
increasing population densities, various plagues were rampant from the 16th century up tothe adoption of public sanitation policies and facilities in the mid-19th century. In London,starting intermittently in 1591, and continuously from 1604 for several decades, there werepublished weekly Bills of Mortality, which listed for each parish the number of births anddeaths of males and females and the statistics compiled by the Searchers , a body of ‘ancient

<<<PAGE 338>>>

306 Part 1 Principles and elementary applications
Matrons’ who carried out the unpleasant task of examining corpses, and, from the physical
evidence and any other information they were able to elicit by inquiry, judged as best asthey could the cause of each death.
In 1662, John Graunt (1620–74) called attention to the fact that these Bills, in their
totality, contained valuable demographic information that could be useful to governmentsand scholars for many other purposes besides judging the current state of public health(Graunt, 1662).
6He aggregated the data for 1632 into a single more useful table and made
the observation that, in sufﬁciently large pools of data on births, there are always slightlymore boys than girls, which circumstance provoked many speculations and calculations byprobabilists for the next 150 years. Graunt was not a scholar, but a self-educated shopkeeper.Nevertheless, his short work contained so much valuable good sense that it came to theattention of Charles II, who as a reward ordered the Royal Society (which he had foundedshortly before) to admit Graunt as a Fellow.
7
Edmund Halley was highly educated, mathematically competent (later succeeding Wallis
(in 1703) as Savilian Professor of Mathematics at Oxford University and Flamsteed (in 1720)as Astronomer Royal and Director of the Greenwich Observatory), a personal friend of IsaacNewton and the one who had persuaded him to publish his Principia by dropping his own
work to see it through publication and paying for it out of his own modest fortune. He was
eminently in a position to do more with demographic data than was John Graunt.
In undertaking to determine the actual distribution of age in the population, Halley had
extensive data on births and deaths from London and Dublin. But records of the age atdeath were often missing, and he perceived that London and Dublin were growing rapidlyby in-migration, biasing the data with people dying there who were not born there. Thosedata were so contaminated with trend that he had no means of extracting the information heneeded. So he found instead ﬁve years’ data (1687–91) for a city with a stable population:Breslau in Silesia (today called Wroclaw, in what is now Poland). Silesians, more meticulousin record keeping and less inclined to migrate, generated better data for his purpose.
Of course, contemporary standards of nutrition, sanitation, and medical care in Breslau
might differ from those in England. But in any event Halley produced a mortality tablesurely valid for Breslau and presumably not badly in error for England. We have convertedit into a graph, with three emendations described below, and present it in Figure 9.1.
In the 17th century, even so learned a man as Halley did not have the habits of full, clear
expression that we expect in scholarly works today. In reading his work we are exasperated
6It appears that this story may be repeated some 330 years later, in the recent realization that the records of credit card companies
contain a wealth of economic data which have been sitting there unused for many years. For the largest such company (Citicorp),a record of 1% of the nation’s retail sales comes into its computers every day. For predicting some economic trends and activity,
this is far more detailed, reliable, and timely than the monthly government releases.
7Contrast this enlightened attitude and behavior with that of Oliver Cromwell shortly before, who, through his henchmen, did
more wanton, malicious damage to Cambridge University than any other person in history. The writer lived for a year in the
Second Court of St John’s College, Cambridge, which Cromwell appropriated and put to use, not for scholarly pursuits, but asthe stockade for holding his prisoners. Whatever one may think of the private escapades of Charles II, one must ask also: againstwhat alternative do we judge him? Had the humorless fanatic Cromwell prevailed, there would have been no Royal Society, andno recognition for scholarly accomplishment in England; quite likely, the magniﬁcent achievements of British science in the19th century would not have happened. It is even problematical whether Cambridge and Oxford Universities would still existtoday.

<<<PAGE 339>>>

9 Repetitive experiments: probability and frequency 307
Table 9.1. Halley’s ﬁrst table.
Age d(y)/5A g e d(y)/5A g e d(y)/5A g e d(y)/5
0 348 28 8...1 0 9 0 1... 198... 7 63 12 91 1
71 1 3 5 7... 9.5 98 0
8 11 36 8 70 14 99 0.596... 9.5 71 9 100 3/5... 5.5 42 8 72 11
14 2...9... 9.5... 3.5 45 7 77 6
18 5...7...7... 6 49 10 81 3
21 4.5 54 11...4... 6.5 55 9 84 2
27 9 56 9...1
0 1 02 03 04 05 06 07 08 00200400600800
Years1000
Fig. 9.1. n(y): estimated number of persons in the age range ( y,y+1) years.
at the ambiguities and omissions, which make it impossible to ascertain some important
details about his data and procedure. We know that his data consisted of monthly records
of the number of births and deaths and the age of each person at death. Unfortunately, hedoes not show us the original, unprocessed data, which would today be of far greater valueto us than anything in his work, because, with modern probability theory and computers,we could easily process the data for ourselves, and extract much more information fromthem than Halley did.
Halley presents two tables derived from the data, giving respectively the estimated num-
berd(x) of annual deaths (total number/5) at each age of xyears, Table 9.1 (but which
inexplicably contains some entries that are not multiples of 1/5), and the estimated distri-bution n(x) of population by age, Table 9.2. Thus, the ﬁrst table is, crudely, something like

<<<PAGE 340>>>

308 Part 1 Principles and elementary applications
Table 9.2. Halley’s second table.
Age n(y)A g e n(y)A g e n(y)A g e n(y)A g e n(y)A g e n(y)A g e n(y)
1 1000 13 640 25 567 37 472 49 357 61 232 73 109
2 855 14 634 26 560 38 463 50 346 62 222 74 983 798 15 628 27 553 39 454 51 335 63 212 75 884 760 16 622 28 546 40 445 52 324 64 202 76 785 732 17 616 29 539 41 436 53 313 65 192 77 686 710 18 610 30 531 42 427 54 302 66 182 78 587 692 19 604 31 523 43 417 55 292 67 172 79 498 680 20 598 32 515 44 407 56 282 68 162 80 41
9 670 21 592 33 507 45 397 57 272 69 152 81 34
10 661 22 586 34 499 46 387 58 262 70 142 82 2811 653 23 579 35 490 47 377 59 252 71 131 83 2312 646 24 573 36 481 48 367 60 242 72 120 84 20
the negative derivative of the second. But, inexplicably, he omits the very young ( <7 yr)
from the ﬁrst table, and the very old ( >84 yr) from the second, thus withholding what are
in many ways the most interesting parts, the regions of strong curvature of the graph.
Even so, if we knew the exact procedure by which Halley constructed the tables from
the raw data, we might be able to reconstruct both tables in their entirety. But he givesabsolutely no information about this, saying only,
From these Considerations I have formed the adjoyned Table , whose Uses are manifold, and give a
more just Idea of the State andCondition of Mankind , than any thing yet extant that I know of.
But he fails to inform us what ‘these Considerations’ are, so we are reduced to conjecturing
what he actually did.
Although we were unable to ﬁnd any conjecture which is consistent with all the numerical
values in Halley’s tables, we can clarify things to some extent. Firstly, the actual numberof deaths at each age in the ﬁrst table naturally shows considerable ‘statistical ﬂuctuations’from one age to the next. Halley must have done some kind of smoothing of this, becausethe ﬂuctuations do not show in the second table.
From other evidence in his article, we infer that he reasoned as follows. If the population
distribution is stable (exactly the same next year as this year), then the difference n(25)−
n(26) between the number now alive at ages 25 and 26 must be equal to the number d(25)
now at age 25 who will die in the next year. Thus we would expect that the second tablemight be constructed by starting with the estimated number (1238) born each year as n(0),
and by recursion taking n(x)=n(x−1)−
d(x), where d(x) is the smoothed estimate of d.
Finally, the total population of Breslau is estimated as/summationtext
xn(x)=34 000. But, although the
later parts of Table 9.2 are well accounted for by this surmise, the early parts (0 <x<7)
do not ﬁt it, and we have been unable to form even a conjecture about how he determinedthe ﬁrst six entries of Table 9.2.

<<<PAGE 341>>>

9 Repetitive experiments: probability and frequency 309
We have shifted the ages downward by one year in our graph because it appears that the
common meanings of terms have changed in 300 years. Today, when we say colloquiallythat a boy is ‘eight years old’, we mean that his exact age xis in the range (8≤x<9); i.e.,
he is actually in his ninth year of life. But we can make sense out of Halley’s numbers onlyif we assume that for him the phrase ‘eight years current’ meant in the eighth year of life;7<x≤8. These points were noted also by Greenwood (1942), whose analysis conﬁrms
our conclusion about the meaning of ‘age current’. However, our attempt to follow hisreasoning beyond that point leaves us more confused than before. At this point we mustgive up, and simply accept Halley’s judgment, whatever it was.
In Figure 9.1 we give Halley’s second table as a graph of a shifted function n(y). Thus,
where Halley’s table reads (25 567) we give it as n(24)=567, which we interpret to mean
an estimated 567 persons in the age range (24 ≤x<25). Thus, our n(y) is what we believe
to be Halley’s estimated number of persons in the age range ( y,y+1) years.
Thirdly, Halley’s second table stops at the entry (84 20); yet the ﬁrst table has data
beyond that age, which he used in estimating the total population of Breslau. His ﬁrst table
indicates what we interpret as 19 deaths in the range (85 ,100) in the ﬁve years, including
three at ‘age current’ 100. He estimated the total population in that age range as 107. Wehave converted this meager information, plus other comparisons of the two tables, intoa smoothed extrapolation of Halley’s second table (our entries n(84),..., n(99)), which
shows the necessary sharp curvature in the tail.
What strikes us ﬁrst about this graph is the appalling infant mortality rate. Halley states
elsewhere that only 56% of those born survived to the age of six (although this does notagree with his Table 9.2) and that 50% survive to age 17 (which does agree with the table).
The second striking feature is the almost perfect linearity in the age range 35–80.
Halley notes various uses that can be made of his second table, including estimating
the size of the army that the city could raise, and the values of annuities. Let us consideronly one, the estimation of future life expectancy. We would think it reasonable to assign aprobability that a person of age ywill live to age z,a sp=n(z)/n(y), to sufﬁcient accuracy.
Actually, Halley does not use the word ‘probability’ but instead refers to ‘odds’ in exactly
the same way that we use it today: ‘ ...if the number of Persons of any Ageremaining after
one year, be divided by the difference between that and the number of the Age proposed,it shews the odds that there is, that a Person of that Age does not die in a Year.’ Thus,
Halley’s odds on a person living mmore years, given a present age of yyears, is O(m|y)=
n(y+m)/[n(y)−n(y+m)]=p/(1−p), in agreement with our calculation.
Another exasperating feature is that Halley pooled the data for males and females, and
thus failed to exhibit their different mortality functions; lacking his raw data, we are unableto rectify this.
Let the things which exasperate us in Halley’s work be a lesson for us today. The First
Commandment of scientiﬁc data analysis publication ought to be: ‘Thou shalt reveal thyfull original data, unmutilated by any processing whatsoever.’ Just as today we could dofar more with Halley’s raw data than he did, future readers may be able to do more withour raw data than we can, if only we will refrain from mutilating it according to our

<<<PAGE 342>>>

310 Part 1 Principles and elementary applications
present purposes and prejudices. At the very least, they will approach our data with a
different state of prior knowledge than ours, and we have seen how much this can affect theconclusions.
Exercise 9.3. Suppose you had the same raw data as Halley. How would you process
them today, taking full advantage of probability theory? How different would the actualconclusions be?
9.16 Comments
9.16.1 The irrationalists
Philosophers have argued over the nature of induction for centuries. Some, from David
Hume (1711–76) in the mid-18th century to Karl Popper in the mid-20th (for example,Popper and Miller, 1983), have tried to deny the possibility of induction, although allscientiﬁc knowledge has been obtained by induction. D. Stove (1982) calls them and theircolleagues ‘the irrationalists’ and tries to understand (1) how could such an absurd view everhave arisen?; and (2) by what linguistic practices do the irrationalists succeed in gainingan audience? However, we are not bothered by this situation because we are not convincedthat much of an audience exists.
In denying the possibility of induction, Popper holds that theories can never attain a high
probability. But this presupposes that the theory is being tested against an inﬁnite number ofalternatives. We would observe that the number of atoms in the known universe is ﬁnite; soalso, therefore, is the amount of paper and ink available to write alternative theories. It is notthe absolute status of an hypothesis embedded in the universe of all conceivable theories,but the plausibility of an hypothesis relative to a deﬁnite set of speciﬁed alternatives , that
Bayesian inference determines.
As we showed in connection with multiple hypothesis testing in Chapter 4, Newton’s
theory in Chapter 5, and the above discussion of signiﬁcance tests, an hypothesis can attaina very high or very low probability within a class of well-deﬁned alternatives . Its probability
within the class of all conceivable theories is neither large nor small; it is simply undeﬁnedbecause the class of all conceivable theories is undeﬁned. In other words, Bayesian inferencedeals with determinate problems – not the undeﬁned ones of Popper – and we would nothave it otherwise.
The objection to induction is often stated in different terms. If a theory cannot attain a
high absolute probability against all alternatives, then there is no way to prov e that induction
from it will be right. But that quite misses the point; it is not the function of induction to be‘right’, and working scientists do not use it for that purpose (and could not if we wanted to).
The functional use of induction in science is not to tell us what predictions must be true,
but rather what predictions are most strongly indicated by our present hypotheses and our
present information ?

<<<PAGE 343>>>

9 Repetitive experiments: probability and frequency 311
Put more carefully: What predictions are most strongly indicated by the information that
we have put into the calculation ? It is quite legitimate to do induction based on hypotheses
that we do not believe, or even that we know to be false, to learn what their predictableconsequences would be. Indeed, an experimenter seeking evidence for his favorite theorydoes not know what to look for unless he knows what predictions are made by somealternative theory. He must give temporary lip-service to the alternative in order to ﬁnd outwhat it predicts, although he does not really believe it.
If predictions made by a theory are borne out by future observation, then we become
more conﬁdent of the hypotheses that led to them; and if the predictions never fail in vastnumbers of tests, we come eventually to call those hypotheses ‘physical laws’. Successfulinduction is, of course, of great practical value in planning strategies for the future. Butfrom successful induction we do not learn anything basically new; we only become moreconﬁdent of what we knew already.
On the other hand, if the predictions prove to be wrong, then induction has served its
real purpose; we have learned that our hypotheses are wrong or incomplete, and from thenature of the error we have a clue as to how they might be improved. So those who criticizeinduction on the grounds that it might not be right, could not possibly be more mistaken.As Harold Jeffreys explained long ago, induction is most valuable to a scientist just when
it turns out to be wrong; only then do we get new fundamental knowledge.
Some striking case histories of induction in use are found in biology, where causal
relations are often so complex and subtle that it is remarkable that it was possible to un-cover them at all. For example, it became clear in the 20th century that new inﬂuenzapandemics were coming out of China; the worst ones acquired names like the Asian Flu(in 1957), the Hong Kong Flu (in 1968), and Beijing A (in 1993). It appears that the
cause has been traced to the fact that Chinese farmers raise ducks and pigs side by side.
Humans are not infected directly by viruses in ducks, even by handling them and eat-ing them; but pigs can absorb duck viruses, transfer some of their genes to other viruses,and in this form pass them on to humans, where they take on a life of their own be-cause they appear as something entirely new, for which the human immune system isunprepared.
An equally remarkable causal chain is in the role of the gooseberry as a host transmuting
and transmitting the white pine blister rust disease. Many other examples of unravelingsubtle cause–effect chains are found in the classic work of Louis Pasteur, and of modern
medical researchers who continue to succeed in locating the speciﬁc genes responsible for
various disorders.
We stress that all of these triumphant examples of highly important detective work were
accomplished by qualitative plausible reasoning using the format deﬁned by P´ olya (1954).
Modern Bayesian analysis is just the unique quantitative expression of this reasoning format,the inductive reasoning that Hume and Popper held to be impossible. It is true that thisreasoning format does not guarantee that the conclusion must be correct; but then direct
tests can conﬁrm it or refute it. Without the preparatory inductive reasoning phase, onewould not know which direct tests to try.

<<<PAGE 344>>>

312 Part 1 Principles and elementary applications
9.16.2 Superstitions
Another curious circumstance is that, although induction has proved a tricky thing to un-
derstand and justify logically, the human mind has a predilection for rampant, uncontrolledinduction, and it requires much education to overcome this. As we noted brieﬂy in Chapter 5,the reasoning of those without training in any mental discipline – who are therefore unfa-miliar with either deductive logic or probability theory – is mostly unjustiﬁed induction.
In spite of modern science, general human comprehension of the world has progressed
very little beyond the level of ancient superstitions. As we observe constantly in newscommentaries and documentaries, the untrained mind never hesitates to interpret everyobserved correlation as a causal inﬂuence, and to predict its recurrence in the future. Forone with no comprehension of what science is, it makes no difference whether that causationis or is not explainable rationally by a physical mechanism. Indeed, the very idea that a
causal inﬂuence requires a physical mechanism to bring it about is quite foreign to the
thinking of the uneducated; belief in supernatural inﬂuences makes such hypotheses, forthem, unnecessary.
8
Thus, the commentators for the very numerous television nature documentaries showing
us the behavior of animals in the wild, never hesitate to see in every random mutation someteleological purpose; always, the environmental niche is there and the animal mutates,purposefully, in order to adapt to it. Every conformation of feather, beak, and claw isexplained to us in terms of its purpose , but never suggesting how an unsubstantial purpose
could bring about a physical change in the animal.
9
It would seem that we have here a valuable opportunity to illustrate and explain evolution;
yet the commentators (usually out-of-work actors) have no comprehension of the simple,easily understood cause-and-effect mechanism pointed out over 100 years ago by CharlesDarwin. When we have the palpable evidence, and a simple explanation of it, before us,it is incredible that anybody could look to something supernatural, that nobody has everobserved, to explain it. But never does a commentator imagine that the mutation occurs ﬁrst,and the resulting animal is obliged to seek a niche where it can survive and use its bodystructures as best it can in that environment. We see only the ones who were successful atthis; the others are not around when the cameraman arrives, and their small numbers make
it unlikely that a paleontologist will ever ﬁnd evidence of them.
10These documentaries
always have very beautiful photography, and they deserve commentaries that make sense.
Indeed, there are powerful counter-examples to the theory that an animal adapts its body
structure purposefully to its environment. In the Andes mountains there are woodpeckerswhere there are no trees. Evidently, they did not become woodpeckers by adapting their body
8In the meantime, progress in human knowledge continues to be made by those who, like modern biologists, do think in terms
of physical mechanisms; as soon as that premise is abandoned, progress ceases, as we observe in modern quantum theory.
9But it is hard to believe that the ridiculous color patterns of the wood duck and the pileated woodpecker serve any survivalpurpose; what would the teleologists have to say about this? Our answer would be that, even without subsequent natural selection,
divergent evolution can proceed by mutations that have nothing to do with survival. We noted some of this in Chapter 7, in
connection with the work of Francis Galton.
10But a striking exception was found in the Burgess shale of the Canadian Rockies (Gould, 1989), in which beautifully preservedfossils of soft-bodied creatures contemporary with trilobites, which did not survive to leave any evolutionary lines, were found
in such profusion that it radically revised our picture of life in the Cambrian.

<<<PAGE 345>>>

9 Repetitive experiments: probability and frequency 313
structures to their environment; rather, they were woodpeckers ﬁrst who, ﬁnding themselves
through some accident in a strange environment, survived by putting their body structuresto a different use. Indeed, the creatures arriving at any environmental niche are seldomperfectly adapted to it; often they are just barely well enough adapted to survive. But then,in this stressful situation, bad mutations are eliminated faster than usual, so natural selectionoperates faster than usual to make them better adapted.

<<<PAGE 346>>>

10
Physics of ‘random experiments’
I believe, for instance, that it would be very difﬁcult to persuade an
intelligent physicist that current statistical practice was sensible, but that
there would be much less difﬁculty with an approach via likelihood andBayes’ theorem.
G. E. P . Box (1962)
As we have noted several times, the idea that probabilities are physically real things, based
ultimately on observed frequencies of random variables, underlies most recent expositionsof probability theory, which would seem to make it a branch of experimental science. Atthe end of Chapter 8 we s aw some of the difﬁculties that this view leads us to; in some
real physical experiments the distinction between random and nonrandom quantities is so
obscure and artiﬁcial that you have to resort to black magic in order to force this distinctioninto the problem at all. But that discussion did not reach into the serious physics of the
situation. In this chapter, we take time off for an interlude of physical considerations that
show the fundamental difﬁculty with the notion of ‘random’ experiments.
10.1 An interesting correlation
There have always been dissenters from the ‘frequentist’ view who have maintained, with
Laplace, that probability theory is properly regarded as the ‘calculus of inductive reasoning’,
and is not fundamentally related to random experiments at all. A major purpose of the presentwork is to demonstrate that probability theory can deal, consistently and usefully, with farmore than frequencies in random experiments. According to this view, consideration ofrandom experiments is only one specialized application of probability theory, and not even
the most important one; for probability theory as logic solves far more general problemsof reasoning which have nothing to do with chance or randomness, but a great deal to dowith the real world. In the present chapter we carry this further and show that ‘frequentist’probability theory has major logical difﬁculties in dealing with the very random experimentsfor which it was invented.
One who studies the literature of these matters perceives that there is a strong correlation;
those who have advocated the non-frequency view have tended to be physicists, while,
314

<<<PAGE 347>>>

10 Physics of ‘random experiments’ 315
up until very recently, mathematicians, statisticians, and philosophers almost invariably
favored the frequentist view. Thus, it appears that the issue is not merely one of philosophyor mathematics; in some way not yet clear, it also involves physics.
The mathematician tends to think of a random experiment as an abstraction – really
nothing more than a sequence of numbers. To deﬁne the ‘nature’ of the random experiment,he introduces statements – variously termed assumptions, postulates, or axioms – whichspecify the sample space and assert the existence, and certain other properties, of limitingfrequencies. But, in the real world, a random experiment is not an abstraction whose prop-erties can be deﬁned at will. It is surely subject to the laws of physics; yet recognition ofthis is conspicuously missing from frequentist expositions of probability theory. Even thephrase ‘laws of physics’ is not to be found in them. However, deﬁning a probability as afrequency is not merely an excuse for ignoring the laws of physics; it is more serious thanthat. We want to show that maintenance of a frequency interpretation to the exclusion of allothers requires one to ignore virtually all the professional knowledge that scientists have
about real phenomena. If the aim is to draw inferences about real phenomena, this is hardly
the way to begin.
As soon as a speciﬁc random experiment is described, it is the nature of a physicist
to start thinking, not about the abstract sample space thus deﬁned, but about the physicalmechanism of the phenomenon being observed. The question whether the usual postulatesof probability theory are compatible with the known laws of physics is capable of logicalanalysis, with results that have a direct bearing on the question, not of the mathematicalconsistency of frequency and non-frequency theories of probability, but of their applicabilityin real situations. In our opening quotation, the statistician G. E. P. Box noted this; let us
analyze his statement in the light both of history and of physics.
10.2 Historical background
As we know, probability theory started in consideration of gambling devices by Gerolamo
Cardano in the 16th century, and by Pascal and Fermat in the 17th; but its developmentbeyond that level, in the 18th and 19th centuries, was stimulated by applications in astronomyand physics, and was the work of people – James and Daniel Bernoulli, Laplace, Poisson,Legendre, Gauss, Boltzmann, Maxwell, Gibbs – most of whom we would describe todayas mathematical physicists.
Reactions against Laplace had begun in the mid-19th century, when Cournot (1843), Ellis
(1842, 1863), Boole (1854), and Venn (1866) – none of whom had any training in physics –were unable to comprehend Laplace’s rationale and attacked what he did, simply ignoringall his successful results. In particular, John Venn, a philosopher without the tiniest fractionof Laplace’s knowledge of either physics or mathematics, nevertheless considered himselfcompetent to write scathing, sarcastic attacks on Laplace’s work. In Chapter 16 we notehis possible later inﬂuence on the young R. A. Fisher. Boole (1854, Chaps XX and XXI)shows repeatedly that he does not understand the function of Laplace’s prior probabilities (torepresent a state of knowledge rather than a physical fact). In other words, he too suffers from

<<<PAGE 348>>>

316 Part 1 Principles and elementary applications
the mind projection fallacy. On p. 380 he rejects a uniform prior probability assignment as
‘arbitrary’, and explicitly refuses to examine its consequences; by which tactics he prevents
himself from learning what Laplace was really doing and why.
Laplace was defended staunchly by the mathematician Augustus de Morgan (1838, 1847)
and the physicist W. Stanley Jevons,1who understood Laplace’s motivations and for whom
his beautiful mathematics was a delight rather than a pain. Nevertheless, the attacks of Booleand Venn found a sympathetic hearing in England among non-physicists. Perhaps this wasbecause biologists, whose training in physics and mathematics was for the most part notmuch better than Venn’s, were trying to ﬁnd empirical evidence for Darwin’s theory andrealized that it would be necessary to collect and analyze large masses of data in order todetect the small, slow trends that they visualized as the means by which evolution proceeds.Finding Laplace’s mathematical works too much to digest, and since the profession ofstatistician did not yet exist, they would naturally welcome suggestions that they need notread Laplace after all.
In any event, a radical change took place at about the beginning of the 20th century when
a new group of workers, not physicists, entered the ﬁeld. They were concerned mostlywith biological problems and with Venn’s encouragement proceeded to reject virtuallyeverything done by Laplace. To ﬁll the vacuum, they sought to develop the ﬁeld anewbased on entirely different principles in which one assigned probabilities only to data and tonothing else. Indeed, this did simplify the mathematics at ﬁrst, because many of the problemssolvable by Laplace’s methods now lay outside the gambit of their methods. As long as theyconsidered only relatively simple problems (technically, problems with sufﬁcient statisticsbut no nuisance parameters and no important prior information), the shortcoming was not
troublesome. This extremely aggressive school soon dominated the ﬁeld so completely that
its methods have come to be known as ‘orthodox’ statistics, and the modern profession ofstatistician has evolved mostly out of this movement. Simultaneously with this development,the physicists – with Sir Harold Jeffreys as almost the sole exception – quietly retired from theﬁeld, and statistical analysis disappeared from the physics curriculum. This disappearancehas been so complete that if today someone were to take a poll of physicists, we think thatnot one in 100 could identify such names as Fisher, Neyman or Wald, or such terms asmaximum likelihood, conﬁdence interval, analysis of variance.
This course of events – the leading role of physicists in development of the original
Bayesian methods, and their later withdrawal from orthodox statistics – was no accident.As further evidence that there is some kind of basic conﬂict between orthodox statisticaldoctrine and physics, we may note that two of the most eloquent proponents of nonfrequencydeﬁnitions in the early 20th century – Poincar´ e and Jeffreys – were mathematical physicists
of the very highest competence, as was Laplace. Professor Box’s statement thus has a clearbasis in historical fact.
1Jevons did so many things that it is difﬁcult to classify him by occupation. Zabell (1989), apparently guided by the title of one
of his books (Jevons, 1874), describes Jevons as a logician and philosopher of science; from examination of his other works weare inclined to list him rather as a physicist who wrote extensively on economics.

<<<PAGE 349>>>

10 Physics of ‘random experiments’ 317
But what is the nature of this conﬂict? What is there in the physicist’s knowledge that leads
him to reject the very thing that the others regard as conferring ‘objectivity’ on probabilitytheory? To see where the difﬁculty lies, we examine a few simple random experiments fromthe physicist’s viewpoint. The facts we want to point out are so elementary that one cannotbelieve they are really unknown to modern writers on probability theory. The continualappearance of new textbooks which ignore them merely illustrates what we physics teachershave always known: you can teach a student the laws of physics, but you cannot teach himthe art of recognizing the relevance of this knowledge, much less the habit of actually
applying it, in his everyday problems.
10.3 How to cheat at coin and die tossing
Cram´ er (1946) takes it as an axiom that ‘any random variable has a unique probability
distribution’. From the later context, it is clear that what he really means is that it has aunique frequency distribution. If one assumes that the number obtained by tossing a die is
a random variable, this leads to the conclusion that the frequency with which a certain facecomes up is a physical property of the die; just as much so as its mass, moment of inertia,or chemical composition. Thus, Cram´ er (1946, p. 154) states:
The numbers prshould, in fact, be regarded as physical constants of the particular die that we are
using, and the question as to their numerical values cannot be answered by the axioms of probabilitytheory, any more than the size and the weight of the die are determined by the geometrical andmechanical axioms. However, experience shows that in a well-made die the frequency of any event r
in a long series of throws usually approaches 1/6, and accordingly we shall often assume that all the
p
rare equal to 1/6 ....
To a physicist, this statement seems to show utter contempt for the known laws of me-
chanics. The results of tossing a die many times do nottell us any deﬁnite number char-
acteristic only of the die. They tell us also something about how the die was tossed. Ifyou toss ‘loaded’ dice in different ways, you can easily alter the relative frequencies ofthe faces. With only slightly more difﬁculty, you can still do this if your dice are perfectly‘honest’.
Although the principles will be just the same, it will be simpler to discuss a random
experiment with only two possible outcomes per trial. Consider , therefore, a ‘biased’ coin,
about which I. J. Good (1962) has remarked:
Most of us probably think about a biased coin as if it had a physical probability. Now whether it is
deﬁned in terms of frequency or just falls out of another type of theory, I think we do argue that way.I suspect that even the most extreme subjecti vist such as de Finetti would have to agree that he did
sometimes think that way, though he would perhaps avoid doing it in print.
We do not know de Finetti’s private thoughts, but would observe that it is just the famous
exchangeability theorem of de Finetti which shows us how to carry out a probability analysisof the biased coin without thinking in the manner suggested.

<<<PAGE 350>>>

318 Part 1 Principles and elementary applications
In any event, it is easy to show how a physicist would analyze the problem. Let us suppose
that the center of gravity of this coin lies on its axis, but displaced a distance xfrom its
geometrical center. If we agree that the result of tossing this coin is a ‘random variable’,then, according to the axiom stated by Cram´ er and hinted at by Good, there must exist a
deﬁnite functional relationship between the frequency of heads and x:
p
H=f(x). (10.1)
But this assertion goes far beyond the mathematician’s traditional range of freedom to invent
arbitrary axioms, and encroaches on the domain of physics; for the laws of mechanics arequite competent to tell us whether such a functional relationship does or does not exist.
The easiest game to analyze turns out to be just the one most often played to decide such
practical matters as the starting side in a football game. Your opponent ﬁrst calls ‘heads’ or‘tails’ at will. You then toss the coin into the air, catch it in your hand, and, without looking
at it, show it ﬁrst to your opponent, who wins if he has called correctly. It is further agreed
that a ‘fair’ toss is one in which the coin rises at least nine feet into the air, and thus spendsat least 1.5 seconds in free ﬂight.
The laws of mechanics now tell us the following. The ellipsoid of inertia of a thin disc is
an oblate spheroid of eccentricity 1 /√
2. The displacement xdoes not affect the symmetry
of this ellipsoid, and, so according to the Poinsot construction, as found in textbooks onrigid dynamics (such as Routh, 1905, or Goldstein, 1980, Chap. 5), the polhodes remain
circles concentric with the axis of the coin. In consequence, the character of the tumbling
motion of the coin while in ﬂight is exactly the same for a biased as an unbiased coin, exceptthat for the biased one it is the center of gravity, rather than the geometrical center, which
describes the parabolic ‘free particle’ trajectory.
An important feature of this tumbling motion is conservation of angular momentum;
during its ﬂight the angular momentum of the coin maintains a ﬁxed direction in space (butthe angular velocity does not; and so the tumbling may appear chaotic to the eye). Let us
denote this ﬁxed direction by the unit vector n; it can be any direction you choose, and it
is determined by the particular kind of twist you give the coin at the instant of launching.Whether the coin is biased or not, it will show the same face throughout the motion if viewedfrom this direction (unless, of course, nis exactly perpendicular to the axis of the coin, in
which case it shows no face at all).
Therefore, in order to know which face will be uppermost in your hand, you have only
to carry out the following procedure. Denote by ka unit vector passing through the coin
along its axis, with its point on the ‘heads’ side. Now toss the coin with a twist so that kand
nmake an acute angle, then catch it with your palm held ﬂat, in a plane normal to n.O n
successive tosses, you can let the direction of n, the magnitude of the angular momentum,
and the angle between nandk, vary widely; the tumbling motion will then appear entirely
different to the eye on different tosses, and it would require almost superhuman powers ofobservation to discover your strategy.
Thus, anyone familiar with the law of conservation of angular momentum can, after some
practice, cheat at the usual coin-toss game and call his shots with 100% accuracy. You can

<<<PAGE 351>>>

10 Physics of ‘random experiments’ 319
obtain any frequency of heads you want – and the bias of the coin has no inﬂuence at all
on the results !
Of course, as soon as this secret is out, someone will object that the experiment analyzed
is too ‘simple’. In other words, those who have postulated a physical probability for thebiased coin have, without stating so, really had in mind a more complicated experiment inwhich some kind of ‘randomness’ has more opportunity to make itself felt.
While accepting this criticism, we cannot suppress the obvious comment: scanning the
literature of probability theory, isn’t it curious that so many mathematicians, usually far morecareful than physicists to list all the qualiﬁcations needed to make a statement correct, shouldhave failed to see the need for any qualiﬁcations here? However, to be more constructive,we can just as well analyze a more complicated experiment.
Suppose that now, instead of catching the coin in our hands, we toss it onto a table, and
let it spin and bounce in various ways until it comes to rest. Is this experiment sufﬁciently‘random’ so that the true ‘physical probability’ will manifest itself? No doubt, the answerwill be that it is not sufﬁciently random if the coin is merely tossed up six inches starting atthe table level, but it will become a ‘fair’ experiment if we toss it up higher.
Exactly how high, then, must we toss it before the true physical probability can be
measured? This is not an easy question to answer, and we make no attempt to answer it here.
It would appear, however, that anyone who asserts the existence of a physical probability
for the coin ought to be prepared to answer it; otherwise, it is hard to see what content theassertion has (that is, the assertion has the nature of theology rather than science; there isno way to conﬁrm it or disprove it).
We do not deny that the bias of the coin will now have some inﬂuence on the frequency of
heads; we claim only that the amount of that inﬂuence depends very much on how you tossthe coin so that, again in this experiment, there is no deﬁnite number p
H=f(x) describing
a physical property of the coin. Indeed, even the direction of this inﬂuence can be reversedby different methods of tossing, as follows.
However high we toss the coin, we still have the law of conservation of angular momen-
tum; and so we can toss it by method A : to ensure that heads will be uppermost when the
coin ﬁrst strikes the table, we have only to hold it heads up, and toss it so that the totalangular momentum is directed vertically. Again, we can vary the magnitude of the angularmomentum, and the angle between nandk, so that the motion appears quite different to
the eye on different tosses, and it would require very close observation to notice that headsremains uppermost throughout the free ﬂight. Although what happens after the coin strikesthe table is complicated, the fact that heads is uppermost at ﬁrst has a strong inﬂuence onthe result, which is more pronounced for large angular momentum.
Many people have developed the knack of tossing a coin by method B : it goes through a
phase of standing on edge and spinning rapidly about a vertical axis, before ﬁnally fallingto one side or the other. If you toss the coin this way, the eccentric position of the centerof gravity will have a dominating inﬂuence, and render it practically certain that it will fallalways showing the same face. Ordinarily, one would suppose that the coin prefers to fallin the position which gives it the lowest center of gravity; i.e., if the center of gravity is

<<<PAGE 352>>>

320 Part 1 Principles and elementary applications
displaced toward tails, then the coin should have a tendency to show heads. However, for
an interesting mechanical reason, which we leave for you to work out from the principlesof rigid dynamics, method Bproduces the opposite inﬂuence, the coin strongly preferring
to fall so that its center of gravity is high.
On the other hand, the bias of the coin has a rather small inﬂuence in the opposite direction
if we toss it by method C : the coin rotates about a horizontal axis which is perpendicular to
the axis of the coin, and so bounces until it can no longer turn over.
In this experiment also, a person familiar with the laws of mechanics can toss a biased
coin so that it will produce predominantly either heads or tails, at will. Furthermore, theeffect of method Apersists whether the coin is biased or not; and so one can even do
this with a perfectly ‘honest’ coin. Finally, although we have been considering only coins,essentially the same mechanical considerations (with more complicated details) apply tothe tossing of any other object, such as a die.
The writer has never thought of a biased coin ‘as if it had a physical probability’ because,
being a professional physicist, I know that it does nothave a physical probability. From the
fact that we have seen a strong preponderance of heads, we cannot conclude legitimately thatthe coin is biased; it may be biased, or it may have been tossed in a way that systematicallyfavors heads. Likewise, from the fact that we have seen equal numbers of heads and tails,we cannot conclude legitimately that the coin is ‘honest’. It may be honest, or it may havebeen tossed in a way that nulliﬁes the effect of its bias.
10.3.1 Experimental evidence
Since the conclusions just stated are in direct contradiction to what is postulated, almost
universally, in expositions of probability theory, it is worth noting that we can verify themeasily in a few minutes of experimentation in a kitchen. An excellent ‘biased coin’ is providedby the metal lid of a small pickle jar, of the type which is not knurled on the outside, andhas the edge rolled inward rather than outward, so that the outside surface is accuratelyround and smooth, and so symmetrical that on an edge view one cannot tell which is thetop side. Suspecting that many people not trained in physics simply would not believe thethings just claimed without experimental proof, we have performed these experiments with ajar lid of diameter d=2
5
8inches, height h=3
8inch. Assuming a uniform thickness for
the metal, the center of gravity should be displaced from the geometrical center by a
distance x=dh/(2d+8h)=0.120 inches; and this was conﬁrmed by hanging the lid by its
edge and measuring the angle at which it comes to rest. Ordinarily, one expects this bias
to make the lid prefer to fall bottom side (i.e., the inside) up; and so this side will be
called ‘heads’. The lid was tossed up about 6 feet, and fell onto a smooth linoleum ﬂoor. Iallowed myself ten practice tosses by each of the three methods described, and then recordedthe results of a number of tosses by: method Adeliberately favoring heads, method A
deliberately favoring tails, method B, and method C, as given in Table 10.1.
In method Athe mode of tossing completely dominated the result (the effect of bias
would, presumably, have been greater if the ‘coin’ were tossed onto a surface with a greater

<<<PAGE 353>>>

10 Physics of ‘random experiments’ 321
Table 10.1. Results of tossing a ‘biased
coin’ in four different ways.
Method Number of tosses Number of heads
A(H) 100 99
A(T)5 0 0
B 100 0
C 100 54
coefﬁcient of friction). In method B, the bias completely dominated the result (in about
30 of these tosses it looked for a while as if the result were going to be heads, as onemight naively expect; but each time the ‘coin’ eventually righted itself and turned over, aspredicted by the laws of rigid dynamics). In method C, there was no signiﬁcant evidence
for any effect of bias. The conclusions are pretty clear.
A holdout can always claim that tossing the coin in any of the four speciﬁc ways described
is ‘cheating’, and that there exists a ‘fair’ way of tossing it, such that the ‘true’ physicalprobabilities of the coin will emerge from the experiment. But again, the person who assertsthis should be prepared to deﬁne precisely what this fair method is, otherwise the assertionis without content. Presumably, a fair method of tossing ought to be some kind of randommixture of methods A(H),A(T),B,C, and others; but what is a ‘fair’ relative weighting
to give them? It is difﬁcult to see how one could deﬁne a ‘fair’ method of tossing except bythe condition that it should result in a certain frequency of heads; and so we are involved ina circular argument.
This analysis can be carried much further, as we shall do below; but perhaps it is suf-
ﬁciently clear already that analysis of coin and die tossing is not a problem of abstractstatistics, in which one is free to introduce postulates about ‘physical probabilities’ whichignore the laws of physics. It is a problem of mechanics, highly complicated and irrelevantto probability theory except insofar as it forces us to think a little more carefully about howprobability theory must be formulated if it is to be applicable to real situations. Performinga random experiment with a coin does not tell us what the physical probability for heads is;it may tell us something about the bias, but it also tells us something about how the coin isbeing tossed. Indeed, unless we know how it is being tossed, we cannot draw any reliable
inferences about its bias from the experiment.
It may not, however, be clear from the above that conclusions of this type hold quite
generally for random experiments, and in no way depend on the particular mechanicalproperties of coins and dice. In order to illustrate this, consider an entirely different kind ofrandom experiment, as a physicist views it.
10.4 Bridge hands
Elsewhere we quote Professor William Feller ’s pronouncements on the use of Bayes ’ the-
orem in quality control testing (Chapter 17), on Laplace’s rule of succession (Chapter 18),

<<<PAGE 354>>>

322 Part 1 Principles and elementary applications
and on Daniel Bernoulli’s conception of the utility function for decision theory (Chapter 13).
He does not fail us here either; in his interesting textbook (Feller, 1950), he writes:
The number of possible distributions of cards in bridge is almost 1030. Usually, we agree to consider
them as equally probable. For a check of this convention more than 1030experiments would be
required – a billion of billion of years if every living person played one game every second, day andnight.
Here again, we have the view that bridge hands possess ‘physical probabilities,’ that the
uniform probability assignment is a ‘convention’, and that the ultimate criterion for itscorrectness must be observed frequencies in a random experiment.
The thing which is wrong here is that none of us – not even Feller – would be willing to
use this criterion with a real deck of cards. Because, if we know that the deck is an honestone, our common sense tells us something which carries more weight than 10
30random
experiments do. We would, in fact, be willing to accept the result of the random experimentonly if it agreed with our preconceived notion that all distributions are equally likely .
To many, this last statement will seem like pure blasphemy – it stands in violent contra-
diction to what we have all been taught is the correct attitude toward probability theory. Yet,in order to see why it is true, we have only to imagine that those 10
30experiments hadbeen
performed, and the uniform distribution was not forthcoming. If all distributions of cardshave equal frequencies, then any combination of two speciﬁed cards will appear together ina given hand, on the average, once in (52 ×51)/(13×12)=17 deals. But suppose that the
combination (jack of hearts – seven of clubs) appeared together in each hand three times asoften as this. Would we then accept it as an established fact that there is something about
the particular combination (jack of hearts – seven of clubs) that makes it inherently morelikely than others?
We would not. We would reject the experiment and say that the cards had not been
properly shufﬂed. But once again we are involved in a circular argument, because thereis no way to deﬁne a ‘proper’ method of shufﬂing except by the condition that it shouldproduce all distributions with equal frequency!
Any attempt to ﬁnd such a deﬁnition involves one in even deeper logical difﬁculties; one
dare not describe the procedure of shufﬂing in exact detail because that would destroy the‘randomness’ and make the exact outcome predictable and always the same. In order to
keep the experiment ‘random’, one must describe the procedure incompletely, so that the
outcome will be different on different runs. But how could one prove that an incompletelydeﬁned procedure will produce all distributions with equal frequency? It seems to us thatthe attempt to uphold Feller’s postulate of physical probabilities for bridge hands leads oneinto an outright logical contradiction.
Conventional teaching holds that probability assignments must be based fundamentally
on frequencies; and that any other basis is at best suspect, at worst irrational with disastrousconsequences. On the contrary, this example shows very clearly that there is a principle
for determining probability assignments which has nothing to do with frequencies, yet is socompelling that it takes precedence over any amount of frequency data . If present teaching

<<<PAGE 355>>>

10 Physics of ‘random experiments’ 323
does not admit the existence of this principle, it is only because our intuition has run so
far ahead of logical analysis – just as it does in elementary geometry – that we have nevertaken the trouble to present that logical analysis in a mathematically respectable form. Butif we learn how to do this, we may expect to ﬁnd that the mathematical formulation can beapplied to a much wider class of problems, where our intuition alone would hardly sufﬁce.
In carrying out a probability analysis of bridge hands, are we really concerned with phys-
ical probabilities, or with inductive reasoning? To help answer this, consider the followingscenario. The date is 1956, when the writer met Willy Feller and had a discussion with himabout these matters. Suppose I had told him that I have dealt at bridge 1000 times, shufﬂing‘fairly’ each time; and that in every case the seven of clubs was in my own hand. Whatwould his reaction be? He would, I think, mentally visualize the number
/parenleftbigg1
4/parenrightbigg1000
=10−602, (10.2)
and conclude instantly that I have not told the truth; and no amount of persuasion on my
part would shake that judgment. But what accounts for the strength of his belief? Obviously,it cannot be justiﬁed if our assignment of equal probabilities to all distributions of cards
(therefore probability 1/4 for the seven of clubs to be in the dealer’s hand) is merely a‘convention’, subject to change in the light of experimental evidence; he rejects my reportedexperimental evidence, just as we did above. Even more obviously, he is not making use ofany knowledge about the outcome of an experiment involving 10
30bridge hands.
Then what is the extra evidence he has , which his common sense tells him carries more
weight than do any number of random experiments, but whose help he refuses to acknowl-edge in writing textbooks? In order to maintain the claim that probability theory is anexperimental science, based fundamentally not on logical inference but on frequency in arandom experiment, it is necessary to suppress some of the information which is available.This suppressed information, however, is just what enables our inferences to approach thecertainty of deductive reasoning in this example and many others.
The suppressed evidence is, of course, simply our recognition of the symmetry of the
situation. The only difference between a seven and an eight is that there is a differentnumber printed on the face of the card. Our common sense tells us that where a cardgoes in shufﬂing depends only on the mechanical forces that are applied to it; and not on
which number is printed on its face. If we observe any systematic tendency for one card
to appear in the dealer’s hand, which persists on indeﬁnite repetitions of the experiment,we can conclude from this only that there is some systematic tendency in the procedure ofshufﬂing, which alone determines the outcome of the experiment.
Once again, therefore, performing the experiment tells you nothing about the ‘physical
probabilities’ of different bridge hands. It tells you something about how the cards are beingshufﬂed. But the full power of symmetry as cogent evidence has not yet been revealed inthis argument; we return to it presently.

<<<PAGE 356>>>

324 Part 1 Principles and elementary applications
10.5 General random experiments
In the face of all the foregoing arguments, one can still take the following position (as a
member of the audience did after one of the writer’s lectures): ‘You have shown only thatcoins, dice, and cards represent exceptional cases, where physical considerations obviatethe usual probability postulates; i.e., they are not really ‘random experiments’. But that isof no importance because these devices are used only for illustrative purposes; in the moredigniﬁed random experiments which merit the serious attention of the scientist, there isa
physical probability.’
To answer this we note two points. Firstly, we reiterate that when anyone asserts the
existence of a physical probability in any experiment, then the onus is on him to deﬁnethe exact circumstances in which this physical probability can be measured; otherwise theassertion is without content.
This point needs to be stressed: those who assert the existence of physical probabilities
do so in the belief that this establishes for their position an ‘objectivity’ that those whospeak only of a ‘state of knowledge’ lack. Yet to assert as fact something which cannotbe either proved or disproved by observation of facts is the opposite of objectivity; it is toassert something that one could not possibly know to be true. Such an assertion is not evenentitled to be called a description of a ‘state of knowledge’.
Secondly, note that any speciﬁc experiment for which the existence of a physical prob-
ability is asserted is subject to physical analysis like the ones just given, which will leadeventually to an understanding of its mechanism. But as soon as this understanding isreached, then this new experiment will also appear as an exceptional case like the abo ve
ones, where physical considerations obviate the usual postulates of physical probabilities.
For, as soon as we have understood the mechanism of any experiment E, then there is
logically no room for any postulate that various outcomes possess physical probabilities; thequestion: ‘What are the probabilities of various outcomes ( O
1,O2,...)?’ then reduces im-
mediately to the question: ‘What are the probabilities of the corresponding initial conditions(I
1,I2,...) that lead to these outcomes?’
We might suppose that the possible initial conditions {Ik}of experiment Ethemselves
possess physical probabilities. But then we are considering an antecedent random experi-ment E
/prime, which produces conditions Ikas its possible outcomes: Ik=O/prime
k. We can analyze
the physical mechanism of E/primeand, as soon as this is understood, the question will revert to:
‘What are the probabilities of the various initial conditions I/prime
kfor experiment E/prime?’
Evidently, we are involved in an inﬁnite regress {E,E/prime,E/prime/prime,...}; the attempt to introduce
a physical probability will be frustrated at every level where our knowledge of physical lawpermits us to analyze the mechanism involved. The notion of ‘physical probability’ mustretreat continually from one level to the next, as knowledge advances.
We are, therefore, in a situation very much like the ‘warfare between science and
theology’ of earlier times. For several centuries, theologians with no factual knowledgeof astronomy, physics, biology, and geology nevertheless considered themselves com-petent to make dogmatic factual assertions which encroached on the domains of those

<<<PAGE 357>>>

10 Physics of ‘random experiments’ 325
ﬁelds – assertions which they were later forced to retract one by one in the face of advanc-
ing knowledge.
Clearly, probability theory ought to be formulated in a way that avoids factual assertions
properly belonging to other ﬁelds, and which will later need to be retracted (as is now thecase for many assertions in the literature concerning coins, dice, and cards). It appears to usthat the only formulation which accomplishes this, and at the same time has the analyticalpower to deal with the current problems of science, is the one which was seen and expoundedon intuitive grounds by Laplace and Jeffreys. Its validity is a question of logic, and doesnot depend on any physical assumptions.
As we saw in Chapter 2, a major contribution to that logic was made by R. T. Cox (1946,
1961), who showed that those intuitive grounds can be replaced by theorems. We think itis no accident that Richard Cox was also a physicist (Professor of Physics and Dean of theGraduate School at Johns Hopkins University), to whom the things we have pointed outhere would be evident from the start.
The Laplace–Jeffreys–Cox formulation of probability theory does not require us to take
one reluctant step after another down that inﬁnite regress; it recognizes that anything which –
like the child’s spook – continually recedes from the light of detailed inspection can existonly in our imagination. Those who believe most strongly in physical probabilities, like thosewho believe in astrology, never seem to ask what would constitute a controlled experimentcapable of conﬁrming or disproving their belief.
Indeed, the examples of coins and cards should persuade us that such controlled exper-
iments are, in principle, impossible. Performing any of the so-called random experimentswill not tell us what the ‘physical probabilities’ are, because there is no such thing as a
‘physical probability’ ; we might as well ask for a square circle. The experiment tells us, in
a very crude and incomplete way, something about how the initial conditions are varyingfrom one repetition to another.
A much more efﬁcient way of obtaining this information would be to observe the initial
conditions directly. However, in many cases this is beyond our present abilities; as in de-termining the safety and effectiveness of a new medicine. Here the only fully satisfactoryapproach would be to analyze the detailed sequence of chemical reactions that follow the tak-ing of this medicine, in persons of every conceivable state of health. Having this analysis, onecould then predict, for each individual patient, exactly what the effect of the medicine will be.
Such an analysis being entirely out of the question at present, the only feasible way
of obtaining information about the effectiveness of a medicine is to perform a ‘random’experiment. No two patients are in exactly the same state of health; and the unknownvariations in this factor constitute the variable initial conditions of the experiment, whilethe sample space comprises the set of distinguishable reactions to the medicine. Our use ofprobability theory in this case is a standard example of inductive reasoning which amountsto the following.
If the initial conditions of the experiment (i.e., the physiological conditions of the patients
who come to us) continue in the future to vary over the same unknown range as they havein the past, then the relative frequency of cures will, in the future, approximate those which

<<<PAGE 358>>>

326 Part 1 Principles and elementary applications
we have observed in the past. In the absence of positive evidence giving a reason why there
should be some change in the future, andindicating in which direction this change should go,
we have no grounds for predicting any change in either direction, and so can only supposethat things will continue in more or less the same way. As we observe the relative frequenciesof cures and side-effects to remain stable over longer and longer times, we become moreand more conﬁdent about this conclusion. But this is only inductive reasoning – there is nodeductive proof that frequencies in the future will not be entirely different from those in thepast.
Suppose now that the eating habits or some other aspect of the lifestyle of the population
starts to change. Then, the state of health of the incoming patients will vary over a differentrange than before, and the frequency of cures for the same treatment may start to driftup or down. Conceivably, monitoring this frequency could be a useful indicator that thehabits of the population are changing, and this in turn could lead to new policies in medicalprocedures and public health education.
At this point, we see that the logic invoked here is virtually identical with that of industrial
quality control, discussed in Chapter 4. But looking at it in this greater generality makes ussee the role of induction in science in a very different way than has been imagined by somephilosophers.
10.6 Induction revisited
As we noted in Chapter 9, some philosophers have rejected induction on the grounds that
there is no way to prove that it is ‘right’ (theories can never attain a high probability); butthis misses the point. The function of induction is to tell us not which predictions are right,but which predictions are indicated by our present knowledge. If the predictions succeed,then we are pleased and become more conﬁdent of our present knowledge; but we have notlearned much.
The real role of induction in science was pointed out clearly by Harold Jeffreys (1931,
Chap. 1) over 60 years ago; yet, to the best of our knowledge, no mathematician or philoso-pher has ever taken the slightest note of what he had to say:
A common argument for induction is that induction has always worked in the past and therefore may
be expected to hold in the future. It has been objected that this is itself an inductive argument andcannot be used in support of induction. What is hardly ever mentioned is that induction has oftenfailed in the past and that progress in science is very largely the consequence of direct attention toinstances where the inductive method has led to incorrect predictions.
Put more strongly, it is only when our inductive inferences are wrong that we learn new
things about the real world. For a scientist, therefore, the quickest path to discovery isto examine those situations where it appears most likely that induction from our presentknowledge will fail. But those inferences must be our bestinferences, which make full use
of all the knowledge we have. One can always make inductive inferences that are wrong ina useless way, merely by ignoring cogent information.

<<<PAGE 359>>>

10 Physics of ‘random experiments’ 327
Indeed, that is just what Popper did. His trying to interpret probability itself as expressing
physical causation not only cripples the applications of probability theory in the way wesaw in Chapter 3 (it would prevent us from getting about half of all conditional probabilitiesright because they express logical connections rather than causal physical ones), it leadsone to conjure up imaginary causes while ignoring what was already known about thereal physical causes at work. This can reduce our inferences to the level of pre-scientiﬁc,uneducated superstition, even when we have good data.
Why do physicists see this more readily than others? Because, having created this knowl-
edge of physical law, we have a vested interest in it and want to see it preserved andused. Frequency or propensity interpretations start by throwing away practically all theprofessional knowledge that we have labored for centuries to get. Those who have notcomprehended this are in no position to discourse to us on the philosophy of science or theproper methods of inference.
10.7 But what about quantum theory?
Those who cling to a belief in the existence of ‘physical probabilities’ may react to the
above arguments by pointing to quantum theory, in which physical probabilities appear toexpress the most fundamental laws of physics. Therefore let us explain why this is another
case of circular reasoning. We need to understand that present quantum theory uses entirely
different standards of logic than does the rest of science.
In biology or medicine, if we note that an effect E(for example, muscle contraction,
phototropism, digestion of protein) does not occur unless a condition C(nerve impulse,
light, pepsin) is present, it seems natural to infer that Cis a necessary causative agent for
E. Most of what is known in all ﬁelds of science has resulted from following up this kind
of reasoning. But suppose that condition Cdoes not always lead to effect E; what further
inferences should a scientist draw? At this point, the reasoning formats of biology andquantum theory diverge sharply.
In the biological sciences, one takes it for granted that in addition to Cthere must be some
other causative factor F, not yet identiﬁed. One searches for it, tracking down the assumed
cause by a process of elimination of possibilities that is sometimes extremely tedious. Butpersistence pays off; over and over again, medically important and intellectually impressivesuccess has been achieved, the conjectured unknown causative factor being ﬁnally identiﬁedas a deﬁnite chemical compound. Most enzymes, vitamins, viruses, and other biologicallyactive substances owe their discovery to this reasoning process.
In quantum theory, one does not reason in this way. Consider, for example, the photo-
electric effect (we shine light on a metal surface and ﬁnd that electrons are ejected fromit). The experimental fact is that the electrons do not appear unless light is present. So lightmust be a causative factor. But light does not always produce ejected electrons; even thoughthe light from a unimode laser is present with absolutely steady amplitude, the electronsappear only at particular times that are not determined by any known parameters of thelight. Why then do we not draw the obvious inference, that in addition to the light there

<<<PAGE 360>>>

328 Part 1 Principles and elementary applications
must be a second causative factor, still unidentiﬁed, and the physicist’s job is to search
for it?
What is done in quantum theory today is just the opposite; when no cause is apparent one
simply postulates that no cause exists – ergo, the laws of physics are indeterministic andcan be expressed only in probability form. The central dogma is that the light determinesnot whether a photoelectron will appear, but only the probability that it will appear. Themathematical formalism of present quantum theory – incomplete in the same way that ourpresent knowledge is incomplete – does not even provide the vocabulary in which one couldask a question about the real cause of an event.
Biologists have a mechanistic picture of the world because, being trained to believe in
causes, they continue to use the full power of their brains to search for them – and so theyﬁnd them. Quantum physicists have only probability laws because for two generations wehave been indoctrinated not to believe in causes – and so we have stopped looking for them.Indeed, any attempt to search for the causes of microphenomena is met with scorn and acharge of professional incompetence and‘obsolete mechanistic materialism’. Therefore,
to explain the indeterminacy in current quantum theory we need not suppose there is anyindeterminacy in Nature; the mental attitude of quantum physicists is already sufﬁcient toguarantee it.
2
This point also needs to be stressed, because most people who have not studied quan-
tum theory on the full technical level are incredulous when told that it does not concernitself with causes; and, indeed, it does not even recognize the notion of ‘physical reality’.The currently taught interpretation of the mathematics is due to Niels Bohr, who directedthe Institute for Theoretical Physics in Copenhagen; therefore it has come to be called ‘TheCopenhagen interpretation’.
As Bohr stressed repeatedly in his writings and lectures, present quantum theory can
answer only questions of the form: ‘If this experiment is performed, what are the possibleresults and their probabilities?’ It cannot, as a matter of principle, answer any questionof the form: ‘What is really happening when ...?’ Again, the mathematical formalism of
present quantum theory, like Orwellian newspeak , does not even provide the vocabulary in
which one could ask such a question. These points have been explained in some detail byJaynes (1986d, 1989, 1990a, 1992a).
We suggest, then, that those who try to justify the concept of ‘physical probability’ by
pointing to quantum theory are entrapped in circular reasoning, not basically different fromthat noted above with coins and bridge hands. Probabilities in present quantum theoryexpress the incompleteness of human knowledge just as truly as did those in classicalstatistical mechanics; only its origin is different.
2Here, there is a striking similarity to the position of the parapsychologists Soal and Bateman (1954), discussed in Chapter 5.
They suggest that to seek a physical explanation of parapsychological phenomena is a regression to the quaint and reprehensible
materialism of Thomas Huxley. Our impression is that by 1954 the views of Huxley in biology were in a position of completetriumph over vitalism, supernaturalism, or any other anti-materialistic teachings; for example, the long mysterious immunemechanism was at last understood, and the mechanism of DNA replication had just been discovered. In both cases the phenomena
could be described in ‘mechanistic’ terms so simple and straightforward – templates, geometrical ﬁt, etc. – that they would be
understood immediately in a machine shop.

<<<PAGE 361>>>

10 Physics of ‘random experiments’ 329
In classical statistical mechanics, probability distributions represented our ignorance of
the true microscopic coordinates – ignorance that was avoidable in principle but unavoidablein practice, but which did not prevent us from predicting reproducible phenomena, justbecause those phenomena are independent of the microscopic details.
In current quantum theory, probabilities express our own ignorance due to our failure
to search for the real causes of physical phenomena; and, worse, our failure even to thinkseriously about the problem. This ignorance may be unavoidable in practice, but in ourpresent state of knowledge we do not know whether it is unavoidable in principle; the‘central dogma’ simply asserts this, and draws the conclusion that belief in causes, andsearching for them, is philosophically na¨ ıve. If everybody accepted this and abided by it,
no further advances in understanding of physical law would ever be made; indeed, no suchadvance has been made since the 1927 Solvay Congress in which this mentality becamesolidiﬁed into physics.
3But it seems to us that this attitude places a premium on stupidity;
to lack the ingenuity to think of a rational physical explanation is to support the supernaturalview.
To many people, these ideas are almost impossible to comprehend because they are so
radically different from what we have all been taught from childhood. Therefore, let us showhow just the same situation could have happened in coin tossing, had classical physicists
used the same standards of logic that are now used in quantum theory.
10.8 Mechanics under the clouds
We are fortunate that the principles of Newtonian mechanics could be developed and veriﬁed
to great accuracy by studying astronomical phenomena, where friction and turbulence donot complicate what we see. But suppose the Earth were, like Venus, enclosed perpetuallyin thick clouds. The very existence of an external universe would be unknown for a longtime, and to develop the laws of mechanics we would be dependent on the observations wecould make locally.
Since tossing of small objects is nearly the ﬁrst activity of every child, it would be
observed very early that they do not always fall with the same side up, and that all one’sefforts to control the outcome are in vain. The natural hypothesis would be that it is thevolition of the object tossed, not the volition of the tosser, that determines the outcome;indeed, that is the hypothesis that small children make when questioned about this.
Then it would be a major discovery, once coins had been fabricated, that they tend to
show both sides about equally often; and the equality appears to get better as the numberof tosses increases. The equality of heads and tails would be seen as a fundamental law ofphysics; symmetric objects have a symmetric volition in falling (as, indeed, Cram´ er and
Feller seem to have thought).
3Of course, physicists continued discovering new particles and calculation techniques – just as an astronomer can discover a new
planet and a new algorithm to calculate its orbit, without any advance in his basic understanding of celestial mechanics.

<<<PAGE 362>>>

330 Part 1 Principles and elementary applications
With this beginning, we could develop the mathematical theory of object tossing, dis-
covering the binomial distribution, the absence of time correlations, the limit theorems, thecombinatorial frequency laws for tossing of several coins at once, the extension to morecomplicated symmetric objects like dice, etc. All the experimental conﬁrmations of thetheory would consist of more and more tossing experiments, measuring the frequencies inmore and more elaborate scenarios. From such experiments, nothing would ever be foundthat called into question the existence of that volition of the object tossed; they only enableone to conﬁrm that volition and measure it more and more accurately.
Then, suppose that someone was so foolish as to suggest that the motion of a tossed object
is determined, not by its own volition, but by laws like those of Newtonian mechanics,governed by its initial position and velocity. He would be met with scorn and derision; forin all the existing experiments there is not the slightest evidence for any such inﬂuence.The Establishment would proclaim that, since all the observable facts are accounted forby the volition theory, it is philosophically na¨ ıve and a sign of professional incompetence
to assume or search for anything deeper . In this respect, the elementary physics textbooks
would read just like our present quantum theory textbooks.
Indeed, anyone trying to test the mechanical theory would have no success; however
carefully he tossed the coin (not knowing what we know) it would persist in showing headand tails about equally often. To ﬁnd any evidence for a causal instead of a statistical theorywould require control over the initial conditions of launching, orders of magnitude moreprecise than anyone can achieve by hand tossing. We would continue almost indeﬁnitely,satisﬁed with laws of physical probability and denying the existence of causes for individualtosses external to the object tossed – just as quantum theory does today – because thoseprobability laws account correctly for everything that we can observe reproducibly with thetechnology we are using.
After thousands of years of triumph of the statistical theory, someone ﬁnally makes a
machine which tosses coins in absolutely still air, with very precise control of the exactinitial conditions. Magically, the coin starts giving unequal numbers of heads and tails; thefrequency of heads is being controlled partially by the machine. With development of moreand more precise machines, one ﬁnally reaches a degree of control where the outcome ofthe toss can be predicted with 100% accuracy. Belief in ‘physical probabilities’ expressing
a volition of the coin is recognized ﬁnally as an unfounded superstition. The existence ofan underlying mechanical theory is proved beyond question; and the long success of theprevious statistical theory is seen as due only to the lack of control over the initial conditionsof the tossing.
Because of recent spectacular advances in the technology of experimentation, with in-
creasingly detailed control over the initial states of individual atoms (see, for example,Rempe, Walter and Klein, 1987), we think that the stage is going to be set, before verymany more years have passed, for the same thing to happen in quantum theory; a centuryfrom now the true causes of microphenomena will be known to every schoolboy and, toparaphrase Seneca, they will be incredulous that such clear truths could have escaped usthroughout the 20th (and into the 21st) century.

<<<PAGE 363>>>

10 Physics of ‘random experiments’ 331
10.9 More on coins and symmetry
Now we go into a more careful, detailed discussion of some of these points, alluding to
technical matters that must be explained more fully elsewhere. The rest of this chapter isnot for the casual reader; only the one who wants a deeper understanding than is conveyedby the above simple scenarios. But many of the attacks on Laplace arise from failure tocomprehend the following points.
The problems in which intuition compels us most strongly to a uniform probability
assignment are not the ones in which we merely apply a principle of ‘equal distributionof ignorance’. Thus, to explain the assignment of equal probabilities to heads and tails onthe grounds that we ‘saw no reason why either face should be more likely than the other’,fails utterly to do justice to the reasoning involved. The point is that we have not merely‘equal ignorance’. We also have positive knowledge of the symmetry of the problem; and
introspection will show that when this positive knowledge is lacking, so also is our intuitivecompulsion toward a uniform distribution. In order to ﬁnd a respectable mathematicalformulation, we therefore need to ﬁnd ﬁrst a more respectable verbal formulation. Wesuggest that the following verbalization does do justice to the reasoning, and shows us howto generalize the principle.
I perceive here two different problems: having formulated one deﬁnite problem – call it P 1– involving
the coin, the operation which interchanges heads and tails transforms the problem into a differentone – call it P
2. If I have positive knowledge of the symmetry of the coin, then I know that all
relevant dynamical or statistical considerations, however complicated, are exactly the same in the twoproblems. Whatever state of knowledge I had in P
1, I must therefore have exactly the same state of
knowledge in P 2, except for the interchange of heads and tails. Thus, whatever probability I assign to
heads in P 1, consistency demands that I assign the same probability to tails in P 2.
Now, it might be quite reasonable to assign probability 2/3 to heads, 1/3 to tails in P 1;
whereupon, from symmetry, it must be 2/3 to tails, 1/3 to heads in P 2. This might be the
case, for example, if P 1speciﬁed that the coin is to be held between the ﬁngers heads up,
and dropped just one inch onto a table. Thus, symmetry of the coin by no means compels usto assign equal probabilities to heads and tails; the question necessarily involves the otherconditions of the problem.
But now suppose the statement of the problem is changed in just one respect; we are
no longer told whether the coin is held initially with heads up or tails up. In this case, ourintuition suddenly takes over with a compelling force, and tells us that we must assign equal
probabilities to heads and tails; and, in fact, we must do this regardless of what frequencies
have been observed in previous repetitions of the experiment .
The great power of symmetry arguments lies just in the fact that they are not deterred
by any amount of complication in the details. The conservation laws of physics arise inthis way; thus, conservation of angular momentum for an arbitrarily complicated system ofparticles is a simple consequence of the fact that the Lagrangian is invariant under spacerotations. In current theoretical physics, almost the only known exact results in atomic and

<<<PAGE 364>>>

332 Part 1 Principles and elementary applications
nuclear structure are those which we can deduce by symmetry arguments, using the methods
of group theory.
These methods could be of the highest importance in probability theory also, if orthodox
ideology did not forbid their use. For example, they enable us, in many cases, to extend theprinciple of indifference to ﬁnd consistent prior probability assignments in a continuousparameter space /Theta1, where its use has always been considered ambiguous. The basic point
is that a consistent principle for assigning prior probabilities must have the property that itassigns equivalent priors to represent equivalent states of knowledge.
The prior distribution must therefore be invariant under the symmetry group of the prob-
lem; and so the prior can be speciﬁed arbitrarily only in the so-called ‘fundamental domain’of the group (Wigner, 1959). This is a subspace /Theta1
0⊂/Theta1such that (1) applying two differ-
ent group elements gi/negationslash=gjto/Theta10, the subspaces /Theta1i≡gi,/Theta10,/Theta1j≡gj,/Theta10are disjoint;
and (2) carrying out all group operations on /Theta10just generates the full hypothesis space:
∪j/Theta1j=/Theta1.
For e xample, let points in a plane be de ﬁned by their polar coordinates ( r,α). If the group
is the four-element one generated by a 90◦rotation of the plane, then any sector 90◦wide,
such as ( β≤α<β+π/2), is a fundamental domain. Specifying the prior in any such
sector, symmetry under the group then determines the prior everywhere in the plane.
If the group contains a continuous symmetry operation, the dimensionality of the funda-
mental domain is less than that of the parameter space; and so the probability density needbe speciﬁed only on a set of points of measure zero, whereupon it is determined everywhere.If the number of continuous symmetry operations is equal to the dimensionality of the space/Theta1, the fundamental domain reduces to a single point, and the prior probability distribution
is then uniquely determined by symmetry alone, just as it is in the case of an honest coin.Later we shall formalize and generalize these symmetry arguments.
There is still an important constructive point to be made about the power of symmetry
arguments in probability theory. To see it, let us go back for a closer look at the coin-tossing problem. The laws of mechanics determine the motion of the coin, as describinga certain trajectory in a 12-dimensional phase space (three coordinates ( q
1,q2,q3) of its
center of mass, three Eulerian angles ( q4,q5,q6) specifying its orientation, and six associated
momenta ( p1,..., p6)). The difﬁculty of predicting the outcome of a toss arises from the fact
that very small changes in the location of the initial phase point can change the ﬁnal results.
Imagine the possible initial phase points to be labeled HorT, according to the ﬁnal
results. Contiguous points labeled Hcomprise a set which is presumably twisted about
in the 12-dimensional phase space in a very complicated, convoluted way, parallel to andseparated by similar T-sets.
Consider now a region Rof phase space, which represents the accuracy with which a
human hand can control the initial phase point. Because of limited skill, we can be sureonly that the initial point is somewhere in R, which has a phase volume
/Gamma1(R)=/integraldisplay
Rdq1···dq6dp1···dp6. (10.3)

<<<PAGE 365>>>

10 Physics of ‘random experiments’ 333
If the region Rcontains both HandTdomains, we cannot predict the result of the toss.
But what probability should we assign to heads? If we assign equal probability to equalphase volumes in R, this is evidently the fraction p
H≡/Gamma1(H)//Gamma1(R) of phase volume
ofRthat is occupied by Hdomains. This phase volume /Gamma1is the ‘invariant measure’ of
phase space. The cogency of invariant measures for probability theory will be explainedlater; for now we note that the measure /Gamma1is invariant under a large group of ‘canonical’
coordinate transformations, and also under the time development, according to the equationsof motion. This is Liouville’s theorem, fundamental to statistical mechanics; the expositionof Gibbs (1902) devotes the ﬁrst three chapters to discussion of it, before introducingprobabilities.
Now, if we have positive knowledge that the coin is perfectly ‘honest’, then it is clear that
the fraction /Gamma1(H)//Gamma1(R) is very nearly 1/2, and becomes more accurately so as the size of
the individual HandTdomains become smaller compared with R. Because, for example,
if we are launching the coin in a region Rwhere the coin makes 50 complete revolutions
while falling, then a 1% change in the initial angular velocity will just interchange headsand tails by the time the coin reaches the ﬂoor. Other things being equal (all dynamicalproperties of the coin involve heads and tails in the same manner), this should just reversethe ﬁnal result.
A change in the initial ‘orbital’ velocity of the coin, which results in a 1% change in the
time of ﬂight, should also do this (strictly speaking, these conclusions are only approximate,but we expect them to be highly accurate, and to become more so if the changes becomeless than 1%). Thus, if all other initial phase coordinates remain ﬁxed, and we vary only the
initial angular velocity ˙θand upward velocity ˙z, the HandTdomains will spread into thin
ribbons, like the stripes on a zebra. From symmetry, the width of adjacent ribbons must bevery nearly equal.
This same ‘parallel ribbon’ shape of the HandTdomains presumably holds also in
the full phase space.
4This is quite reminiscent of Gibbs’ illustration of ﬁne-grained and
coarse-grained probability densities, in terms of the stirring of colored ink in water. Ona sufﬁciently ﬁne scale, every phase region is either HorT; the probability for heads is
either zero or unity. But on the scale of sizes of the ‘macroscopic’ region Rcorresponding
to ordinary skills, the probability density is the coarse-grained one, which from symmetrymust be very nearly 1/2 if we know that the coin is honest.
What if we don’t consider all equal phase volumes within Ras equally likely? Well, it
doesn’t really matter if the HandTdomains are sufﬁciently small. ‘Almost any’ probability
density which is a smooth, continuous function within R, will give nearly equal weight to the
HandTdomains, and we will still have very nearly 1/2 for the probability for heads. This
is an example of a general phenomenon, discussed by Poincar´ e, that, in cases where small
4Actually, if the coin is tossed onto a perfectly ﬂat and homogeneous level ﬂoor, and is not only perfectly symmetrical under
the reﬂection operation that interchanges heads and tails, but also perfectly round, the probability for heads is independent ofﬁve of the 12 coordinates, so we have this intricate structure only in a seven-dimensional space. Let the reader for whom this
is a startling statement think about it hard, to see why symmetry makes ﬁve coordinates irrelevant (they are the two horizontal
coordinates of its center of mass, the direction of its horizontal component of momentum, the Eulerian angle for rotation abouta vertical axis, and the Eulerian angle for rotation about the axis of the coin).

<<<PAGE 366>>>

334 Part 1 Principles and elementary applications
changes in initial conditions produce big changes in the ﬁnal results, our ﬁnal probability
assignments will be, for all practical purposes, independent of the initial ones.
As soon as we know that the coin has perfect dynamical symmetry between heads and
tails – i.e., its Lagrangian function
L(q1,..., p6)=(kinetic energy)−(potential energy) (10.4)
is invariant under the symmetry operation that interchanges heads and tails – then we know
an exact result. No matter where in phase space the initial region Ris located, for every
Hdomain there is a Tdomain of equal size and identical shape, in which heads and tails
are interchanged. Then if Ris large enough to include both, we shall persist in assigning
probability 1/2 to heads.
Now suppose the coin is biased. The above argument is lost to us, and we expect that
the phase volumes of HandTdomains within Rare no longer equal. In this case, the
‘frequentist’ tells us that there still exists a deﬁnite ‘objective’ frequency of heads, pH/negationslash=
1/2, which is a measurable physical property of the coin. Let us understand clearly what
this implies. To assert that the frequency of heads is a physical property only of the coin,
is equivalent to asserting that the ratio v(H)/v(R)is independent of the location of region
R. If this were true, it would be an utterly unprecedented new theorem of mechanics, with
important implications for physics which extend far beyond coin tossing.
Of course, no such thing is true. From the three speciﬁc methods of tossing the coin
discussed in Section 10.3 which correspond to widely different locations of the region R,
it is clear that the frequency of heads will depend very much on how the coin is tossed.
Method Auses a region of phase space where the individual HandTdomains are large
compared with R, so human skill is able to control the result. Method Buses a region where,
for a biased coin, the Tdomain is very much larger than either Ror the Hdomain. Only
method Cuses a region where the HandTdomains are small compared with R, making
the result unpredictable from knowledge of R.
It would be interesting to know how to calculate the ratio v(H)/v(R) as a function of the
location of Rfrom the laws of mechanics; but it appears to be a very difﬁcult problem. Note,
for example, that the coin cannot come to rest until its initial potential and kinetic energy
have been either transferred to some other object or dissipated into heat by frictional forces;so all the details of how that happens must be taken into account. Of course, it would bequite feasible to do controlled experiments which measure this ratio in various regions ofphase space. But it seems that the only person who would have any use for this informationis a professional gambler.
Clearly, our reason for assigning probability 1/2 to heads when the coin is honest is not
based merely on observed frequencies. How many of us can cite a single experiment inwhich the frequency 1/2 was established under conditions we would accept as signiﬁcant?Yet none of us hesitates a second in choosing the number 1/2. Our real reason is simplycommon sense recognition of the symmetry of the situation. Prior information which does
not consist of frequencies is of decisive importance in determining probability assignmentseven in this simplest of all random experiments .

<<<PAGE 367>>>

10 Physics of ‘random experiments’ 335
Those who adhere publicly to a strict frequency interpretation of probability jump to such
conclusions privately just as quickly and automatically as anyone else; but in so doing theyhave violated their basic premise that (probability) ≡(frequency); and so in trying to justify
this choice they must suppress any mention of symmetry, and fall back on remarks aboutassumed frequencies in random experiments which have, in fact, never been performed.
5
Here is an example of what one loses by so doing. From the result of tossing a die,
we cannot tell whether it is symmetrical or not. But if we know, from direct physicalmeasurements, that the die isperfectly symmetrical and we accept the laws of mechanics as
correct, then it is no longer plausible inference, but deductive reasoning, that tells us this: any
nonuniformity in the frequencies of different faces is proof of a corresponding nonuniformityin the method of tossing . The qualitative nature of the conclusions we can draw from the
random experiment depend on whether we do or do not know that the die is symmetrical.
This reasoning power of arguments based on symmetry has led to great advances in
physics for 60 years; as noted, it is not very exaggerated to say that the only known exactresults in mathematical physics are the ones that can be deduced by the methods of group
theory from symmetry considerations. Although this power is obvious once noted, and it is
used intuitively by every worker in probability theory, it has not been widely recognized asa legitimate formal tool in probability theory.
6
We have just seen that, in the simplest of random experiments, any attempt to deﬁne a
probability merely as a frequency involves us in the most obvious logical difﬁculties as soonas we analyze the mechanism of the experiment. In many situations where we can recognizean element of symmetry, our intuition readily takes over and suggests an answer; and ofcourse it is the same answer that our basic desideratum – that equivalent states of knowledgeshould be represented by equivalent probability assignments – requires for consistency.
But situations in which we have positive knowledge of symmetry are rather special ones
among all those faced by the scientist. How can we carry out consistent inductive reasoningin situations where we do not perceive any clear element of symmetry? This is an open-ended problem because there is no end to the variety of different special circumstances thatmight arise. As we shall see, the principle of maximum entropy gives a useful and versatiletool for many such problems. But in order to give a start toward understanding this, let’sgo way back to the beginning and consider the tossing of the coin still another time, in adifferent way.
10.10 Independence of tosses
‘When I toss a coin, the probability for heads is one-half.’ What do we mean by this
statement? Over the past two centuries, millions of words have been written about this
simple question. A recent exchange (Edwards, 1991) shows that it is still enveloped in total
5Or rather, whenever anyone has tried to perform such experiments under sufﬁciently controlled conditions to be signiﬁcant, the
expected equality of frequencies is notobserved. The famous experiments of Weldon (E. S. Pearson, 1967; K. Pearson, 1980)
and Wolf (Czuber, 1908) are discussed elsewhere in this book.
6Indeed, L. J. Savage (1962, p. 102) rejects symmetry arguments, thereby putting his system of ‘personalistic’ probability in theposition of recognizing the need for prior probabilities, but refusing to admit any formal principles for assigning them.

<<<PAGE 368>>>

336 Part 1 Principles and elementary applications
confusion in the minds of some. But, by and large, the issue is between the following two
interpretations:
(A) ‘The available information gives me no reason to expect heads rather than tails, or vice versa – I
am completely unable to predict which it will be.’
(B) ‘If I toss the coin a very large number of times, in the long run heads will occur about half the
time – in other words, the frequency of heads will approach 1/2.’
We belabor still another time, what we have already stressed many times before. Statement
(A) does not describe any property of the coin, but only the robot’s state of knowledge (or,
if you prefer, of ignorance). Statement (B) is, at least by implication, asserting somethingabout the coin. Thus, (B) is a very much stronger statement than (A). Note, however, that(A) does not in any way contradict (B); on the contrary, (A) could be a consequence of (B).For if our robot were told that this coin has in the past given heads and tails with equalfrequenc y, this would give it no help at all in predicting the result of the next toss.
Why, then, has interpretation (A) been almost universally rejected by writers on proba-
bility and statistics for two generations? There are, we think, two reasons for this. In theﬁrst place, there is a widespread belief that if probability theory is to be of any use in
applications, we must be able to interpret our calculations in the strong sense of (B). But
this is simply untrue, as we have demonstrated throughout the preceding eight chapters.We have seen examples of almost all known applications of frequentist probability theory,and many useful problems outside the scope of frequentist probability theory, which arenevertheless solved readily by probability theory as logic.
Secondly, it is another widely held misconception that the mathematical rules of proba-
bility theory (the ‘laws of large numbers’) would lead to (B) as a consequence of (A), and
this seems to be ‘getting something for nothing’. For, the fact that I know nothing about thecoin is clearly not enough to make the coin give heads and tails equally often!
This misconception arises because of a failure to distinguish between the following two
statements:
(C) ‘Heads and tails are equally likely on a single toss.’
(D) ‘If the coin is tossed Ntimes, each of the 2Nconceivable outcomes is equally likely.’
To see the difference between statements (C) and (D), consider a case where it is known that
the coin is biased, but not whether the bias favors heads or tails. Then (C) is applicable but
(D) is not. For, on this state of knowledge, as was noted already by Laplace, the sequences
HH andTTare each somewhat more likely than HTorTH. More generally, our common
sense tells us that any unknown inﬂuence which favors heads on one toss will likely favorheads on the other toss. Unless our robot has positive knowledge (symmetry of both thecoin and the method of tossing) which deﬁnitely rules out allsuch possibilities, (D) is not
a correct description of his true state of knowledge; it assumes too much.
Statement (D) implies (C), but says a great deal more. Statement (C) says only, ‘I do not
know enough about the situation to give me any help in predicting the result of any throw’,while (D) seems to be saying, ‘I know that the coin is honest, andthat it is being tossed in

<<<PAGE 369>>>

10 Physics of ‘random experiments’ 337
a way which favors neither face over the other, andthat the method of tossing and the wear
of the coin give no tendency for the result of one toss to inﬂuence the result of another’. Butprobability theory is subtle; in Chapter 9 we met the poorly informed robot, who makesstatement (D) without having any of that information.
Mathematically, the laws of large numbers require much more than (C) for their deriva-
tion. Indeed, if we agree that tossing a coin generates an exchangeable sequence (i.e., theprobability that Ntosses will yield heads at nspeciﬁed trials depends only on Nandn, not
on the order of heads and tails), then application of the de Finetti theorem, as in Chapter 9,shows that the weak law of large numbers holds only when (D) can be justiﬁed. In this
case, it is almost correct to say that the probability assigned to heads is equal to the fre-quency with which the coin gives heads; because, for any /epsilon1→0, the probability that the
observed frequency f=(n/N) lies in the interval (1 /2±/epsilon1) tends to unity as N→∞ .
Let us describe this by saying that there exists a strong connection between probability and
frequency. We analyze this more deeply in Chapter 18.
In most recent treatments of probability theory, the writer is concerned with situations
where a strong connection between probability and frequency is taken for granted – indeed,this is usually considered essential to the very notion of probability. Nevertheless, theexistence of such a strong connection is clearly only an ideal limiting case, unlikely to
be realized in any real application. For this reason, the laws of large numbers and limit
theorems of probability theory can be grossly misleading to a scientist or engineer whona¨ıvely supposes them to be experimental facts, and tries to interpret them literally in his
problems. Here are two simple examples.
(1) Suppose there is some random experiment in which you assign a probability pfor some particular
outcome A. It is important to estimate accurately the fraction fof times Awill be true in the
next million trials. If you try to use the laws of large numbers, it will tell you various thingsabout f; for example, that it is quite likely to differ from pby less than one-tenth of 1%, and
enormously unlikely to differ from pby more than 1%. But now imagine that, in the ﬁrst 100
trials, the observed frequency of Aturned out to be entirely different from p. Would this lead you
to suspect that something was wrong, and would you revise your probability assignment for the101st trial? If it would, then your state of knowledge is different from that required for the validityof the law of large numbers. You are not sure of the independence of different trials, and/or youare not sure of the correctness of the numerical value of p. Your prediction of ffor one million
trials is probably no more reliable than for 100.
(2) The common sense of a good experimental scientist tells him the same thing without any proba-
bility theory. Suppose someone is measuring the velocity of light. After making allowances forthe known systematic errors, he could calculate a probability distribution for the various othererrors, based on the noise level in his electronics, vibration amplitudes, etc. At this point, a na¨ ıve
application of the law of large numbers might lead him to think that he can add three signiﬁcantﬁgures to his measurement merely by repeating it one million times and averaging the results.But, of course, what he would actually do is to repeat some unknown systematic error one milliontimes. It is idle to repeat a physical measurement an enormous number of times in the hope that‘good statistics’ will average out your errors, because we cannot know the full systematic error.This is the old ‘Emperor of China’ fallacy, discussed in Chapter 8.

<<<PAGE 370>>>

338 Part 1 Principles and elementary applications
Indeed, unless we know that all sources of systematic error – recognized or unrecognized –
contribute less than about one-third the total error, we cannot be sure that the average ofone million measurements is any more reliable than the average of ten. Our time is muchbetter spent in designing a new experiment which will give a lower probable error per trial .
As Poincar´ e put it, ‘The physicist is persuaded that one good measurement is worth many
bad ones’. In other words, the common sense of a scientist tells him that the probabilities heassigns to various errors do not have a strong connection with frequencies, and that methodsof inference which presuppose such a connection could be disastrously misleading in hisproblems.
Then, in advanced applications, it will behoove us to consider: How are our ﬁnal con-
clusions altered if we depart from the universal custom of orthodox statistics, and relaxthe assumption of strong connections? Harold Jeffreys showed a very easy way to answerthis, as we shall see later. As common sense tells us it must be, the ultimate accuracy ofour conclusions is then determined not by anything in the data or in the orthodox pictureof things, but rather by our own state of knowledge about the systematic errors. Of course,the orthodoxian will protest that, ‘We understand this perfectly well; and in our analysiswe assume that systematic errors have been located and eliminated’. But he does not tellus how to do this, or what to do if – as is the case in virtually every real experiment –they are unknown and so cannot be eliminated. Then all the usual ‘asymptotic’ rules arequalitatively wrong, and only probability theory as logic can give defensible conclusions.
10.11 The arrogance of the uninformed
Now we come to a very subtle and important point, which has caused trouble from the
start in the use of probability theory. Many of the objections to Laplace’s viewpoint whichyou ﬁnd in the literature can be traced to the author’s failure to recognize it. Suppose wedo not know whether a coin is honest, and we fail to notice that this state of ignoranceallows the possibility of unknown inﬂuences which would tend to favor the same face on alltosses. We say, ‘Well, I don’t see any reason why any one of the 2
Noutcomes in Ntosses
should be more likely than any other, so I’ll assign uniform probabilities by the principleof indifference’.
We would be led to statement (D) and the resulting strong connection between probability
and frequency. But this is absurd – in this state of uncertainty, we could not possibly makereliable predictions of the frequency of heads. Statement (D), which is supposed to representa great deal of positive knowledge about the coin and the method of tossing, can also resultfrom failure to make proper use of all the available information! In other applications of
mathematics, if we fail to use all of the relevant data of a problem, the result will not be thatwe get an incorrect answer. The result will be that we are unable to get any answer at all.But probability theory cannot have any such built-in safety device, because, in principle, thetheory must be able to operate no matter what our incomplete information might be. If wefail to include all of the relevant data, or to take into account all the possibilities allowed bythe data and prior information, probability theory will still give us a deﬁnite answer; and that

<<<PAGE 371>>>

10 Physics of ‘random experiments’ 339
answer will be the correct conclusion from the information that we actually gave the robot.
But that answer may be in violent contradiction to our common sense judgments which didtake everything into account, if only crudely. The onus is always on the user to make sure
that all the information, which his common sense tells him is relevant to the problem, isactually incorporated into the equations, and that the full extent of his ignorance is alsoproperly represented . If you fail to do this, then you should not blame Bayes and Laplace
for your nonsensical answers.
We shall see examples of this kind of misuse of probability theory later, in the various
objections to the rule of succession. It may seem paradoxical that a more careful analysisof a problem may lead to less certainty in prediction of the frequency of heads. However,look at it this way. It is commonplace that in all kinds of questions the fool feels a certaintythat is denied to the wise man. The semiliterate on the next bar stool will tell you withabsolute, arrogant assurance just how to solve all the world’s problems; while the scholarwho has spent a lifetime studying their causes is not at all sure how to do this. Indeed,we have seen just this phenomenon in Chapter 9, in the scenario of the poorly informed
robot, who arrogantly asserts all the limit theorems of frequentist probability theory out of
its ignorance rather than its knowledge.
In almost any example of inference, a more careful study of the situation, uncovering new
facts, can lead us to feel either more certain or less certain about our conclusions, dependingon what we have learned. New facts may support our previous conclusions, or they mayrefute them; we saw some of the subtleties of this in Chapter 5. If our mathematical modelof reasoning failed to reproduce this phenomenon, it could not be an adequate ‘calculus ofinductive reasoning’.

<<<PAGE 372>>>



<<<PAGE 373>>>

Part 2
Advanced applications

<<<PAGE 374>>>



<<<PAGE 375>>>

11
Discrete prior probabilities: the entropy principle
At this point, we return to the job of designing the robot. We have part of its brain designed,
and we have seen how it would reason in a few simple problems of hypothesis testing andestimation. In every problem it has solved thus far, the results have either amounted to thesame thing as, or were usually demonstrably superior to, those offered in the ‘orthodox’
statistical literature. But it is still not a very versatile reasoning machine, because it has onlyone means by which it can translate raw information into numerical values of probabilities,
the principle of indifference (2.95). Consistency requires it to recognize the relevance of
prior information, and so in almost every problem it is faced at the onset with the problem
of assigning initial probabilities, whether they are called technically prior probabilities orsampling probabilities. It can use indifference for this if it can break the situation up into
mutually exclusive, exhaustive possibilities in such a way that no one of them is preferred
to any other by the evidence. But often there will be prior information that does not changethe set of possibilities but does give a reason for preferring one possibility to another. Whatdo we do in this case?
Orthodoxy evades this problem by simply ignoring prior information for ﬁxed param-
eters, and maintaining the ﬁction that sampling probabilities are known frequencies. Yet,in some 40 years of active work in this ﬁeld, the writer has never seen a real problem inwhich one actually has prior information about sampling frequencies! In practice, samplingprobabilities are always assigned from some standard theoretical model (binomial distribu-
tion, etc.) which starts from the principle of indifference. If the robot is to rise above such
false pretenses, we must give it more principles for assigning initial probabilities by logicalanalysis of the prior information. In this chapter and the following one we introduce two
new principles of this kind, each of which has an unlimited range of useful applications.
But the ﬁeld is open-ended in all directions; we expect that more principles will be foundin the future, leading to a still wider range of applications.
11.1 A new kind of prior information
Imagine a class of problems in which the robot’s prior information consists of average
values of certain things. Suppose, for example, that statistics were collected in a recentearthquake and that, out of 100 windows broken, there were 976 pieces found. But we are
343

<<<PAGE 376>>>

344 Part 2 Advanced applications
not given the numbers 100 and 976; we are told only that ‘the average window is broken
intom=9.76 pieces’. Given only that information, what is the probability that a window
would be broken into exactly mpieces? There is nothing in the theory so far that will answer
that question.
As another example, suppose we have a table covered with black cloth, and some dice,
but, for reasons that will be clear in a minute, they are black dice with white spots. A die istossed onto the black table. Above there is a camera. Every time the die is tossed, we takea snapshot. The camera will record only the white spots. Now we don’t change the ﬁlm inbetween, so we end up with a multiple exposure; uniform blackening of the ﬁlm after wehave done this a few thousand times. From the known density of dots and the number oftosses, we can infer the average number of spots which were on top, but not the frequencieswith which various faces came up. Suppose that the average number of spots turned out tobe 4.5 instead of 3.5. Given only this information (i.e., not making use of anything else thatyou or I might know about dice except that they have six faces), what estimates should therobot make of the frequencies with which nspots came up? Supposing that successive tosses
form an exchangeable sequence as deﬁned in Chapter 3, what probability should it assignto the nth face coming up on the next toss?
As a third example, suppose that we have a string of N=1000 cars, bumper to bumper,
and that they occupy the full length of L=3 miles. As they drive onto a rather large ferry
boat, the distance that it sinks into the water determines their total weight W. But the
numbers N,L,Ware withheld from us; we are told only their average length L/Nand
average weight W/N. We can look up statistics from the manufacturers, and ﬁnd out how
long the V olkswagen is, how heavy it is, how long a Cadillac is, and how heavy it is, andso on, for all the other brands. From knowledge only of the average length and the average
weight of these cars, what can we then infer about the proportion of cars of each make that
were in the cluster?
If we knew the numbers N,L,W, then this could be solved by direct application of
Bayes’ theorem; without that information, we could still introduce the unknowns N,L,W
as nuisance parameters and use Bayes’ theorem, eliminating them at the end. We shall givean example of this procedure in the nonconglomerability problem in Chapter 15. However,the Bayesian solution would not really address our problem; it only transfers it to theproblem of assigning priors to N,L,W, leaving us back in essentially the same situation;
how do we assign informative probabilities?
Now, it is not at all obvious how our robot should handle problems of this sort. Actually,
we have deﬁned two different problems; estimating a frequency distribution, and assigning
a probability distribution. But in an exchangeable sequence these are almost identical math-ematically. So let’s think about how we would want the robot to behave in this situation. Ofcourse, we want it to take into account fully all the information it has, of whatever kind. Butwe would not want it to jump to conclusions that are not warranted by the evidence it has.We have seen that a uniform probability assignment represents a state of mind completelynoncommittal with regard to all possibilities; it favors no one over any other, and thus leaves
the entire decision to the subsequent data which the robot may receive. The knowledge of

<<<PAGE 377>>>

11 Discrete prior probabilities: the entropy principle 345
average values does give the robot a reason for preferring some possibilities to others, but
we would like it to assign a probability distribution which is as uniform as it can be whileagreeing with the available information. The most conservative, noncommittal distributionis the one which is as ‘spread-out’ as possible. In particular, the robot must not ignore anypossibility – it must not assign zero probability to any situation unless its information reallyrules out that situation.
This sounds very much like deﬁning a variational problem; the information available
deﬁnes constraints ﬁxing some properties of the initial probability distribution, but notall of them. The ambiguity remaining is to be resolved by the policy of honesty; franklyacknowledging the full extent of its ignorance by taking into account all possibilities allowedby its knowledge.
1To cast it into mathematical form, the aim of avoiding unwarranted
conclusions leads us to ask whether there is some reasonable numerical measure of how
uniform a probability distribution is, which the robot could maximize subject to constraints
which represent its available information. Let’s approach this in the way most problems aresolved: the time-honored method of trial and error. We just have to invent some measuresof uncertainty, and put them to the test to see what they give us.
One measure of how broad an initial distribution is would be its variance. Would it
make sense if the robot were to assign probabilities so as to maximize the variance subjectto its information? Consider the distribution of maximum variance for a given
m, if the
conceivable values of mare essentially unlimited, as in the broken window problem. Then
the maximum variance solution would be the one where the robot assigns a very largeprobability for no breakage at all, and an enormously small probability of a window to bebroken into billions and billions of pieces. You can get an arbitrarily high variance thisway, while keeping the average at 9.76. In the dice problem, the solution with maximumvariance would be to assign all the probability to the one and the six, in such a way that
p
1+6p6=4.5, or p1=0.3,p6=0.7. So that, evidently, is not the way we would want
our robot to behave; it would be jumping to wildly unjustiﬁed conclusions, since nothingin its information says that it is impossible to have spots two through ﬁve up.
11.2 Minimum/summationtextp
2
i
Another kind of measure of how spread out a probability distribution is, which has been
used a great deal in statistics, is the sum of the squares of the probabilities assigned to eachof the possibilities. The distribution which minimizes this expression, subject to constraintsrepresented by average values, might be a reasonable way for our robot to behave. Let’s seewhat sort of a solution this would lead to. We want to make
/summationdisplay
mp2
m (11.1)
1This is really an ancient principle of wisdom, recognized clearly already in such sources as Herodotus and the Old Testament.

<<<PAGE 378>>>

346 Part 2 Advanced applications
a minimum, subject to the constraints that the sum of all pmshall be unity and the average
over the distribution is m. A formal solution is obtained at once from the variational problem
δ/bracketleftbigg/summationdisplay
mp2
m−λ/summationdisplay
mmpm−µ/summationdisplay
mpm/bracketrightbigg
=/summationdisplay
m(2pm−λm−µ)δpm=0, (11.2)
where λandµare Lagrange multipliers. So pmwill be a linear function of m:2pm−λm−
µ=0. Then µandλare found from
/summationdisplay
mpm=1, (11.3)
and
/summationdisplay
mmpm=m, (11.4)
where mis the average value of m, given to us in the statement of the problem.
Suppose that mcan take on only the values 1 ,2,and 3. Then the formal solution is
p1=4
3−m
2, p2=1
3, p3=m
2−2
3. (11.5)
This would be at least usable for some values of m. But, in principle, mcould be anywhere in
1≤m≤3, and p1becomes negative when m>8/3=2.667, while p3becomes negative
when m<4/3=1.333. The formal solution for minimum/summationtextp2
ilacks the property of
non-negativity. We might try to patch this up in an ad hoc way by replacing the negative
values by zero and adjusting the other probabilities to keep the constraint satisﬁed. Butthen the robot is using different principles of reasoning in different ranges of
m; and it is
still assigning zero probability to situations that are not ruled out by its information. Thisperformance is not acceptable; it is an improvement over maximum variance, but the robotis still behaving inconsistently and jumping to unwarranted conclusions. We have taken thetrouble to examine this criterion because some writers have rejected the entropy solutiongiven next and suggested on intuitive grounds, without examining the actual results, thatminimum/summationtextp
2
iwould be a more reasonable criterion.
But the idea behind the variational approach still looks like a good one. There should
be some consistent measure of the uniformity, or ‘amount of uncertainty’, of a probabilitydistribution which we can maximize, subject to constraints, and which will have the propertythat forces the robot to be completely honest about what it knows, and in particular it doesnot permit the robot to draw any conclusions unless those conclusions are really justiﬁedby the evidence it has.
11.3 Entropy: Shannon’s theorem
At this stage, we turn to the most quoted theorem in Shannon’s work on information
theory (Shannon, 1948). If there exists a consistent measure of the ‘amount of uncertainty’

<<<PAGE 379>>>

11 Discrete prior probabilities: the entropy principle 347
represented by a probability distribution, there are certain conditions it will have to satisfy.
We shall state them in a way which will remind you of the arguments we gave in Chapter 2;in fact, this is really a continuation of the basic development of probability theory.
(1) We assume that some numerical measure Hn(p1,..., pn) exists; i.e., that it is possible to set up
some kind of association between ‘amount of uncertainty’ and real numbers.
(2) We assume a continuity property: Hnis a continuous function of the pi. Otherwise, an arbi-
trarily small change in the probability distribution would lead to a big change in the amount ofuncertainty.
(3) We require that this measure should correspond qualitatively to common sense in that, when there
are many possibilities, we are more uncertain than when there are fe w. This condition takes the
form that in the case that the p
iare all equal, the quantity
h(n)=Hn/parenleftbigg1
n,1
n,...,1
n/parenrightbigg
(11.6)
is a monotonic increasing function of n. This establishes the ‘sense of direction’.
(4) We require that the measure Hnbe consistent in the same sense as before; i.e., if there is more
than one way of working out its value, we must get the same answer for every possible way.
Previously, our conditions of consistency took the form of the functional equations (2.13)
and (2.45). Now we have instead a hierarchy of functional equations relating the different
Hnto each other. Suppose the robot perceives two alternatives, to which it assigns probabil-
ities p1andq≡1−p1. Then the ‘amount of uncertainty’ represented by this distribution
isH2(p1,q). But now the robot learns that the second alternative really consists of two
possibilities, and it assigns probabilities p2,p3to them, satisfying p2+p3=q. What is
now the robot’s full uncertainty H3(p1,p2,p3) as to all three possibilities? Well, the process
of choosing one of the three can be broken down into two steps. Firstly, decide whetherthe ﬁrst possibility is or is not true; the uncertainty removed by this decision is the original
H
2(p1,q). Then, with probability q, the robot encounters an additional uncertainty as to
events 2, 3, leading to
H3(p1,p2,p3)=H2(p1,q)+qH 2/parenleftbiggp2
q,p3
q/parenrightbigg
(11.7)
as the condition that we shall obtain the same net uncertainty for either method of calculation.
In general, a function Hncan be broken down in many different ways, relating it to the lower
order functions by a large number of equations like this.
Note that (11.7) says rather more than our previous functional equations did. It says
not only that the Hnare consistent in the aforementioned sense, but also that they are to
be additive. So this is really an additional assumption which we should have included inour list.

<<<PAGE 380>>>

348 Part 2 Advanced applications
Exercise 11.1. It seems intuitively that the most general condition of consistency
would be a functional equation which is satisﬁed by any monotonic increasing functionofH
n. But this is ambiguous unless we say something about how the monotonic
functions for different nare to be related; is it possible to invoke the same function for
alln? Carry out some new research in this ﬁeld by investigating this matter; try either
to ﬁnd a possible form of the new functional equations, or to explain why this cannotbe done.
At any rate, the next step is perfectly straightforward mathematics; let’s see the full proofof Shannon’s theorem, now dropping the unnecessary subscript on H
n.
We ﬁnd the most general form of the composition law (11.7) for the case that there
arenmutually exclusive propositions ( A1,..., An), to which we assign probabilities
(p1,..., pn). Instead of giving the probabilities for the ( A1,..., An) directly, we might
group the ﬁrst kof them together as the proposition ( A1+A2+···+ Ak) and as-
sign probability w1=(p1+···+ pk); then the next mpropositions are grouped into
(Ak+1+···+ Ak+m), to which we assign probability w2=(pk+1+···+ pk+m), etc. The
amount of uncertainty as to the composite propositions is H(w1,...,w r).
Next we give the conditional probabilities ( p1/w1,..., pk/w1) for the propositions
(A1,..., Ak), given that the composite proposition ( A1+···+ Ak) is true. The additional
uncertainty, encountered with probability w1, is then H(p1/w1,..., pk/wk). Carrying this
out for the composite propositions ( Ak+1+···+ Ak+m), etc., we arrive ultimately at the
same state of knowledge as if the ( p1,..., pn) had been given directly; so consistency re-
quires that these calculations yield the same ultimate uncertainty, no matter how the choiceswere broken down. Thus we have
H(p
1,..., pn)=H(w1,...,w r)+w1H/parenleftbiggp1
w1,...,pk
w1/parenrightbigg
+w2H/parenleftbiggpk+1
w2,...,pk+m
w2/parenrightbigg
+···,(11.8)
which is the general form of the functional equation (11.7). For example,
H/parenleftbigg1
2,1
3,1
6/parenrightbigg
=H/parenleftbigg1
2,1
2/parenrightbigg
+1
2H/parenleftbigg2
3,1
3/parenrightbigg
. (11.9)
Since H(p1,..., pn) is to be continuous, it will sufﬁce to determine it for all rational values
pi=ni/summationtextni(11.10)
with niintegers. But then (11.8) determines the function Halready in terms of the quantities
h(n)≡H(1/n,1/n,..., 1/n) which measure the ‘amount of uncertainty’ for the case of n
equally likely alternatives. For we can regard a choice of one of the alternatives ( A1,..., An)

<<<PAGE 381>>>

11 Discrete prior probabilities: the entropy principle 349
as the ﬁrst step in the choice of one of
n/summationdisplay
i=1ni (11.11)
equally likely alternatives in the manner just described, the second step of which is also a
choice between niequally likely alternatives. As an example, with n=3, we might choose
n1=3,n2=4,n3=2. For this case the composition law (11.8) becomes
h(9)=H/parenleftbigg3
9,4
9,2
9/parenrightbigg
+3
9h(3)+4
9h(4)+2
9h(2). (11.12)
For a general choice of the ni, (11.8) reduces to
h/parenleftBig/summationdisplay
ni/parenrightBig
=H(p1,..., pn)+/summationdisplay
ipih(ni). (11.13)
Now we can choose all ni=m; whereupon (11.13) collapses to
h(mn)=h(m)+h(n). (11.14)
Evidently, this is solved by setting
h(n)=Klog(n), (11.15)
where Kis a constant. But is this solution unique? If m,nwere continuous variables,
this would be easy to answer; differentiate with respect to m, set m=1, and integrate the
resulting differential equation with the initial condition h(1)=0 evident from (11.14), and
you have proved that (11.15) is the only solution. But in our case, (11.14) need hold onlyfor integer values of m,n; and this elevates the problem from a trivial one of analysis to an
interesting little exercise in number theory.
Firstly, note that (11.15) is no longer unique; in fact, (11.14) has an inﬁnite number
of solutions for integer m,n. Each positive integer Nhas a unique decomposition into
prime factors; and so, by repeated application of (11.14), we can express h(N) in the form/summationtext
imih(qi), where qiare the prime numbers and miare the non-negative integers. Thus we
can specify h(qi)arbitrarily for the prime numbers qi, whereupon (11.14) is just sufﬁcient
to determine h(N) for all positive integers.
To get any unique solution for h(n), we have to add our qualitative requirement that h(n)
be monotonic increasing in n. To show this, note ﬁrst that (11.14) may be extended by
induction:
h(nmr···)=h(n)+h(m)+h(r)+···, (11.16)
and setting the factors equal in the kth order extension gives
h(nk)=kh(n). (11.17)

<<<PAGE 382>>>

350 Part 2 Advanced applications
Now let t,sbe any two integers not less than 2. Then, for arbitrarily large n, we can ﬁnd an
integer msuch that
m
n≤log(t)
log(s)<m+1
n, or sm≤tn<sm+1. (11.18)
Since his monotonic increasing, h(sm)≤h(tn)≤h(sm+1); or, from (11.17),
mh(s)≤nh(t)≤(m+1)h(s), (11.19)
which can be written as
m
n≤h(t)
h(s)≤m+1
n. (11.20)
Comparing (11.18) and (11.20), we see that
/vextendsingle/vextendsingle/vextendsingle/vextendsingleh(t)
h(s)−log(t)
log(s)/vextendsingle/vextendsingle/vextendsingle/vextendsingle≤1
n, or/vextendsingle/vextendsingle/vextendsingle/vextendsingleh(t)
log(t)−h(s)
log(s)/vextendsingle/vextendsingle/vextendsingle/vextendsingle≤/epsilon1, (11.21)
where
/epsilon1≡h(s)
nlog(t)(11.22)
is arbitrarily small. Thus h(t)/log(t) must be a constant, and the uniqueness of (11.15) is
proved.
Now, different choices of Kin (11.15) amount to the same thing as taking logarithms
to different bases; so if we leave the base arbitrary for the moment, we can just as wellwrite h(n)=log(n). Substituting this into (11.13), we have Shannon’s theorem: The only
function H(p
1,..., pn) satisfying the conditions we have imposed on a reasonable measure
of ‘amount of uncertainty’ is
H(p1,..., pn)=−n/summationdisplay
i=1pilog(pi). (11.23)
Accepting this interpretation, it follows that the distribution ( p1,..., pn) which maximizes
(11.23), subject to constraints imposed by the available information, will represent the‘most honest’ description of what the robot knows about the propositions ( A
1,..., An).
The only arbitrariness is that we have the option of taking the logarithm to any base weplease, corresponding to a multiplicative constant in H. This, of course, has no effect on
the values of ( p
1,..., pn) which maximize H.
As in Chapter 2, we note the logic of what has and has not been proved. We have shown
that use of the measure (11.23) is a necessary condition for consistency; but, in accordance
with G¨ odel’s theorem, one cannot prove that it actually is consistent unless we move out
into some as yet unknown region beyond that used in our proof. From the above argument,given originally in Jaynes (1957a) and leaning heavily on Shannon, we conjectured thatany other choice of ‘information measure’ will lead to inconsistencies if carried far enough;and a direct proof of this was found subsequently by Shore and Johnson (1980) using

<<<PAGE 383>>>

11 Discrete prior probabilities: the entropy principle 351
an argument entirely independent of ours. Many years of use of the maximum entropy
principle (variously abbreviated to PME, MEM, MENT, MAXENT by various writers) hasnot revealed any inconsistency; and of course we do not believe that one will ever be found.
The function His called the entropy , or, better, the information entropy of the distribution
{p
i}. This is an unfortunate terminology, which now seems impossible to correct. We must
warn at the outset that the major occupational disease of this ﬁeld is a persistent failure todistinguish between the information entropy , which is a property of any probability distri-
bution, and the experimental entropy of thermodynamics, which is instead a property of
a thermodynamic state as deﬁned, for example by such observed quantities as pressure,volume, temperature, magnetization, of some physical system. They should never havebeen called by the same name; the experimental entropy makes no reference to any prob-ability distribution, and the information entropy makes no reference to thermodynamics.
2
Many textbooks and research papers are ﬂawed fatally by the author’s failure to distinguishbetween these entirely different things, and in consequence proving nonsense theorems.
We ha ve seen the mathematical expression/summationtextplog(p) appearing incidentally in several
previous chapters, generally in connection with the multinomial distribution; now it has ac-quired a new meaning as a fundamental measure of how uniform a probability distribution is.
Exercise 11.2. Prove that any change in the direction of equalizing two probabilities
will increase the information entropy. That is, if pi<pj, then the change pi→pi+/epsilon1,
pj→pj−/epsilon1,where /epsilon1is inﬁnitesimal and positive, will increase H(p1,..., pn)b y
an amount proportional to /epsilon1. Applying this repeatedly, it follows that the maximum
attainable entropy is one for which all the differences |pi−pj|are as small as possi-
ble. This shows also that information entropy is a global property, not a local one; a
difference|pi−pj|has just as great an effect on entropy whether |i−j|is 1 or 1000.
Although the above demonstration appears satisfactory mathematically, it is not yet in
completely satisfactory form conceptually. The functional equation (11.7) does not seemquite so intuitively compelling as our previous ones did. In this case, the trouble is probablythat we have not yet learned how to verbalize the argument leading to (11.7) in a fullyconvincing manner. Perhaps this will inspire others to try their hand at improving theverbiage that we used just before writing (11.7). Then it is comforting to know that thereare several other possible arguments, like the aforementioned one of Shore and Johnson,which also lead uniquely to the same conclusion (11.23). We note another of them.
11.4 The Wallis derivation
This resulted from a suggestion made to the writer in 1962 by Graham Wallis (although the
argument we give differs slightly from his). We are given information I, which is to be used
2But in case the problem happens to be one of thermodynamics, there is a relation between them, which we shall ﬁnd presently.

<<<PAGE 384>>>

352 Part 2 Advanced applications
in assigning probabilities {p1,..., pm}tomdifferent possibilities. We have a total amount
of probability
m/summationdisplay
i=1pi=1 (11.24)
to allocate among them. Now, in judging the reasonableness of any particular allocation, we
are limited to consideration of Iand the rules of probability theory; to call upon any other
evidence would be to admit that we had not used all the available information in the ﬁrstplace.
The problem can also be stated as follows. Choose some integer n/greatermuchm, and imagine
that we have nlittle ‘quanta’ of probability, each of magnitude δ=n
−1, to distrib ute in any
way we see ﬁt. In order to ensure that we have a ‘fair’ allocation, in the sense that none ofthempossibilities shall knowingly be given either more or fewer of these quanta than it
‘deserves’, in the light of the information I, we might proceed as follows.
Suppose we were to scatter these quanta at random among the mchoices – you can
make this a blindfolded penny-pitching game into mequal boxes if you like. If we simply
toss these ‘quanta’ of probability at random, so that each box has an equal probability ofgetting them, nobody can claim that any box is being unfairly favored over any other. If wedo this, and the ﬁrst box receives exactly n
1quanta, and the second n2, etc., we will say
that the random experiment has generated the probability assignment
pi=niδ=ni
n, i=1,2,..., m. (11.25)
The probability that this will happen is the multinomial distribution
m−n n!
n1!···nm!. (11.26)
Now imagine that a blindfolded friend repeatedly scatters the nquanta at random among
themboxes. Each time he does this we examine the resulting probability assignment. If it
happens to conform to the information I, we accept it; otherwise we reject it and tell him
to try again. We continue until some probability assignment {p1,..., pm}is accepted.
What is the most likely probability distribution to result from this game? From (11.26) it
is the one which maximizes
W=n!
n1!···nm!(11.27)
subject to whatever constraints are imposed by the information I. We can reﬁne this pro-
cedure by choosing smaller quanta; i.e. large n. In this limit we have, by the Stirling
approximation,
log(n!)=nlog(n)−n+√
2πn+1
12n+O/parenleftbigg1
n2/parenrightbigg
, (11.28)

<<<PAGE 385>>>

11 Discrete prior probabilities: the entropy principle 353
where O(1/n2) denotes terms that tend to zero as n→∞ ,a s( 1/n2) or faster. Using this
result, and writing ni=npi, we ﬁnd easily that as n→∞ ,ni→∞ , in such a way that
ni/n→pi=const.,
1
nlog(W)→−m/summationdisplay
i=1pilog(pi)=H(p1,..., pm), (11.29)
and, so, the most likely probability assignment to result from this game is just the one that
has maximum entropy subject to the given information I.
You might object that this game is still not entirely ‘fair’, because we have stopped at the
ﬁrst acceptable result without seeing what other acceptable ones might also have turned up.In order to remove this objection, we can consider all possible acceptable distributions andchoose the average
piof them. But here the ‘laws of large numbers’ come to our rescue. We
leave it as an exercise for the reader to prove that in the limit of large n,the overwhelming
majority of all acceptable probability allocations that can be produced in this game arearbitrarily close to the maximum entropy distribution .
3
From a conceptual standpoint, the Wallis derivation is quite attractive. It is entirely
independent of Shannon’s functional equations (11.8); it does not require any postulatesabout connections between probability and frequency; nor does it suppose that the differentpossibilities{1,..., m}are themselves the result of any repeatable random experiment.
Furthermore, it leads automatically to the prescription that His to be maximized – and not
treated in some other way – without the need for any quasi-philosophical interpretation of
Hin terms of such a vague notion as ‘amount of uncertainty’. Anyone who accepts the
proposed game as a fair way to allocate probabilities that are not determined by the priorinformation is thereby led inexorably to the maximum entropy principle.
Let us stress this point. It is a big mistake to try to read too much philosophical sig-
niﬁcance into theorems which lead to (11.23). In particular, the association of the word‘information’ with entropy expressions seems in retrospect quite unfortunate, because itpersists in carrying the wrong connotations to so many people. Shannon himself, withprophetic insight into the reception his work would get, tried to play it down by pointingout immediately after stating the theorem that it was in no way necessary for the theoryto follow. By this he meant that the inequalities which Hsatisﬁes are already quite suf-
ﬁcient to justify its use; it does not really need the further support of the theorem, whichdeduces it from functional equations expressing intuitively the properties of ‘amount ofuncertainty’.
However, while granting that this is perfectly true, we would like now to show that if
we do accept the expression for entropy, very literally, as thecorrect expression for the
‘amount of uncertainty’ represented by a probability distribution, this will lead us to amuch more uniﬁed picture of probability theory in general. It will enable us to see that theprinciple of indifference, and many frequency connections of probability, are special cases
3This result is formalized more completely in the entropy concentration theorem given later.

<<<PAGE 386>>>

354 Part 2 Advanced applications
of a single principle, and that statistical mechanics, communication theory, and a mass of
other applications are all instances of a single method of reasoning.
11.5 An example
Let’s test this principle by seeing how it would work on the example discussed above, in
which mcan take on only the values 1, 2, 3, and mis given. We can use our Lagrange
multiplier argument again to solve this problem; as in (11.2),
δ/bracketleftbigg
H−λ3/summationdisplay
m=1mpm−µ3/summationdisplay
m=1pm/bracketrightbigg
=3/summationdisplay
m=1/bracketleftbigg∂H
∂pm−λm−µ/bracketrightbigg
δpm=0. (11.30)
Now,
∂H
∂pm=− log(pm)−1, (11.31)
so our solution is
pm=exp{−λ0−λm}, (11.32)
where λ0≡µ+1.
So the distribution which has maximum entropy, subject to a given average value, will
be in exponential form, and we have to ﬁt the constants λ0andλby forcing this to agree
with the constraints that the sum of the p’s must be one and the expectation value must be
equal to the average mthat we assigned. This is accomplished quite neatly if we deﬁne a
function
Z(λ)≡3/summationdisplay
m=1exp{−λm}, (11.33)
which we called the partition function in Chapter 9. The equations (11.3) and (11.4) which
ﬁx our Lagrange multipliers take the form
λ0=logZ(λ), (11.34)
m=−∂logZ(λ)
∂λ. (11.35)
We ﬁnd that p1(m),p2(m),p3(m) are given in parametric form by
pk=exp{−kλ}
exp{−λ}+exp{−2λ}+exp{−3λ}
=exp/braceleftbig
(3−k)λ/bracerightbig
exp{2λ}+exp{λ}+1, k=1,2,3;(11.36)
m=exp{2λ}+2e x p{λ}+3
exp{2λ}+exp{λ}+1. (11.37)

<<<PAGE 387>>>

11 Discrete prior probabilities: the entropy principle 355
In a more complicated problem, we would just have to leave it in parametric form, but in
this particular case we can eliminate the parameter λalgebraically, leading to the explicit
solution
p1=3−m−p2
2,
p2=1
3/bracketleftBig/radicalbig
4−3(m−2)2−1/bracketrightBig
,
p3=m−1−p2
2.(11.38)
As a function of m,p2is the arc of an ellipse which comes in with unit slope at the end
points. p1andp3are also arcs of ellipses, but slanted one way and the other.
We have ﬁnally arrived here at a solution which meets the objections we had to the
ﬁrst two criteria. The maximum entropy distribution (11.36) has automatically the property
pk≥0 because the logarithm has a singularity at zero which we could never get past. It
has, furthermore, the property that it never allows the robot to assign zero probability to anypossibility unless the evidence forces that probability to be zero.
4The only place where a
probability goes to zero is in the limit where mis exactly one or exactly three. But of course,
in those limits, some probabilities did have to be zero by deductive reasoning, whateverprinciple we invoked.
11.6 Generalization: a more rigorous proof
The maximum entropy solution can be generalized in many ways. Suppose a variable x
can take on ndifferent discrete values ( x
1,..., xn), which correspond to the ndifferent
propositions ( A1,..., An); and that there are mdifferent functions of x,
fk(x), 1≤k≤m<n, (11.39)
and that we want them to have expectations
/angbracketleftfk(x)/angbracketright=Fk, 1≤k≤m, (11.40)
where the{Fk}are numbers given to us in the statement of the problem. What probabilities
(p1,..., pn) will the robot assign to the possibilities ( x1,..., xn)? We shall have
Fk=/angbracketleftfk(x)/angbracketright=n/summationdisplay
i=1pifk(xi), (11.41)
and, to ﬁnd the set of pi’s which has maximum entropy subject to all these con-
straints simultaneously, we introduce as many Lagrange multipliers as there are
4This property was stressed by David Blackwell, who considered it the most fundamental requirement of a rational procedure
for assigning probabilities.

<<<PAGE 388>>>

356 Part 2 Advanced applications
constraints:
0=δ/bracketleftbigg
H−(λ0−1)/summationdisplay
ipi−m/summationdisplay
j=1λj/summationdisplay
ipifj(xi)/bracketrightbigg
=/summationdisplay
i/bracketleftbigg∂H
∂pi−(λ0−1)−m/summationdisplay
j=1λjfj(xi)/bracketrightbigg
δpi.(11.42)
So from (11.23) our solution is the following:
pi=exp/braceleftbigg
−λ0−m/summationdisplay
j=1λjfj(xi)/bracerightbigg
, (11.43)
as always, exponential in the constraints. The sum of all probabilities has to be unity, so
1=/summationdisplay
ipi=exp{−λ0}/summationdisplay
iexp/braceleftbigg
−m/summationdisplay
j=1λjfj(xi)/bracerightbigg
. (11.44)
If we now deﬁne the partition function
Z(λ1···λm)≡n/summationdisplay
i=1exp/braceleftbigg
−m/summationdisplay
j=1λjfj(xi)/bracerightbigg
, (11.45)
then (11.44) reduces to
λ0=logZ(λ1,...,λ m). (11.46)
The average value Fkmust be equal to the expected value of fx(x) over the probability
distribution
Fk=exp{−λ0}/summationdisplay
ifk(xi)e x p/braceleftbigg
−m/summationdisplay
j=1λjfj(xi)/bracerightbigg
, (11.47)
or
Fk=−∂logZ(λ1,...,λ m)
∂λk. (11.48)
The maximum value of the entropy is
Hmax=/bracketleftbigg
−n/summationdisplay
i=1pilog(pi)/bracketrightbigg
max, (11.49)
and from (11.43) we ﬁnd that
Hmax=λ0+m/summationdisplay
j=1λjFj. (11.50)
Now, these results open up so many new applications that it is important to have as rigorous
a proof as possible. But to solve a maximization problem by variational means, as we justdid, is not 100% rigorous. Our Lagrange multiplier argument has the nice feature that it

<<<PAGE 389>>>

11 Discrete prior probabilities: the entropy principle 357
gives us the answer instantaneously. It has the bad feature that after we done it, we’re not
quite sure it isthe answer. Suppose we wanted to locate the maximum of a function whose
absolute maximum happened to occur at a cusp (discontinuity of slope) instead at a roundedtop. Variational methods will locate some subsidiary rounded maxima, but they will notﬁnd the cusp. Even after we’ve proved that we have the highest value that can be reachedby variational methods, it is possible that the function reaches a still higher value at somecusp that we can’t locate by variational methods. There would always be a little grain ofdoubt remaining if we do only the variational problem.
So now we give an entirely different derivation which is strong just where the variational
argument is weak. For this we need a lemma. Let p
ibe any set of numbers which could be
a possible probability distribution; in other words,
n/summationdisplay
i=1pi=1, pi≥0, (11.51)
and let uibe another possible probability distribution,
n/summationdisplay
i=1ui=1, ui≥0. (11.52)
Now,
log(x)≤(x−1), 0≤x<∞, (11.53)
with equality if and only if x=1. Therefore,
n/summationdisplay
i=1pilog/parenleftbiggui
pi/parenrightbigg
≤n/summationdisplay
i=1pi/parenleftbiggui
pi−1/parenrightbigg
=0, (11.54)
or
H(p1,..., pn)≤n/summationdisplay
i=1pilog/parenleftbigg1
ui/parenrightbigg
, (11.55)
with equality if and only if pi=ui,i=1,..., n. This is the lemma we need.
Now we simply pull a distribution uiout of the hat;
ui≡1
Z(λ1,...,λ m)exp/braceleftbigg
−m/summationdisplay
j=1λjfj(xi)/bracerightbigg
, (11.56)
where Z(λ1,...,λ m) is deﬁned by (11.45). Never mind why we chose uithis particular
way; we’ll see why in a minute. We can now write the inequality (11.55) as
H≤n/summationdisplay
i=1pi/bracketleftbigg
logZ(λ1,...,λ m)+m/summationdisplay
j=1λjfj(xi)/bracketrightbigg
(11.57)

<<<PAGE 390>>>

358 Part 2 Advanced applications
or
H≤logZ(λ1,...,λ m)+m/summationdisplay
j=1λj/angbracketleftbig
fj(x)/angbracketrightbig
. (11.58)
Now let the pivary over the class of all possible probability distributions that satisfy the
constraints (11.41). The right-hand side of (11.58) stays constant. Our lemma now says that
Hattains its absolute maximum Hmax, making (11.58) an equality, if and only if the piare
chosen as the canonical distribution (11.56).
This is the rigorous proof, which is independent of the things that might happen if we try
to do it as a variational problem. This argument is, as we see, strong just where the variationalargument is weak. On the other hand, this argument is weak where the variational argumentis strong, because we just had to pull the answer out of a hat in writing (11.56). We had toknow the answer before we could prove it. If you have both arguments side by side, thenyou have the whole story.
11.7 Formal properties of maximum entropy distributions
Now we want to list the formal properties of the canonical distribution (11.56). This is a
bad way to proceed in one sense because it all sounds very abstract and we don’t see theconnections to real problems. On the other hand, we get all the things we need a lot fasterif we ﬁrst become aware of all the formal properties that are in the theory; and then later gointo speciﬁc physical problems and see that every one of these formal relations has manydifferent useful meanings, depending on the particular problem.
The maximum attainable Hthat we can obtain by holding these averages ﬁxed depends,
of course, on the average values we speciﬁed,
H
max=S(F1,..., Fm)=logZ(λ1,...,λ m)+m/summationdisplay
k=1λkFk. (11.59)
We can regard Has a measure of the ‘amount of the uncertainty’ in any probability distribu-
tion. After we have maximized it, it becomes a function of the deﬁnite data of the problem{F
i}, and we’ll call this maximum S(F1,..., Fm) with a view to the original application in
physics. It is still a measure of ‘uncertainty’, but it is uncertainty when all the information we
have consists of just these numbers . It is completely ‘objective’ in the sense that it depends
only on the given data of the problem , and not on anybody’s personality or wishes.
IfSis to be a function only of ( F1,..., Fm), then in (11.59) the Z(λ1,...,λ m) must also
be thought of as functions of ( F1,..., Fm). At ﬁrst, the λ’s were just unspeciﬁed Lagrange
multipliers, but eventually we will want to know what they are. If we choose different λi,
we are writing down different probability distributions (11.56); and we saw in (11.48) thatthe averages over these distributions agree with the given averages F
kif
Fk=/angbracketleftfk/angbracketright=−∂logZ(λ1,...,λ m)
∂λk, k=1,2,..., m. (11.60)

<<<PAGE 391>>>

11 Discrete prior probabilities: the entropy principle 359
Equation (11.60) is a set of msimultaneous nonlinear equations which must be solved for
theλ’s in terms of the Fk. Generally, in a nontrivial problem, it is impractical to solve
for the λ’s explicitly (although there is a simple formal solution, (11.62), below). We leave
theλkwhere they are, expressing things in parametric form. Actually, this isn’t such a
tragedy, because the λ’s usually turn out to have such important physical meanings that we
are quite happy to use them as the independent variables. However, if we can evaluate thefunction S(F
1,..., Fm) explicitly, then we cangive the λ’s as explicit functions of the {Fk}
as follows.
Suppose we make a small change in one of the Fk; how does this change the maximum
attainable H? We have, from (11.59),
∂S(F1,..., Fm)
∂Fk=m/summationdisplay
j=1/bracketleftbigg∂logZ(λ1,...,λ m)
∂λj/bracketrightbigg/bracketleftbigg∂λj
∂Fk/bracketrightbigg
+m/summationdisplay
j=1∂λj
∂FkFk+λk,(11.61)
which, thanks to (11.60), collapses to
λk=∂S(F1,..., Fm)
∂Fk, (11.62)
in which λkis given explicitly.
Compare this equation with (11.60); one gives Fkexplicitly in terms of the λk, the other
gives the λkexplicitly in terms of the Fk. Specifying log Z(λ1,...,λ m)o rS(F1,..., Fm)
are equivalent in the sense that each gives full information about the probability distribution.The complete story is contained in either function, and in fact (11.59) is just the Legendretransformation that takes us from one representative function to the other.
We can derive some more interesting laws simply by differentiating either (11.60) or
(11.62). If we differentiate (11.60) with respect to λ
j, we obtain
∂Fk
∂λj=∂2logZ(λ1,...,λ m)
∂λj∂λk=∂Fj
∂λk, (11.63)
because the second cross-derivatives of log Z(λ1,...,λ m) are symmetric in jandk. So,
here is a general reciprocity law which will hold in any problem we do by maximizing theentropy. Likewise, if we differentiate (11.62) a second time, we have
∂λ
k
∂Fj=∂2S
∂Fj∂Fk=∂λj
∂Fk, (11.64)
another reciprocity law, which is, however, not independent of (11.63), because, if we deﬁne
the matrices Ajk≡∂λj/∂Fk,Bjk≡∂Fj/∂λ k, we see easily that they are inverse matrices:
A=B−1,B=A−1. These reciprocity laws might appear trivial from the ease with which
we derived them here; but when we get around to applications we’ll see that they havehighly nontrivial and nonobvious physical meanings. In the past, some of them were foundby tedious means that made them seem mysterious and arcane.
Now let’s consider the possibility that one of the functions f
k(x) contains a parameter
αwhich can be varied. If you want to think of applications, you can say fk(xi;α) stands

<<<PAGE 392>>>

360 Part 2 Advanced applications
for the ith energy level of some system and αrepresents the volume of the system. The
energy levels depend on the volume. Or, if it’s a magnetic resonance system, you can say that
fk(xi) represents the energy of the ith stationary state of the spin system and αrepresents the
magnetic ﬁeld Happlied to it. Often we want to make a prediction of how certain quantities
change as we change α. We may want to calculate the pressure or the susceptibility. By the
criterion of minimum mean-square error, the best estimate of the derivative would be themean value over the probability distribution
/angbracketleftbigg∂f
k
∂α/angbracketrightbigg
=1
Z/summationdisplay
iexp{−λ1f1(xi)−···− λkfk(xi;α)−···− λmfm(xi)}∂fk(xi,α)
∂α,
(11.65)
which reduces to
/angbracketleftbigg∂fk
∂α/angbracketrightbigg
=−1
λk∂logZ(λ1,...,λ m;α)
∂α. (11.66)
In this derivation, we supposed that αappeared in only one function, fk. If the same
parameter is in several different fk, then we verify easily that this generalizes to
m/summationdisplay
k=1λk/angbracketleftbigg∂fk
∂α/angbracketrightbigg
=−∂logZ(λ1,...,λ m;α)
∂α. (11.67)
This general rule contains, among other things, the equation of state of any thermodynamic
system.
When we add αto the problem, both Z(λ1,...,λ m;α) and S(F1,..., Fk;α) become
functions of α. If we differentiate log Z(λ1,...,λ m;α)o r S(F1,..., Fk;α), we get the
same thing:
∂S(F1,..., Fk;α)
∂α=−m/summationdisplay
k=1λk/angbracketleftbigg∂fk
∂α/angbracketrightbigg
=∂logZ(λ1,...,λ m;α)
∂α, (11.68)
with one tricky point: in (11.68) we have to understand that in ∂S(F1,..., Fm;α)/∂α we
are holding the Fkﬁxed, while in ∂logZ(λ1,...,λ m;α)/∂α we are holding the λkﬁxed.
The equality of these derivatives then follows from the Legendre transformation (11.59).
Evidently, if there are several different parameters {α1,α2,...,α r}in the problem, a relation
of the form (11.68) will hold for each of them.
Now let’s note some general ‘ﬂuctuation laws’, or moment theorems. Firstly, a comment
about notation: we were using the Fkand/angbracketleftfk/angbracketrightto stand for the same number . They are equal
because we speciﬁed that the expectation values {/angbracketleftf1/angbracketright,...,/angbracketleftfm/angbracketright}are to be set equal to the
given data{F1,..., Fm}. When we want to emphasize that these quantities are expectation
values over the canonical distribution (11.56), we will use the notation /angbracketleftfk/angbracketright. When we want
to emphasize that they are the given data, we will call them Fk. At the moment, we want to
do the former, and so the reciprocity law (11.63) can be written equally well as
∂/angbracketleftfk/angbracketright
∂λj=∂/angbracketleftfj/angbracketright
∂λk=∂2logZ(λ1,...,λ m)
∂λj∂λk. (11.69)

<<<PAGE 393>>>

11 Discrete prior probabilities: the entropy principle 361
In varying the λ’s here, we were changing from one canonical distribution (11.56) to a
slightly different one in which the /angbracketleftfk/angbracketrightare slightly different. Since the new distribution cor-
responding to ( λk+dλk) is still of canonical form, it is still a maximum entropy distribution
corresponding to slightly different data ( Fk+dFk). Thus we are comparing two slightly
different maximum entropy problems. For later physical applications it will be importantto recognize this in interpreting the reciprocity law (11.69).
Now we want to show that the quantities in (11.69) also have an important meaning with
reference to a single maximum entropy problem. In the canonical distribution (11.56), how
are the different quantities f
k(x) correlated with each other? More speciﬁcally, how are
departures from their mean values /angbracketleftfk/angbracketrightcorrelated? The measure of this is the covariance ,
or second central moments, of the distribution:
/angbracketleftBig/parenleftbig
fj−/angbracketleftfj/angbracketright/parenrightbig/parenleftbig
fk−/angbracketleftfk/angbracketright/parenrightbig/angbracketrightBig
=/angbracketleftBig
fjfk−fj/angbracketleftfk/angbracketright−/angbracketleft fj/angbracketrightfk+/angbracketleftfj/angbracketright/angbracketleftfk/angbracketright/angbracketrightBig
=/angbracketleftfjfk/angbracketright−/angbracketleft fj/angbracketright/angbracketleftfk/angbracketright.(11.70)
If a value of fkgreater than the average /angbracketleftfk/angbracketrightis likely to be accompanied by a value of fj
greater than its average /angbracketleftfj/angbracketright, the covariance is positive; if they tend to ﬂuctuate in opposite
directions, it is negative; and if their variations are uncorrelated, the covariance is zero. If
j=k, this reduces to the variance :
/angbracketleftbig
(fk−/angbracketleftfk/angbracketright)2/angbracketrightbig
=/angbracketleftf2
k/angbracketright−/angbracketleft fk/angbracketright2≥0. (11.71)
To calculate these quantities directly from the canonical distribution (11.56), we can ﬁrst ﬁnd
/angbracketleftfjfk/angbracketright=1
Z(λ1,...,λ m)n/summationdisplay
i=1fj(xi)fk(xi)e x p/braceleftbigg
−m/summationdisplay
j=1λjfj(xi)/bracerightbigg
=1
Z(λ1,...,λ m)n/summationdisplay
i−1∂2
∂λj∂λkexp/braceleftbigg
−m/summationdisplay
j=1λjfj(xi)/bracerightbigg
=1
Z(λ1,...,λ m)∂2Z(λ1,...,λ m)
∂λj∂λk.(11.72)
Then, using (11.60), the covariance becomes
/angbracketleftfjfk/angbracketright−/angbracketleft fj/angbracketright/angbracketleftfk/angbracketright=1
Z∂2Z
∂λj∂λk−1
Z2∂Z
∂λj∂Z
∂λk=∂2logZ
∂λj∂λk. (11.73)
But this is just the quantity (11.69); therefore the reciprocity law takes on a bigger meaning,
/angbracketleftfjfk/angbracketright−/angbracketleft fj/angbracketright/angbracketleftfk/angbracketright=−∂/angbracketleftfj/angbracketright
∂λk=−∂/angbracketleftfk/angbracketright
∂λj. (11.74)
The second derivatives of log Z(λ1,...,λ m) which gave us the reciprocity law also give us
the covariance of fjand fkin our distribution.

<<<PAGE 394>>>

362 Part 2 Advanced applications
Note that (11.74) is in turn only a special case of a more general rule. Let q(x)b ea n y
function; then the covariance with fk(x) is, as can be easily veriﬁed,
/angbracketleftqfk/angbracketright−/angbracketleft q/angbracketright/angbracketleftfk/angbracketright=−∂/angbracketleftq/angbracketright
∂λk. (11.75)
Exercise 11.3. From comparing (11.60), (11.69) and (11.74), we might expect that still
higher derivatives of log Z(λ1,...,λ m) would correspond to higher central moments
of the distribution (11.56). Check this conjecture by calculating the third and fourthcentral moments in terms of log Z(λ
1,...,λ m).
Hint: See Appendix C on the theory of cumulants.
For noncentral moments, it is customary to de ﬁne a moment generating function
/Phi1(β1,...,β m)≡/angbracketleftbigg
exp/braceleftBigm/summationdisplay
j=1βjfj/bracerightBig/angbracketrightbigg
, (11.76)
which evidently has the property
/angbracketleftbig
fmi
ifmj
j···/angbracketrightbig
=/parenleftBigg
∂mi
∂βmi
i∂mj
∂βmj
j···/parenrightBigg
/Phi1(β1,...,β m)/vextendsingle/vextendsingle/vextendsingle/vextendsingle
βk=0. (11.77)
However, we ﬁnd from (11.76),
/Phi1(β1,...,β m)=Z([λ1−β1],..., [λm−βm])
Z(λ1,...,λ m), (11.78)
so that the partition function Z(λ1,...,λ m) serves this purpose; instead of (11.77) we may
write equally well
/angbracketleftbig
fmi
ifmj
j···/angbracketrightbig
=1
Z(λ1,...,λ m)/parenleftBigg
∂mi
∂λmi
i∂mj
∂λmj
j···/parenrightBigg
Z(λ1,...,λ m), (11.79)
which is the generalization of (11.72).
Now, we might ask, what are the covariances of the derivatives of fkwith respect to a
parameter α? Deﬁne
gk≡∂fk
∂α; (11.80)
then, for example, if fkis the energy and αis the volume then −gkis the pressure. We
easily verify another reciprocity relation:
∂/angbracketleftgj/angbracketright
∂λk=−/bracketleftBig
/angbracketleftgjfk/angbracketright−/angbracketleft gj/angbracketright/angbracketleftgk/angbracketright/bracketrightBig
=∂/angbracketleftgk/angbracketright
∂λj(11.81)

<<<PAGE 395>>>

11 Discrete prior probabilities: the entropy principle 363
analogous to (11.74). By a similar derivation, we ﬁnd the identity
m/summationdisplay
j=1λj/bracketleftBig
/angbracketleftgjgk/angbracketright−/angbracketleft gj/angbracketright/angbracketleftgk/angbracketright/bracketrightBig
=/angbracketleftbigg∂gk
∂α/angbracketrightbigg
−∂/angbracketleftgk/angbracketright
∂α. (11.82)
We had found and used special cases of this for some time before realizing its generality.
Other derivatives of log Z(λ1,...,λ m) are related to various moments of the fkand their
derivatives with respect to α. For example, closely related to (11.82) is
∂2logZ(λ1,...,λ m)
∂α2=/summationdisplay
jkλjλk/bracketleftbig
/angbracketleftgjgk/angbracketright−/angbracketleft gj/angbracketright/angbracketleftgk/angbracketright/bracketrightbig
−/summationdisplay
kλk/angbracketleftbigg∂gk
∂α/angbracketrightbigg
. (11.83)
The cross-derivatives give us a simple and useful relation,
∂2logZ(λ1,...,λ m)
∂α∂λ k=−∂/angbracketleftfk/angbracketright
∂α=/summationdisplay
jλj/bracketleftBig
/angbracketleftfkgj/angbracketright−/angbracketleft fk/angbracketright/angbracketleftgj/angbracketright/bracketrightBig
−/angbracketleftgk/angbracketright, (11.84)
which also follows from (11.69) and (11.75); by taking further derivatives, an in ﬁnite
hierarchy of similar moment relations is obtained. As we will see later, the above theoremshave, as special cases, many relations, such as the Einstein ﬂuctuation laws for black-bodyradiation and for density of a gas or liquid, the Nyquist voltage ﬂuctuations, or ‘noise’generated by a reversible electric cell, etc.
It is evident that if several different parameters {α
1,...,α r}are present, relations of the
above form will hold for each of them; and new ones such as
∂2logZ(λ1,...,λ m)
∂α1∂α2=/summationdisplay
kλk/angbracketleftbigg∂2fk
∂α1∂α2/angbracketrightbigg
−/summationdisplay
kjλjλk/bracketleftbigg/angbracketleftbigg∂fk
∂α1∂fj
∂α2/angbracketrightbigg
−/angbracketleftbigg∂fk
∂α1/angbracketrightbigg/angbracketleftbigg∂fj
∂α2/angbracketrightbigg/bracketrightbigg
(11.85)
will appear.
The relationship between log Z(λ1,...,λ m;α1,...,α r) and S(/angbracketleftf1/angbracketright,...,/angbracketleftfm/angbracketright;
α1,...,α r) shows that they can all be stated also in terms of derivatives (i.e. variational
properties) of S; see (11.59). In the case of S, however, there is a still more general and
important variational property.
In (11.62) we supposed that the deﬁnitions of the functions fk(x) were ﬁxed once and for
all, the variation of/angbracketleftfk/angbracketrightbeing due only to variations in the pi. We now derive a more general
variational statement in which both of these quantities are varied. Let δfk(xi) be speciﬁed
arbitrarily and independently for each value of kandi, letδ/angbracketleftfk/angbracketrightbe speciﬁed independently
of the δfk(xi), and consider the resulting change from one maximum entropy distribution
pito a slightly different one p/prime
i=pi+δpi, the variations δpiandδλkbeing determined
in terms of δfk(xi) andδ/angbracketleftfk/angbracketrightthrough the above equations. In other words, we are now
considering two slightly different maximum entropy problems in which all conditions ofthe problem – including the deﬁnitions of the functions f
k(x) on which it is based – are

<<<PAGE 396>>>

364 Part 2 Advanced applications
varied arbitrarily. The variation in log Z(λ1,...,λ m)i s
δlogZ(λ1,...,λ m)=1
Zn/summationdisplay
i=1/bracketleftBiggm/summationdisplay
k=1/bracketleftBig
−λkδfk(xi)−δλkfk(xi)/bracketrightBig
exp/braceleftbigg
−m/summationdisplay
j=1λjfj(xi)/bracerightbigg/bracketrightBigg
=−m/summationdisplay
k=1/bracketleftBig
λk/angbracketleftδfk/angbracketright+δλk/angbracketleftfk/angbracketright/bracketrightBig
,
(11.86)
and thus from the Legendre transformation (11.59)
δS=−/summationdisplay
kλk/bracketleftBig
δ/angbracketleftfk/angbracketright−/angbracketleftδfk/angbracketright/bracketrightBig
, or δS=/summationdisplay
kλkδQk, (11.87)
where
δQk≡δ/angbracketleftfk/angbracketright−/angbracketleftδfk/angbracketright=n/summationdisplay
i=1fk(xi)δpi. (11.88)
This result, which generalizes (11.62), shows that the entropy Sis stationary not only in
the sense of the maximization property which led to the canonical distribution (11.56); itis also stationary with respect to small variations in the functions f
k(xi)i ft h e piare held
ﬁxed.
As a special case of (11.87), suppose that the functions fkcontain parameters{α1,...,α r}
as in (11.85), which generate the δfk(xi)b y
δfk(xi,αj)=r/summationdisplay
j=1∂fk(xi,α)
∂αjδαj. (11.89)
While δQkis not in general the exact differential of any function Qk(/angbracketleftfi/angbracketright;αj), (11.87)
shows that λkis an integrating factor such that/summationtextλkδQkis the exact differential of a ‘state
function’ S(/angbracketleftfi/angbracketright;αj). At this point, perhaps all this is beginning to sound familiar to those
who have studied thermodynamics. Finally, we leave it for you to prove from (11.87) that
m/summationdisplay
k=1/angbracketleftfk/angbracketright∂λk
∂α=0, (11.90)
where/angbracketleftf1/angbracketright,...,/angbracketleftfr/angbracketrightare held constant in the differentiation.
Evidently, there’s now a large new class of problems which we can ask the robot to do,
which it can solve in rather a wholesale way. It ﬁrst evaluates this partition function Z,
or, better still, log Z. Then, just by differentiating log Zwith respect to all its arguments
in every possible way, it obtains all sorts of predictions in the form of mean values overthe maximum entropy distribution. This is quite a neat mathematical procedure, and, ofcourse, you recognize what we have been doing here. These relations are all just the standardequations of statistical mechanics given to us by J. Willard Gibbs, but now in a disembodiedform with all the physics removed.
Indeed, virtually all known thermodynamic relations, found over more than a century ago
by the most diverse and difﬁcult kinds of physical reasoning and experimentation, are now

<<<PAGE 397>>>

11 Discrete prior probabilities: the entropy principle 365
seen as special cases of simple mathematical identities of the maximum entropy formalism.
This makes it clear that those relations are actually independent of any particular physicalassumptions and are properties of extended logic in general, giving us a new insight intowhy the relations of thermodynamics are so general, independent of the properties of anyparticular substance. Gibbs’ statistical mechanics is historically the oldest application ofthe principle of maximum entropy and is still the most used (although many of its users arestill unaware of its generality).
The maximum entropy mathematical formalism has a mass of other applications outside
of physics. In Chapter 14 we work out the full numerical solution to a nontrivial problem ofinventory control, and in Chapter 22 we give a highly nontrivial analytical solution of aproblem of optimal encoding in communication theory. In a sense, once we have understoodthe maximum entropy principle as explained in this chapter, most applications of probabilitytheory are seen as invoking it to assign the initial probabilities – whether called technicallyprior probabilities or sampling probabilities. Whenever we assign uniform prior probabil-ities, we can say truthfully that we are applying maximum entropy (although in that casethe result is so simple and intuitive that we do not need any of the above formalism). As wesaw in Chapter 7, whenever we assign a Gaussian sampling distribution, this is the same asapplying maximum entropy for given ﬁrst and second moments. And we saw in Chapter 9that, whenever we assign a binomial sampling distribution, this is mathematically equivalentto assigning the uniform maximum entropy distribution on a deeper hypothesis space.
11.8 Conceptual problems – frequency correspondence
The principle of maximum entropy is basically a simple and straightforward idea, and, in the
case that the given information consists of average values, it leads, as we have just seen, toa surprisingly concise mathematical formalism, since essentially everything is known if
we can evaluate a single function log Z(λ
1,...,λ m;α1,...,α r). Nevertheless, it seems to
generate some serious conceptual difﬁculties, particularly to people who have been trainedto think of probability only in the frequency sense. Therefore, before turning to applications,we want to examine, and hopefully resolve, some of these difﬁculties. Here are some of theobjections that have been raised against the principle of maximum entropy.
(A) If the only justiﬁcation for the canonical distribution (11.56) is ‘maximum uncertainty’, that is a
negative thing which can’t possibly lead to any useful predictions; you can’t get reliable resultsout of mere ignorance.
(B) The probabilities obtained by maximum entropy cannot be relevant to physical predictions be-
cause they have nothing to do with frequencies – there is absolutely no reason to suppose thatdistributions observed experimentally would agree with ones found by maximizing entropy.
(C) The principle is restricted to the case where the constraints are average values – but almost always
the given data{F
1,..., Fn}arenotaverages over anything. They are deﬁnite measured numbers.
When you set them equal to averages, Fk=/angbracketleftfk/angbracketright, you are committing a logical contradiction,
for the given data said that fkhad the value Fk; yet you immediately write down a probability
distribution that assigns nonzero probabilities to values of fk/negationslash=Fk.

<<<PAGE 398>>>

366 Part 2 Advanced applications
(D) The principle cannot lead to any deﬁnite physical results because different people have different
information, which would lead to different distributions – the results are basically arbitrary.
Objection (A) is, of course, nothing but a play on words. The ‘uncertainty’ was always there.
Our maximizing the entropy did not create any ‘ignorance’ or ‘uncertainty’; it is rather the
means of determining quantitatively the full extent of the uncertainty already present. It isfailure to do this – and as a result using a distribution that implies more knowledge than we
really have – that would lead to unreliable conclusions.
Of course, the information put into the theory as constraints on our maximum entropy
distribution, may be so meager – the distribution is so weakly constrained from the unin-formative uniform one – that no reliable predictions can be made from it. But in that case,as we will see later, the theory automatically tells us this: if we emerge with a very broadprobability distribution for some quantity θ(such as pressure, magnetization, electric cur-
rent density, rate of diffusion, etc.), that is the robot’s way of telling us: ‘You haven’t givenme enough information to determine any deﬁnite prediction’. But if we get a very sharpdistribution for θ(for example – and typical of what does happen in many real problems –
if the theory says the odds on θbeing in the interval θ
0(1±10−6) are greater than 1010: 1),
then the given information wassufﬁcient to make a very deﬁnite prediction.
In both cases, and in the intermediate ones, the distribution for θalways tells us just what
conclusions we areentitled to draw about θ, on the basis of the information which was put
into the equations . If someone has additional cogent information, but fails to incorporate it
into his calculation, the result is not a failure, only a misuse, of the maximum entropy method.
To answer objection (B), we show that the situation is vastly more subtle than that.
The principle of maximum entropy has, fundamentally, nothing to do with any repeatable‘random experiment’. Some of the most important applications are to cases where the
probabilities p
iin (11.56) have no frequency connection – the xiare simply an enumeration
of the possibilities , in the single situation being considered, as in the cars on the ferry
problem.
Nothing prevents us, however, from applying the principle of maximum entropy also to
cases where the xiare generated by successive repetitions of some experiment as in the dice
problem; and, in this case, the question of the relationship between the maximum entropyprobability p(x
i) and the frequency with which xiis observed, is capable of mathematical
analysis. We demonstrate that (1) in this case the maximum entropy probabilities dohave
a precise connection with frequencies; (2) in most real problems, however, this relation isunnecessary for the usefulness of the method; and (3) in fact, the principle of maximum
entropy is most useful to us in just those cases where the observed frequencies do notagree
with the maximum entropy probabilities.
Suppose now that the value of xis determined by some random experiment; at each
repetition of the experiment, the ﬁnal result is one of the values x
i,i=1,2,..., n; in the
dice problem, n=6. But now, instead of asking for the probability pi, let’s ask an entirely
different question: on the basis of the available information, what can we say about therelative frequencies f
iwith which the various xioccur?

<<<PAGE 399>>>

11 Discrete prior probabilities: the entropy principle 367
Let the experiment consist of Ntrials (we are particularly interested in the limit N→∞ ,
because that is the situation contemplated in the usual frequency theory of probability), andlet every conceivable sequence of results be analyzed. Each trial could give, independently,any one of the results {x
1,..., xn}, and so there are nNconceivable outcomes of the whole
experiment. But many of these will be incompatible with the given information. (Let’s sup-pose again that this consists of average values of several functions f
k(x),k=1,2,..., m;
in the end, it will be clear that the ﬁnal conclusions are independent of whether it takes thisform or some other.) We will, of course, assume that the result of the experiment agreeswith this information – if it didn’t, then the given information was false and we are doingthe wrong problem. In the whole experiment, the results x
1will be obtained n1times, x2
will be obtained n2times, etc. Of course,
n/summationdisplay
i=1ni=N, (11.91)
and if the speciﬁed mean values Fkgiven to us are in fact observed in the actual experiment,
we have the additional relation
n/summationdisplay
i=1nifk(xi)=NF k, d=1,2,..., m. (11.92)
Ifm<n−1, (11.91) and (11.92) are insufﬁcient to determine the relative frequencies
fi=ni/N. Nevertheless, we do have grounds for preferring some choices of the fito
others. For, out of the original nNconceivable outcomes, how many would lead to a given set
of sample numbers {n1,n2,..., nn}? The answer is, of course, the multinomial coefﬁcient
W=N!
n1!n2!···nn!=N!
(Nf1)!(Nf2)!···(Nfn)!. (11.93)
The set of frequencies {f1,..., fn}which can be realized in the greatest number of ways is
therefore the one which maximizes Wsubject to the constraints (11.91), (11.92). Now we can
equally well maximize any monotonic increasing function of W, in particular N−1log(W);
but as N→∞ we have, as we saw already in (11.29),
1
Nlog(W)→−n/summationdisplay
i=1filog(fi)=Hf. (11.94)
So you see that, in (11.91), (11.92) and (11.94) we hav e formulated exactly the same
mathematical problem as in the maximum entropy derivation, so the two problems will have
the same solution. This argument is mathematically reminiscent of the Wallis derivationgiven in Section 11.4; and the same result could have been found as well by direct applica-tion of Bayes’ theorem, assigning uniform prior probabilities over all the n
Nconceivable
outcomes and passing to the limit N→∞ .
You see also, in partial answer to objection (C), that this identity of the mathematical
problems will persist whether or not the constraints take the form of mean values. If thegiven information does consist of mean values, then the mathematics is particularly neat,

<<<PAGE 400>>>

368 Part 2 Advanced applications
leading to the partition function, etc. But, for given information which places anydeﬁnite
kind of constraint on the problem, we have the same conclusion: the probability distribution
which maximizes the entropy is numerically identical with the frequency distribution which
can be realized in the greatest number of ways.
The maximum in Wis, furthermore, enormously sharp. To show this, let {f1,..., fn}
be the set of frequencies which maximizes Wand has entropy Hf; and let{f/prime
1,..., f/prime
n}be
any other set of possible frequencies (that is, a set which satisﬁes the constraints (11.91),(11.92) and has entropy H
f/prime<Hf). The ratio (number of ways in which ficould be
realized)/(number of ways in which f/prime
icould be realized) grows asymptotically, according
to (11.94), as
W
W/prime→exp/braceleftbig
N(Hf−Hf/prime)/bracerightbig
(11.95)
and passes all bounds as N→∞ . Therefore, the frequency distribution predicted by max-
imum entropy can be realized experimentally in overwhelmingly more ways than can any
other that satisﬁes the same constraints.
We have here another precise and quite general connection between probability and fre-
quency; it had nothing to do with the deﬁnition of probability, but emerged as a mathematicalconsequence of probability theory, interpreted as extended logic. Another kind of connec-
tion between probability and frequency, whose precise mathematical statement is different
in form, but which has the same practical consequences, will appear in Chapter 12.
Turning to objection (C), our purpose in imposing constraints is to incorporate certain
information into our probability distribution. Now, what does it mean to say that a probability
distribution ‘contains’ some information? We take this as meaning that the information canbe extracted from it by using the usual rule for estimating the expectation. Usually, the datum
F
kis of unknown accuracy, and so using it to constrain only the /angbracketleftFk/angbracketrightis just the process of
being honest, leaving the width of the distribution for fk(x) to be determined by the range
and density of the set of possibilities xi. But if we do have independent information about
the accuracy of F1, that can be incorporated by adding a new constraint on /angbracketleftf1(xi)2/angbracketright; the
formalism already allows for this. But this seldom makes any substantive difference in theﬁnal conclusions, because the variance of the maximum entropy distribution for f
1(x)i s
usually small compared with any reasonable mean-square experimental error.
Now let’s turn to objection (D) and analyze the situation with some care, because it is
perhaps the most common of all of them. Does the above connection between probability
and frequency justify our predicting that the maximum entropy distribution will in fact
be observed as a frequency distribution in a real experiment? Clearly not, in the sense ofdeductive proof; for, just as objection (D) points out, we have to concede that differentpeople may have different amounts of information, which will lead them to writing downdifferent distributions, which make different predictions of observable facts, and they can’tall be right. But this misses the point about what we are trying to do; let’s look at it moreclosely.

<<<PAGE 401>>>

11 Discrete prior probabilities: the entropy principle 369
Consider a speciﬁc case: Mr Aimposes constraints on the mean values /angbracketleftf1(x)/angbracketright,/angbracketleftf2(x)/angbracketright
to agree with his data F1,F2.M r B, better informed, imposes in addition a constraint on
/angbracketleftf3(x)/angbracketrightto agree with his extra datum F3. Each sets up a maximum entropy distribution
on the basis of his information. Since Mr B’s entropy is maximized subject to one further
constraint, we will have
SB≤SA. (11.96)
Suppose that Mr B’s extra information was redundant, in the sense that it was only what
MrAwould have predicted from his distribution. Now, Mr Ahas maximized his entropy
with respect to all variations of the probability distribution which hold /angbracketleftf1/angbracketright,/angbracketleftf2/angbracketrightﬁxed at
the speciﬁed values F1,F2. Therefore, he has a fortiori maximized it with respect to the
smaller class of variations which also hold /angbracketleftf3/angbracketrightﬁxed at the value ﬁnally attained. Therefore
MrA’s distribution also solves Mr B’s problem in this case; λ3=0, and Mr Aand Mr B
have identical probability distributions. In this case, and only in this case, we have equalityin (11.96).
From this we learn two things. (1) Two people with different given information do not
necessarily arrive at different maximum entropy distributions; this is the case only whenMrB’s extra information was ‘surprising’ to Mr A. (2) In setting up a maximum entropy
problem, it is not necessary to determine whether the different pieces of information usedare independent: any redundant information will not be ‘counted twice’, but will drop outof the equations automatically. Indeed, this not only agrees with our basic desideratum that
AA=Ain Boolean algebra; it would be true of any variational principle (imposing a new
constraint cannot change the solution if the old solution already satisﬁed that constraint).
Now suppose the opposite extreme: Mr B’s extra information was logically contradictory
to what Mr Aknows. For example, it might turn out that f
3(x)=f1(x)+2f2(x), but Mr B’s
data failed to satisfy F3=F1+2F2. Evidently, there is noprobability distribution that ﬁts
MrB’s supposed data. How does our robot tell us this? Mathematically, you will then ﬁnd
that the equations
Fk=−∂logZ(λ1,λ2,λ3)
∂λk(11.97)
have no simultaneous solution with real λk. In the example just mentioned,
Z(λ1,λ2,λ3)=n/summationdisplay
i=1exp{−λ1f1(xi)−λ2f2(xi)−λ3f3(xi)}
=n/summationdisplay
i=1exp{−(λ1+λ3)f1(xi)−(λ2+2λ3)f2(xi)}(11.98)
and so
∂Z(λ1,λ2,λ3)
∂λ3=∂Z(λ1,λ2,λ3)
∂λ1+2∂Z(λ1,λ2,λ3)
∂λ2, (11.99)

<<<PAGE 402>>>

370 Part 2 Advanced applications
and so (11.97) cannot have solutions for λ1,λ2,λ3unless F3=F1+2F2. So, when a new
piece of information logically contradicts previous information, the principle of maximumentropy breaks down, as it should, refusing to give us any distribution at all.
The most interesting case is the intermediate one where Mr B’s extra information was
neither redundant nor contradictory. He then ﬁnds a maximum entropy distribution differentfrom that of Mr A, and the inequality holds in (11.96), indicating that Mr B’s extra infor-
mation was ‘useful’ in further narrowing down the range of possibilities allowed by Mr A’s
information. The measure of this range is just W; and from (11.95) we have asymptotically
W
A
WB∼exp/braceleftbig
N(SA−SB)/bracerightbig
. (11.100)
For large N, even a slight decrease in the entropy leads to an enormous decrease in the
number of possibilities.
Suppose now that we start performing the experiment with Mr Aand Mr Bwatching.
Since Mr Apredicts a mean value /angbracketleftf3/angbracketrightdifferent from the correct one known to Mr B,i ti s
clear that the experimental distribution cannot agree in all respects with Mr A’s prediction.
We cannot be sure in advance that it will agree with Mr B’s prediction either, for there may
be still further constraints on f4(x),f5(x),..., etc. operating in the experiment unknown
to Mr B.
The property demonstrated above justiﬁes the following weaker statement of frequency
correspondence: If the information incorporated into the maximum entropy analysis in-cludes all the constraints actually operating in the random experiment, then the distributionpredicted by maximum entropy is overwhelmingly the most likely to be observed experi-mentally. Indeed, most frequency distributions observed in Nature are maximum entropy
distributions, simply because they can be realized in so many more ways than can any other.
Conversely, suppose the experiment fails to conﬁrm the maximum entropy prediction,
and this disagreement persists indeﬁnitely on repetition of the experiment. Then, since byhypothesis the data F
iwere true if incomplete, we will conclude that the physical mechanism
of the experiment must contain some additional constraint which was not taken into accountin the maximum entropy calculation. The observed deviations then provide a clue as to thenature of this new constraint. In this way, Mr Acan discover empirically that his information
was incomplete.
In summary, the principle of maximum entropy is not an oracle telling which predictions
must be right; it is a rule for inductive reasoning that tells us which predictions are most
strongly indicated by our present information .
11.9 Comments
The little scenario just described in Section 11.8 is an accurate model of just what did happen
in one of the most important applications of statistical analysis, carried out by J. WillardGibbs. By the year 1901 it was known that, in classical statistical mechanics, use of thecanonical ensemble (which Gibbs derived as the maximum entropy distribution over the

<<<PAGE 403>>>

11 Discrete prior probabilities: the entropy principle 371
classical state space, or phase volume, based on a speciﬁed mean value of the energy) failed
to predict some thermodynamic properties (heat capacities, equation of state) correctly.Analysis of the data showed that the entropy of a real physical system was always less thanthe value predicted. At that time, therefore, Gibbs was in just the position of Mr Ain the
scenario, and the conclusion was that the microscopic laws of physics must involve someadditional constraint not contained in the laws of classical mechanics.
But Gibbs died in 1903, and it was left to others to ﬁnd the nature of this constraint; ﬁrst
by Planck, in the case of radiation, then by Einstein and Debye for solids, and ﬁnally by Bohrfor isolated atoms. The constraint consisted in the discreteness of the possible energy values,thenceforth called energy levels. By 1927, the mathematical theory by which these couldbe calculated from ﬁrst principles had been developed by Heisenberg and Schr¨ odinger.
Thus, it is an historical fact that the ﬁrst clues indicating the need for the quantum theory,
and indicating some necessary features of the new theory, were uncovered by a seemingly‘unsuccessful’ application of the principle of maximum entropy. We may expect that suchthings will happen again in the future, and this is the basis of the remark that the principleof maximum entropy is most useful to us in just those cases where it fails to predict thecorrect experimental facts. This illustrates the real nature, function, and value of inductivereasoning in science; an observation that was stressed also by Jeffreys (see 1957 edition ofJeffreys, 1931).
Gibbs (1902) wrote his probability density in phase space in the form
w(q
1,..., qn;p1,..., pn)=exp/braceleftbig
η(q1,..., qn)/bracerightbig
(11.101)
and called the function ηthe ‘index of probability of phase’. He derived his canonical and
grand canonical ensembles from constraints on average energy, and average energy andparticle numbers, respectively, as (Gibbs, 1902, p. 143) ‘the distribution in phase whichwithout violating this condition gives the least value of the average index of probabilityof phase
η...’. This is, of course, just what we would describe today as maximizing the
entropy subject to constraints.
Unfortunately, Gibbs’ work was left unﬁnished due to failing health. He did not give
any clear explanation, and we can only conjecture whether he possessed one, as to whythis particular function is to be maximized in preference to all others. Consequently, hisprocedure appeared arbitrary to many, and for 60 years there was confusion and contro versy
over the justiﬁcation for Gibbs’ methods; they were rejected summarily by some writers onstatistical mechanics, and treated with the greatest caution by others. Only with the work
of Shannon (1948) could one see the way to new thinking on a fundamental level. Thesehistorical matters are discussed in more detail in Jaynes (1967) and Jaynes (1992b).

<<<PAGE 404>>>

12
Ignorance priors and transformation groups
Ignorance is preferable to error and he is less remote from the truth who
believes nothing than he who believes what is wrong.
Thomas Jefferson (1781)
The problem of translating prior information uniquely into a prior probability assignment
represents the as yet unﬁnished half of probability theory, though the principle of maximumentropy in the preceding chapter provides one important tool. It is unﬁnished because ithas been rejected for many decades by those who were unable to conceive of a probability
distribution as representing information; but, just because of that long neglect, many currentscientiﬁc, engineering, economic, and environmental problems are today calling out for newsolutions to this problem, without which important new applications cannot proceed.
12.1 What are we trying to do?
It is curious that, even when different workers are in substantially complete agreement on
what calculations should be done, they may have radically different views as to what we areactually doing and why we are doing it. For example, there is a large Bayesian community,whose members call themselves ‘subjective Bayesians’, who have settled into a positionintermediate between ‘orthodox’ statistics and the theory expounded here. Their membershave had, for the most part, standard orthodox training; but then they saw the absurditiesin it and defected from the orthodox philosophy, while retaining the habits of orthodoxterminology and notation.
These habits of expression put subjective Bayesians under a severe handicap. While
perceiving that probabilities cannot represent only frequencies, they still regard samplingprobabilities as representing frequencies of ‘random variables’. But for them prior and pos-terior probabilities represent only private opinions, which are to be updated, in accordancewith de Finetti’s principle of coherence. Fortunately, this leads to the Bayesian algorithm,so we do the same calculations.
Subjective Bayesians face an awkward ambiguity at the beginning of a problem, when one
assigns prior probabilities. If these represent merely prior opinions, then they are basicallyarbitrary and undeﬁned; it seems that only private introspection could assign them, and
372

<<<PAGE 405>>>

12 Ignorance priors and transformation groups 373
different people will make different assignments. Yet most subjective Bayesians continue
to use a language which implies that there exists some unknown ‘true’ prior probabilitydistribution in a real problem. In our view, problems of inference are ill-posed until werecognize three essential things.
(A) The prior probabilities represent our prior information , and are to be determined, not by intro-
spection, but by logical analysis of that information.
(B) Since the ﬁnal conclusions depend necessarily on both the prior information and the data, it
follows that, in formulating a problem, one must specify the prior information to be used just asfully as one speciﬁes the data.
(C) Our goal is that inferences are to be completely ‘objective’ in the sense that two persons with the
same prior information must assign the same prior probabilities.
If one fails to specify the prior information, a problem of inference is just as ill-posed as if one
had failed to specify the data. Indeed, since the time of Laplace, applications of probability
theory have been hampered by difﬁculties in the treatment of prior information. In realisticproblems of inference, it is typical that we have cogent prior information, highly relevant
to the question being asked; to fail to take it into account is to commit the most obvious
inconsistency of reasoning, and it may lead to absurd or dangerously misleading results.
Having speciﬁed the prior information, we then have the problem of translating that
information into a speciﬁc prior probability assignment. It is this formal translation processthat represents fully half of probability theory, as it is needed for real applications; yet it isentirely absent from orthodox statistics, and only dimly perceived in subjective Bayesiantheory.
Just as zero is the natural starting point in adding a column of numbers, the natural start-
ing point in translating a number of pieces of prior information is the state of completeignorance. In the previous chapter we have seen that for discrete probabilities the principleof maximum entropy tells us, in agreement with our obvious intuition, that complete igno-rance, but for speciﬁcation of a ﬁnite set of possibilities, is represented by a uniform priorprobability assignment. For continuous probabilities the problem is much more difﬁcult, be-cause intuition fails us and we must resort to formal desiderata and principles. In this chapterwe examine the use of the mathematical tool of transformation groups for this purpose.
Some object to the very attempt to represent complete ignorance, on the grounds that a
state of complete ignorance does not ‘exist’. We would reply that a perfect triangle does notexist either; nevertheless, a surveyor who was ignorant of the properties of perfect triangleswould not be competent to do his job. Complete ignorance is, for us, an ideal limitingcase of real prior information, in exactly the same sense that a perfect triangle is an ideallimiting case of the real triangles made by surveyors. If we have not learned how to dealwith complete ignorance, we are hardly in a position to solve a real problem.
The relatively simple problems examined up till now could be dealt with by reasonable
common sense, which could see, nearly always, what the prior ought to be. When we advanceto more complicated problems, a formal theory of how to ﬁnd ignorance priors becomes moreand more necessary. The principle of maximum entropy sufﬁces in many cases, but other

<<<PAGE 406>>>

374 Part 2 Advanced applications
principles such as transformation groups, marginalization theory, and coding theory, should
also be available in our toolbox. In this chapter we develop the method of transformationgroups. Before beginning that development, we ﬁrst, as a way of introduction, discuss theprinciple of maximum entropy for continuous distributions, and show how this naturallyleads to the idea of assigning distributions to represent complete ignorance.
12.2 Ignorance priors
Thus far we have considered the principle of maximum entropy only for the, discrete case
and have seen that, if the distribution sought can be regarded as having been producedby a random experiment, there is a correspondence property between probability and fre-quency, and the results are consistent with other principles of probability theory. However,nothing in the mathematics requires that any random experiment be in fact performed orconceivable; and so we interpret the principle in the broadest sense which gives it the
widest range of applicability, i.e. whether or not any random experiment is involved, the
maximum entropy distribution still represents the most ‘honest’ description of our state ofknowledge.
In such applications, the principle is easy to apply and leads to the kind of results we
should want and expect. For example, in Jaynes (1963a) a sequence of problems aboutdecision making under uncertainty (essentially, of inventory control), of a type which arisesconstantly in practice, was analyzed. Here, the state of nature was not the result of anyrandom experiment; there was no sampling distribution and no sample. Thus it might bethought to be a ‘no data’ decision problem, in the sense of Chernoff and Moses (1959).However, in successive stages of the sequence, there were available more and more piecesof prior information, and digesting them by maximum entropy led to a sequence of priordistributions in which the range of possibilities was successively narrowed down. They ledto a sequence of decisions, each representing the rational one on the basis of the informationavailable at that stage, which corresponds to intuitive common-sense judgments in the earlystages where intuition was able to see the answer. It is difﬁcult to see how this problemcould have been treated at all without the use of the principle of maximum entropy, or someother device that turns out in the end to be equivalent to it.
In several years of routine application of this principle in problems of physics and en-
gineering, we have yet to ﬁnd a case involving a discrete prior where it fails to producea useful and intuitively reasonable result. To the best of the author’s knowledge, no othergeneral method for setting up discrete priors has been proposed. It appears, then, that theprinciple of maximum entropy may prove to be the ﬁnal solution to the problem of assigningdiscrete priors.
12.3 Continuous distributions
Use of the principle of maximum entropy in setting up continuous prior distributions,
however, requires considerably more analysis because at ﬁrst glance the results appear to

<<<PAGE 407>>>

12 Ignorance priors and transformation groups 375
depend on the choice of parameters. We do not refer here to the well-known fact that the
quantity
H/prime=−/integraldisplay
dxp(x|I) log[ p(x|I)] (12.1)
lacks invariance under a change of variables x→y(x), for (12.1) is not the result of any
derivation, and it turns out not to be the correct information measure for a continuous dis-tribution. Shannon’s theorem establishing (11.23) as an information measure goes throughonly for discrete distributions; to ﬁnd the corresponding expression in the continuous casewe can pass to the limit from a discrete distribution. The following argument can be madeas rigorous as we please, but at considerable sacriﬁce of clarity.
In the discrete entropy expression
H
d
I=−n/summationdisplay
i=1pilog[pi], (12.2)
we suppose that the discrete points xi,i=1,2,..., n, become more and more numerous,
in such a way that, in the limit n→∞ ,
lim
n→∞1
n(number of points in a<x<b)=/integraldisplayb
adxm(x). (12.3)
If this passage to the limit is sufﬁciently well-behaved, it will also be true that adjacent
differences ( xi+1−xi) in the neighborhood of any particular value of xwill tend to zero
so that
lim
n→∞[n(xi+1−xi)]=[m(xi)]−1. (12.4)
The discrete probability distribution piwill go over into a continuous probability p(x|I),
according to the limiting form of
pi=p(xi|I)(xi+1−xi) (12.5)
or, from (12.4),
pi→p(xi|I)[nm(xi)]−1. (12.6)
Consequently, the discrete entropy (12.2) goes over into the integral
Hd
I→/integraldisplay
dxp(x|I) log/bracketleftbiggp(x|I)
nm(x)/bracketrightbigg
. (12.7)
In the limit, this contains an inﬁnite term log( n); if we subtract this, the difference will, in
the cases of interest, approach a deﬁnite limit, which we take as the continuous informationmeasure:
H
c
I≡lim
n→∞/bracketleftbig
Hd
I−log(n)/bracketrightbig
=−/integraldisplay
dxp(x|I) log/bracketleftbiggp(x|I)
m(x)/bracketrightbigg
. (12.8)
The ‘invariant measure’ function, m(x), is proportional to the limiting density of discrete
points. (In all applications so far studied, m(x) is a well-behaved continuous function, and

<<<PAGE 408>>>

376 Part 2 Advanced applications
so we continue to use the notion of Riemann integrals; we call m(x) a ‘measure’ only to
suggest the appropriate generalization, readily supplied if a practical problem should everrequire it.) Since p(x|I) and m(x) transform in the same way under a change of variables,
H
c
Iis invariant.
We seek a probability density p(x|I) which is normalized:
/integraldisplay
dxp(x|I)=1 (12.9)
(we understand the range of integration to be the full parameter space), and constrained by
information ﬁxing the mean values of mdifferent functions fk(x):
Fk=/integraldisplay
dxp(x|I)fk(x),k=1,2,..., m, (12.10)
where the Ffare the given numerical values. Subject to these constraints, we are to maximize
(12.8). The solution is again elementary:
p(x|I)=Z−1m(x)e x p{λ1f1(x)+···+ λmfm(x)}, (12.11)
with the partition function
Z(λ1,...,λ m)≡/integraldisplay
dxm(x)e x p{λ1f1(x)+···+ λmfm(x)}, (12.12)
and the Lagrange multipliers λkare determined by
Fk=−∂logZ(λ1,...,λ m)
∂λkk=1,..., m. (12.13)
Our ‘best’ estimate (by quadratic loss function) of any other quantity q(x) is then
/angbracketleftq/angbracketright=/integraldisplay
dxq(x)p(x|I). (12.14)
It is evident from these equations that when we use (12.8) rather than (12.1) as our infor-
mation measure not only our ﬁnal conclusions (12.14), but also the partition function andLagrange multipliers are all invariant under a change of parameter x→y(x). In applica-
tions, these quantities acquire deﬁnite physical meanings.
There remains, however, a practical difﬁculty. If the parameter space is not the result of
any obvious limiting process, what determines the proper measure m(x)? The conclusions,
evidently, will depend on which measure we adopt. This is the shortcoming from which themaximum entropy principle has suffered until now, and which must be cleared up beforewe can regard it as a full solution to the prior probability problem.
Let us note the intuitive meaning of this measure. Consider the one-dimensional case,
and suppose it is known that a<x<bbut we have no other prior information. Then there
are no Lagrange multipliers λ
k, and (12.11) reduces to
p(x|I)=/bracketleftbigg/integraldisplayb
adxm(x)/bracketrightbigg−1
m(x),a<x<b. (12.15)

<<<PAGE 409>>>

12 Ignorance priors and transformation groups 377
Except for a constant factor, the measure m(x) is also the prior distribution describing
‘complete ignorance’ of x. The ambiguity is, therefore, just the ancient one which has always
plagued Bayesian statistics: how do we ﬁnd the prior representing ‘complete ignorance’?Once this problem is solved, the maximum entropy principle will lead to a deﬁnite,parameter-independent method of setting up prior distributions based on any testable priorinformation. Since this problem has been the subject of so much discussion and controversyfor 200 years, we wish to state what appears to us a constructive attitude toward it.
To reject the question, as some have done, on the grounds that the state of complete
ignorance does not ‘exist’ would be just as absurd as to reject Euclidean geometry on thegrounds that a physical point does not exist. In the study of inductive inference, the notionof complete ignorance intrudes itself into the theory just as naturally and inevitably as theconcept of zero in arithmetic.
If one rejects the consideration of complete ignorance on the grounds that the notion is
vague and ill-deﬁned, the reply is that the notion cannot be evaded in any full theory ofinference. So if it is still ill-deﬁned, then a major and immediate objecti ve must be to ﬁnd
a precise deﬁnition which will agree with intuitive requirements and be of constructive usein a mathematical theory.
With this in mind, let us survey some previous thoughts on the problem. Bayes suggested,
in one particular case, that we express complete ignorance by assigning a uniform priorprobability density; the domain of useful applications of this rule is certainly not zero, forLaplace was led to some of the most important discoveries in celestial mechanics by usingit in analysis of astronomical data. However, Bayes’ rule has the obvious difﬁculty that it isnot invariant under a change of parameters, and there seems to be no criterion for telling us
which parameterization to use. (We note in passing that the notions of an unbiased estimator,
and efﬁcient estimator, and a shortest conﬁdence interval are all subject to just the sameambiguity with equally serious consequences, and so orthodox statistics cannot claim tohave solved this problem any better than Bayes did.)
Jeffreys (1931; 1939, 1957 edn) suggested that we assign a prior d σ/σ to a continuous
parameter σknown to be positive, on the grounds that we are then saying the same thing
whether we use the parameter σorσ
m. Such a desideratum is surely a step in the right
direction; however, it cannot be extended to more general parameter changes. We do notwant (and obviously cannot have) invariance of the form of the prior under all parameterchanges; what we want is invariance of content, but the rules of probability theory alreadydetermine how the prior must transform, under any parameter change, so as to achieve this.
The real problem, therefore, must be stated rather differently. We suggest that the proper
question to ask is: ‘For which choice of parameters does a given form, such as that of Bayesor Jeffreys, apply?’ Our parameter spaces seem to have a mollusk-like quality that preventsus from answering this, unless we can ﬁnd a new principle that gives them a property of‘rigidity’.
Stated in this way, we recognize that problems of just this type have already appeared and
have been solved in other branches of mathematics. In Riemannian geometry and generalrelativity theory, we allow arbitrary continuous coordinate transformations; yet the property

<<<PAGE 410>>>

378 Part 2 Advanced applications
of rigidity is maintained by the concept of the invariant line element, which enables us to
make statements of deﬁnite geometrical and physical meaning independently of the choiceof coordinates. In the theory of continuous groups, the group parameter space has justthis mollusk-like quality until the introduction of invariant group measure by Harr (1933),Pontryagin (1946), and Wigner (1959). We seek to do something very similar to this for theparameter spaces of statistics.
The idea of utilizing groups of transformations in problems related to this was discussed
by Poincar´ e (1912) and more recently by Hartigan (1964), Stone (1965) and Fraser (1966).
In the following sections we give four examples of a different group theoretical method ofreasoning developed largely by Wigner (1959) and Weyl (1961), which has met with greatsuccess in physical problems and seems uniquely adapted to our problem.
12.4 Transformation groups
The method of reasoning is best illustrated by some simple examples, the ﬁrst of which also
happens to be one of the most important in practice.
12.4.1 Location and scale parameters
We sample from a continuous two-parameter distribution
p(x|νσ)=φ(x,ν,σ )dx (12.16)
and consider problem A, as follows.
Problem A
Given a sample{x
1,..., xn}, estimate νandσ. The problem is indeterminate, both mathe-
matically and conceptually, until we introduce a deﬁnite prior distribution
p(νσ|I)dνdσ=f(ν,σ)dνdσ, (12.17)
but if we merely specify ‘complete initial ignorance’, this does not tell us which function
f(ν,σ) to use.
Suppose we carry out a change of variables to the new quantities {x/prime,ν/prime,σ/prime}according to
ν/prime=ν+b
σ/prime=aσ
x/prime−ν/prime=a(x−ν),(12.18)
where 0 <a<∞,−∞<b<∞. The distribution (12.16) expressed in the new
variables is
p(x/prime|ν/primeσ/prime)=ψ(x/prime,ν/prime,σ/prime)=φ(x,ν,σ )dx, (12.19)

<<<PAGE 411>>>

12 Ignorance priors and transformation groups 379
or, from (12.18),
ψ(x/prime,ν/prime,σ/prime)=a−1φ(x,ν,σ ). (12.20)
Likewise, the prior distribution is changed to g(ν/prime,σ/prime), where, from the Jacobian of the
transformation (12.18),
g(ν/prime,σ/prime)=a−1f(ν,σ). (12.21)
The above relations will hold whatever the distributions φ(x,ν,σ ),f(ν,σ).
Now suppose the distribution (12.16) is invariant under the group of transformations
(12.18), so that ψandφare the same function:
ψ(x,ν,σ )=φ(x,ν,σ ), (12.22)
whatever the values of a,b. The condition for this invariance is that φ(x,ν,σ ) must satisfy
the functional equation
φ(x,ν,σ )=aφ(ax−aν+ν+b,ν+b,aσ). (12.23)
Differentiating with respect to a,band solving the resulting differential equation, we ﬁnd
that the general solution of (12.23) is
φ(x,ν,σ )=1
σh/parenleftbiggx−ν
σ/parenrightbigg
, (12.24)
where h(q)i san arbitrary function. Thus, the usual de ﬁnition of a location parameter νand
a scale parameter σis equivalent to specifying that the distribution shall be invariant under
the group of transformations (12.18).
What do we mean by the statement that we are ‘completely ignorant’ of νandσexcept
for the knowledge that νis a location parameter and σis a scale parameter? To answer
this, we might reason as follows. If a change of scale can make the problem appear in anyway different to us, then we were notcompletely ignorant; we must have had some kind of
information about the absolute scale of the problem. Likewise, if a shift of location can makethe problem appear in any way different, then we must have had some prior informationabout location. In other words, ‘complete ignorance’ of a location and a scale parameter is
a state of knowledge such that a change of scale and shift of location does not change that
state of knowledge. We shall presently have to state this more carefully, but ﬁrst let us see
its consequences. Consider, therefore, problem B.
Problem B
Given a sample{x
/prime
1,..., x/prime
n}, estimate ν/primeandσ/prime. If we are ‘completely ignorant’ in the above
sense, then we must consider AandBas entirely equivalent problems; they have identical
sampling distributions, and our state of prior knowledge about ν/primeandσ/primein problem Bis
exactly the same as for νandσin problem A.
Our basic desideratum now acquires a nontrivial content; for we have formulated two
problems in which we have the same prior information. Consistency demands, therefore,

<<<PAGE 412>>>

380 Part 2 Advanced applications
that we assign the same prior probability distribution in them. Thus, fandgmust be the
same function:
f(ν,σ)=g(ν,σ) (12.25)
whatever the values of ( a,b). But the form of the prior distribution is now uniquely deter-
mined; for, combining (12.18), (12.21), and (12.25), we see that f(ν,σ) must satisfy the
functional equation
f(ν,σ)=af(ν+b,aσ), (12.26)
whose general solution is
f(ν,σ)=const.
σ(12.27)
which is the Jeffreys rule!
We must not jump to the conclusion that the prior (12.27) has been determined by the
form (12.24) of the population. Indeed, it would be very disconcerting if the form of the priorwere determined merely by the form of the population from which we are sampling; anyprinciple which led to such a result would be suspect. Examination of the above reasoningshows, however, that the result (12.27) was uniquely determined by the transformation
group (12.18), and not by the form of the distribution (12.24).
To illustrate this, note that there is more than one transformation group under which
(12.24) is invariant. In the transformations (12.18) we carry out a change of scale by afactor aand a translation b. Denoting this operation by the symbol ( a,b), we can carry out
the transformation ( a
1,b1), then ( a2,b2), and, from (12.18), obtain the composition law of
group elements:
(a2,b2)(a1,b1)=(a2a1,b2+b1). (12.28)
Thus the group (12.18) is Abelian, the direct product of two one-parameter groups. It has
a faithful representation in terms of the matrices
/parenleftbigga 0
0e x p{b}/parenrightbigg
. (12.29)
Now consider the group of transformations in which we ﬁrst carry out a change of scale
aon the quantities, and follow this by a translation b. This group is given by
ν/prime=aν+b
σ/prime=aσ
x/prime=ax+b.(12.30)
These transformations have the composition law
(a2,b2)(a1,b2)=(a2a1,a2b1+b2), (12.31)

<<<PAGE 413>>>

12 Ignorance priors and transformation groups 381
and so the group (12.30) is non-Abelian; it has a faithful representation in terms of the
matrices
/parenleftbiggab
01/parenrightbigg
, (12.32)
which cannot be reduced to diagonal form. Therefore, (12.18) and (12.30) are entirely
different groups.
If we specify the transformation group (12.30) instead of (12.18), (12.21) and (12.23)
are modiﬁed to
g(ν/prime,σ/prime)=a−2f(ν,σ), (12.33)
and
φ(x,ν,σ )=aφ(ax+b,aν+b,aσ). (12.34)
But we ﬁnd that the general solution of (12.34) is also (12.24); and so both groups deﬁne
location and scale parameters equally well. However, their consequences for the prior aredifferent; for the functional equation (12.26) is modi ﬁed to
f(ν,σ)=a
2f(aν+b,aσ), (12.35)
whose general solution is
f(ν,σ)=const.
σ2. (12.36)
Thus, the state of knowledge which is invariant under the group (12.18) is notthe same as
that which is invariant under (12.30); and we see a new subtlety in the concept of ‘completeignorance’. In order to deﬁne it unambiguously, it is not enough to say merely, ‘A changeof scale and shift of location does not change that state of knowledge’. We must specifythe precise manner in which these operations are to be carried out; i.e. we must specify a
deﬁnite group of transformations.
We thus face the question: Which group, (12.18) or (12.30), really describes the prior
information? The difﬁculty with (12.30) lies in the equations x
/prime=ax+b,ν/prime=ax+b;
thus, the change of scale operation is to be carried out about two points denoted by x=0,
ν=0. But, if we are ‘completely ignorant’ about location, then the condition x=0 has no
particular meaning; what determines this ﬁxed point about which the change of scale is tobe carried out?
In every problem which I have been able to imagine, it is the group (12.18), and therefore
the Jeffreys prior probability rule, which seems appropriate. Here the change of scaleinvolves only the difference {x−ν}; thus it is carried out about a point which is itself
arbitrary, and so no ‘ﬁxed point’ is deﬁned by the group (12.18). However, it will beinteresting to see whether others can produce examples in which the point x=0 always
has a special meaning, justifying the stronger prior (12.36).
To summarize: if we merely specify ‘complete initial ignorance’, we cannot hope to
obtain any deﬁnite prior distribution, because such a statement is too vague to deﬁne any

<<<PAGE 414>>>

382 Part 2 Advanced applications
mathematically well-posed problem. We are deﬁning this state of knowledge far more
precisely if we can specify a set of operations which we recognize as transforming theproblem into an equivalent one. Having found such a set of operations, the basic desideratumof consistency then places nontrivial restrictions on the form of the prior.
12.4.2 A Poisson rate
As another example, not very different mathematically but differently verbalized, consider
a Poisson process. The probability that exactly nevents will occur in a time interval tis
p(n|λt)=exp/braceleftbigg
−(λt)
n
n!/bracerightbigg
, (12.37)
and by observing the number of events we wish to estimate the rate constant λ. We are
initially completely ignorant of λexcept for the knowledge that it is a rate constant of
physical dimensions (seconds)−1, i.e. we are completely ignorant of the absolute time scale
of the process.
Suppose, then, that two observers, Mr Xand Mr X/prime, whose watches run at different
rates such that their measurements of a giv en interval are related by t=qt/prime, conduct this
experiment. Since they are observing the same physical experiment, their rate constantsmust be related by λ
/primet/prime=λt,o rλ/prime=qλ. They assign prior distributions
p(dλ|X)=f(λ)dλ, (12.38)
p(dλ/prime|X/prime)=g(λ/prime)dλ/prime, (12.39)
and if these are mutually consistent (i.e. they have the same content), it must be that
f(λ)dλ=g(λ/prime)dλ/prime;o rf(λ)=qg(λ/prime). But Mr Xand Mr X/primeare both completely ignorant,
and they are in the same state of knowledge, and so fandgmust be the same function:
f(λ)=g(λ). Combining those relations gives the functional equation f(λ)=qf(qλ)o r
p(dλ|X)∼λ−1dλ. (12.40)
To use any other prior than this will have the consequence that a change in the time scale
will lead to a change in the form of the prior, which would imply a different state of priorknowledge; but if we are completely ignorant of the time scale, then all time scales shouldappear equivalent.
12.4.3 Unknown probability for success
As a third and less trivial example, where intuition did not anticipate the result, consider
Bernoulli trials with an unknown probability for success. Here the probability for success

<<<PAGE 415>>>

12 Ignorance priors and transformation groups 383
is itself the parameter θto be estimated. Given θ, the probability that we shall observe r
successes in ntrials is
p(r|nθ)=/parenleftbiggn
r/parenrightbigg
θr(1−θ)n−r, (12.41)
and again the question is: What prior distribution f(θ)dθdescribes ‘complete initial
ignorance’ of θ?
In discussing this problem, Laplace followed the example of Bayes and answered the
question with the famous sentence: ‘When the probability for a simple event is unknown,we may suppose all values between zero and one as equally likely.’ In other words, Bayesand Laplace used the uniform prior f
B(θ)=1. However, Jeffreys (1939) and Carnap (1952)
have noted that the resulting rule of succession does not seem to correspond well with theinductive reasoning which we all carry out intuitively. Jeffreys suggested that f(θ) ought
to give greater weight to the end-points θ=(0,1) if the theory is to account for the kind of
inferences made by a scientist.
For example, in a chemical laboratory we ﬁnd a jar containing an unknown and unlabeled
compound. We are at ﬁrst completely ignorant as to whether a small sample of this compoundwill dissolve in water or not. But, having observed that one small sample does dissolve,we infer immediately that all samples of this compound are water soluble, and althoughthis conclusion does not carry quite the force of deductive proof, we feel strongly that theinference was justiﬁed. Yet the Bayes–Laplace rule leads to a negligibly small probabilityfor this being true, and yields only a probability of 2/3 that the next sample tested willdissolve.
Now let us examine this problem from the standpoint of transformation groups. There
is a conceptual difﬁculty here, since f(θ)dθis a ‘probability for a probability’. However,
it can be removed by carrying the notion of a split personality to extremes; instead ofsupposing that f(θ) describes the state of knowledge of any one person, imagine that we
have a large population of individuals who hold varying beliefs about the probability forsuccess, and that f(θ) describes the distribution of their beliefs. Is it possible that, although
each individual holds a deﬁnite opinion, the population as a whole is completely ignorantofθ? What distribution f(θ) describes a population in a state of total confusion on the
issue?
Since we are concerned with a consistent extension of probability theory, we must suppose
that each individual reasons according to the mathematical rules (Bayes’ theorem, etc.) ofprobability theory. The reason they hold different beliefs is, therefore, that they have beengiven different and conﬂicting information; one man has read the editorials of the St Louis
Post-Dispatch , another the Los Angeles Times , one has read the Daily Worker , another the
National Review , etc., and nothing in probability theory tells one to doubt the truth of what
he has been told in the statement of the problem.
Now suppose that, before the experiment is performed, one more deﬁnite piece of ev-
idence Eis given simultaneously to all of them. Each individual will change his state of

<<<PAGE 416>>>

384 Part 2 Advanced applications
belief according to Bayes’ theorem; Mr X, who had previously held the probability for
success to be
θ=p(S|X), (12.42)
will change it to
θ/prime=p(S|EX)=p(S|X)p(E|SX)
p(E|SX)p(S|X)+p(E|FX)p(F|X), (12.43)
where p(F|X)=1−p(S|X) is his prior belief in probability for failure. This new evidence
thus generates a mapping of the parameter space 0 ≤θ≤1 onto itself, given from (12.43)
by
θ/prime=aθ
1−θ+aθ, (12.44)
where
a=p(E|SX)
p(E|FX). (12.45)
If the population as a whole can learn nothing from this new evidence, then it would
seem reasonable to say that the population has been reduced, by conﬂicting propaganda, toa state of total confusion on the issue. We therefore deﬁne the state of ‘total confusion’ or‘complete ignorance’ by the condition that, after the transformation (12.44), the number ofindividuals who hold beliefs in any given range θ
1<θ<θ 2is the same as before.
The mathematical problem is again straightforward. The original distribution for beliefs
f(θ) is shifted by the transformation (12.44) to a new distribution g(θ/prime) with
f(θ)dθ=g(θ/prime)dθ/prime, (12.46)
and if the population as a whole learned nothing, then fandgmust be the same function:
f(θ)=g(θ). (12.47)
Combining (12.44), (12.46), and (12.47), we ﬁnd that f(θ) must satisfy the functional
equation
af/parenleftbiggaθ
1−θ−aθ/parenrightbigg
=(1−θ+aθ)2f(θ). (12.48)
This may be solved directly by eliminating abetween (12.44) and (12.48) or, in the more
usual manner, by differentiating with respect to aand setting a=1. This leads to the
differential equation
θ(1−θ)f/prime(θ)=(2θ−1)f(θ), (12.49)
whose solution is
f(θ)=const.
θ(1−θ), (12.50)

<<<PAGE 417>>>

12 Ignorance priors and transformation groups 385
which has the qualitative property anticipated by Jeffreys. Now that the imaginary popula-
tion of individuals has served its purpose of revealing the transformation group (12.44)of the problem, let them coalesce again into a single mind (that of a statistician whowishes to estimate θ), and let us examine the consequences of using (12.50) as our prior
distribution.
If we had observed rsuccesses in ntrials, then from (12.41) and (12.50) the posterior
distribution for θis (provided that r≥1,n−r≥1)
p(dθ|rn)=(n−1)!
(r−1)!(n−r−1)!θr−1(1−θ)n−r−1dθ. (12.51)
This distribution has expectation value and variance
/angbracketleftθ/angbracketright=r
n=f, (12.52)
σ2=f(1−f)
n+1. (12.53)
Thus the ‘best’ estimate of the probability of success, by the criterion of quadratic loss
function, is just equal to the observed frequency of success f; and this is also equal to the
probability for success at the next trial, in agreement with the intuition of everybody whohas studied Bernoulli trials. On the other hand, the Bayes–Laplace uniform prior wouldlead instead to the mean value /angbracketleftθ/angbracketright
B=(r+1)/(n+2) of the rule of succession, which has
always seemed a bit peculiar.
For interval estimation, numerical analysis shows that the conclusions drawn from (12.51)
are, for all practical purposes, the same as those based on conﬁdence intervals (i.e. the short-est 90% conﬁdence interval for θis nearly equal to the shortest 90% posterior probability
interval determined from (12.51)). If r/greatermuch1 and ( n−r)/greatermuch1, the normal approximation
to (12.51) will be valid, and the 100 P% posterior probability interval is simply ( f±qσ),
where qis the (1+P)/2 percentile of the normal distribution; for the 90%, 95%, and
99% levels, q=1.645, 1.960, and 2.576, respectively. Under conditions where this normal
approximation is valid, the difference between this result and the exact conﬁdence intervalis generally less than the difference between various published conﬁdence interval tables,which have been calculated from different approximation schemes.
Ifr=(n−r)=1, (12.51) reduces to p(dθ|r,n)=dθ, the uniform distribution which
Bayes and Laplace took as their prior. Therefore, we can now interpret the Bayes–Laplaceprior as describing not a state of complete ignorance, but the state of knowledge in whichwe have observed one success and one failure. It thus appears that the Bayes–Laplacechoice will be the appropriate prior if the prior information assures us that it is physicallypossible for the experiment to yield either a success or a failure, while the distribution forcomplete ignorance (12.50) describes a ‘pre-prior’ state of knowledge in which we are not
even sure of that.
Ifr=0, or r=n, the derivation of (12.51) breaks down and the posterior distribution
remains unnormalizable, proportional to θ
−1(1−θ)n−1orθn−1(1−θ)−1, respectively. The

<<<PAGE 418>>>

386 Part 2 Advanced applications
weight is concentrated overwhelmingly on the value θ=0o rθ=1. The prior (12.50) thus
accounts for the kind of inductive inference noted in the case of chemicals, which we allmake intuitively. However, once we have seen at least one success and one failure, thenwe know that the experiment is a true binary one, in the sense of physical possibility, andfrom that point on all posterior distributions (12.51) remain normalized, permitting deﬁniteinferences about θ.
The transformation group method therefore yields a prior which appears to meet the
common objections raised against the Laplace rule of succession; but we also see thatwhether (12.50) or the Bayes–Laplace prior is appropriate depends on the exact priorinformation available.
12.4.4 Bertrand’s problem
Finally, we give an example where transformation groups may be used to ﬁnd more informa-
tive priors. Bertrand’s problem (Bertrand, 1889) was stated originally in terms of drawinga straight line ‘at random’ intersecting a circle. It will be helpful to think of this in a moreconcrete way; presumably, we do no violence to the problem (i.e. it is still just as ‘random’)if we suppose that we are tossing straws onto the circle, without specifying how they aretossed. We therefore formulate the problem as follows.
A long straw is tossed at random onto a circle; given that it falls so that it intersects
the circle, what is the probability that the chord thus deﬁned is longer than a side of theinscribed equilateral triangle? Since Bertrand proposed it in 1889, this problem has beencited to generations of students to demonstrate that Laplace’s ‘principle of indifference’contains logical inconsistencies. For there appear to be many ways of deﬁning ‘equallypossible’ situations, and they lead to different results. Three of these are: assign uniformprobability density to (A) the linear distance between centers of chord and circle, (B) anglesof intersections of the chord on the circumference, (C) the center of the chord over theinterior area of the circle. These assignments lead to the results p
A=1/2,pB=1/3, and
pC=1/4, respectively.
Which solution is correct? Of the ten authors cited (Bertrand 1889; Borel 1909; Poincar´ e
1912; Uspensky 1937; Northrop 1944; von Mises 1957; Gnedenko 1962; Kendell and Moran1963; Mosteller 1965), only Borel is willing to express a de ﬁnite preference, although he
does not support it by any proof. V on Mises takes the opposite extreme, declaring thatsuch problems (including the similar Buffon needle problem) do not belong to the ﬁeld ofprobability theory at all. The others, including Bertrand, take the intermediate position ofsaying simply that the problem has no deﬁnite solution because it is ill-posed, the phrase‘at random’ being undeﬁned.
In works on probability theory, this state of affairs has been interpreted, almost universally,
as showing that the principle of indifference must be totally rejected. Usually, there is thefurther conclusion that the only valid basis for assigning probabilities is frequency in somerandom experiment. It would appear, then, that the only way of answering Bertrand’squestion is to perform the experiment.

<<<PAGE 419>>>

12 Ignorance priors and transformation groups 387
But do we really believe that it is beyond our power to predict by ‘pure thought’ the
result of such a simple experiment? The point at issue is far more important than merelyresolving a geometric puzzle; for, as discussed further in the conclusion of this chapter,applications of probability theory to physical experiments usually lead to problems of justthis type; i.e. they appear at ﬁrst to be undetermined, allowing many different solutions withnothing to choose among them. For example, given the average particle density and totalenergy of a gas, predict its viscosity. The answer, evidently, depends on the exact spatial andvelocity distributions of the molecules (in fact, it depends critically on position–velocitycorrelations), and nothing in the given data seems to tell us which distribution to assume.Yet physicists have made deﬁnite choices, guided by the principle of indifference, and
they have led us to correct and nontrivial predictions of viscosity and many other physical
phenomena.
Thus, while in some problems the principle of indifference has led us to paradoxes, in
others it has produced some of the most important and successful applications of probabilitytheory. To reject the principle without having anything better to put in its place would lead toconsequences so unacceptable that for many years even those who profess the most faithfuladherence to the strict frequency deﬁnition of probability have managed to overlook theselogical difﬁculties in order to preserve some very useful solutions.
Evidently, we ought to examine the apparent paradoxes such as Bertrand’s more closely;
there is an important point to be learned about the application of probability theory to realphysical situations.
It is evident that if the circle becomes sufﬁciently large, and the tosser sufﬁciently skilled,
various results could be obtained at will. However, in the limit where the skill of the tosser
must be described by a ‘region of uncertainty’ large compared with the circle, the distribution
for chord lengths must surely go into one unique function obtainable by ‘pure thought’. Aviewpoint toward probability theory which cannot show us how to calculate this functionfrom ﬁrst principles, or even denies the possibility of doing this, would imply severe – and,to a physicist, intolerable – restrictions on the range of useful applications of probabilitytheory.
An invariance argument was applied to problems of this type by Poincar´ e (1912), and
cited more recently by Kendall and Moran (1963). In this treatment we consider straightlines drawn ‘at random’ in the xyplane. Each line is located by specifying two parameters
(u,v) such that the equation of the line is ux+vy=1, and one can ask: Which probability
density p(u,v)dudvhas the property that it is invariant in form under the group of Euclidean
transformations (rotations and translations) of the plane? This is a readily solvable problem(Kendall and Moran 1963), with the answer p(u,v)=(u
2+v2)−3/2.
Yet evidently this has not seemed convincing; for later authors have ignored Poincar ´e’s
invariance argument, and have adhered to Bertrand’s original judgment that the problemhas no deﬁnite solution. This is understandable, for the statement of the problem does notspecify that the distribution for straight lines is to have this invariance property, and we donot see any compelling reason to expect that a rain of straws produced in a real experimentwould have it. To assume this would seem to be an intuitive judgment resting on no stronger

<<<PAGE 420>>>

388 Part 2 Advanced applications
grounds than the ones which led to the three different solutions above. All of this amounts
to trying to guess what properties a ‘random’ rain of straws should have, by specifying theintuitively ‘equally possible’ events; and the fact remains that different intuitive judgmentslead to different results.
The viewpoint just expressed, which is by far the most common in the literature, clearly
represents one valid way of interpreting the problem. If we can ﬁnd another viewpointaccording to which such problems dohave deﬁnite solutions, and deﬁne the conditions
under which these solutions are experimentally veriﬁable, then, while it would perhaps be
overstating the case to say that this new viewpoint is more ‘correct’ in principle than theconventional one, it will surely be more useful in practice.
We now suggest such a viewpoint, and we understand from the start that we are not
concerned at this stage with frequencies of various events. We ask rather: Which probability
distribution describes our state of knowledge when the only information available is that
given in the above statement of the problem? Such a distribution must conform to thedesideratum of consistency formulated in Chapter 1: in two problems where we have the
same state of knowledge we must assign the same probabilities. The essential point is
this: if we start with the assumption that Bertrand’s problem has a deﬁnite solution in
spite of the many things left unspeciﬁed, then the statement of the problem automatically
implies certain invariance properties, which in no way depend on our intuitive judgments.After the solution is found, it may be used as a prior for Bayesian inference whetheror not it has any correspondence with frequencies; any frequency connections that mayemerge will be regarded as an additional bonus, which justify its use also for direct physicalprediction.
Bertrand’s problem has an obvious element of rotational symmetry, recognized in all
the proposed solutions; however, this symmetry is irrelevant to the distribution for chordlengths. There are two other ‘symmetries’ which are highly relevant: neither Bertrand’soriginal statement nor our restatement in terms of straws speciﬁed the exact size of thecircle, or its exact location. If, therefore, the problem is to have any deﬁnite solution at all,it must be ‘indifferent’ to these circumstances; i.e. it must be unchanged by a small changein the size or position of the circle. This seemingly trivial statement, as we will see, fullydetermines the solution.
It would be possible to consider all these invariance requirements simultaneously by
deﬁning a four-parameter transformation group, whereupon the complete solution wouldappear suddenly, as if by magic. However, it will be more instructive to analyze the effectsof these invariances separately, and see how each places its own restrictions on the form ofthe solution.
Rotational invariance
Let the circle have radius R. The position of the chord is determined by giving the polar
coordinates ( r,θ) of its center. We seek to answer a more detailed question than Bertrand’s:
What probability density f(r,θ)dA=f(r,θ)rdrdθshould we assign over the interior

<<<PAGE 421>>>

12 Ignorance priors and transformation groups 389
area of the circle? The dependence on θis actually irrelevant to Bertrand’s question, since
the distribution for chord lengths depends only on the radial distribution
g(r)=/integraldisplay2π
0dθf(r,θ). (12.54)
However, intuition suggests that f(r,θ) should be independent of θ, and the formal trans-
formation group argument deals with the rotational symmetry as follows.
The starting point is the observation that the statement of the problem does not specify
whether the observer is facing north or east; therefore, if there is a deﬁnite solution, itmust not depend on the direction of the observer’s line of sight. Suppose, therefore, thattwo different observers, Mr XandMrY, are watching this experiment. They view the
experiment from different directions, their lines of sight making an angle α. Each uses a
coordinate system oriented along his line of sight. Mr Xassigns the probability density
f(r,θ) in his coordinate system S; and Mr Yassigns g(r,θ) in his system S
α. Evidently, if
they are describing the same situation, then it must be true that
f(r,θ)=g(r,θ−α), (12.55)
which expresses a simple change of variables, transforming a ﬁxed distribution fto a
new coordinate system; this relation will hold whether or not the problem has rotationalsymmetry.
But now we recognize that, because of the rotational symmetry, the problem appears
exactly the same to Mr Xin his coordinate system as it does to Mr Yin his. Since they are
in the same state of knowledge, our desideratum of consistency demands that they assignthe same probability distribution; and so fandgmust be the same function:
f(r,θ)=g(r,θ). (12.56)
These relations must hold for all αin 0≤α≤2π; and so the only possibility is f(r,θ)=
f(r).
This formal argument may appear cumbersome when compared with our obvious ﬂash
of intuition; and of course it is, when applied to such a trivial problem. However, as Wigner(1931) and Weyl (1946) have shown in other physical problems, it is this cumbersomeargument that generalizes at once to nontrivial cases where our intuition fails us. It alwaysconsists of two steps: we ﬁrst ﬁnd a transformation equation like (12.55) which shows howtwo problems are related to each other, irrespective of symmetry; then a symmetry relationlike (12.56) which states that we have formulated two equivalent problems. Combining
them leads in most cases to a functional equation which imposes some restriction on theform of the distribution.

<<<PAGE 422>>>

390 Part 2 Advanced applications
Scale invariance
The problem is reduced, by rotational symmetry, to determining a function f(r), normalized
according to
/integraldisplay2π
0dθ/integraldisplayR
0rdrf(r)=1. (12.57)
Again, we consider two different problems; concentric with a circle of radius R, there is a
circle of radius aR,0<a≤1. Within the smaller circle there is a probability h(r)rdrdθ
which answers the question: given that a straw intersects the smaller circle, what is theprobability that the center of its chord lies in the area d A=rdrdθ?
Any straw that intersects the small circle will also deﬁne a chord on the larger one; and
so, within the small circle f(r) must be proportional to h(r). This proportionality is, of
course, given by the standard formula for a conditional probability, which in this case takesthe form
f(r)=2πh(r)/integraldisplay
αR
0rdrf(r)0 <a≤1,0≤r≤aR. (12.58)
This transformation equation will hold whether or not the problem has scale invariance.
But we now invoke scale invariance; to two different observers with different size eyeballs,
the problems of the large and small circles would appear exactly the same. If there is anyunique solution independent of the size of the circle, there must be another relationshipbetween f(r) and h(r), which expresses the fact that one problem is merely a scaled-down
version of the other. Two elements of area rdrdθand ( ar)d (ar)dθare related to the large
and small circles, respectively, in the same way; and so they must be assigned the sameprobabilities by the distributions f(r) and h(r), respectively:
h(ar)(ar)d (ar)dθ=f(r)rdrdθ, (12.59)
or
a
2h(ar)=f(r), (12.60)
which is the symmetry equation. Combining (12.58) and (12.60), we see that invariance
under change of scale requires that the probability density satisfy the functional equation
a2f(ar)=2πf(r)/integraldisplayaR
0uduf(u)0 <a≤1,0≤r≤R. (12.61)
Differentiating with respect to a, setting a=1, and solving the resulting differential equa-
tion, we ﬁnd that the most general solution of (12.61) satisfying the normalization condition(12.57) is
f(r)=qr
q−2
2πRq, (12.62)
where qis a constant in the range 0 <q<∞, not further determined by scale invariance.

<<<PAGE 423>>>

12 Ignorance priors and transformation groups 391
C
C/H11032S
r
r/H11032
bθ/H11032 θP/H11032P
Γ/H11032Γ
Fig. 12.1. A Straw Sintersects two slightly displaced circles CandC/prime.
We note that the proposed solution Bin the introduction has now been eliminated,
for it corresponds to the choice f(r)∼1//radicalbig
(R2−r2), which is not of the form (12.62).
This means that if the intersections of chords on the circumference were distributed inangle uniformly and independently on one circle, this would not be true for a smaller circleinscribed in it; i.e. the probability assignment of Bcould be true for, at most, only one size of
circle. However, solutions AandCare still compatible with scale invariance, corresponding
to the choices q=1 and q=2, respectively.
Translational invariance
We now investigate the consequences of the fact that a given straw Scan intersect two circles
C,C
/primeof the same radius R, but with a relative displacement b. Referring to Figure 12.1, the
midpoint of the chord with respect to circle Cis the point P, with coordinates ( r,θ); while the
same straw deﬁnes a midpoint of the chord with respect to C/primeat the point P/primewhose coordi-
nates are ( r/prime,θ/prime). From Figure 12.1 the coordinate transformation ( r,θ)→(r/prime,θ/prime) is given by
r/prime=|r−bcosθ|, (12.63)
θ/prime=/braceleftbiggθ r>bcosθ
θ+πr<bcosθ.(12.64)
AsPvaries over the region /Gamma1,P/primevaries over /Gamma1/prime, and vice versa; thus the straws deﬁne a
1:1 mapping of /Gamma1onto/Gamma1/prime.
Now we note the translational symmetry; since the statement of the problem gave no
information about the location of the circle, the problems of CandC/primeappear exactly the
same to two slightly displaced observers OandO/prime. Our desideratum of consistency then
demands that they assign probability densities in CandC/prime, respectively, which have the
same form (12.62) with the same value of q.

<<<PAGE 424>>>

392 Part 2 Advanced applications
It is further necessary that these two observers assign equal probabilities to the regions
/Gamma1and/Gamma1/prime, respectively, since (a) they are probabilities of the same event, and (b) the prob-
ability that a straw which intersects one circle will also intersect the other, thus setting upthis correspondence, is also the same in the two problems. Let us see whether these tworequirements are compatible.
The probability that a chord intersecting Cwill have its midpoint in /Gamma1is
/integraldisplay
/Gamma1rdrdθf(r)=q
2πRq/integraldisplay
/Gamma1drdθrq−1. (12.65)
The probability that a chord intersecting C/primewill have its midpoint in /Gamma1/primeis
q
2πRq/integraldisplay
/Gamma1/primedr/primedθ/prime(r/prime)q−1=q
2πRq/integraldisplay
/Gamma1drdθ|r−bcosθ|q−1, (12.66)
where we have transformed the integral back to the variables ( r,θ) by use of (12.63)
and (12.64), noting that the Jacobian is unity. Evidently, (12.65) and (12.66) will be
equal for arbitrary /Gamma1if and only if q=1; and so our distribution f(r) is now uniquely
determined.
The proposed solution Cin the introduction is thus eliminated for lack of translational
invariance; a rain of straws which had the property assumed with respect to one circle couldnot have the same property with respect to a slightly displaced one.
We have found that the invariance requirements determine the probability density
f(r,θ)=1
2πRr,0≤r≤R,0≤θ≤2π, (12.67)
corresponding to solution Ain the introduction. It is interesting that this has a singularity
at the center, the need for which can be understood as follows. The condition that themidpoint ( r,θ) falls within a small region /Delta1imposes restrictions on the possible directions
of the chord. But as /Delta1moves inward, as soon as it includes the center of the circle all
angles are suddenly allowed. Thus there is an inﬁnitely rapid change in the ‘manifold ofpossibilities’.
Further analysis (almost obvious from contemplation of Figure 12.1) shows that the re-
quirement of translational invariance is so stringent that it already determines the result(12.67) uniquely; thus the proposed solution Bis incompatible with either scale or transla-
tional invariance, and in order to ﬁnd (12.67) it was not really necessary to consider scaleinvariance. However, the solution (12.67) would in any event have to be tested for scaleinvariance, and if it failed to pass that test we would conclude that the problem as statedhasnosolution; i.e. although at ﬁrst glance it appears underdetermined, it would have to be
regarded, from the standpoint of transformation groups, as overdetermined. As luck wouldhave it, these requirements arecompatible; and so the problem has one unique solution.
The distribution for chord lengths follows at once from (12.67). A chord whose midpoint
is at ( r,θ) has a length L=2/radicalbig
(R2−r2). In terms of the reduced chord lengths, x≡L/2R,

<<<PAGE 425>>>

12 Ignorance priors and transformation groups 393
we obtain the universal distribution law
p(x)dx=xdx/radicalbig
(1−x2),0≤x≤1, (12.68)
in agreement with Borel’s conjecture (1909).
Frequency correspondence
From the manner of its derivation, the distribution (12.68) would appear to have only a
subjective meaning; while it describes the only possible state of knowledge correspondingto a unique solution in view of the many things left unspeciﬁed in the statement of Bertrand’sproblem, we have as yet given no reason to suppose that it has any relation to frequenciesobserved in the actual experiment. In general, of course, no such claim can be made; themere fact that my state of knowledge gives me no reason to prefer one event over another is
not enough to make the events occur equally often! Indeed, it is clear that no ‘pure thought’
argument, whether based on transformation groups or any other principle, can predict withcertainty what must happen in a real experiment. And we can easily imagine a very precisemachine which tosses straws in such a way as to produce any distribution for chord lengthswe please on a given circle.
Nevertheless, we are entitled to claim a deﬁnite frequency correspondence for the result
(12.68). For there is one ‘objective fact’ which hasbeen proved by the above derivation:
anyrain of straws which does notproduce a frequency distribution agreeing with (12.68)
will necessarily produce different distributions on different circles.
This is all we need in order to predict with conﬁdence that the distribution (12.68) will
be observed in any experiment where the ‘region of uncertainty’ is large compared with the
circle. For, if we lack the skill to toss straws so that, with certainty, they intersect a givencircle, then surely we lack a fortiori the skill consistently to produce different distributions
on different circles within this region of uncertainty!
It is for this reason that distributions predicted by the method of transformation groups
turn out to have a frequency correspondence after all. Strictly speaking, this result holdsonly in the limiting case of ‘zero skill’, but, as a moment’s thought will show, the skillrequired to produce any appreciable deviation from (12.68) is so great that in practice itwould be difﬁcult to achieve even with a machine.
These conclusions seem to be in direct contradiction to those of von Mises (1957), who
denied that such problems belong to the ﬁeld of probability theory at all. It appears to us thatif we were to adopt von Mises’ philosophy of probability theory strictly and consistently,the range of legitimate physical applications of probability theory would be reduced almostto the vanishing point. Since we have made a deﬁnite, unequivocal prediction, this issue hasnow been removed from the realm of philosophy into that of veriﬁable fact. The predictivepower of the transformation group method can be put to the test quite easily in this andother problems by performing the experiments.
The Bertrand experiment has, in fact, been performed by the writer and Dr Charles
E. Tyler, tossing broom straws from a standing position onto a 5 inch diameter circle

<<<PAGE 426>>>

394 Part 2 Advanced applications
drawn on the ﬂoor. Grouping the range of chord lengths into ten categories, 128 successful
tosses conﬁrmed Eq. (12.68) with an embarrassingly low value of chi-squared. However,experimental results will no doubt be more convincing if reported by others.
12.5 Comments
Bertrand’s problem has a greater importance than appears at ﬁrst glance, because it is a
simple crystallization of a deeper paradox which has permeated much of probability theoryfrom its beginnings. In ‘real’ physical applications, when we try to formulate the problemof interest in probability terms, we ﬁnd almost always that a statement emerges which,like Bertrand’s, appears too vague to determine any deﬁnite solution, because apparentlyessential things are left unspeciﬁed.
We elaborate the example noted in the introduction of the preceding section. Given a gas
ofNmolecules in a volume V, with known intermolecular forces, total energy E, predict its
molecular velocity distribution, the pressure, distribution for pressure ﬂuctuations, viscosity,
thermal conductivity, and diffusion constant. Here again the viewpoint expressed by mostwriters on probability theory would lead one to conclude that the problem has no deﬁnitesolution because it is ill-posed; the things speciﬁed are grossly inadequate to determine anyunique probability distribution over microstates. If we reject the principle of indifference,and insist that the only valid basis for assigning probabilities is frequency in some randomexperiment, it would again appear that the only way of determining these quantities is to
perform the experiment.
It is, however, a matter of record that over a century ago, without beneﬁt of any frequency
data on positions and velocities of molecules, James Clark Maxwell was able to predict allthese quantities correctly by a ‘pure thought’ probability analysis, which amounted to rec-ognizing the ‘equally possible’ cases. In the case of viscosity, the predicted dependence ondensity appeared at ﬁrst to contradict common sense, casting doubt on Maxwell’s analysis.But when the experiments were performed they conﬁrmed Maxwell’s prediction, leading tothe ﬁrst great triumph of kinetic theory. These are solid, positive accomplishments; and theycannot be made to appear otherwise merely by deploring Maxwell’s use of the principle ofindifference.
Likewise, we calculate the probability for obtaining various hands at poker; and we are
so conﬁdent of the results that we are willing to risk money on bets which the calculationsindicate are favorable to us. But underlying these calculations is the intuitive judgment thatall distributions of cards are equally likely; and with a different judgment our calculationswould give different results. Once again we are predicting deﬁnite, veriﬁable facts by ‘purethought’ arguments based ultimately on recognizing the ‘equally possible’ cases; and yetpresent statistical doctrine, both orthodox and personalistic, denies that this is a valid basisfor assigning probabilities!
The dilemma is thus apparent. On the one hand, one cannot deny the force of arguments
which, by pointing to such things as Bertrand’s paradox, demonstrate the ambiguities and

<<<PAGE 427>>>

12 Ignorance priors and transformation groups 395
dangers in the principle of indifference. On the other hand, it is equally undeniable that use
of this principle has, over and over again, led to correct, nontrivial, and useful predictions.Thus it appears that, although we cannot wholly accept the principle of indifference, wecannot wholly reject it either; to do so would be to cast out some of the most important andsuccessful applications of probability theory.
The transformation group method grew out of the writer’s conviction that the principle
of indifference has been unjustly maligned in the past; what it has needed was not blanketcondemnation, but recognition of the proper way to apply it. We agree with most otherwriters on probability theory that it is dangerous to apply this principle at the level ofindifference between events, because our intuition is a very unreliable guide in such matters,
as Bertrand’s paradox illustrates.
The principle of indifference may, in our view, be applied legitimately at the more abstract
level of indifference between problems; because that is a matter that is deﬁnitely determined
by the statement of a problem, independently of our intuition. Every circumstance leftunspeciﬁed in the statement of a problem deﬁnes an invariance property which the solutionmust have if there is to be any deﬁnite solution at all. The transformation group, whichexpresses these invariances mathematically, imposes deﬁnite restrictions on the form of thesolution, and in many cases fully determines it.
Of course, not all invariances are useful. For example, the statement of Bertrand’s problem
does not specify the time of day at which the straws are tossed, the color of the circle, theluminosity of Betelgeuse, or the number of oysters in Chesapeake Bay; from which weinfer, correctly, that if the problem as stated is to have a unique solution, it must not dependon these circumstances. But this would not help us unless we had previously thought thatthese things might be germane.
Study of a number of cases makes it appear that the aforementioned dilemma can now
be resolved as follows. We suggest that the cases in which the principle of indifferencehas been applied successfully in the past are just the ones in which the solution can be‘reverbalized’ so that the actual calculations used are seen as an application of indifferencebetween problems, rather than events.
The transformation group derivation of the Jeffreys prior enables us to see that prior in a
new light. It has, perhaps, always been obvious that the real justiﬁcation of the Jeffreys rulecannot lie merely in the fact that the parameter is positive. As a simple example, supposethatµis known to be a location parameter; then both intuition and the preceding analysis
agree that a uniform prior density is the proper way to express complete ignorance of µ.
The relation µ=θ−θ
−1deﬁnes a 1:1 mapping of the region ( −∞<µ<∞) onto the
region (0 <θ<∞); but the Jeffreys rule cannot apply to the parameter θ, consistency
demanding that its prior density be taken proportional to d µ=(1+θ−2)dθ. It appears that
the fundamental justiﬁcation of the Jeffreys rule is not merely that a parameter is positive,but that it is a scale parameter.
The fact that the distributions representing complete ignorance found by transformation
groups cannot be normalized may be interpreted in two ways. One can say that it arisessimply from the fact that our formulation of the notion of complete ignorance was an

<<<PAGE 428>>>

396 Part 2 Advanced applications
idealization that does not strictly apply in any realistic problem. A shift of location from a
point in St Louis to a point in the Andromeda nebula, or a change of scale from the size ofan atom to the size of our galaxy, does not transform any problem of earthly concern into acompletely equivalent one. In practice we will always have some kind of prior knowledgeabout location and scale, and in consequence the group parameters ( a,b) cannot vary over
a truly inﬁnite range. Therefore, the transformations (12.50) do not, strictly speaking, forma group. However, over the range which does express our prior ignorance, the above kindof arguments still apply. Within this range, the functional equations and the resulting formof the priors must still hold.
Our discussion of maximum entropy has shown a more constructive way of looking at
this, however. Finding the distribution representing complete ignorance is only the ﬁrst stepin ﬁnding the prior for any realistic problem. The pre-prior distribution resulting from atransformation group does not strictly represent any realistic state of knowledge, but it doesdeﬁne the invariant measure for our parameter space, without which the problem of ﬁndinga realistic prior by maximum entropy is mathematically indeterminate.

<<<PAGE 429>>>

13
Decision theory, historical background
‘Your act was unwise,’ I exclaimed ‘as you see
by the outcome.’ He solemnly eyed me.
‘When choosing the course of my action,’ said he,‘I had not the outcome to guide me.’
Ambrose Bierce
In several previous discussions we inserted parenthetic remarks to the effect that ‘there
is still an essential point missing here, which will be supplied when we take up decisiontheory’. However, in postponing the topic until now, we have not deprived the reader of aneeded technical tool, because the solution of the decision problem was, from our viewpoint,so immediate and intuitive that we did not need to in voke any underlying formal theory.
13.1 Inference vs. decision
The situation of appraising inference vs. decision arose as soon as we started applying
probability theory to our ﬁrst problem. When we illustrated the use of Bayes’ theorem bysequential testing in Chapter 4, we noted that there is nothing in probability theory per se
which could tell us where to put the critical levels at which the robot changes its decision:whether to accept the batch, reject it, or make another test. The location of these critical levelsobviously depends in some way on value judgments as well as on probabilities; what are theconsequences of making wrong decisions, and what are the costs of making further tests?
The same situation occurred in Chapter 6 when the robot was faced with the job of
estimating a parameter. Probability theory determined only the robot’s state of knowledgeabout the parameter; it did not tell the robot what estimate it should in fact make. We notedat that time that taking the mean value over the posterior pdf was the same as making thatdecision which minimizes the expected square of the error; but we noted also that in somecases we should really prefer the median.
Qualitatively and intuitively, these considerations are clear enough; but before we can
claim to have a really complete design for our robot, we must clean up the logic of this, andshow that our procedures were not just intuitive ad hockeries , but were optimal by some
clearly deﬁned criterion. Wald’s decision theory aims to accomplish this.
397

<<<PAGE 430>>>

398 Part 2 Advanced applications
A common feature of all the problems considered thus far was: probability theory alone
can solve only the inference problem; i.e. it can give us only a probability distribution whichrepresents the robot’s ﬁnal state of knowledge with all the available prior information anddata taken into account. But in practice its job does not end at that point. An essential thing
which is still missing in our design of this robot is the rule by which it converts its ﬁnalprobability assignment into a deﬁnite course of action . But for us, formal decision theory
will only legitimize – not change – what our intuition has already told us to do.
Decision theory has for us a different kind of importance, in the light that it sheds on
the centuries-old controversies about the foundations of probability theory. Decision theorycan be derived equally well from either of two diametrically opposed views about whatprobability theory is, and it therefore forms a kind of bridge between them, and suggeststhat decision theory might help to resolve the controversy. We dwell here on the historicalbackground of and relationship between the two approaches to the decision problem.
13.2 Daniel Bernoulli’s suggestion
As one might expect from the way this situation appeared in the most elementary applications
of probability theory, the relationship between the two approaches to decision theory is by
no means a new problem. It was clearly recognized, and a deﬁnite solution offered for acertain class of problems, by Daniel Bernoulli (1738). In a crude form, the same principle
had been seen even earlier, at the time when probability theory was concerned almost
exclusively with problems of gambling. Although today it seems very hard to understand,the historical record shows clearly and repeatedly that the notion of ‘expectation of proﬁt’was very intuitive to the ﬁrst workers in probability theory; even more intuitive than that ofprobability.
Consider each possibility, i=1,2,...n, assign probabilities p
ito them, and also assign
numbers Miwhich represent the ‘proﬁt’ we would obtain if the ith possibility should in
fact turn out to be true. Then the expectation of proﬁt is, in either of our standard notations,
E(M)=/angbracketleftM/angbracketright=n/summationdisplay
i=1piMi. (13.1)
The prosperous merchants in 17th century Amsterdam bought and sold expectations as if
they were tangible goods. It seemed obvious to many that a person acting in pure self-interestshould always behave in such a way as to maximize his expected proﬁt. This, however,led to some paradoxes (particularly that of the famous St Petersbur g problem) which led
Bernoulli to recognize that simple expectation of proﬁt is not always a sensible criterion ofaction.
For example, suppose that your information leads you to assign probability 0.51 to heads
in a certain slightly biased coin. Now you are given the choice of two actions: (1) to betevery cent you have at even money, on heads for the next toss of this coin; (2) not to bet atall. According to the criterion of expectation of proﬁt, you should always choose to gamble

<<<PAGE 431>>>

13 Decision theory, historical background 399
when faced with this choice. Your expectation of proﬁt, if you do not gamble, is zero;
but if you do gamble, it is
/angbracketleftM/angbracketright=0.51M0+0.49 (−M0)=0.02M0>0, (13.2)
where M0is the amount you have now. Nevertheless it seemed obvious to Bernoulli, as it
doubtless does also to the reader, that nobody in his right mind would really choose theﬁrst alternative. This means that our common sense, in some cases, rejects the criterion ofmaximizing expected proﬁt.
Suppose that you are offered the following opportunity. You can bet any amount you
want on the basis that, with probability (1 −10
−6), you will lose your money; but with
probability 10−6, you will win 1 000 001 times the amount you had wagered. Again, the
criterion of maximizing expected proﬁt says that you should bet all the money you have.Common sense rejects this solution even more forcefully.
Daniel Bernoulli proposed to resolve these paradoxes by recognition that the true value
to a person, of receiving a certain amount of money, is not measured simply by the amountreceived; it depends also upon how much he has already. In other words, Bernoulli said thatwe should recognize that the mathematical expectation of proﬁt is not the same thing as its‘moral expectation’. A modern economist is expressing the same idea when he speaks ofthe ‘diminishing marginal utility of money’.
In the St Petersburg game we toss an honest coin until it comes up heads for the ﬁrst time.
The game is then terminated. If heads occurs for the ﬁrst time at the nth throw, the player
receives 2
ndollars. The question is: what is a ‘fair’ entrance fee for him to pay, for the priv-
ilege of playing this game? If we use the criterion that a fair game is one where the entrance
fee is equal to the expectation of proﬁt, you see what happens. The expectation is inﬁnite:
∞/summationdisplay
k=1(2−k)(2k)=∞/summationdisplay
k=11=∞. (13.3)
Nevertheless, it is clear again that no sane person would be willing to risk more than a very
small amount on this game. We quote Laplace (1814, 1819) at this point:
Indeed, it is apparent that one franc has much greater value for him who possesses only 100 than
for a millionaire. We ought then to distinguish the absolute value of the hoped-for beneﬁt from itsrelative value. The latter is determined by the motives which make it desirable, whereas the ﬁrst isindependent of them. The general principle for assigning this relative value cannot be given, but hereis one proposed by Daniel Bernoulli which will serve in many cases: The relative value of an inﬁnitelysmall sum is equal to its absolute value divided by the total fortune of the person interested.
In other words, Bernoulli proposed that the ‘moral value’, or what the modern economist
would call the ‘utility’ of an amount Mof money, should be taken proportional to log( M).
Laplace, in discussing the St Petersburg problem and this criterion, reports the followingresult without giving the calculation: a person whose total fortune is 200 francs ought notreasonably to stak e more than 9 francs on the play of this game. Let us, 180 years later,
check Laplace’s calculation.

<<<PAGE 432>>>

400 Part 2 Advanced applications
For a person whose initial ‘fortune’ is mfrancs, the fair fee f(m) is determined by
equating his present utility with his expected utility if he pays the fee and plays the game;i.e.f(m) is the root of
log(m)=∞/summationdisplay
n=11
2nlog(m−f+2n). (13.4)
Computer evaluation gives f(200)=8.7204; Laplace, without a computer, did his cal-
culation very well. Likewise, f(103)=10.95,f(104)=14.24,f(106)=20.87. Even a
millionaire should not risk more than 21 francs on this dubious game.
It seems to us that this kind of numerical result is entirely reasonable. However, the
logarithmic assignment of utility is not to be taken literally, either in the case of extremelysmall fortunes (as Laplace points out), or in the case of extremely large ones, as the followingexample of Savage (1954) shows.
Suppose your present fortune is $1 000 000; if your utility for money is proportional to
the logarithm of the amount, you should be as willing as not to accept a wager in which,with probability one-half, you’ll be left with only $1000, and with probability one-halfyou will be left with $1 000 000 000. Most of us would consider such a bet to be distinctlydisadvantageous to a person with that initial fortune. This shows that our intuitive ‘utility’for money must increase even less rapidly than the logarithm for extremely large values.Chernoff and Moses (1959) claim that it is bounded; this appears to us plausible theoretically,but not really demonstrated in the real world.
The gist of Daniel Bernoulli’s suggestion was therefore that, in the gambler’s problem
of decision making under uncertainty, one should act so as to maximize the expectedvalue, not necessarily of the proﬁt itself, but of some function of the proﬁt which he calledthe ‘moral value’. In more modern terminology, the optimist will call this ‘maximizingexpected utility’, while the pessimist will speak instead of ‘minimizing expected loss’, theloss function being taken as the negative of the utility function.
13.3 The rationale of insurance
Let us illustrate some of the above remarks brieﬂy with the example of insurance, which
is in some ways like the St Petersburg game. The following scenario is oversimpliﬁed inobvious ways; nevertheless, it makes some valid and important points. Insurance premiumsare always set high enough to guarantee the insurance company a positive expectation ofproﬁt over all the contingencies covered in the contract, and every dollar the company earnsisa dollar spent by a customer. Then why should anyone ever want to buy insurance?
The point is that the individual customer has a utility function for money that may
be strongly curved over ranges of $1000; but the insurance company is so much largerthat its utility for money is accurately linear over ranges of millions of dollars. Thus, let
Pbe the premium for some proposed insurance contract, let i=1,..., nenumerate the
contingencies covered, the ith having probability w
iand cost to the insurance company, if

<<<PAGE 433>>>

13 Decision theory, historical background 401
Table 13.1. Expanded utility.
Buy Don’t buy
Company P−/summationtextwiLi 0
Customer log( M−P)/summationtextwilog(M−Li)
it happens, of Li. Let the prospective customer have Daniel Bernoulli’s logarithmic utility
for money and an initial amount M. Of course, by Mwe should understand his so-called
‘net worth’, not merely the amount of cash he has on hand. Then the expected utility forthe insurance company and for the customer, if he does or does not buy the insurance, willbe as given in Table 13.1. So if /angbracketleftL/angbracketright<P, the company wants to sell the insurance, and if
/angbracketleftlog(M−L)/angbracketright<log(M−P) the customer wants to buy it. If the premium is in the range
/angbracketleftL/angbracketright<P<[M−exp/angbracketleftlog(M−L)/angbracketright], (13.5)
it will be advantageous for both to do business.
We leave it as an exercise for the reader to show from (13.5) that a poor man should buy
insurance, but a rich man should not unless his assessment of expected loss /angbracketleftL/angbracketrightis much
greater than the insurance company’s. Indeed, if your present fortune is much greater thanany likely loss, then your utility for money is nearly as linear as the insurance company’s,in the region where it matters; and you may as well be your own insurance company.
Further insight into the rich man’s psychology is had by noting that if M/greatermuch/angbracketleftL/angbracketrightwe may
expand in powers of M
−1;
M−exp/angbracketleftlog(M−L)/angbracketright=/angbracketleft L/angbracketright+var(L)
2M+···, (13.6)
where var( L)=/angbracketleftL2/angbracketright−/angbracketleft L/angbracketright2. Thus, a moderately rich man might be willing to buy insurance
even if the premium is slightly larger than his expected loss, because this removes theuncertainty var( L) about the actual loss which he would otherwise have to live with; we
have an aversion not only to risk, but to uncertainty about it.
Further insight into the poor man’s psychology is had by writing the right-hand side of
(13.5) as
M−exp/angbracketleftlog(M−L)/angbracketright=M−/productdisplay
iexp{wilog(M−Li)}. (13.7)
Let the Libe enumerated so that L1≥L2≥L3···, then this expression does not make
sense unless M>L1; but presumably it is not possible to have M<L1, for one cannot lose
more than he has. But if Mapproaches L1, the last term becomes singular [exp {−∞} ] and
drops out. Equation (13.5) then reduces to /angbracketleftL/angbracketright<P<M; it appears that this unfortunate
person should always buy insurance if he can, even if this leaves him as poor as if the worstpossible contingency had happened to him!

<<<PAGE 434>>>

402 Part 2 Advanced applications
Of course, this only illustrates that the logarithmic utility assignment is unrealistic for
very small amounts. In fact, the utility is clearly bounded in that region also; he whopossesses only one penny does not consider it a calamity to lose it. We may correct thisby replacing log( M) by log( M+b), where bis an amount so small that we consider it
practically worthless. This modiﬁes our conclusion from (13.7) in a way that we leave forthe reader to work out, and which may suggest a good choice for b.
13.4 Entropy and utility
The logarithmic assignment of utility is reasonable for many purposes, as long as it is not
pushed to extremes. It is also, incidentally, closely connected with the notion of entropy,
as shown by Bellman and Kalaba (1956, 1957). A gambler who receives partially reliableadvance tips on a game acts (i.e. decides on which side and how much to bet) so as to
maximize the expected logarithm of his fortune. Bellman and Kalaba show that (1) one cannever go broke following this strategy, in contrast to the strategy of maximizing expectedproﬁt, where it is easily seen that with probability one this will happen eventually (theclassical ‘gambler’s ruin’ situation), and (2) the amount one can reasonably expect towin on any one game is clearly proportional to the amount M
0he has to begin with, so,
after ngames, one could hope to have an amount M=M0exp{αn}. Evidently, to use
the logarithmic utility function means that one acts so as to maximize the expectationofα.
Exercise 13.1. Show that the maximum attainable /angbracketleftα/angbracketrightis just ( H0−H), where His
the entropy which describes the gambler’s uncertainty as to the truth of his tips, and
H0is the maximum possible entropy, if the tips were completely uninformative.
A similar result is derived below. This suggests that, with more development of the theory,entropy might have an important place in guiding the strategy of a businessman or stockmarket investor.
There is a more subtle use of these considerations; the possibility not only of max-
imizing our own utility, but of manipulating the utility considerations of others so asto induce them to behave as we wish. Competent administrators know, instinctively butqualitatively, how to offer rewards and punishments so as to keep their organizationsrunning smoothly and on course. A much oversimpliﬁed but quantitative example of thisfollows.
13.5 The honest weatherman
The weatherman’s prior information and data yield a probability p=P(rain|data,I) that it
will rain tomorrow. Then what probability qwill he announce publicly, in his evening TV

<<<PAGE 435>>>

13 Decision theory, historical background 403
forecast? This depends on his perceived utility function. We suspect that weather forecasters
systematically overstate the probability for bad weather, i.e. announce a value q>p, in the
belief that they will incur more criticism from failing to predict a storm that arrives thanfrom predicting one that fails to arrive.
1
Nevertheless, we would prefer to be told the value pactually indicated by all the data at
hand; indeed, if we were sure that we were being told this, we could not reasonably criticizethe weatherman for his failures. Is it possible to give the weatherman a utility environmentthat will induce him always to tell the truth?
Suppose we write the weatherman’s employment contract to stipulate that he will never
be ﬁred for making too many wrong predictions; but that, each day, when he announcesa probability qof rain, his pay for that day will be Blog(2 q) if it actually rains the next
day, and Blog(2[1−q]) if it does not, where Bis a base rate that does not matter for our
present considerations, as long as it is high enough to make him want the job. Then theweatherman’s expected pay for today, if he announces probability q,i s
B[plog(2 q)+(1−p) log(2[1−q])]=B[log(2)+plog(q)+(1−p) log(1−q)].
(13.8)
Taking the ﬁrst and second derivatives, we ﬁnd that this is a maximum when q=p.
Now any continuous utility function appears linear if we examine only a small segment
of it. Thus, if the weatherman considers a single day’s pay small enough so that his utilityfor it is linear in the amount, it will always be to his advantage to tell the truth. There existcombinations of rewards and utility functions for which, quite literally, honesty is the bestpolicy.
More generally, let there be npossible events ( A
1,..., An) for which the available prior
information and data indicate the probabilities ( p1,..., pn). But a predictor chooses to
announce instead the probabilities ( q1,..., qn). Let him be paid Blog(nqi) if the event Ai
subsequently occurs; he is rewarded for placing a high probability on the true event. Then
his expectation of pay is
B[log( n)−I(q;p)], (13.9)
where I(q;p)≡/summationtextpilog(qi) is essentially (to within an additive constant) the relative
entropy of the distributions (today commonly called the Kullback–Leibler information(Kullback and Leibler, 1951), although its fundamental properties were proved and exploitedalready by Gibbs (1902, Chap. 11)). Then it will be to the weatherman’s advantage toannounce always q
i=pi, and his maximum expectation of pay is
B[log( n)−H(p1,..., pn)], (13.10)
where H(pi)=−/summationtextpilog(pi) is the entropy that measures his uncertainty about the Ai.
It is not only to his advantage to tell the truth; it is to his advantage to acquire the maximumpossible amount of information so as to decrease that entropy.
1Evidence for this is seen in the fact that, in St Louis, we experience a predicted nonstorm almost every other week; but a
nonpredicted storm is so rare that it is a major news item.

<<<PAGE 436>>>

404 Part 2 Advanced applications
As a very real, concrete example, consider a drug company, which has only a ﬁnite amount
of research and development facilities. We have two potential new drugs: drug Aalleviates
a disorder that afﬂicts 106persons per year, while drug Bwould help only 1000 persons per
year. Supposing equally good preliminary evidence for the efﬁcacy and safety of the drugs,the company will naturally prefer to expend its development efforts on drug A; and for this
decision we can predict conﬁdently that it will come under attack from some misanthropewho charges it with being interested only in its own proﬁts. Yet had he thought it throughone more step, he might have perceived that this policy, while undeniably beneﬁtting thecompany, also beneﬁts a much larger proportion of society.
13.6 Reactions to Daniel Bernoulli and Laplace
The mathematically elementary – yet evidently important – nature of these results, might
make one think that such things must have been not only perceived by many, but put to gooduse immediately, as soon as Daniel Bernoulli and Laplace had started this train of thought.Indeed, it seems in retrospect surprising that the notion of entropy was not discovered inthis way, 100 years before Gibbs.
The actual course of history has been very different; for most of the 20th century the
‘frequentist’ school of thought either ignored the above line of reasoning or condemned it
as metaphysical nonsense. In one of the best known books on probability theory (Feller,1950, p. 199), Daniel Bernoulli’s resolution of the St Petersburg paradox is rejected without
even being described, except to assure the reader that he ‘tried in vain to solve it by the
concept of moral expectation’. Warren M. Hirsch, in a review of the book, ampliﬁed this asfollows:
Various mystifying ‘explanations’ of this paradox had been offered in the past, involving, for example,
the concept of moral expectation. These explanations are hardly understandable to the modern studentof probability. Feller gives a straightforward mathematical argument which leads to the determinationof ﬁnite entrance fee with which the St Petersburg game has all the properties of a fair game.
We have just seen how ‘vain’ and ‘hardly understandable’ Daniel Bernoulli’s efforts were.
Reading Feller, one ﬁnds that he ‘resolved’ the paradox merely by deﬁning and analyzinga different game. He undertakes to explain the rationale of insurance in the same way;
but, since he rejects Daniel Bernoulli’s concept of a curved utility function, he concludes
that insurance is always necessarily ‘unfair’ to the insured. These explanations are hardlyunderstandable to the modern economist.
In the 1930s and 1940s, a form of decision rules, as an adjunct to hypothesis testing, was
expounded by J. Neyman and E. S. Pearson. It enjoyed a period of popularity with electricalengineers (Middleton, 1960) and economists (Simon, 1977), but it is now obsolete becauseit lacks two fundamental features now recognized as essential to the problem. In Chapter 14we give a simple example of the Neyman–Pearson procedure, which shows how it is relatedto others. In 1950, Abraham Wald gave a formulation that operates at a more fundamental

<<<PAGE 437>>>

13 Decision theory, historical background 405
level which makes it appear likely to have a permanent validity, as far as it goes, and gives a
rather fundamental justiﬁcation to Daniel Bernoulli’s intuitive ideas. But these efforts werenot appreciated in all quarters. Maurice Kendall (1963) wrote:
There has been a strong movement in the USA to regard inference as a branch of decision theory.
Fisher would have maintained (and in my opinion rightly) that inference in science is not a matter ofdecision, and that, in any case, criteria for choice in decision based on pay-offs of one kind or anotherare not available. This, broadly speaking, is the English as against the American point of view ....I
propound the thesis that some such difference of attitude is inevitable between countries where whata man does is more important than what he thinks, and those where what he thinks is more importantthan what he does.
We need not rely on second-hand sources for Fisher’s attitude toward decision theory; as
noted in Chapter 16, he was never at a loss to express himself on anything. In discussingsigniﬁcance tests, he writes (Fisher, 1956, p. 77):
...recently ...a considerable body of doctrine has attempted to explain, or rather to reinterpret,
these tests on the basis of quite a different acceptance procedure. The differences between these twosituations seem to the author many and wide, and I do not think it would have been possible to overlookthem had the authors of this reinterpretation had any real familiarity with work in the natural sciences,or consciousness of those features of an observational record which permit of an improved scientiﬁcunderstanding.
Then he identiﬁes Neyman and Wald as the objects of his criticism.
Apparently, Kendall, appealing to motives usually disavowed by scholars, regarded de-
cision theory as a defect of the American, as opposed to the British, character (althoughneither Neyman nor Wald was born or educated in America – they ﬂed here from Europe).Fisher regarded it as an aberration of minds not versed in natural science (although theprocedures were due originally to Daniel Bernoulli and Laplace, whose stature as naturalscientists will easily bear comparison with Fisher’s).
We agree with Kendall that the approach of Wald does indeed give the impression
that inference is only a special case of decision; and we deplore this as much as he did.But we observe that in the original Bernoulli–Laplace formulation (and in ours), theclear distinction between these two functions is maintained, as it should be. But, whilewe perceive this necessary distinction between inference and decision, we perceive alsothat inference not followed by decision is largely idle, and no natural scientist worthyof the name would undertake the labor of conducting inference unless it served somepurpose.
These quotations give an idea of the obstacles which the perfectly natural, and immensely
useful, ideas of Daniel Bernoulli and Laplace had to overcome; 200 years later, anyonewho suggested such things was still coming under attack from the entrenched ‘orthodox’
statistical establishment – and in a way that reﬂected no credit on the attackers. Let us nowexamine Wald’s theory.

<<<PAGE 438>>>

406 Part 2 Advanced applications
13.7 Wald’s decision theory
Wald’s formulation, in its initial stages, had no apparent connection with probability theory.
We begin by imagining (i.e. enumerating) a set of possible ‘states of nature’, {θ1,θ2,...,θ N}
whose number is always, in practice, ﬁnite, although it might be a useful limiting approx-imation to think of them as inﬁnite or even as forming a continuum. In the quality control
example of Chapter 4, the ‘state of nature’ was the unknown number of defectives in thebatch.
There are certain illusions that tend to grow and propagate here. Let us dispel one by noting
that, in enumerating the different states of nature, we are not describing any real (veriﬁable)property of nature – for one and only one of them is in fact true. The enumeration is onlya means of describing a state of knowledge about the range of possibilities. Two persons,
or robots, with different prior information may enumerate the θ
jdifferently without either
being in error or inconsistent. One can only strive to do the best he can with the informationhe has, and we expect that the one with better information will naturally – and deservedly –make better decisions. This is not a paradox, but a platitude.
The next step in our theory is to make a similar enumeration of the decisions {D
1,
D2,..., Dk}that might be made. In the quality control example, there were three possible
decisions at each stage:
D1≡accept the batch,
D2≡reject the batch,
D3≡make another test.
In the particle counter problem of Mr Bin Chapter 6, where we were to estimate the number
n1of particles passing through the counter in the ﬁrst second, there were an inﬁnite number
of possible decisions:
Di≡n1is estimated as equal to 0, 1, 2, ....
If we are to estimate the source strength, there are so many possible estimates that we
thought of them as forming a continuum of possible decisions, even though in actual factwe can write down only a ﬁnite number of decimal digits.
This theory is clearly of no use unless by ‘making a decision’ we mean, ‘deciding to
act as if the decision were correct’. It is idle for the robot to ‘decide’ that n
1=150 is the
best estimate unless we are then prepared to act on the assumption that n1=150. Thus the
enumeration of theDithat we give the robot is a means of describing our knowledge as to
what kinds of actions are feasible ; it is idle and computationally wasteful to consider any
decision which we know in advance corresponds to an impossible course of action.
There is another reason why a particular decision might be eliminated; even though D1
is easy to carry out, we might know in advance that it would lead to intolerable conse-
quences. An automobile driver can make a sharp turn at any time; but his common senseusually tells him not to. Here we see two more points: (1) there is a continuous gradation –the consequences of an action might be serious without being absolutely intolerable, and

<<<PAGE 439>>>

13 Decision theory, historical background 407
(2) the consequences of an action will in general depend on what is the true state of nature –
a sudden sharp turn does not always lead to disaster, and it may actually avert disaster.
This suggests a third necessary concept – the loss function L(Di,θj), which is a set of
numbers representing our judgment as to the ‘loss’ incurred by making decision Diifθj
should turn out to be the true state of nature. If the Diandθjare both discrete, this is a loss
matrix Lij.
Quite a bit can be done with just the θj,Di,Lij,and there is a rather extensive literature
dealing with criteria for making decisions with no more than this. In the early days ofthis theory the results were summarized in a very readable and entertaining form by Luceand Raiffa (1989), and in the aforementioned elementary textbook of Chernoff and Moses(1959), which we recommend as still very much worth reading today. This culminated inthe more advanced work of Raiffa and Schlaifer (1961), which is still a standard referencework because of its great amount of useful mathematical material.
For a modern exposition with both the philosophy and the mathematics in more detail than
we give here, see James Berger (1985). This is written from a Bayesian viewpoint almostidentical to ours, and it takes up many technical circumstances important for inference butwhich are not, in our view, really part of decision theory.
The minimax criterion is: for each D
iﬁnd the maximum possible loss Mi=max j(Lij);
then choose that Difor which Miis a minimum. This would be a reasonable strategy if we
regard Nature as an intelligent adversary who foresees our decision and deliberately choosesthe state of nature so as to cause us the maximum frustration. In the theory of some games, thisis not a completely unrealistic way of describing the situation, and consequently minimaxstrategies are of fundamental importance in game theory (von Neumann and Morgenstern,1953).
In the decision problems of the scientist, engineer, or economist we have no intelligent
adversary, and the minimax criterion is that of the long-faced pessimist who concentratesall his attention on the worst possible thing that could happen, and thereby misses out onthe favorable opportunities.
Equally unreasonable from our standpoint is the starry-eyed optimist who believes that
Nature is deliberately trying to help him, and so uses this ‘minimin’ criterion: for each D
iﬁnd
the minimum possible loss mi=min j(Lij) and choose the Dithat makes mia minimum.
Evidently, a reasonable decision criterion for the scientist, engineer, or economist is in
some sense intermediate between minimax and minimin, expressing our belief that Natureis neutral toward our goals. Many other criteria have been suggested, with such namesas maximin utility (Wald), α-optimism–pessimism (Hurwicz), minimax regret (Savage),
etc. The usual procedure, as described in detail by Luce and Raiffa, has been to analyzeany proposed criterion to see whether it satisﬁes about a dozen qualitative common senseconditions such as
(1)Transitivity :I fD1is preferred to D2, and D2preferred to D3, then D1should be preferred to D3.
(2)Strong domination : If for all states of nature θjwe have Lij<Lkj, then Dishould always be
preferred to Dk.

<<<PAGE 440>>>

408 Part 2 Advanced applications
This kind of analysis, although straightforward, can become tedious. We do not follow it
any further, because the ﬁnal result is that there is only one class of decision criteria whichpasses all the tests, and this class is obtained more easily by a different line of reasoning.
A full decision theory, of course, cannot concern itself merely with the θ
j,Di,Lij.W e
also, in typical problems, have additional evidence E, which we recognize as relevant
to the decision problem, and we have to learn how to incorporate Einto the theory.
In the quality control example of Chapter 4, Econsisted of the results of the previous
tests.
At this point, the decision theory of Wald takes a long, difﬁcult, and, as we now realize,
unnecessary mathematical detour. One deﬁnes a ‘strategy’ S, which is a set of rules of the
form, ‘If I receive new evidence Ei, then I will make decision Dk’. In principle, one ﬁrst
enumerates all conceivable strategies (whose number is, however , astronomical even in quite
simple problems), and then eliminates the ones considered undesirable by the following
criterion. Denote by
p(Dk|θjS)=/summationdisplay
ip(Dk|EiθjS)p(Ei|θj) (13.11)
the sampling probability that, if θjis the true state of nature, strategy Swould lead us to
make decision Dk, and deﬁne the riskpresented by θjwith strategy Sas the expected loss
over this distribution:
Rj(S)=/angbracketleftL/angbracketrightj=/summationdisplay
kp(Dk|θjS)Lkj. (13.12)
Then a strategy Sis called admissible if no other S/primeexists for which
Rj(S/prime)≤Rj(S), for all j. (13.13)
If an S/primeexists for which the strict inequality holds for at least one θj, then Sis termed
inadmissible . The notions of risk and admissibility are evidently sampling theory criteria,
not Bayesian, since they invoke only the sampling distribution. Wald, thinking in samplingtheory terms, considered it obvious that the optimal strategy should be sought only withinthe class of admissible ones.
A principal object of Wald’s theory is then to characterize the class of admissible
strategies in mathematical terms, so that any such strategy can be found by carryingout a deﬁnite procedure. The fundamental theorem bearing on this is Wald’s completeclass theorem, which establishes a result shocking to sampling theorists (including Waldhimself). Berger (1985, Chap. 8) discusses this in Wald’s terminology. The term ‘completeclass’ is deﬁned in a rather awkward way (Berger, 1985, pp. 521–522). What Wald reallywanted was just the set of all admissible rules, which Berger calls a ‘minimal completeclass’. From Wald’s viewpoint it is a highly nontrivial mathematical problem to provethat such a class exists, and to ﬁnd an algorithm by which any rule in the class can be
constructed.

<<<PAGE 441>>>

13 Decision theory, historical background 409
From our viewpoint, however, these are unnecessary complications, signifying only an
inappropriate deﬁnition of the term ‘admissible’. We shall return to this issue in Chapter 17and come to a different conclusion: an ‘inadmissible’ decision may be overwhelminglypreferable to an ‘admissible’ one, because the criterion of admissibility ignores prior in-formation – even information so cogent that, for example, in major medical, public health,or airline safety decisions, to ignore it would put lives in jeopardy and support a charge ofcriminal negligence.
The notion of admissibility is ﬂawed in another respect. According to the above deﬁnition,
an estimation rule which simply ignores the data and always estimates θ
∗=5 is admissible if
the point θ=5 is in the parameter space. In this case it is clear that almost any ‘inadmissible’
rule would be superior to the ‘admissible’ one.
This illustrates the folly of inventing noble-sounding names such as ‘admissible’ and
‘unbiased’ for principles that are far from noble; and not even fully rational. In the futurewe should proﬁt from this lesson and take care that we describe technical conditions by
names that are ethically and morally neutral, and so do not have false connotations whichcould mislead others for decades, as these have.
Since in real applications we do not want to – and could not – restrict ourselves to
admissible rules anyway, we shall not follow this quite involved argument. We give adifferent line of reasoning which leads to the rules which are appropriate in the real world,while giving us a better understanding of the reason for them.
What makes a decision process difﬁcult? Well, if we knew which state of nature was
the correct one, there would be no problem at all; if θ
3is the true state of nature, then the
best decision Diis the one which renders Li3a minimum. In other words, once the loss
function has been speciﬁed, our uncertainty as to the best decision arises solely from ouruncertainty as to the state of nature. Whether the decision minimizing L
i3is or is not best
depends on this: how strongly do we believe that θ3is the true state of nature? How plausible
isθ3?
To our robot it seems a trivial step – really only a rephrasing of the question – to ask
next, ‘Conditional on all the available evidence, what is the probability P 3thatθ3is the
true state of nature?’ Not so to the sampling theorist, who regards the word ‘probability’as synonymous with ‘long-run relative frequency in some random experiment’. On thisdeﬁnition it is meaningless to speak of the probability for θ
3, because the state of nature
is not a ‘random variable’. Thus, if we adhere consistently to the sampling theory viewof probability, we shall conclude that probability theory cannot be applied to the decisionproblem, at least not in this direct way.
It was just this kind of reasoning which led statisticians, in the early part of the
20th century, to relegate problems of parameter estimation and hypothesis testing to anew ﬁeld, statistical inference, which was regarded as distinct from probability theory, andbased on entirely different principles. Let us examine a typical problem of this type from thesampling theory viewpoint, and see how introducing the notion of a loss function changesthis conclusion.

<<<PAGE 442>>>

410 Part 2 Advanced applications
13.8 Parameter estimation for minimum loss
There is some unknown parameter α, and we make nrepeated observations of a quantity,
obtaining an observed ‘sample’ x≡{x1,..., xn}. We interpret the symbol x, without sub-
scripts, as standing for a vector in an n-dimensional ‘sample space’, and suppose that the
possible results xiof individual observations are real numbers which we think of as contin-
uously variable in some domain ( a≤xi≤b). From observation of the sample x, what can
we say about the unknown parameter α? We have already studied such problems from the
Bayesian ‘probability theory as logic’ viewpoint; now we consider them from the samplingtheory viewpoint.
To state the problem more drastically, suppose that we are compelled to choose one
speciﬁc numerical value as our ‘best’ estimate of α, on the basis of the observed sample x,
and any other prior information we might have, and then to act as if this estimate were true.This is the decision situation which we all face daily, both in our professional capacity andin everyday life. The automobile dri ver approaching a blind intersection cannot know with
certainty whether he will have enough time to cross it safely; but still he is compelled to
make a decision based on what he can see, and act on it.
Now it is clear that in estimating α, the observed sample xis of no use to us unless we
can see some kind of logical (not necessarily causal) connection between αandx. In other
words, if we knew α, but not x, then the probabilities which we would assign to various
observable samples must depend in some way on the value of α. If we consider the different
observations as independent, as was almost always done in the sampling theory of parameterestimation, then the sampling density function factors:
f(x|α)=f(x
1|α)···f(xn|α). (13.14)
However, this very restrictive assumption is not necessary (and in fact does not lead to any
formal simpliﬁcation) in discussing the general principles of parameter estimation from thedecision theory standpoint.
Letβ=β(x
1,..., xn) be an ‘estimator,’ i.e. any function of the data values, proposed as
an estimate of α. Also, let L(α, β) be the ‘loss’ incurred by guessing the value βwhenαis
in fact the true value. Then for any given estimator the risk is the ‘pre-data’ expected loss;i.e. the loss for a person who already knows the true value of αbut does not know what
data will be observed :
R
α≡/integraldisplay
dxL(α, β)f(x|α). (13.15)
By/integraltext
dx( ) we mean the n-fold integration
/integraldisplay
···/integraldisplay
dx1···dxn(). (13.16)
We may interpret this notation as including both the continuous and discrete cases; in the
latter, f(x|α) is a sum of delta-functions.

<<<PAGE 443>>>

13 Decision theory, historical background 411
On the view of one who uses the frequency deﬁnition of probability, the above phrase ‘for
a person who already knows the true value of α’ is misleading and unwanted. The notion
of the probability for sample x for a person with a certain state of knowledge is entirely
foreign to him; he regards f(x|α) not as a description of a mere state of knowledge about
the sample, but as an objective statement of fact, giving the relative frequencies with whichdifferent samples would be observed ‘in the long run’.
Unfortunately, to maintain this view strictly and consistently would reduce the legitimate
applications of probability theory almost to zero; for one can (and most of us do) work inthis ﬁeld for a lifetime without ever encountering a real problem in which one actually hasknowledge of the ‘true’ limiting frequencies for an inﬁnite number of trials; how could oneever acquire such knowledge? Indeed, quite apart from probability theory, no scientist everhas sure knowledge of what is ‘really true’; the only thing we can ever know with certaintyis:what is our state of knowledge ?
Then how could one ever assign a probability which he knew was equal to a limiting
frequency in the real world? It seems to us that the belief that probabilities are realitiesexisting in Nature is pure mind projection fallacy. True ‘scientiﬁc objectivity’ demands thatwe escape from this delusion and recognize that in conducting inference our equations arenot describing reality; they are describing and processing our information about reality.
In any event, the ‘frequentist’ believes that R
αis not merely the ‘expectation of loss’ in the
present situation, but is also, with probability one, the limit of the average of actual losses
which would be incurred by using the estimator βan indeﬁnitely large number of times; i.e.
by drawing a sample of nobservations repeatedly with a ﬁxed value of α. Furthermore, the
idea of ﬁnding the estimator which is ‘best for the present speciﬁc sample’ is quite foreignto his outlook; because he regards the notion of probability as referring to a collection ofcases rather than a single case, he is forced to speak instead of ﬁnding that estimator ‘whichwill prove best, on average, in the long run’.
On the frequentist view, therefore, it would appear that the best estimator will be the one
that minimizes R
α. Is this a variational problem? A small change δβ(x) in the estimator
changes the risk by
δRα=/integraldisplay
dx∂L(α, β)
∂βf(x|α)δβ(x). (13.17)
If we were to require this to vanish for all δβ(x), this would imply
∂L
∂β=0, all possible β. (13.18)
Thus the problem as stated has no truly stationary solution except in the trivial – and useless –
case where the loss function is independent of the estimated value β; if there is any ‘best’
estimator by the criterion of minimum risk, it cannot be found by variational methods.
Nevertheless, we can get some understanding of what is happening by considering (13.15)
for some speciﬁc choices of loss function. Suppose we take the quadratic loss function

<<<PAGE 444>>>

412 Part 2 Advanced applications
L(α, β)=(α−β)2. Then (13.15) reduces to
Rα=/integraldisplay
dx(α2−2αβ+β2)f(x|α), (13.19)
or
Rα=(α−/angbracketleftβ/angbracketright)2+var(β), (13.20)
where var( β)≡/angbracketleftβ2/angbracketright−/angbracketleftβ/angbracketright2is the variance of the sampling pdf for β, and
/angbracketleftβn/angbracketright≡/integraldisplay
dx[β(x)]nf(x|α) (13.21)
is the nth moment of that pdf. The risk (13.20) is the sum of two positive terms, and a good
estimator by the criterion of minimum risk has two properties:
(1)/angbracketleftβ/angbracketright=α,
(2) var( β) is a minimum.
These are just the two conditions which sampling theory has considered most important. An
estimator with property (1) is called unbiased (more generally, the function b(α)=/angbracketleftβ/angbracketright−α
is called the bias of the estimator β(x)), and one with both properties (1) and (2) was called
efﬁcient by R. A. Fisher. Nowadays, it is often called an unbiased minimum variance (UMV)
estimator.
In Chapter 17 we shall examine the relative importance of removing bias and minimizing
variance, and derive the Cram´ er–Rao inequality which places a lower limit on the possible
value of var( β). For the present, our concern is only with the failure of (13.17) to provide any
optimal estimator for a given loss function. This weakness of the sampling theory approachto parameter estimation, that it does not tell us how to ﬁnd the best estimator, but only howto compare different guesses, can be overcome as follows: we give a simple substitute forWald’s complete class theorem.
13.9 Reformulation of the problem
It is easy to see why the criterion of minimum risk is bound to get us into trouble and is
unable to furnish any general rule for constructing an estimator. The mathematical problemwas: for given L(α, β) and f(x|α), what function β(x
1,..., xn) will minimize Rα?
Although this is not a variational problem, it might have a unique solution; but the more
fundamental difﬁculty is that the solution will still, in general, depend on α. Then the
criterion of minimum risk leads to an impossible situation – even if we could solve the
mathematical minimization problem and had before us the best estimator βα(x1,..., xn)
for each value of α, we could use that result only if αwere already known, in which case
we would have no need to estimate. We were looking at the problem backwards!
This makes it clear how to correct the trouble. It is of no use to ask what estimator is ‘best’
for some particular value of α; the answer to that question is always, obviously, β(x)=α,

<<<PAGE 445>>>

13 Decision theory, historical background 413
independent of the data. But the only reason for using an estimator is that αis unknown.
The estimator must therefore be some compromise that allows for all possibilities withinsome prescribed range of α; within this range, it must do the best job of protecting against
loss, no matter what the true value of αturns out to be.
Thus it is some weighted average of R
α,
/angbracketleftR/angbracketright=/integraldisplay
dαg(α)Rα, (13.22)
that we should really minimize, where the function g(α)≥0 measures in some way the
relative importance of minimizing Rαfor the various possible values that αmight turn out
to have.
The mathematical character of the problem is completely changed by adopting (13.22)
as our criterion; we now have a solvable variational problem with a unique, well-behaved,and useful solution. The ﬁrst variation in /angbracketleftR/angbracketrightdue to an arbitrary variation δβ(x
1,..., xn)
in the estimator is
δ/angbracketleftR/angbracketright=/integraldisplay
···/integraldisplay
dx1···dxn/braceleftbigg/integraldisplay
dαg(α)∂L(α, β)
∂βf(x1,..., xn|α)/bracerightbigg
δβ(x1,..., xn),
(13.23)
which vanishes independently of δβif
/integraldisplay
dαg(α)∂L(α, β)
∂βf(x1,..., xn|α)=0 (13.24)
for all possible samples {x1,..., xn}.
Equation (13.24) is the fundamental integral equation which determines the ‘best’ esti-
mator by our new criterion. Taking the second variation, we ﬁnd that (13.24) yields a trueminimum if
/integraldisplay
dαg(α)∂
2L
∂β2f(x1,..., xn|α)>0. (13.25)
Thus a sufﬁcient condition for a minimum is simply ∂2L/∂β2≥0, but this is stronger than
necessary.
If we take the quadratic loss function L(α, β)=K(α−β)2, (13.24) reduces to
/integraldisplay
dαg(α)(α−β)f(x1,..., xn|α)=0, (13.26)
or the optimal estimator for quadratic loss is
β(x1,..., xn)=/integraltext
dαg(α)αf(x1,..., xn|α)/integraltext
dαg(α)f(x1,..., xn|α). (13.27)
But this is just the mean value over the posterior pdf for α:
f(α|x1,..., xn,I)=g(α)f(x1,..., xn|α)/integraltext
dαg(α)f(x1,..., xn|α)(13.28)

<<<PAGE 446>>>

414 Part 2 Advanced applications
given by Bayes’ theorem, if we interpret g(α) as a prior probability density! This argument
shows, perhaps more clearly than any other we have given, why the mathematical form of
Bayes’ theorem intrudes itself inevitably into parameter estimation.
If we take as a loss function the absolute error, L(α, β)=|α−β|, then the integral
(13.24) becomes
/integraldisplayβ
−∞dαg(α)f(x1,..., xn|α)=/integraldisplay∞
βdαg(α)f(x1,..., xn|α), (13.29)
which states that β(x1...xn) is to be taken as the median over the posterior pdf for α:
/integraldisplayβ
−∞dαf(α|x1,..., xn,I)=/integraldisplay∞
βdαf(α|x1,..., xn,I)=1
2. (13.30)
Likewise, if we take a loss function L(α, β)=(α−β)4, (13.24) leads to an estimator
β(x1,..., xn), which is the real root of
f(β)=β3−3/angbracketleftα/angbracketrightβ2+3/angbracketleftα2/angbracketrightβ−/angbracketleftα3/angbracketright=0, (13.31)
where
/angbracketleftαn/angbracketright=/integraldisplay
dααnf(α|x1,..., xnI) (13.32)
is the nth moment of the posterior pdf for α. (That (13.31) has only one real root is seen on
forming the discriminant; the condition f/prime(β)≥0 for all real βis just (/angbracketleftα2/angbracketright−/angbracketleftα2)/angbracketright≥0.)
If we take L(α, β)=|α−β|k, and pass to the limit k→0, or if we just take
L(α, β)=/braceleftBigg
0 α=β
1 otherwise ,(13.33)
(13.24) tells us that we should choose β(x1,..., xn) as the ‘most probable value’, or mode
of the posterior pdf f(α|x1,..., xnI). Ifg(α)=constant in the high-likelihood region, and
is not much greater elsewhere, this is just the maximum-likelihood estimate advocated byFisher.
In this result we see ﬁnally just what maximum likelihood accomplishes, and under what
circumstances it is the appropriate method to use. The maximum-likelihood criterion is theone in which we care only about the chance of being exactly right; and, if we are wrong,we don’t care how wrong we are. This is just the situation we have in shooting at a smalltarget, where ‘a miss is as good as a mile’. But it is clear that there are few other situationswhere this would be a rational way to behave; almost always, the amount of error is of someconcern to us, and so maximum likelihood is not the best estimation criterion.
Note that in all these cases it was the posterior pdf, f(α|x
1,..., xn,I) that was involved.
That this will always be the case is seen by noting that our ‘fundamental integral equation’(13.24) is not so profound after all. It can be written equally well as
∂
∂β/integraldisplay
dαg(α)L(α, β)f(x1,..., xn|α)=0. (13.34)

<<<PAGE 447>>>

13 Decision theory, historical background 415
But if we interpret g(α) as a prior probability density, this is just the statement that we are
indeed to minimize the expectation of L(α, β): it is not the expectation over the sampling
pdf for β; it is always the expectation over the Bayesian posterior pdf for α!
We have here an interesting case of ‘chickens coming home to roost’. If a sampling
theorist will think his estimation problems through to the end, he will ﬁnd himself obligedto use the Bayesian mathematical algorithm, even if his ideology still leads him to reject theBayesian rationale for it. But in arriving at these inevitable results, the Bayesian rationalehas the advantages that (1) it leads us to this conclusion immediately; (2) it makes it obviousthat its range of validity and usefulness is far greater than supposed by the sampling theorist.The Bayesian mathematical form is required for simple logical reasons, independently ofall philosophical hangups over ‘which quantities are random?’ or the ‘true meaning ofprobability’.
Wald’s complete class theorem led him to essentially the same conclusion: if the θ
jare
discrete and we agree not to include in our enumeration of states of nature any θjthat is
known to be impossible, then the class of admissible strategies is just the class of Bayes
strategies (i.e. those that minimize expected loss over a posterior pdf). If the possible θj
form a continuum, the admissible rules are the proper Bayesian ones; i.e. Bayes rules from
proper (normalizable) prior probabilities. But few people have ever tried to follow his proofof this; Berger (1985) does not attempt to present it, but gives instead a number of isolatedspecial results.
There is a great deal of mathematical nitpicking, also noted by Berger, over the exact
situation when one tries to jump into an improper prior in inﬁnite parameter spaces withoutconsidering any limit from a proper prior. But for us such questions are of no interest, because
the concept of admissibility is itself ﬂawed when stretched to such extreme cases. Becauseof its refusal to consider any prior information whatsoever, it must consider all points of
an inﬁnite domain equivalent; the resulting singular mathematics is only an artifact thatcorresponds to no singularity in the real problem, where prior information always excludesthe region at inﬁnity.
For a given sampling distribution and loss function, we are content to say simply that the
defensible decision rules are the Bayes rules characterized by the different proper priors, andtheir well-behaved limits. This is the conclusion that was shocking to sampling theorists –including Wald himself, who had been one of the proponents of the von Mises’ ‘collective’theory of probability – and it was psychologically the main spark that touched off ourpresent ‘Bayesian revolution’ in statistics. To his everlasting credit, Abraham Wald had theintellectual honesty to see the inevitable consequences of this result, and in his ﬁnal work
(Wald, 1950), he termed the admissible decision rules, ‘Bayes strategies’.
13.10 Effect of varying loss functions
Since the new feature of the theory being expounded here lies only in the introduction of the
loss function, it is important to understand how the ﬁnal results depend on the loss functionsby some numerical examples. Suppose that the prior information Iand data Dlead to the

<<<PAGE 448>>>

416 Part 2 Advanced applications
following posterior pdf for a parameter α:
f(α|DI)=kexp{−kα}, 0≤α<∞. (13.35)
Thenth moment of this pdf is
/angbracketleftαn/angbracketright=/integraldisplay∞
0dααnf(α|DI)=n!k−n. (13.36)
With loss function ( α−β)2, the best estimator is the mean value
β=/angbracketleftα/angbracketright=k−1. (13.37)
With the loss function |α−β|, the best estimator is the median, determined by
1
2=/integraldisplayβ
0dαf(α|DI)=1−exp{−kβ} (13.38)
or
β=k−1loge(2)=0.693/angbracketleftα/angbracketright. (13.39)
To minimize/angbracketleft(α−β)4/angbracketright, we should choose βto satisfy (13.31), which becomes y3−3y2+
6y−6=0 with y=kβ. The real root of this is at y=1.59, so the optimal estimator is
β=1.59/angbracketleftα/angbracketright. (13.40)
For the loss function ( α−β)s+1,with san odd integer, the fundamental equation (13.34)
is
/integraldisplay∞
0dα(α−β)sexp{−kα}=0, (13.41)
which reduces to
s/summationdisplay
m=0(−kβ)m
m!=0. (13.42)
The case s=3 leads to (13.40), while in the case s=5, loss function ( α−β)6,w eﬁ n d
β=2.025/angbracketleftα/angbracketright. (13.43)
Ass→∞ ,βalso increases without limit. But the maximum-likelihood estimate, which
corresponds to the loss function L(α, β)=−δ(α−β), or equally well to
lim
k→0|α−β|k, (13.44)
isβ=0. These numerical examples merely illustrate what was already clear intuitively;
when the posterior pdf is not sharply peaked, the best estimate of αdepends very much on
which particular loss function we use.
One might suppose that a loss function must always be a monotonically increasing
function of the error |α−β|. In general, of course, this will be the case; but nothing in this
theory restricts us to such functions. You can think of some rather frustrating situations in

<<<PAGE 449>>>

13 Decision theory, historical background 417
which, if you are going to make an error, you would rather make a large one than a small
one. William Tell was in just that ﬁx. If you study our equations for this case, you will seethat there is really no very satisfactory decision at all (i.e. no decision has small expectedloss); and nothing can be done about it.
Note that the decision rule is invariant under any proper linear transformation of the loss
function; i.e. if L(D
i,θj) is one loss function, then the new one,
L/prime(Di,θj)≡a+bL(Di,θj)/braceleftBigg
−∞<a<∞
0<b<∞,(13.45)
will lead to the same decision, whatever the prior probabilities and data. Thus, in a binary
decision problem, given the loss matrix
Lij=/parenleftbigg10 19
100 10/parenrightbigg
, (13.46)
we can equally well use
L/prime
ij=/parenleftbigg01
10 0/parenrightbigg
(13.47)
corresponding to a=−10/9,b=1/9. This may simplify the calculation of expected loss
quite a bit.
13.11 General decision theory
In the foregoing, we examined decision theory only in terms of one particular application,
parameter estimation. But we really have the whole story already; the criterion (13.34) forconstructing the optimal estimator generalizes immediately to the criterion for ﬁnding theoptimal decision of any kind. The ﬁnal rules are simple; to solve the problem of inference,there are four steps.
(1) Enumerate the possible states of nature θj, discrete or continuous, as the case may be.
(2) Assign prior probabilities p(θj|I) which represent whatever prior information Iyou have about
them.
(3) Assign sampling probabilities p(Ei|θj) which represent your prior knowledge about the mecha-
nism of the measurement process yielding the possible data sets Ei.
(4) Digest any additional evidence E=E1E2···by application of Bayes’ theorem, thus obtaining
the posterior probabilities p(θj|EI).
That is the end of the inference problem, and p(θj|EI) expresses all the information about
theθjthat is contained in the prior information and data. To solve the problem of decision
there are three more steps.
(5) Enumerate the possible decisions Di.
(6) Assign the loss function L(Di,θj) that tells what you want to accomplish.
(7) Make that decision Diwhich minimizes the expected loss over the posterior probabilities for θj.

<<<PAGE 450>>>

418 Part 2 Advanced applications
After all is said and done, the ﬁnal rules of calculation to which the theorems of Cox,
Wald, and Shannon lead are just the ones which had been given already by Laplace andDaniel Bernoulli in the 18th century on intuitive grounds, except that the entropy principlegeneralizes the principle of indifference in step (2).
Theoretically, these rules are now determined uniquely by elementary qualitative desider-
ata of rationality and consistency. Some protest that they do not have any prior probabilityor loss function. The theorem is that rationality and consistency require you to behave as if
you had them; for every strategy that obeys the desiderata, there is a prior probability andloss function which would have led to that strategy; conversely, if a strategy is derived froma prior probability and loss function, it is guaranteed to obey the desiderata.
Pragmatically, these rules either include, or improve upon, practically all known statistical
methods for hypothesis testing and point estimation of parameters. If you have masteredthem, then you have just about the entire ﬁeld at your ﬁngertips. The outstanding thingabout them is their intuitive appeal and simplicity – if we sweep aside all the polemics andfalse starts that have cluttered up this ﬁeld in the past and consider only the constructivearguments that lead directly to these rules, it is clear that the underlying rationale could bedeveloped fully in a one-semester undergraduate course.
However, in spite of the formal simplicity of the rules themselves, really facile application
of them in nontrivial problems involves intricate mathematics, and ﬁne subtleties of concept;so much so that several generations of workers in this ﬁeld misapplied them and concludedthat the rules were all wrong. So, we still need a good deal of leading by the hand in orderto develop facility in using this theory. It is like learning how to play a musical instrument –anybody can make noise with it, but to play this instrument well requires years of practice.
13.12 Comments
13.12.1 ‘Objectivity’ of decision theory
Decision theory occupies a unique position in discussion of the logical foundations of
statistics, because, as we have seen in (13.24) and (13.34), its procedures can be derivedfrom either of two diametrically opposed viewpoints about the nature of probability theory.While there appears to be universal agreement as to the actual procedures that should befollowed, there remains a fundamental disagreement as to the underlying reason for them,having its origin in the old issue of frequency vs. nonfrequency deﬁnitions of probability.
From a pragmatic standpoint, such considerations may seem at ﬁrst to be unimportant.
However, in the attempt to apply decision theory methods in real problems one learnsvery quickly that these questions intrude in the initial stage of setting up the problem inmathematical terms. In particular, our judgment as to the generality and range of validityof decision theory depends on how these conceptual problems are resolved. Our aim is toexpound the viewpoint according to which these methods have the greatest possible rangeof application.
Now, we ﬁnd that the main source of controversy here is on the issue of prior probabilities;
on the sampling theory viewpoint, if the problem involves use of Bayes’ theorem then these

<<<PAGE 451>>>

13 Decision theory, historical background 419
methods are just not applicable unless the prior probabilities are known frequencies. But
to maintain this position consistently would imply an enormous restriction on the range oflegitimate applications; indeed, we doubt whether there has ever been a real problem inwhich the prior probabilities were, in fact, known frequencies. But can the mathematicalform of our ﬁnal equations shed any light on this issue?
Notice ﬁrst that only the product g(α)L(α, β) is involved in (13.24) or (13.34); thus we
could interpret the problem in three different ways:
(1) prior probability g(α), loss function L(α, β)=(α−β)2;
(2) uniform prior probability, loss function L(α, β)=g(α)(α−β)2;
(3) prior probability h(α), loss function g(α)(α−β)2/h(α);
but the optimal decision is just the same. This is equally true for any loss function.
We emphasize this rather trivial mathematical fact because of a curious psychological
phenomenon. In expositions of decision theory written from the sampling theory viewpoint
(for example, Chernoff and Moses, 1959), the writers are reluctant to introduce the notionof prior probability. They postpone it as long as possible, and ﬁnally give in only when themathematics forces them to recognize that prior probabilities are the only basis for choiceamong the different admissible decision rules. Even then, they are so unhappy about the useof prior probabilities that they feel it necessary always to invent a situation – often highlyartiﬁcial – which makes the prior probabilities appear to be frequencies; and they will notuse this theory for any problem where they do not see how to do this.
But these same writers do not hesitate to pull a completely arbitrary loss function out of
thin air without any basis at all, and proceed with the calculation! Our equations show that ifthe ﬁnal decision depends strongly on which particular prior probability assignment we use,it is going to depend just as strongly on which particular loss function we use. If one worries
about arbitrariness in the prior probabilities, then, in order to be consistent, one ought to
worry just as much about arbitrariness in the loss functions. If one claims (as samplingtheorists did for decades and as some still do) that uncertainty as to the proper choice ofprior probabilities invalidates the Laplace–Bayes theory, then, in order to be consistent, onemust claim also that uncertainty as to the proper choice of loss functions invalidates Wald ’s
decision theory.
The reason for this strange lopsided attitude is closely connected with a certain philosophy
variously called behavioristic, or positivistic, which wants us to restrict our statements andconcepts to objectively veriﬁable things. Therefore the observable decision is the thing to
emphasize, while the process of plausible reasoning and the judgment described by a priorprobability must be deprecated and swept under the rug. But we see no need to do this,because it seems to us obvious that rational action can come only as the result of rationalthought.
If we refuse to consider the problem of rational thought merely on the grounds that it is
not ‘objective’, the result will not be that we obtain a more ‘objective’ theory of inferenceor decision. The result will be that we have lost the possibility of getting any satisfactorytheory at all, because we have denied ourselves any way of describing what is actually

<<<PAGE 452>>>

420 Part 2 Advanced applications
going on in the decision process. And, of course, the loss function is just the expression of a
purely subjective value judgment, which can in no way be considered any more ‘objective’than the prior probabilities.
In fact, prior probabilities are usually far more ‘objective’ than loss functions, both
in the mathematical theory and in the everyday decision problems of ‘real life’. In themathematical theory we have general formal principles – maximum entropy, transformationgroups, marginalization – that remove the arbitrariness of prior probabilities for a large classof important problems, which includes most of those discussed in textbooks. But we haveno such principles for determining loss/utility functions.
This is not to say that the problem has not been discussed; de Groot (1970) notes the very
weak abstract conditions (transitivity of preferences, etc.) sufﬁcient to guarantee existenceof a utility function. Long ago, L. J. Savage considered construction of utility functionsby introspection. This is described by Chernoff and Moses (1959): suppose there are twopossible rewards r
1andr2; then for what reward r3would you be indifferent between ( r3
for sure) or (either r1orr2as decided by the ﬂip of a coin)? Presumably, r3is some where
between r1andr2. If one makes enough such intuitive judgments and manages to correct
all intransitivities, a crude utility function emerges. Berger (1985, Chap. 2) gives a scenarioin which this happens.
This is hardly a practical procedure, however, much less a formal principle; the result is
just as arbitrary as if one simply drew a curve freehand. Indeed, the latter is much easierand cannot get one into intransitivity difﬁculties. One can, of course, invent a crude prior inthe same way, as L. J. Savage often demonstrated. Such constructions, if one can transferthem into a computer, will be better than nothing; but they are clearly desperation movesin lieu of a really satisfactory formal theory such as we have in the principles of maximumentropy and transformation groups for priors.
Noting that the decision depends only on the product of loss function and prior suggests
what seems at ﬁrst an attractive possibility; could we simplify the foundations of this theoryso as to make it obvious that we need only a single function, not two? The writer pondered thisfor some time, but decided ﬁnally that this is not the right direction for future development,because (1) priors and loss functions have very different – almost opposite – roles to play,both in the mathematical theory and in ‘real life’, and (2) the theory of inference involvingpriors is more fundamental than that of loss functions; the latter would need to be developedmuch further before it would be ﬁt to join with priors into a single mathematical quantity.
What determines the validity of this theory? We would say, unhesitatingly, ‘logical con-
sistency’. But there is a perennial fallacy of basing validity judgments on whether peopleactually reason in the way required by consistency arguments. The theory is held by someto be invalid if real people do not always reason this way. It seems to us that this is getting itexactly backward; the theory being developed is, just because of the consistency properties,the normative goal which people should strive to approach in the real world.
Some authors get into e ven stranger problems in approaching decision theory. L. J. Savage
(1954) faces many inexplicable difﬁculties. He thinks (p. 16) that the proverbs ‘Look beforeyou leap’ and ‘You can cross that bridge when you come to it’ are contradictory. We feel that

<<<PAGE 453>>>

13 Decision theory, historical background 421
we routinely obey both, and see no conﬂict between them. That is, we do not act without
considering the likely consequences; but at the same time we do not waste time and effortplanning for future contingencies that are very unlikely to happen.
The original formulation of Wald contemplates, following the orthodox line of thought,
thatbefore seeing the data one will plan in advance for every possible contingency and
list the decision to be made after getting every conceivable data set. The problem with thisis that the number of such data sets is usually astronomical; no worker has the computingfacilities needed to do it. Yet Savage (1954) thinks that planning for every contingency inadvance is the proper course for decision theory because orthodox practice is conﬁned to asmall class of artiﬁcially simple problems. We take exactly the opposite view: it is only bydelaying a decision until we know the actual data that it is possible to deal with complexproblems at all. The defensible inferences are the post-data inferences.
As Chernoff and Moses (1959) demonstrate very convincingly, the Bayesian formulation
saves us from this; whatever data set is actually observed, we enter it into the computerprogram and it calculates the appropriate response for that data set . It is wasteful and
irrelevant to calculate the response to any data set that is not observed. This is not a trivialpoint; at stake is many orders of magnitude in computation. So carrying this observation abit further, we ﬁll out our proverb list with ‘Never make an irrevocable decision until youhave to’.
13.12.2 Loss functions in human society
We note the sharp contrast between the roles of prior probabilities and loss functions in
human relations. People with similar prior probabilities get along well together, becausethey have about the same general view of the world and philosophy of life. People withradically different prior probabilities cannot get along – this has been the root cause of allthe religious wars and most of the political repressions throughout history.
Loss functions operate in just the opposite way. People with similar loss functions are after
the same thing, and are in contention with each other. People with different loss functionsget along well because each is willing to give something that the other wants. Amicabletrade or business transactions, advantageous to all, are possible only between parties withvery different loss functions. We illustrated this by the example of insurance above.
In ‘real life’ decision problems, each man knows, pretty well, what his prior probabilities
are; and because his beliefs are based on all his past experience, they are not easily changedby one more experience, so they are fairly stable. But, in the heat of argument, he may losesight of his loss function.
Thus the labor mediator must deal with parties with sharply opposing ideologies; policies
considered good by one are considered evil by the other. The successful mediator realizesthat mere talk will not alter prior beliefs; and so his role must be to turn the attention of bothparties away from this area, and explain clearly to each what his loss function is. In thissense, we can claim that in real life decision problems, the loss function is often far more‘subjective’ (in the sense of being less well-ﬁxed in our minds) than the prior probabilities.

<<<PAGE 454>>>

422 Part 2 Advanced applications
Indeed, failure to judge one’s own loss function correctly is one of the major dangers that
humans face. Having a little intelligence, one can invent myths out of his own imagination,and come to believe them. Worse, one person may persuade thousands of others to believehis private myths, as the sordid history of religious, political, and military disasters shows.
We think that these considerations have a bearing on other social problems. For example,
some psychologists never tire of trying to explain criminal behavior in terms of early child-hood experiences. It is conceivable that these may generate a certain general ‘propensity’ tocrime; but the fact that the vast majority of people with the same experiences do not becomecriminals shows that a far more important and immediate cause must exist. Perhaps criminalbehavior has a much simpler explanation: poor reasoning, leading to a wrongly perceivedloss function. Whatever our early childhood experiences, law abiding citizens have just thesame motivations as do criminals; all of us have felt the urge to commit robbery, assault, andmurder. The difference is that the criminal does not think ahead far enough to appreciate thepredictable consequences of his actions; we were not surprised to learn that most violentcriminals have very low intelligence.
Inability to perceive one’s own loss function can have disastrous personal consequences
in other ways. Consider the case of Ramanujan, whom many would consider to be, in oneparticular area, the greatest mathematical genius who ever lived. His death at age 32 wasprobably the result of his own ridiculous dietary views. He refused to eat the food servedin Hall at Trinity College, Cambridge (although it was undoubtedly more wholesome thanany food he had ever eaten before coming to England) and tried to subsist on rotten fruitshipped from India without refrigeration.
A strikingly similar case is that of Kurt G¨ odel, whom many would consider the greatest –
certainly the best known – of all logicians. He died of starvation in a hospital with the ﬁnestfood facilities, because he became obsessed with the idea that the doctors were trying topoison him. It is curious that the greatest intellectual gifts sometimes carry with them theinability to perceive simple realities that would be obvious to a moron.
We stress that the real world is vastly more complicated than supposed in Wald’s theory,
and many real decision problems are not covered by it. For example, the state of naturetomorrow might be inﬂuenced by our decision today (as when one decides to get an educa-tion). Recognizing this is a step in the direction of game theory, or dynamic programming.But to treat such problems does not require any departure from the principles of probabilitytheory as logic; only a generalization of what we did above.
Actually, human intuition, in making decisions with seemingly no rational basis, does
surprisingly well; persons with no mathematical comprehension whatsoever may still makegood decisions. However, ‘intuition’ may make use of facts and memories so deeply buriedin the subconscious that one is not aware of them; but without mathematical understandingit can also fail disastrously. For example, attempts to apply probability theory and decisiontheory to strategy in athletic performance provide several amusing illustrations of the fal-lacies that one can produce by combining a little bit of mathematics with a great deal ofsuperstitious folklore. The book of Machol, Ladany and Morrison (1976) is a good sourcefor this.

<<<PAGE 455>>>

13 Decision theory, historical background 423
13.12.3 A new look at the Jeffreys prior
Our noting that the optimal decision depends only on the product of prior probability and
loss function sets off several other lines of thought. As we noted in Chapter 12, Jeffreys(1939) proposed that, in the case of a continuous parameter αknown to be positive, we
should express prior ignorance by assigning, not uniform prior density, but a prior densityproportional to (1 /α). The theoretical justiﬁcation of this rule was long unclear, but it yields
very sensible-looking results in practice, which led Jeffreys to adopt it as fundamental inhis signiﬁcance tests.
We learned that, in the case that αis a scale parameter, the Jeffreys prior is uniquely
determined by invariance under the scale transformation group; but now we can see a quite
different justiﬁcation for it. If we use the absolute error loss function |β−α|whenαis
known to be positive, then to assign g(α)=constant in (13.24) and (13.34) amounts to
saying that we demand an estimator which yields, as nearly as possible, a constant absoluteaccuracy for all values of αin 0<α<∞. That is clearly asking for too much in the case
of large α; and we must pay the price in a poor estimate for small α. But the median of
Jeffreys’ posterior distribution is mathematically the same thing as the optimal estimatorfor uniform prior and loss function |β−α|/α; we ask for, as nearly as possible, a constant
percentage accuracy over all values of α. This is, of course, what we do want in most cases
where we know that 0 <α<∞. Another reason for the superior performance of Jeffreys’
rule is thus made apparent, if we reinterpret it as saying that the (1 /α) factor is part of the
loss function. This requires only that αbe positive, not necessarily a scale parameter; just
what Jeffreys originally stated.
13.12.4 Decision theory is not fundamental
What parts of the theories expounded here will be a permanent part of human thinking, what
parts may evolve on into different forms in the future? We can only speculate, but it seemsclear to the writer that there is something necessary and timeless in the methods of inferencedeveloped here; not only their compelling theoretical basis
2explained in Chapters 1 and 2,
but, equally well, the beautiful way they work out in practice in all the later chapters –always giving us the right answer to whatever question we ask of them, while orthodoxmethods yield sense and nonsense about equally often – convinces us that these methodscannot be altered in any substantive way in the future.
However, views as to the foundation of those methods may change; for example, instead
of our desiderata of logical consistency, future workers may prefer desiderata of optimal in-formation processing, as suggested by the work of Zellner (1988). Indeed, many advantageswould result from more common recognition that inference has fundamentally nothing todo with ‘randomness’ or ‘chance’ but is concerned rather with optimal processing of infor-
mation . We noted at the end of Chapter 2 how G¨ odel’s theorem appears as a platitude rather
than a paradox, as soon as we recognize the information processing aspect of mathematics.
2Of course, better proofs than those we were able to give in Chapter 2 will be found.

<<<PAGE 456>>>

424 Part 2 Advanced applications
But we can feel no such certainty about the decision theory addendum to inference. In the
ﬁrst place, many present applications already require an extension to game theory, dynamicprogramming or beyond. The state of nature may be chosen by another person; or it maybe inﬂuenced by our decision without the intervention of a conscious second agent. Theremay be more than two agents involved. They might be either adversaries or helpful friends.Those are more complicated situations than the ones we have considered here. We do notthink such extensions appropriate to our present topic of scientiﬁc inference, because wedo not think of ourselves as playing an adversary game against Nature. However, futurescientists may ﬁnd good reasons to consider the more general theory.
For all the reasons noted in this chapter, it now appears that from a fundamental standpoint
loss functions are less ﬁrmly grounded than are prior probabilities. This is just the oppositeof the view that propelled the Wald-inspired development of decision theory in the 1950s,when priors were regarded as vague and ill-deﬁned, but nobody seemed to notice that lossfunctions are far more so. For reasons we cannot explain, loss functions appeared to workersat that time to be ‘real’ and deﬁnite, although no principles for determining them were evergiven, beyond the truism that any function with a continuous derivative appears linear if weexamine a sufﬁciently small piece of it.
In the meantime, there have been several advances in the technique for assigning priors
by logical analysis of the prior information. But, to the best of our knowledge, we have asyet no formal principles at all for assigning numerical values to loss functions; not evenwhen the criterion is purely economic, because the utility of money remains ill-deﬁned.
13.12.5 Another dimension?
There is another respect in which loss functions are less ﬁrmly grounded than are prior
probabilities. We consider it an important aspect of ‘objectivity’ in inference – almost aprinciple of morality – that we should not allow our opinions to be swayed by our desires;what we believe should be independent of what we want. But the converse need not be true;on introspection, we would probably agree that what we want depends very much on whatwe know, and we do not feel guilty of any inconsistency or irrationality on that account.
3
Indeed, it is clear that the act of assigning a loss function is itself only a means of
describing certain prior information about the phenomena of interest, which now notes not
just their plausibilities, but also their consequences. Thus a change in prior informationwhich affects the prior probabilities could very well induce a change in the loss function aswell.
But then, having admitted this possibility, it appears that value judgments need not be
introduced in the form of loss functions at all. Already at the end of Chapter 1 we noted thepossibility of future ‘multidimensional’ models of human mental activity. In view of theabove considerations, the doors now seem wide open for new developments in that direction;
3Quasimodo, condemned by an accident of Nature to be something intermediate between man and gargoyle, wished that he
had been made a whole man. But, after learning about the behavior of men, he wished instead that he had been made a wholegargoyle: ‘O, why was I not made of stone like these?’

<<<PAGE 457>>>

13 Decision theory, historical background 425
representing a mental state about a proposition or action not by one coordinate (plausibility)
as in present probability theory, but by two coordinates (plausibility and value). Thus, whilethe principles of ‘one-dimensional’ inference seem permanent, the future can still bringmany kinds of change in the representation of value judgments, which need not resemblepresent decision theory at all. But this in turn reacts back on the question of foundations ofprobability theory.
Thomas Bayes (1763) thought it necessary to explain the notion of probability in terms of
that of expectation;
4and this persisted to modern times in the work of both Wald (1950) and
de Finetti (1972, 1974b). At ﬁrst glance, it appears that the work of de Finetti on foundationsof probability theory could hardly be more different in outlook from Wald’s decision theory;yet these two avenues to Bayesianity shared the common premise that value judgments arein some way primary to inference.
de Finetti would base probability theory on the notion of ‘coherence’, which means
roughly that in betting one should behave as if he assigned probabilities to the events (dicetosses, etc.) being betted on; but those probabilities should be chosen so that he cannot bemade a sure loser, whatever the ﬁnal outcome of those events.
It has always seemed objectionable to some, including this writer, to base probability
theory on such vulgar things as betting, expectation of proﬁt, etc. We think that the principlesof logic ought to be on a higher plane. But that was only an aesthetic feeling; now, inrecognizing the indeﬁnite and provisional nature of loss functions, we have a more cogentreason for not basing probability theory on decisions or betting. Any rules which werefound to be coherent, but not consistent, would be unusable in practice because a well-posed question would have more than one ‘right’ answer with nothing to choose betweenthem. This is, in our view, still another aspect of the superiority of Richard Cox ’s approach,
which stresses logical consistency instead and, just for that reason, is more likely to have alasting place in probability theory.
4The difﬁculty of reading Bayes today can be appreciated from the bewildering sentence in which he states this: ‘The probability
of any event is the ratio between the value at which an expectation depending on the happening of the event ought to be computed,
and the value of the thing expected upon its happening.’

<<<PAGE 458>>>

14
Simple applications of decision theory
We now examine in detail two of the simplest applications of the general decision theory just
formulated, and compare the ﬁrst with the older Neyman–Pearson procedure. The problemof detection of signals in noise is really the same as Laplace’s old problem of detecting thepresence of unknown systematic inﬂuences in celestial mechanics, and Shewhart’s (1931)
more recent problem of detecting a systematic drift in machine characteristics, in industrialquality control. Statisticians would call the procedure a ‘signiﬁcance test’. It is unfortunate
that the basic identity of all these problems was not more widely recognized, because it
forced workers in several different ﬁelds to rediscover the same things, with varying degrees
of success, over and over again.
As is clear by now, all we really have to do to solve this problem is to tak e the principles
of inference developed in Chapters 2 and 4, and supplement them with the loss function
criterion for converting ﬁnal probabilities into decisions (and, if needed, the maximumentropy principle for assigning priors). However, the literature of this ﬁeld has been createdlargely from the standpoint of the original decision theory before this was realized. Theexisting literature therefore uses a different sort of vocabulary and set of concepts thanwe have been using up to now. Since it exists, we have no choice but to learn these termsand viewpoints if we want to read the literature of the ﬁeld. This material appeared in thepapers of Middleton and Van Meter (1955, 1956), and later in the monumental treatise ofMiddleton (1960), in an enormously expanded form where a beginner can get lost for months
without ever ﬁnding the real underlying principles. So we need a very rapid, condensedreview of the literature of the 1950s on these problems. To have a complete, self-containedsummary, we repeat a little from previous chapters as a way of introducing this different
language.
14.1 Deﬁnitions and preliminaries
We employ the notation:
p(A|B)=conditional probability for A,g i v e n B,
p(AB|CD)=joint conditional probability for AandB,g i v e n CandD,etc.(14.1)
426

<<<PAGE 459>>>

14 Simple applications of decision theory 427
For our purposes, everything follows from the product rule:
p(AB|C)=p(A|BC)p(B|C)=p(B|AC)p(A|C). (14.2)
If the propositions BandCare not mutually contradictory, this may be rearranged to give
the rule of ‘learning by experience’, Bayes’ theorem:
p(A|BC)=p(A|C)p(B|AC)
p(B|C)=p(A|B)p(C|AB)
p(C|B). (14.3)
If there are several mutually exclusive and exhaustive propositions Bi, then, by summing
(14.2) over them, we obtain the chain rule
p(A|C)=/summationdisplay
ip(A|BiC)p(Bi|C) (14.4)
or, in a simple skeleton notation,
p(A|C)=/summationdisplay
Bp(A|BC)p(B|C). (14.5)
Now let
X=prior knowledge, of any kind whatsoever,
S=signal,
N=noise,
V=V(S,N)=observed voltage,
D=decision about the nature of the signal.(14.6)
Thus we have
p(S|X)=prior probability for the particular signal S,
p(N|X)=W(N)=prior probability for the particular sample of noise N.(14.7)
We understand that the prior information Xis always built into the right-hand side of all
our probability symbols, whether or not we write it explicitly. Thus, in a linear system,
V=S+Nand
p(V|S)≡p(V|SX)=W(V−S). (14.8)
The reader may be disturbed by the absence of density functions, d S,dN, etc., which
might be expected in the case of continuous S,N. Note, however, that our equations are
homogeneous in these quantities, so they cancel out anyway. We are trying only to conveythe broad ideas, without bothering with ﬁne details which would make the notation veryintricate. Thus by/summationtext
Awe mean ordinary summation over some previously agreed set
of possible values if Ais discrete, integration with appropriate density functions if Ais
continuous.
Adecision rule p (Di|Vj), or for brevity just p(D|V), represents the process of drawing
inferences about the signal from the observed voltage. If it is always made in a deﬁnite way,then p(D|V) has only the values 0, 1 for any choice of DandV; however, we may also have

<<<PAGE 460>>>

428 Part 2 Advanced applications
a ‘randomized’ decision rule according to which p(D|V) is a true probability distribution.
Maintaining this more general view turns out to be a help in formulating the theory.
The essence of any decision rule, and in particular any one which can be built into
automatic equipment, is that the decision must be made on the basis of Valone; Vis, by
deﬁnition, the quantity which contains all the information actually used (in addition to theever-present X) in arriving at the decision. Thus, if Y/negationslash=Dis any other proposition, we
have
p(D|V)=p(D|VY). (14.9)
The fact that Yis to be ignored in the presence of Vmight appear a departure from our
previous exhortations that the robot is al ways to take into account all the relevant information
it has. However, if we consider that the property (14.9) is a part of the prior information X
there is no difﬁculty. To put it differently, (14.9) expresses the prior knowledge that there
is a direct logical relation by which Dis determined by Valone. If this relationship was a
known law of physics, there would be nothing strange in (14.9). The only difference is thatin the present case this relationship does not express any law of Nature, but rather our own
design of the apparatus. Then Yis ignored not because the robot has relaxed its rules, but
because our design makes Yirrelevant.
An equivalent statement is that the probability for reaching a decision Ddepends on any
proposition Yonly through the intermediate inﬂuence of YonV:
p(D|Y)=/summationdisplay
Vp(D|V)p(V|Y) (14.10)
which is a kind of ‘Huygens principle’ for logic. To see the analogy, think of Yas a light
source which cannot be seen from D, but it illuminates various points V. Then the resulting
light arriving at Dis the sum of the Huygens wavelets p(D|V) with amplitudes p(V|Y).
The almost exact mathematical analogy between conditional information ﬂow and the ﬂowof light according to the Huygens principle of optics appears in statistical mechanics ofirreversible processes.
14.2 Sufﬁciency and information
Equation (14.9) has interesting consequences; suppose we wish to judge the plausibility of
some proposition Y, on the basis of knowledge of VandD. From the product rule (14.2),
p(DY|V)=p(Y|VD)p(D|V)=p(D|VY)p(Y|V) (14.11)
and, using (14.9), this reduces to
p(Y|VD)=p(Y|V). (14.12)
Thus, if Vis known, knowledge of Dis redundant and cannot help us in estimating
any other quantity. The reverse is not true, however; we could equally well use (14.9) in

<<<PAGE 461>>>

14 Simple applications of decision theory 429
another way:
p(VY|D)=p(Y|VD)p(V|D)=p(Y|D)p(V|YD). (14.13)
Combining this with (14.12), there results the following theorem.
Theorem
LetDbe a possible decision, given V. Then p(V|D)/negationslash=0, and
p(Y|V)=p(Y|D) if and only if p(V|D)=p(V|YD). (14.14)
In words: knowledge of Dis as good as knowledge of Vfor judgments about Yif and only
ifYis irrelevant for judgments about V,g i v e n D. Stated differently: in the ‘environment’
produced by knowledge of D, the probabilities for YandVare independent, i.e.
p(YV|D)=p(Y|D)p(V|D). (14.15)
In this case, in the literature of this ﬁeld Dis said to be a sufﬁcient statistic for judgments
about Y. We shall want to see whether this is in agreement with our earlier deﬁnitions of
sufﬁciency, made from a quite different point of view in Chapter 8.
Evidently, a decision rule which makes Da sufﬁcient statistic for judgments about the
signal Sis superior to one without this property, in that it tells us more about the signal.
However, such a rule does not necessarily exist. Equation (14.15) is a very restrictivecondition, since it must be satisﬁed for all values of Y,V,and all Dfor which p(D|V)/negationslash=0.
As you might guess from this, the concept of sufﬁciency is closely related to that of
information. The above deﬁnition of sufﬁciency could be stated equally well as: Dis a
sufﬁcient statistic for judgments about Yif it contains all the information about Ywhich
Vcontains. Since Dis determined from V, if it is not a sufﬁcient statistic, it necessarily
contains lessinformation about Ythan does V. In this statement, the term ‘information’
was used in a loose, intuitive sense; does it remain true if we adopt Shannon’s measure ofinformation?
Imagine that there are several mutually exclusive propositions Y
i, one of which must be
true. For brevity we use, as above, the notation/summationtext
Yf(Y)≡/summationtext
if(Yi). With a speciﬁc value
ofDgiven, the entropy which measures our information about the propositions Yiis
HD(Y)=−/summationdisplay
Yp(Y|D) log[ p(Y|D)], (14.16)
and its expectation over all values of Dis
HD(Y)=/summationdisplay
Dp(D|X)HD(Y). (14.17)
If
HC(Y)<HD(Y), (14.18)

<<<PAGE 462>>>

430 Part 2 Advanced applications
we say colloquially that Ccontains, ‘on the average’, more information about Ythan does
D. Note, however, that it may be otherwise for speciﬁc values of CandD.
Acquisition of new information can never increase H; let{Zi}be, for the moment, any
set of propositions and form the expression
HV(Z)−HDV(Z)=/summationdisplay
DV Zp(DV|X)p(Z|DV) log[ p(Z|DV)]
−/summationdisplay
VZp(V|X)p(Z|V) log[ p(Z|V)]
=/summationdisplay
DV Zp(DV|X)p(Z|DV) log/bracketleftbiggp(Z|DV)
p(Z|V)/bracketrightbigg
.(14.19)
Using the fact that on the positive real line log( x)≥(1−x−1), with equality if and only if
x=1, this becomes
HV(Z)−HDV(Z)≥/summationdisplay
DV Zp(DV|X)[p(Z|DV)−p(Z|V)]=0. (14.20)
Thus, HDV(Z)≤HV(Z), with equality if and only if (14.12) holds for all D,VandZfor
which p(DV|X)/negationslash=0.
But now, since (14.20) holds regardless of the meaning of DandV, we can conclude
equally well that, for all D,V,Z,
HD(Y)≥HDV(Z)≤HV(Z). (14.21)
Choosing Z=Y, we have in consequence of (14.12) HV(Y)=HDV(Y), so that
HV(Y)≤HD(Y), (14.22)
with equality if and only if (14.15) holds, i.e. if and only if Dis a sufﬁcient statistic as just
deﬁned. Thus, if by ‘information’ we mean minus the expectation of the entropy of Yover
the prior distribution of DorV,zero information loss in going from VtoDis equivalent
to sufﬁciency of D. Note that inequality (14.20) holds only for the expections of H, not for
theH. Acquisition of a speciﬁc piece of information (that an event previously considered
improbable had in fact occurred) may in some cases increase the entropy of Y. However,
this is an improbable situation, and on the average the entropy can only be lowered byadditional information. This shows again that the term ‘information’ is not a happy choiceof words to describe entropy expressions. In spite of the entropy increases, the situationjust described could hardly be called one of less information in the colloquial sense of that
word; but rather one of less certainty .
14.3 Loss functions and criteria of optimum performance
In order to say that one decision rule is better than another, we need some speciﬁc criterion
of what we want our detection system to accomplish. The criterion will vary with theapplication, and obviously no single decision rule can be best for all purposes. But our

<<<PAGE 463>>>

14 Simple applications of decision theory 431
discussion in Chapter 13 will apply, almost unchanged, in this slightly different language.
A very general type of criterion is obtained by assigning a loss function L (D,S) which
represents our judgment of how serious it is to make decision Dwhen signal Sis in fact
present.
In the case where are only two possible signals, S0=0 (i.e. no signal), and S1>0, and
consequently two possible decisions D0,D1about the signal, there are two types of error,
the false alarm A=(D1,S0) and the false rest R=(D0,S1). In some applications, one type
of error might be much more serious than the other.
Suppose that a false rest is considered ten times as serious as is a false alarm, while
a correct decision of either type represents no ‘loss’. We could then take L(D0,S0)=
L(D1,S1)=0,L(D0,S1)=10,L(D1,S0)=1. Whenever the possible signals and the
possible decisions form discrete sets, the loss function becomes a loss matrix . In the above
example,
Lij=/parenleftbigg01 0
10/parenrightbigg
. (14.23)
Instead of assigning arbitrarily a certain loss value to each possible type of detection error,
we may consider information loss by the assignment L(D,S)=− log[p(S|D)]. This is
somewhat more difﬁcult to manipulate, because now L(D,S) depends on the decision rule.
A decision rule which minimizes information loss is one which makes the decision in somesense as close as possible to being a sufﬁcient statistic for judgments about the signal. In
exactly what sense seems never to have been clariﬁed. The conditional loss L (S) is the
expected loss incurred when the speciﬁc signal Sis present:
L(S)=/summationdisplay
DL(D,S)p(D|S), (14.24)
which may in turn be expressed in terms of the decision rule and the properties of the noise
by using (14.10). What is often called colloquially the ‘average loss’ is the expectation ofthe conditional loss over all possible signals:
/angbracketleftL/angbracketright=/summationdisplay
SL(S)p(S|X). (14.25)
Two different criteria of optimal performance now suggest themselves:
The minimax criterion. For a given decision rule p(D|V), consider the conditional loss L(S) for
all possible signals, and let [ L(S)]maxbe the maximum value attained by L(S). We seek that decision
rule for which [ L(S)]maxis as small as possible. As we noted in Chapter 13, this criterion concentrates
attention on the worst possible case, regardless of the probability for occurrence of this case, and itis thus in a sense too conserv ative. However, it gives some the psychological comfort that it does
not involve the prior probabilities for the different signals p(S|X), and therefore it can be applied by
persons who, under the handicap of orthodox training, have a mental hangup against prior probabilities.The Bayes criterion. We seek that decision rule for which the expected loss /angbracketleftL/angbracketrightis minimized. In
order to apply this, a prior distribution p(S|X) must be available.

<<<PAGE 464>>>

432 Part 2 Advanced applications
Other criteria were proposed before the days of Wald’s decision theory. In the Neyman–
Pearson theory, we ﬁx the probability for occurrence of one type of error at some small value/epsilon1, and then minimize the probability δof the other type of error subject to this constraint.
1
Arnold Siegert’s ‘ideal observer’ minimizes the total probability for error ( /epsilon1+δ).
After having invented many different such ad hoc criteria from various viewpoints, and
arguing their relative merits on philosophical grounds, the basic mathematical identity of allthese criteria came as quite a surprise to the early workers in this ﬁeld. We shall see belowthat all of them are special cases of the Bayes criterion, for particular prior probabilities.
Let us ﬁnd the Bayes solution, as it was rationalized in decision theory. Substituting in
succession (14.24), (14.10), and (14.9) into (14.25), we obtain for the expected loss
/angbracketleftL/angbracketright=/summationdisplay
DV/bracketleftBigg/summationdisplay
SL(D,S)p(VS|X)/bracketrightBigg
p(D|V). (14.26)
IfL(D,S) is a deﬁnite function independent of p(D|V) (this assumption excludes for
the moment the information loss function), there is no function p(D|V) for which this
expression is stationary in the sense of the calculus of variations. We then minimize /angbracketleftL/angbracketright
merely by choosing for each possible Vthat decision D1(V) for which the coefﬁcient in
(14.26)
K(D,V)≡/summationdisplay
SL(D1,S)p(VS|X) (14.27)
is a minimum. Thus, we adopt the decision rule
p(D|V)=δ(D,D1). (14.28)
In general, there will be only one such D1, and the best decision rule is nonrandom. However,
in case of ‘degeneracy’, K(D1,V)=K(D2,V), any randomized rule of the form
p(D|V)=aδ(D,D1)+bδ(D,D2),a+b=1, (14.29)
is just as good by the criterion being used. This degeneracy occurs at ‘threshold’ values of
V,where we change from one decision to another.
14.4 A discrete example
Consider the case already mentioned, where there are two possible signals, S0andS1, and
a loss matrix
Lij=/parenleftbiggL00L01
L10L11/parenrightbigg
=/parenleftbigg0Lr
La0/parenrightbigg
, (14.30)
1For example, we suspect that at an Early Warning Radar Installation, the primary constraint might be that the Commanding
Ofﬁcer shall not be roused out of bed by a false alarm more often than once per month, and, subject to that requirement, weminimize the probability for a false rest.

<<<PAGE 465>>>

14 Simple applications of decision theory 433
where La,Lrare the losses incurred by a false alarm and a false rest, respectively. Then
K(D0,V)=L01p(VS1|X)=Lrp(VS1|X),
K(D1,V)=L10p(VS0|X)=Lap(VS0|X),(14.31)
and the decision rule that minimizes /angbracketleftL/angbracketrightis
choose D1if(VS1|X)
p(VS0|X)>La
Lr,
choose D0ifp(VS1|X)
p(VS0|X)<La
Lr,
choose either at random in case of equality.(14.32)
If the prior probabilities for a signal and no signal are
p(S1|X)=p, p(S0|X)=q=1−p, (14.33)
respectively, the decision rule becomes
choose D1ifp(V|S1)
p(V|S0)>qLa
pLr,etc. (14.34)
The left-hand side of (14.34) is a likelihood ratio, which depends only on the pdf assigned
to the noise, and is the quantity which should be computed by the optimum receiver ac-cording to the Bayes criterion.
This same quantity is the essential one regardless of the assumed loss function and
regardless of the probability for the occurrence of the signal; these affect only the thresholdof detection. Furthermore, if the receiver merely computes this likelihood ratio and deliversit at the output without making any decision, it provides us with all the information we needto make optimum decisions in the Bayes sense. Note the generality of this result, which isimportant for applications; no assumptions were needed as to the type of signal, linearityof the system, or properties of the noise.
We now work out, for purposes of illustration, the decision rules and their degree of
reliability, for several of the above criteria, in the simplest possible problem. We have alinear system in which the voltage is observed at a single instant. We are to decide whethera signal, which can have only amplitude S
1, is present in noise. We assign a Gaussian pdf
for the noise with variance σ2:
W(N)=1√
2πσ2exp/braceleftbigg
−N2
2σ2/bracerightbigg
. (14.35)
The likelihood ratio in (14.34) then becomes
p(V|S1)
p(V|S0)=W(V−S1)
W(V)=exp/braceleftbigg2VS1−S2
1
2σ2/bracerightbigg
, (14.36)

<<<PAGE 466>>>

434 Part 2 Advanced applications
and, since this is a monotonic function of V, the Bayesian decision rule, Vbcan be written as
choose/parenleftbiggD1
D0/parenrightbigg
when V/parenleftbigg>
</parenrightbigg
Vb, (14.37)
with
Vb
σ=1
2s/bracketleftbigg
2 log/parenleftbiggqLa
pLr/parenrightbigg
+s2/bracketrightbigg
=vb, (14.38)
in which
s≡S1
σis the voltage signal-to-noise ratio, (14.39a)
and
v≡V
σis the normalized voltage. (14.39b)
Now we ﬁnd the probability for a false rest:
p(R|X)=p(D0S1|X)
=p/summationdisplay
Vp(D0|V)p(V|S1)
=p/integraldisplayVb
−∞dVW (V−S1)
=p/Phi1(vb−s)(14.40)
and for a false alarm
p(A|X)=p(D1S0|X)
=q/summationdisplay
Vp(D1|V)p(V|S0)
=q/integraldisplay∞
VbdVW (V)
=q[1−/Phi1(vb)].(14.41)
Here/Phi1(x) is the cumulative normal distribution function and, as shown in (7.2), it may be
computed from an error function:
/Phi1(x)=1√
2π/integraldisplayx
−∞dtexp{−t2/2}=1
2[1+erf(x)]. (14.42)
Forx>2, a good approximation is
1−/Phi1(x)≈exp{−x2/2}
x√
2π. (14.43)
As a numerical example, if Lr=10La,q=10p, these expressions reduce to
p(A|X)=10p(R|X)=10
11/bracketleftBig
1−/Phi1/parenleftBigs
2/parenrightBig/bracketrightBig
. (14.44)

<<<PAGE 467>>>

14 Simple applications of decision theory 435
The probability for a false alarm is less than 0.027, and for a false rest less than 0.0027 for
s>4. For s>6, these numbers become 1 .48×10−3,1.48×10−4,respectively.
Let us see what the minimax criterion would give in this problem. The conditional losses
are
L(S0)=La/summationdisplay
Vp(D1|V)p(V|S0)=La/integraldisplay∞
−∞dVp(D1|V)W(V),
L(S1)=Lr/summationdisplay
Vp(D0|V)p(V|S1)=Lr/integraldisplay∞
−∞dVp(D0|V)W(V−S1).(14.45)
Writing f(V)≡p(D1|V)=1−p(D0|V), the only restriction on f(V)i s0≤f(V)≤1.
Since La,Lr, and W(V) are all positive, a change δf(V) in the neighborhood of any
given point Vwill always increase one of the quantities in (14.45) and decrease the other.
Thus, when the maximum L(S) has been made as small as possible, we will certainly have
L(S0)=L(S1), and the problem is thus to minimize L(S0) subject to this constraint.
Suppose that for some particular p(S|X) the Bayes decision rule happened to give L(S0)=
L(S1). Then this particular solution must be identical with the minimax solution, for with the
above constraint,/angbracketleftL/angbracketright=[L(S)]max, and, if the Bayes solution minimizes /angbracketleftL/angbracketrightwith respect
to all variations δf(V) in the decision rule, it a fortiori minimizes it with respect to the
smaller class of variations which keep L(S0)=L(S1). Therefore the decision rule will have
the same form as before: there is a minimax threshold Vmsuch that
f(V)=/braceleftBigg
0V<Vm
1V>Vm.(14.46)
Any change in Vmfrom the value which makes L(S0)=L(S1) necessarily increases one or
the other of these quantities. The equation determining Vmis therefore
La/integraldisplay∞
VmdVW (V)=Lr/integraldisplayVm
−∞dVW (V−S1), (14.47)
or, in terms of normalized quantities,
La[1−/Phi1(vm)]=Lr/Phi1(vm−s). (14.48)
Note that (14.40) and (14.41) give the conditional probabilities for a false rest and false alarm
for any decision rule of type (14.46), regardless of whether the threshold was determined
from (14.38) or not; for the arbitrary threshold V0
p(R|S1)=p(V<V0|S1)=/Phi1(v0−s)
p(A|S0)=p(V>V0|S0)=1
2[1−/Phi1(v0)].(14.49)
From (14.38) we see that there is always a particular ratio ( p/q) which makes the Bayes
threshold Vbequal to the minimax threshold Vm. For values of ( p/q) other than this worst
value, the Bayes criterion gives a lower expected loss than does the minimax, although oneof the conditional losses L(S
0),L(S1) will be greater than the minimax value.

<<<PAGE 468>>>

436 Part 2 Advanced applications
02
Normalized voltage, v=V/S0.00.51.0
...............................
L(S0)/angbracketleftL/angbracketright,p=1/4/angbracketleftL/angbracketright,p=1/2/angbracketleftL/angbracketright,p=3/4L(S1)
13
↓
Fig. 14.1. Various risks as a function of voltage for Lr=1,La=2,p=1/4,1/2,3/4.
These relations and several previous remarks are illustrated in Figure 14.1, in which
we plot the conditional losses L(S0),L(S1) and the expected loss /angbracketleftL/angbracketrightas functions of the
threshold V0, for the case La=(3/2)Lr,p=q=1/2. The minimax threshold is at the
common crossing point of these curves, while the Bayes threshold occurs at the lowestpoint of the/angbracketleftL/angbracketrightcurve.
One sees how the Bayes threshold moves as the ratio ( p/q) is varied, and in particular
that the value of ( p/q) which makes V
b=Vmalso leads to the maximum value of the /angbracketleftL/angbracketrightmin
obtained by the Bayes criterion. Thus we could also deﬁne a ‘maximin’ criterion; ﬁrst ﬁnd
the Bayes decision rule which gives minimum /angbracketleftL/angbracketrightfor a given p(S|X), then vary the prior
probability p(S|X) until the maximum value of /angbracketleftL/angbracketrightminis attained. The decision rule thus
obtained is identical with the one resulting from the minimax criterion; this is the worstpossible prior probability, in the sense that the most pessimistic rule is the best that can bedone.
The Neyman–Pearson criterion is easily discussed in this example. Suppose the condi-
tional probability for a false alarm p(D
1|S0) is held ﬁxed at some value /epsilon1, and we wish
to minimize the conditional probability p(D0|S1) of a false rest, subject to this constraint.
Now the Bayes criterion minimizes the expected loss
/angbracketleftL/angbracketright=pLrp(D0|S1)+qLap(D1|S0) (14.50)
with respect to any variation δp(D|V) in the decision rule. In particular, therefore, it min-
imizes it with respect to the smaller class of variations which hold p(D1|S0) constant at

<<<PAGE 469>>>

14 Simple applications of decision theory 437
the value ﬁnally obtained. Thus it minimizes p(D0|S1) with respect to these variations and
solves the Neyman–Pearson problem; we need only choose the particular value of the ratio(qL
a/pLr) which results in the assumed value of /epsilon1according to (14.38) and (14.41).
We ﬁnd for the Neyman–Pearson threshold, from (14.49),
/Phi1(vnp)=1−/epsilon1, (14.51)
and the conditional probability for detection is
p(D1|S1)=1−p(D0|S1)=/Phi1(s−vnp). (14.52)
If/epsilon1=10−3, a detection probability of 99% or better is attained for s>6.
It is important to note that these numerical examples depend critically on our noise
pdf assignment. If we have prior information about the noise beyond its ﬁrst and secondmoments, the noise pdf expressing this may not be Gaussian, and the actual situation maybe either more or less favorable than indicated by the above relations.
It is well known that in one sense noise with a Gaussian frequency distribution is the
worst possible kind; because of its maximum entropy properties, it can obscure a weaksignal more completely than can any other noise of the same average power. On the otherhand, Gaussian noise is a very favorable kind from which to extract a fairly strong signal,because the probability that the noise will exceed a few times the RMS value σ=/radicalbig
/angbracketleftN2/angbracketright
becomes vanishingly small. Consequently, the probability for making an incorrect decisionon the presence or absence of a signal goes to zero very rapidly as the signal strength isincreased. The high reliability of operation found above for s>6 would not be found for
noise possessing a frequency distribution with wider tails.
The type of noise frequency distribution to be expected in any particular case depends,
of course, on the physical mechanism which gives rise to the noise. When the noise is theresult of a large number of small, independent effects, the Landon derivation of Chapter 7and the central limit theorem both tell us that a Gaussian frequency distribution for the totalnoise is by far the most likely to be found, regardless of the nature of the individual sources.
All of these apparently different decision criteria lead to a probability ratio test. In the
case of a binary decision, it took the simple form (14.32). Of course, any decision processcan be broken down into successive binary decisions, so this case really has the whole storyin it. All the different criteria amounted, in the ﬁnal analysis, only to different philosophiesabout how you choose the threshold value at which you change your decision.
14.5 How would our robot do it?
Now, let’s see how this problem appears from the viewpoint of our robot. The rather long
arguments we had to go through above (and even they are very highly condensed fromthe original literature) to obtain the result are due only to the orthodox view which insistson looking at the problem backwards, i.e. on concentrating attention on the ﬁnal decisionrather than on the inference process which logically has to precede it.

<<<PAGE 470>>>

438 Part 2 Advanced applications
To the robot, if our job is to make the best possible decision as to whether the signal
is present, the obvious thing we must do is to calculate the probability that the signal is
present, conditional on all the evidence at hand. If there are only two possibilities, S0,S1,
to be taken into account, then, after we have seen voltage V,the posterior odds on S1are,
from (4.7),
O(S1|VX)=O(S1|X)p(V|S1)
p(V|S0). (14.53)
If we give the robot the loss function (14.31) and ask it to make the decision which minimizes
the expected loss, it will evidently use the decision rule
choose D1ifO(S1|V)=p(S1|V)
p(S0|V)>La
Lr, (14.54)
etc. But from the product rule, p(VS1|X)=p(S1|V)p(V|X),p(VS0|X)=p(S0|V)
p(V|X), and (14.54) is identical with (14.32). So, just from looking at this problem the
other way around, our robot obtains the same ﬁnal result in just two lines!
You see that all this discussion of strategies, admissibility, conditional losses, etc. was
unnecessary. Except for the introduction of the loss function at the end, there is nothingin the actual functional operation of Wald’s decision theory that isn’t contained already inbasic probability theory, if we will only use it in the full generality given to it by Laplace
and Jeffreys.
14.6 Historical remarks
This comparison shows why the development of decision theory has, more than any other
single factor, touched off our ‘Bayesian revolution’ in statistical thought. For some 50 years,Harold Jeffreys tried valiantly to explain the great advantages of the Laplace methods tostatisticians, and his efforts met only with a steady torrent of denials and ridicule. It was thena real irony that the work of one of the most respected of ‘orthodox’ statisticians (AbrahamWald), which was hailed, very properly, as a great advance in statistical practice, turned outto give, after very long and complicated arguments, exactly the same ﬁnal results that theLaplace methods give you immediately. Wald showed in great generality what we have justillustrated by one simple example.
The only proper conclusion, as a few recognized at once, is that the supposed distinction
between statistical inference and probability theory was entirely artiﬁcial – a tragic error ofjudgment which has wasted perhaps 1000 man-years of our best mathematical talent in the
pursuit of false goals.
In the works cited, addressed to electrical engineers, the viewpoint of Middleton and
van Meter was that of the Neyman–Pearson and Wald decision theories. At about thesame time, Herbert Simon expounded the Neyman–Pearson viewpoint to economists. Thewriter collaborated with David Middleton for a short time while he was writing his largework, and tried to persuade him of the superiority of the straight Bayesian approach to

<<<PAGE 471>>>

14 Simple applications of decision theory 439
decision theory. The success of the effort may be judged by comparing Middleton (1960,
Chap. 18) – particularly its length – with our exposition deriving (14.54). It seems thatpersons with orthodox training had received such strong anti-Bayesian indoctrination thatthey were locked in an inﬁnite regress situation; although they could not deny the resultsthat Bayesians got on any speciﬁc problem, they could never believe that Bayesian methodswould work on the next problem until that next solution was also presented to them.
14.6.1 The classical matched ﬁlter
A funny thing happened in the history of this subject. In the 1930s, electrical engineers
knew nothing whatsoever about probability theory; they knew about signal to noise ratios.Receiver input circuits were designed for many years on the basis that signal to noise ratiowas maximized by empirical trial and error. Then a general theoretical result was found: ifyou take the ratio of (peak signal)
2to mean-square noise, and ﬁnd, as a variational principle,
the design of input stages of the receiver which will maximize it, this turned out to have ananalytically neat and useful solution. It is now called the classical matched ﬁlter , and it has
been discovered independently by dozens of people.
To the best of our knowledge, the ﬁrst person to derive this matched ﬁlter solution was
the late Professor W. W. Hansen of Stanford University. The writer was working with him,beginning in May 1942, on problems of radar detection. Shortly before then, Hansen hadcirculated a little memorandum dated 1941, in which he gave this solution for the design ofthe optimum response curve for the recei verﬁrst stage. Years later, I was thinking about an
entirely different problem (an optimum antenna pattern for a radar system to maximize the
ratio (signal)/(ground clutter response)), and when I ﬁnally got the solution, I recognized itas the same result that Bill Hansen had shown me many years before.
Throughout the 1950s, almost every time one opened a journal concerned with these
problems, somebody else had a paper announcing the discovery of the same solution. Thesituation was satirized in a famous editorial by Peter Elias (1958), entitled ‘Two famouspapers’. He suggested that it was high time that people stopped rediscovering the easiestsolution, and started to think about the many harder problems still in need of solution.
But also in the 1950s people became more sophisticated about the way they handled their
detection problems, and they started using this wonderful new tool, statistical decision the-ory, to see if there were still better ways of handling these design problems. The strangething happened that in the case of a linear system with Gaussian noise, the optimum solutionwhich decision theory leads you to turns out to be exactly the same old classical matchedﬁlter! At ﬁrst glance, it was very surprising that two approaches so entirely different con-ceptually should lead to the same solution. But note that our robot represents a viewpointfrom which it is obvious that the two lines of argument would have to give the same result.
To our robot, it is obvious that the best analysis we can make of the problem will always
be one in which we calculate the probabilities that the various signals are present by means
of Bayes’ theorem. But let us apply Bayes’ theorem in the logarithmic form of Chapter 4.If we now let S
0andS1stand for numerical values giving the amplitude of two possible

<<<PAGE 472>>>

440 Part 2 Advanced applications
signals as a function of V, the evidence forS1is increased by
log/bracketleftbiggp(V|S1)
p(V|S0)/bracketrightbigg
=(V−S0)2−(V−S1)2
2/angbracketleftσ2/angbracketright=const.+(S1−S0)
/angbracketleftσ2/angbracketrightV. (14.55)
In the case of a linear system with Gaussian noise, the observed voltage is itself just a linear
function of the posterior probability measured in decibels. So, they are essentially just twodifferent ways of formulating the same problem. Without recognizing it, we had essentiallysolved this problem already in the Bayesian hypothesis testing discussion of Chapter 4.
In England, P. M. Woodword had perceived much of this correctly in the 1940s – but he
was many years ahead of his time. Those with conventional statistical training were unableto see any merit in his work, and simply ignored it. His book (Woodword, 1953) is highlyrecommended reading; although it does not solve any of our current problems, its thinkingis still in advance of some current literature and practice.
We have seen that the other non-Bayesian approaches to the theory all amounted to
different philosophies of how you choose the threshold at which you change your decision.Because of the fact that they all lead to the same probability ratio test, they must necessarilyall be derivable from Bayes’ theorem.
The problem just examined by several different decision criteria is, of course, the simplest
possible one. In a more realistic problem, we will observe the voltage V(t) as a function of
time, perhaps several voltages V
1(t),V2(t),...in several different channels. We may have
many different possible signals Sa(t),Sb(t),...to distinguish and correspondingly many
possible decisions. We may need to decide not only whether a given signal is present, but
also to make the best estimates of one or more signal parameters (such as intensity, startingtime, frequency, phase, rate of frequency modulation, etc.). Therefore, just as in the problemof quality control discussed in Chapter 4, the details can become arbitrarily complicated.But these extensions are, from the Bayesian viewpoint, straightforward in that they requireno new principles beyond those already given, only mathematical generalization.
We shall return to some of these more complicated problems of detection and ﬁltering
when we take up frequency/shape estimation; but for now let’s look at another elementarykind of decision problem. In the ones just discussed, we needed Bayes’ theorem, but notmaximum entropy. Now we examine a kind of decision problem where we need maximumentropy, but not Bayes’ theorem.
14.7 The widget problem
This problem was ﬁrst propounded at a symposium held at Purdue University in November,
1960 – at which time, however, the full solution was not known. This was worked out later
(Jaynes, 1963c), and some numerical approximations were improved in the computer workof Tribus and Fitts (1968).
The widget problem has proved to be interesting in more respects than originally realized.
It is a decision problem in which there is no occasion to use Bayes’ theorem, because no‘new’ information is acquired. Thus it would be termed a ‘no data’ decision problem in the

<<<PAGE 473>>>

14 Simple applications of decision theory 441
sense of Chernoff and Moses (1959). However, at successive stages of the problem we have
more and more prior information; and digesting it by maximum entropy leads to a sequenceof prior probability assignments, which lead to different decisions. Thus it is an exampleof the ‘pure’ use of maximum entropy, as in statistical mechanics. It is hard to see howthe problem could be formulated mathematically at all without use of maximum entropy, orsome other device (such as the method of Darwin and Fowler (Fowler, 1929) in statisticalmechanics, or the ‘method of the most probable distribution’ dating back to Boltzmann(1871)) which turns out in the end to be mathematically equivalent to maximum entropy.
The problem is interesting also in that we can see a continuous gradation from decision
problems so simple that common sense tells us the answer instantly, with no need for anymathematical theory, through problems more and more involved so that common sensehas more and more difﬁculty in making a decision, until ﬁnally we reach a point wherenobody has yet claimed to be able to see the right decision intuitively, and we require themathematics to tell us what to do.
Finally, the widget problem turns out to be very close to an important real problem faced
by oil prospectors. The details of the real problem are shrouded in proprietary caution; butit is not giving away any secrets to report that, a few years ago, the writer spent a week atthe research laboratories of one of our large oil companies, lecturing for over 20 hours onthe widget problem. We went through every part of the calculation in excruciating detail –with a room full of engineers armed with calculators, checking up on every stage of thenumerical work.
Here is the problem: Mr Ais in charge of a widget factory, which proudly advertises that it
can make delivery in 24 hours on any size order. This, of course, is not really true, and MrA’s
job is to protect, as best he can, the advertising manager’s reputation for veracity. This meansthat each morning he must decide whether the day’s run of 200 widgets will be painted red,yellow or green. (For complex technological reasons, not relevant to the present problem,only one color can be produced per day.) We follow his problem of decision through severalstages of increasing knowledge.
Stage 1
When he arrives at work, Mr Achecks with the stock room and ﬁnds that they now have in
stock 100 red widgets, 150 yellow, and 50 green. His ignorance lies in the fact that he doesnot know how many orders for each type will come in during the day. Clearly, in this state ofignorance, Mr Awill attach the highest signiﬁcance to any tiny scrap of information about
orders likely to come in today; and if no such scraps are to be had, we do not envy Mr Ahis
job. Still, if a decision must be made here and now on no more information than this, hiscommon sense will probably tell him that he had better build up that stock of green widgets.
Stage 2
MrA, feeling the need for more information, calls up the front ofﬁce and asks, ‘Can you
give me some idea of how many orders for red, yellow, and green widgets are likely to come

<<<PAGE 474>>>

442 Part 2 Advanced applications
Table 14.1. Summary of four stages of the widget problem.
Stage R Y G Decision
1. In stock 100 150 50 G
2. Av. daily order total 50 100 10 Y3. Av. individual order 75 10 20 R4. Speciﬁc order 40 ?
in today?’ They reply, ‘Well, we don’t have the breakdown of what has been happening
each day, and it would take us a week to compile that information from our ﬁles. But we dohave a summary of the total sales last year. Over the last year, we sold a total of 13 000 red,26 000 yellow, and 2600 green. Figuring 260 working days, this means that last year wesold an average of 50 red, 100 yello w, and 10 green each day. ’I fM r Aponders this new
information for a few seconds, I think he will change his mind, and decide to make yellowones today.
Stage 3
The man in the front ofﬁce calls Mr Aback and says, ‘It just occurred to me that we do have
a little more information that might possibly help you. We have at hand not only the totalnumber of widgets sold last year, but also the total number of orders we processed. Last yearwe got a total of 173 orders for red, 2600 for yellow, and 130 for green. This means that thecustomers who use red widgets order, on the average, 13 000 /173=75 widgets per order,
while the average order for yellow and green were 26 000 /2600=10, and 2600 /130=20,
respectively.’ These new data do not change the expected daily demand; but, if Mr Ais very
shrewd and ponders it very hard, I think he may change his mind again, and decide to makered ones today.
Stage 4
MrAis just about to give the order to make red widgets when the front ofﬁce calls him
again to say, ‘We just got word that a messenger is on his way here with an emergency orderfor 40 green widgets.’ Now, what should he do? Up to this point, Mr A’s decision problem
has been simple enough so that reasonably good common sense will tell him what to do.But now he is in trouble; qualitative common sense is just not powerful enough to solve hisproblem, and he needs a mathematical theory to determine a deﬁnite optimum decision.
Let’s summarize all the above data in Table 14.1. In the ﬁnal column, we give the
decision that seemed intuitively to be the best one before we had worked out the math-ematics. Do other people agree with this intuitive judgment? Professor Myron Tribushas put this to a test by giving talks about this problem, and taking votes from the au-dience before the solution is given. We quote his ﬁndings as given in Tribus and Fitts

<<<PAGE 475>>>

14 Simple applications of decision theory 443
(1968). They use D1,D2,D3,D4to stand for the optimum decisions in stages 1, 2, 3, 4,
respectively:
Before taking up the formal solution, it may be reported that Jaynes’ widget problem has been
presented to many gatherings of engineers who have been asked to vote on D1,D2,D3,D4. There is
almost unanimous agreement about D1. There is about 85% agreement on D2. There is about 70%
agreement on D3, and almost no agreement on D4. One conclusion stands out from these informal
tests; the average engineer has remarkably good intuition in problems of this kind. The majority voteforD
1,D2,andD3has always been in agreement with the formal mathematical solution. However,
there has been almost universal disagreement over how to defend the intuitive solution. That is, whilemany engineers could agree on the best course of action, they were much less in agreement on why
that course was the best one.
14.7.1 Solution for Stage 2
Now, how are we to set up this problem mathematically? In a real life situation, evidently,
the problem would be a little more complicated than indicated so far, because what Mr A
does today also affects how serious his problem will be tomorrow. That would get us intothe subject of dynamic programming. But for now, just to keep the problem simple, weshall solve only the truncated problem in which he makes decisions on a day to day basiswith no thought of tomorrow.
We have just to carry out the steps enumerated in Section 13.11. Since Stage 1 is almost
too trivial to work with, consider the problem of Stage 2. Firstly, we deﬁne our underlyinghypothesis space by enumerating the possible ‘states of nature’ θ
jthat we will consider.
These correspond to all possible order situations that could arise; if Mr Aknew in advance
exactly how many red, yellow, and green widgets would be ordered today, his decisionproblem would be trivial. Let n
1=0,1,2,...be the number of red widgets that will be
ordered today, and similarly n2,n3for yellow and green, respectively. Then, any conceivable
order situation is given by specifying three non-negative integers {n1,n2,n3}. Conversely,
every ordered triple of non-negative integers represents a conceivable order situation.
Next, we are to assign prior probabilities p(θj|X)=p(n1n2n3|X) to the states of nature,
which maximize the entropy of the distribution subject to the constraints of our prior knowl-edge. We solved this problem in general in Chapter 11, Eqs. (11.39)–(11.50); and so we justhave to translate the result into our present notation. The index ionx
iin Chapter 11 now cor-
responds to the three integers n1,n2,n3; the function fk(xi) also corresponds to the ni, since
the prior information at this stage will be used to ﬁx the expectations /angbracketleftn1/angbracketright,/angbracketleftn2/angbracketright,/angbracketleftn3/angbracketrightof or-
ders for red, yellow, and green widgets at 50, 100, 10, respectively. With three constraints wewill have three Lagrange multipliers λ
1,λ2,λ3, and the partition function (11.45) becomes
Z(λ1,λ2,λ3)=∞/summationdisplay
n1=0∞/summationdisplay
n2=0∞/summationdisplay
n3=0exp{−λ1n1−λ2n2−λ3n3}
=3/productdisplay
i=1(1−exp{−λi})−1.(14.56)

<<<PAGE 476>>>

444 Part 2 Advanced applications
Theλiare determined from (11.46):
/angbracketleftni/angbracketright=−∂log(Z)
∂λi=1
exp{λi}−1. (14.57)
The maximum entropy probability assignment (11.41) for the states of nature θj={n1n2n3}
therefore factors:
p(n1n2n3)=p1(n1)p2(n2)p3(n3) (14.58)
with
pi(ni)=(1−exp{−λi})e x p{−λini},ni=1,2,3...
=1
/angbracketleftni/angbracketright+1/bracketleftbigg/angbracketleftni/angbracketright
/angbracketleftni/angbracketright+1/bracketrightbiggni
.(14.59)
Thus, in Stage 2, Mr A’s state of knowledge about today’s orders is given by three
exponential distributions:
p1(n1)=1
51/parenleftbigg50
51/parenrightbiggn1
, p2(n2)=1
101/parenleftbigg100
101/parenrightbiggn2
, p3(n3)=1
11/parenleftbigg10
11/parenrightbiggn3
.
(14.60)
Applications of Bayes’ theorem to digest new evidence Eis absent because there is no
new evidence. Therefore, the decision must be made directly from the prior probabilities(14.60), as is always the case in statistical mechanics.
So, we now proceed to enumerate the possible decisions. These are D
1≡make red ones
today, D2≡make yellow ones, D3≡make green ones, for which we are to introduce a
loss function L(Di,θj). Mr A’s judgment is that there is no loss if all orders are ﬁlled today;
otherwise, the loss will be proportional to – and in view of the invariance of the decisionrule under proper linear transformations that we noted at the end of Chapter 13, we may aswell take it equal to – the total number of unﬁlled orders.
The present stock of red, yellow, and green widgets is S
1=100, S2=150, S3=50,
respectively. On decision D1(make red widgets) the available stock S1will be increased
by the day’s run of 200 widgets, and the loss will be
L(D1;n1,n2,n3)=R(n1−S1−200)+R(n2−S2)+R(n3−S3), (14.61)
where R(x) is the ramp function
R(x)≡/braceleftBigg
xx≥0
0x≤0.(14.62)
Likewise, on decisions D2,D3, the loss will be
L(D2;n1,n2,n3)=R(n1−S1)+R(n2−S2−200)+R(n3−S3), (14.63)
L(D3;n1,n2,n3)=R(n1−S1)+R(n2−S2)+R(n3−S3−200). (14.64)

<<<PAGE 477>>>

14 Simple applications of decision theory 445
So, if decision D1is made, the expected loss will be
/angbracketleftL/angbracketright1=/summationdisplay
nip(n1n2n3)L(D1;n1,n2,n3)
=∞/summationdisplay
n1=0p1(n1)R(n1−S1−200)
+∞/summationdisplay
n2=0p2(n2)R(n2−S2)
+∞/summationdisplay
n3=0p3(n3)R(n3−S3),(14.65)
and similarly for D2,D3. The summations are elementary, giving
/angbracketleftL/angbracketright1=/angbracketleftn1/angbracketrightexp{−λ1(S1+200)}+/angbracketleft n2/angbracketrightexp{−λ2S2}+/angbracketleft n3/angbracketrightexp{−λ3S3},
/angbracketleftL/angbracketright2=/angbracketleftn1/angbracketrightexp{−λ1S1}+/angbracketleft n2/angbracketrightexp{−λ2(S2+200)}+/angbracketleft n3/angbracketrightexp{−λ3S3},
/angbracketleftL/angbracketright3=/angbracketleftn1/angbracketrightexp{−λ1S1}+/angbracketleft n2/angbracketrightexp{−λ2S2}+/angbracketleft n3/angbracketrightexp{−λ3(S3+200)},(14.66)
or, inserting numerical values,
/angbracketleftL/angbracketright1=0.131+22.48+0.085=22.70,
/angbracketleftL/angbracketright2=6.902+3.073+0.085=10.6,
/angbracketleftL/angbracketright3=6.902+22.48+4×10−10=29.38,(14.67)
showing a strong preference for decision D2≡‘make yellow ones today’, as common sense
had already anticipated.
Physicists will recognize that Stage 2 of Mr A’s decision problem is mathematically the
same as the theory of harmonic oscillators in quantum statistical mechanics. There is stillanother engineering application of the harmonic oscillator equations, in some problems ofmessage encoding, to be noted when we take up communication theory. We are trying toemphasize the generality of this theory, which is mathematically quite old and well-known,but which has been applied in the past only in some specialized problems in thermodynamics.This general applicability can be seen only after we are emancipated from the orthodox viewof probability.
14.7.2 Solution for Stage 3
In Stage 3 of Mr A’s problem we have some additional pieces of information: the average
individual orders for red, yellow, and green widgets. To take account of this new information,
we need to go down into a deeper hypothesis space; set up a more detailed enumeration of thestates of nature in which we take into account not only the total orders for each type, but alsothe breakdown into individual orders. We could have done this also in Stage 2, but since atthat stage there was no information available bearing on this breakdown, it would have addednothing to the problem (the subtle difference that this makes after all will be noted later).

<<<PAGE 478>>>

446 Part 2 Advanced applications
In Stage 3, a possible state of nature can be described as follows. We receive u1individual
orders for one red widget each, u2orders for two red widgets each, ...,urindividual orders
forrred widgets each. Also, we receive vyorders for yyellow widgets each, and wg
orders for ggreen widgets each. Thus, a state of nature is speciﬁed by an inﬁnite number
of non-negative integers
θ={u1···;v1···;w1···}, (14.68)
and conversely every such set of integers represents a conceivable state of nature, to which
we assign a probability p(u1···;v1···;w1···).
Today’s total demands for red, yellow, and green widgets are, respectively,
n1=∞/summationdisplay
r=1rur, n2=∞/summationdisplay
y=1yvy, n3=∞/summationdisplay
g=1gwg, (14.69)
the expectations of which were given in Stage 2 as /angbracketleftn1/angbracketright=50,/angbracketleftn2/angbracketright=100,/angbracketleftn3/angbracketright=10. The
total number of individual orders for red, yellow, and green widgets are, respectively,
m1=∞/summationdisplay
r=1ur, m2=∞/summationdisplay
y=1vy, m3=∞/summationdisplay
g=1wg, (14.70)
and the new feature of Stage 3 is that /angbracketleftm1/angbracketright,/angbracketleftm2/angbracketright,/angbracketleftm3/angbracketrightare also known. For example, the
statement that the average individual order for red widgets is 75 means that /angbracketleftn1/angbracketright=75/angbracketleftm1/angbracketright.
With six average values given, we will ha ve six Lagrange multipliers {λ1,µ1;
λ2,µ2;λ3,µ3}. The maximum entropy probability assignment will have the form
p(u1···;v1···;w1···)=exp{−λ0−λ1n1−µ1m1−λ2n2−µ2m2−λ3n3−µ3m3},
(14.71)
which factors:
p(u1···;v1···;w1···)=p1(u1···)p2(v1···)p3(w1···). (14.72)
The partition function also factors:
Z=Z1(λ1µ1)Z2(λ2µ2)Z(λ3µ3), (14.73)
with
Z1(λ1µ1)=∞/summationdisplay
u1=1∞/summationdisplay
u2=1···exp{−λ1(u1+2u2+3u3+··· )−µ1(u1+u2+u3+··· )}
=∞/productdisplay
r=11
1−exp{−rλ1−µ}(14.74)

<<<PAGE 479>>>

14 Simple applications of decision theory 447
and similar expressions for Z2,Z3.T oﬁ n d λ1,µ1we apply the general rule, Eq. (14.57):
/angbracketleftn1/angbracketright=∂
∂λ1∞/summationdisplay
r=1log(1−exp{−rλ1−µ1})=∞/summationdisplay
r=1r
exp{rλ1+µ1}−1, (14.75)
/angbracketleftm1/angbracketright=∂
∂µ1∞/summationdisplay
r=1log(1−exp{−rλ1−µ1})=∞/summationdisplay
r=11
exp{rλ1+µ1}−1. (14.76)
Combining with (14.69) and (14.70), we see that
/angbracketleftur/angbracketright=1
exp{rλ1+µ1}−1, (14.77)
and now the secret is out – Stage 3 of Mr A’s decision problem is just the theory of the ideal
Bose–Einstein gas in quantum statistical mechanics!
If we treat the ideal Bose–Einstein gas by the method of the Gibbs grand canonical
ensemble, we obtain just these equations, in which the number rcorresponds to the rth
single-particle energy level, urto the number of particles in the rth state, and λ1andµ1to
the temperature and chemical potential.
In the present problem it is clear that for all r,/angbracketleftur/angbracketright/lessmuch 1, and that/angbracketleftur/angbracketrightcannot decrease
appreciably below/angbracketleftu1/angbracketrightuntil ris of the order of 75, the average individual order. Therefore,
µ1will be numerically large, and λ1numerically small, compared with unity. This means
that the series (14.75), (14.76) converge very slowly and are useless for numerical work
unless you write a computer program to do it. However, we can do it analytically if we
transform them into rapidly converging sums as follows:
∞/summationdisplay
r=11
exp{λr+µ}−1=∞/summationdisplay
r=1∞/summationdisplay
n=1exp{−n(λr+µ)}
=∞/summationdisplay
n=1exp{−nµ}
1−exp{−nλ}.(14.78)
The ﬁrst term is already an excellent approximation. Similarly,
∞/summationdisplay
r=1r
exp{λr+µ}−1=∞/summationdisplay
n=1exp{−n(λr+µ)}
(1−exp{−nλ})2, (14.79)
and so (14.75) and (14.76) become
/angbracketleftn1/angbracketright=exp{−µ1}
λ2
1, (14.80)
/angbracketleftm1/angbracketright=exp{−µ1}
λ1, (14.81)
λ1=/angbracketleftm1/angbracketright1
/angbracketleftn1/angbracketright=1
75=0.0133, (14.82)

<<<PAGE 480>>>

448 Part 2 Advanced applications
exp{µ1}=/angbracketleftn1/angbracketright1
/angbracketleftm1/angbracketright=112.5, (14.83)
µ1=4.722. (14.84)
Tribus and Fitts, evaluating the sums by computer, obtain λ1=0.0131,µ1=4.727; so our
approximations (14.80), (14.81) are very good, at least in the case of red widgets.
The probability that urhas a particular value is, from (14.72) or (14.74),
p(ur)=(1−exp{−rλ1−µ})e x p{(−rλ1+µ1)ur}, (14.85)
which has the mean value (14.77) and the variance
var(ur)=/angbracketleftu2
r/angbracketright−/angbracketleft ur/angbracketright2=exp{rλ1+µ1}
exp{rλ1+µ1}−1. (14.86)
The total demand for red widgets
n1=∞/summationdisplay
r=1rur (14.87)
is expressed as the sum of a large number of independent terms. The pdf for n1will have
the mean value (14.80) and the variance
var(n1)=∞/summationdisplay
r=1r2var(ur)=∞/summationdisplay
r=1r2exp{rλ1+µ1}
(exp{rλ1+µ1}−1)2, (14.88)
which we convert into the rapidly convergent sum
∞/summationdisplay
r,n=1nr2exp{−n(rλ+µ)}=∞/summationdisplay
n=1nexp{−n(λ+µ)}+exp{−n(2λ+µ)}
(1−exp{−nλ})3(14.89)
or, approximately,
var(n1)=2e x p{−µ1}
λ3
1=2
λ1/angbracketleftn1/angbracketright. (14.90)
At this point we can use some mathematical facts concerning the central limit theorem. Be-
cause n1is the sum of a large number of small terms to which we have assigned independent
probabilities, our probability distribution for n1will be very nearly Gaussian:
p(n1)≈Aexp/braceleftbigg
−λ1(n1−/angbracketleftn1/angbracketright)2
4/angbracketleftn1/angbracketright/bracerightbigg
(14.91)
for those values of n1which can arise in many different ways. For example, the case n=2
can arise in only two ways: u1=2, or u2=1, all others ukbeing zero. On the other hand,
the case n1=150 can arise in an enormous number of different ways, and the ‘smoothing’
mechanism of the central limit theorem can operate. Thus, Eq. (14.91) will be a goodapproximation for the large values of n
1of interest to us, but not for small n1.

<<<PAGE 481>>>

14 Simple applications of decision theory 449
The expected loss on the various decisions is, as we saw in (14.66), the sum of three
terms arising from failure to meet orders for red, yellow, or green widgets, respectively. Ifwe do not make red ones today, then the possibility of failing to meet orders for red widgetscontributes to the expected loss the amount
∞/summationdisplay
n1=0p(n1)R(n1−S1)/similarequal/radicalBigg/bracketleftbiggλ1
4π/angbracketleftn1/angbracketright/bracketrightbigg/integraldisplay∞
S1dn1(n1−S1)e x p/braceleftbigg
−λ1(n1−/angbracketleftn1/angbracketright)2
4/angbracketleftn1/angbracketright/bracerightbigg
=(/angbracketleftn1/angbracketright−S1)/Phi1/bracketleftBig
α1√
2(/angbracketleftn1/angbracketright−S1)/bracketrightBig
+1
2α1√πexp/braceleftbig
−α2
1(/angbracketleftn1/angbracketright−S1)2/bracerightbig
, (14.92)
where α2
1=λ1/4/angbracketleftn1/angbracketright, and/Phi1(x) is the cumulative normal distribution function (14.42).
If we do decide to make red widgets today, the possibility of failing to meet red orders
contributes to the expected loss the above expression (14.92) with S1replaced by ( S1+200).
Similar equations hold for yellow and green widgets. Although the approximations we
made are not equally good in all cases, let us use (14.92) for the partial losses and apply itthree times with the given numerical values
S
1=100, S2=150, S3=50,
/angbracketleftn1/angbracketright=50,/angbracketleftn2/angbracketright=100,/angbracketleftn3/angbracketright=10,
α1=0.0082,α 2=0.0160,α 3=0.035.(14.93)
Doing the indicated calculations, we ﬁnd that on the decisions D1,D2,D3the expected
losses are
/angbracketleftL/angbracketright1=(0)+2.86+0.18=3.04 unﬁlled orders
/angbracketleftL/angbracketright2=14.9+(0)+0.18=15.1 unﬁlled orders
/angbracketleftL/angbracketright3=14.9+2.86+(0)=17.8 unﬁlled orders(14.94)
where (0) stands for a term orders of magnitude smaller than the others. The breakdown
indicated is to be read as follows. If Decision D1(make red widgets) is made, there is
negligible loss from the possibility of failing to meet red orders, while the possibility offailure with yellow orders contributes an expected loss of 2.86, and only 0.18 for green.
These results show the great preference for D
1caused by the additional information
about average individual orders, which had the intuitive effect of making the situation withrespect to yellow widgets much safer than it seemed in Stage 2.
14.7.3 Solution for Stage 4
It is in the passage from Stage 3 to Stage 4 (where the new information consists of a speciﬁc
order for 40 green widgets) that our common sense ﬁrst fails us. Now both the red andgreen situations seem rather precarious, and our common sense lacks the ‘resolving power’to tell which is the more serious. Strangely enough, this new knowledge, which makes the

<<<PAGE 482>>>

450 Part 2 Advanced applications
problem so hard for our common sense, causes no difﬁculty at all in the mathematics. The
previous equations still apply, with the sole difference that the stock S3of green widgets is
reduced from 50 to 10. We now have ( /angbracketleftn3/angbracketright−S3)=0 so that (14.92) reduces to
1
2α3√π=8.08, (14.95)
and in place of (14.94) we have
/angbracketleftL/angbracketright1=(0)+2.86+8.08=10.9 unﬁlled orders
/angbracketleftL/angbracketright2=14.9+(0)+8.08=23.0 unﬁlled orders
/angbracketleftL/angbracketright3=14.9+2.86+(0)=17.8 unﬁlled orders.(14.96)
So, Mr Ashould stick to his decision to make red widgets! Our common sense fails just
because there is now so little difference between /angbracketleftL/angbracketright1and/angbracketleftL/angbracketright3.
14.8 Comments
We have tried to show that use of probability theory in the sense of Laplace, with prior
probabilities determined by the principle of maximum entropy, leads to a reasonable methodof treating decision problems and to results in good correspondence with common sense.Mathematically, our equations are nothing but the Gibbs formalism in statistical mechanics,
the only new feature being the recognition that the Gibbs methods are of far more general
applicability than had been supposed.
The moral of this is simply that questions about ‘interpretation of a formalism’, which
the positivist philosophy tends to reject as meaningless and useless, are, on the contrary,of central importance in scientiﬁc work. It is, of course, true that, in an application alreadyestablished, a different interpretation of the equations cannot lead to any new numericalresults. But our judgment as to the range of validity of a formalism can depend entirely on
how we interpret it. The interpretation (probability) ≡(frequency) has led to a great and
unnecessary restriction on the kinds of problem where probability theory can be applied.Today, the scientist, engineer, and economist face many problems which require the broaderLaplace–Jeffreys interpretation.

<<<PAGE 483>>>

15
Paradoxes of probability theory
I protest against the use of inﬁnite magnitude as something accomplished,
which is never permissible in mathematics. Inﬁnity is merely a ﬁgure of
speech, the true meaning being a limit.
C. F . Gauss
The term ‘paradox’ appears to have several different common meanings. Sz´ ekely (1986)
deﬁnes a paradox as anything which is true but surprising. By that deﬁnition, every scientiﬁcfact and every mathematical theorem qualiﬁes as a paradox for someone. We use the term inalmost the opposite sense; something which is absurd or logically contradictory, but which
appears at ﬁrst glance to be the result of sound reasoning. Not only in probability theory,
but in all mathematics, it is the careless use of inﬁnite sets, and of inﬁnite and inﬁnitesimalquantities, that generates most paradoxes.
In our usage, there is no sharp distinction between a paradox and an error. A paradox is
simply an error out of control; i.e. one that has trapped so many unwary minds that it hasgone public, become institutionalized in our literature, and taught as truth. It might seemincredible that such a thing could happen in an ostensibly mathematical ﬁeld; yet we canunderstand the psychological mechanism behind it.
15.1 How do paradoxes survive and grow?
As we stress repeatedly, from a false proposition – or from a fallacious argument that
leads to a false proposition – all propositions, true and false, may be deduced. But thisis just the danger; if fallacious reasoning always led to absurd conclusions, it would befound out at once and corrected. But once an easy, shortcut mode of reasoning has led toa few correct results, almost everybody accepts it; those who try to warn against it are notlistened to.
When a fallacy reaches this stage, it takes on a life of its own, and develops very effective
defenses for self-preservation in the face of all criticisms. Mathematicians of the statureof Henri Poincar´ e and Hermann Weyl tried repeatedly to warn against the kind of reason-
ing used in inﬁnite-set theory, with zero success. For details, see Appendix B and Kline(1980). The writer was also guilty of this failure to heed warnings for many years, until
451

<<<PAGE 484>>>

452 Part 2 Advanced applications
absurd results that could no longer be ignored ﬁnally forced him to see the error in an easy
mode of reasoning.
To remove a paradox from probability theory will require, at the very least, detailed
analysis of the result and the reasoning that leads to it, showing that:
(1) the result is indeed absurd;
(2) the reasoning leading to it violates the rules of inference developed in Chapter 2;(3) when one obeys those rules, the paradox disappears and we have a reasonable result.
There are too many paradoxes contaminating the current literature for us to analyze sepa-
rately. Therefore we seek here to study a few representative examples in some depth, in thehope that the reader will then be on the alert for the kind of reasoning which leads to them.
15.2 Summing a series the easy way
As a kind of introduction to fallacious reasoning with inﬁnite sets, we recall an old parlor
game by which you can prove that any given inﬁnite series S=/summationtext
iaiconver ges to any
number xthat your victim chooses. The sum of the ﬁrst nterms is sn=a1+a2+···+ an.
Then, deﬁning s0≡0, we have
an=(sn−x)−(sn−1−x), 1≤n<∞, (15.1)
so that the series becomes
S=(s1−x)+(s2−x)+(s3−x)+···
−(s0−x)−(s1−x)−(s2−x)−···.(15.2)
The terms ( s1−x), (s2−x),... all cancel out, so the sum of the series is
S=−(s0−x)=xQ E D . (15.3)
The reader for whom this reasoning appears at ﬁrst glance to be valid has a great deal
of company, and is urged to study this example carefully. Such fallacious arguments areavoided if we follow this advice, repeated from Chapter 2:
Apply the ordinary processes of arithmetic and analysis only to expressions with a ﬁnite
number n of terms. Then after the calculation is done, observe how the resulting ﬁniteexpressions behave as the parameter n increases indeﬁnitely.
Put more succinctly, passage to a limit should always be the last operation, not the ﬁrst. In
case of doubt, this is the only safe way to proceed. Our present theory of convergence ofinﬁnite series could never have been achieved if its founders – Abel, Cauchy, d’Alembert,Dirichlet, Gauss, Weierstrasz, and others – had not followed this advice meticulously. In pre-Bourbakist mathematics (such as Whittaker and Watson, 1927) this policy was consideredso obvious that there was no need to stress it. The results thus obtained have never beenfound defective.
Had we followed this advice above, we would not have tried to cancel out an inﬁnite
number of terms in a single stroke; we would have found that at any ﬁnite nth stage, instead

<<<PAGE 485>>>

15 Paradoxes of probability theory 453
of the sicancelling out and one xremaining, the xvalues would have cancelled out and the
lastsremains, leading to the correct summation of the series.
Yet today, reasoning essentially equivalent to what we did in (15.2) is found repeatedly
where inﬁnite sets are used in probability theory. As an example, we examine another of theconsequences of ignoring this advice, which has grown into far more than a parlor game.
15.3 Nonconglomerability
If (C
1,..., Cn) denote a ﬁnite set of mutually exclusive, exhaustive propositions on prior
information I, then for any proposition Athe sum and product rules of probability theory
give
P(A|I)=n/summationdisplay
i=1P(AC i|I)=n/summationdisplay
i=1P(A|CiI)P(Ci|I) (15.4)
in which the prior probability P(A|I) is written as a weighted average of the conditional
probabilities P(A|CiI). Now, it is a very elementary theorem that a weighted average of a
set of real numbers cannot lie outside the range spanned by those numbers; if
L≤P(A|CiI)≤U, (1≤i≤n) (15.5)
then necessarily
L≤P(A|I)≤U, (15.6)
a property which de Finetti (1972) called ‘conglomerability’ or, more precisely, ‘conglom-
erability in the partition {Ci}’, although it may seem too trivial to deserve a name. Obviously,
nonconglomerability cannot arise from a correct application of the rules of probability the-ory on ﬁnite sets. It cannot, therefore, occur in an inﬁnite set which is approached as awell-deﬁned limit of a sequence of ﬁnite sets.
Yet nonconglomerability has become a minor industry, with a large and growing literature.
There are writers who believe that it is a real phenomenon, and that they are proving theoremsabout the circumstances in which it occurs, which are important for the foundations ofprobability theory. Nonconglomerability has become, quite literally, institutionalized in our
literature and taught as truth.
In spite of its mathematical triviality, then, we need to examine some cases where non-
conglomerability has been claimed. Rather than trying to cite all of this vast literature, wedraw upon a single reference (Kadane, Schervish and Seidenfeld, 1986), hereafter denotedby KSS, where several examples of nonconglomerability and some references to other workmay be found.
Example 1: Rectangular array. Firstly, we note the typical way in which nonconglom-
erability is manufactured, and the illustrative example most often cited. We start from atwo-dimensional ( M×N) set of probabilities:
p(i,j), 1≤i≤M, 1≤j≤N, (15.7)

<<<PAGE 486>>>

454 Part 2 Advanced applications
and think of iplotted horizontally, jvertically, so that the sample space is a rectangular
array of MN points in the ﬁrst quadrant. It will sufﬁce to take some prior information I
for which these probabilities are uniform: p(i,j)=(1/MN). Then the probability of the
event ( A:i<j) is found by direct counting to be
P(A|I)=/braceleftBigg
(2N−M−1)/2NM≤N
(N−1)/2MN≤M.(15.8)
Let us resolve this in the manner of (15.4), into probabilities conditional on the set of
propositions ( C1,..., CM), where Ciis the statement that we are on the ith column of the
array: then P(Ci|I)=(1/M), and
P(A|CiI)=

(N−i)/N 1≤i≤M≤N
(N−i)/N 1≤i≤N≤M
0 N≤i≤M.(15.9)
These conditional probabilities reach the upper and lower bounds
U=(N−1)/N allM,N,
L=/braceleftBigg
1−RM≤N
0 N≤M.(15.10)
where Rdenotes the ratio R=M/N. Substituting (15.8) and (15.10) into (15.6), it is
evident that the condition for conglomerability is always satis ﬁed, as it must be, whatever
the values of ( M,N). How, then, can one possibly create a nonconglomerability out of this?
Just pass to the limit M→∞ ,N→∞ , and ask for the probabilities P(A|CiI) for
i=1,2,.... But instead of examining the limiting form of (15.9), which gives the exact
values for all ( M,N), we try to evaluate these probabilities directly on the inﬁnite set.
Then, it is argued that, for any given i, there are an inﬁnite number of points where Ais true
and only a ﬁnite number where it is false. Ergo , the conditional probability P(A|CiI)=1
for all i; yet P(A|I)<1. We see here the same kind of reasoning that we used in (15.2);
we are trying to carry out very simple arithmetic operations (counting), but directly on aninﬁnite set.
Now consider the set of propositions ( D
1,..., DN), where Djis the statement that we
are on the jth row of the array, counting from the bottom. Now, by the same argument, for
any given j, there are an inﬁnite number of points where Ais false, and only a ﬁnite number
where Ais true. Ergo , the conditional probability P(A|DjI)=0 for all j; yet P(A|I)>0.
By this reasoning, we have produced two nonconglomerabilities, in opposite directions,from the same model (i.e. the same inﬁnite set).
It is even more marvellous than that. In (15.8), it is true that if we pass to the limit holding
iﬁxed, the conditional probability P(A|C
iB) tends to one for all i; but if instead we hold
(N−i) ﬁxed, it tends to zero for all i. Therefore, if we consider the cases ( i=1,i=2,...)
in increasing order, the probabilities P(A|CiB) appear to be one for all i. But it is equally

<<<PAGE 487>>>

15 Paradoxes of probability theory 455
valid to consider them in decreasing order ( i=N,i=N−1,...); then, by the same
reasoning, they would appear to be zero for all i. (Note that we could redeﬁne the labels
by subtracting N+1 from each one, thus numbering them ( i=− N,..., i=−1) so that
asN→∞ the upper indices stay ﬁxed; this would have no effect on the validity of the
reasoning.)
Thus, to produce two opposite nonconglomerabilities we need not introduce two different
partitions{Ci},{Dj}; they can be produced by two equally valid arguments from a single
partition. What produces them is that one supposes the inﬁnite limit already accomplishedbefore doing the arithmetic, reversing the policy of Gauss which we recommended above.
But if we follow that policy and do the arithmetic ﬁrst, then an arbitrary redeﬁnition of thelabels{i}has no effect; the counting for any Nis the same.
Once one has understood the fallacy in (15.2), then whenever someone claims to have
proved some result by carrying out arithmetic or analytical operations directly on an inﬁniteset, it is hard to shake off a feeling that he could have proved the opposite just as easily andby an equally sound argument, had he wished to. Thus there is no reason to be surprised bywhat we have just found.
Suppose that instead we had done the calculation by obeying our rules strictly, doing ﬁrst
the arithmetic operations onﬁnite sets to obtain the e xact solution (15.8); then passing to the
limit. However the inﬁnite limit is approached, the conditional probabilities take on values
in a wide interval whose lower bound is zero or 1 −R, and whose upper bound tends to
one. The condition (15.5) is always satisﬁed, and a nonconglomerability could never havebeen found.
The reasoning leading to this nonconglomerability contains another fallacy. Clearly,
one cannot claim to have produced a nonconglomerability on the inﬁnite set until the‘unconditional’ probability P(A|I) has also been calculated on that set, not merely bounded
by a verbal argument. But as MandNincrease, from (15.8) the limiting P(A|I) depends
only on the ratio R=M/N:
P(A|I)→/braceleftBigg
1−R/2 R≤1
1/(2R) R≥1.(15.11)
If we pass to the inﬁnite limit without specifying the limiting ratio, the unconditional
probability P(A|I) becomes indeterminate; we can get any value in [0 ,1] depending on how
the limit is approached. Put differently, the ratio Rcontains all the information relevant to the
probability of A; yet it was thrown away in passing to the limit too soon. The unconditional
probability P(A|I) could not have been evaluated directly on the inﬁnite set, any more than
could the conditional probabilities.
Thus, nonconglomerability on a rectangular array, far from being a phenomenon of
probability theory, is only an artifact of failure to obey the rules of probability theory asdeveloped in Chapter 2. But from studying a single example we cannot see the commonfeature underlying all claims of nonconglomerability.

<<<PAGE 488>>>

456 Part 2 Advanced applications
15.4 The tumbling tetrahedra
We now examine a claim that nonconglomerability can occur even in a one-dimensional
inﬁnite set n→∞ where there does not appear to be any limiting ratio like the above M/N
to be ignored. Also we now consider a problem of inference, instead of the above samplingdistribution example. The scenario (Stone, 1979) appears to be equivalent to the ‘stronginconsistency’ problem (Stone, 1976). We follow the KSS notation for the time being –until we see why we must not.
A regular tetrahedron with faces labeled e
+(positron), e−(electron), µ+(muon), µ−
(antimuon), is tossed repeatedly. A record is kept of the result of each toss, except that,
whenever a record contains e+followed immediately by e−(or e−by e+,o rµ+byµ−,o r
µ−byµ+), the particles annihilate each other, erasing that pair from the record. At some
arbitrary point in the sequence, the player (who is ignorant of what has happened to date)calls for one more toss, and then is shown the ﬁnal record x∈X, after which he must
place bets on the truth of the proposition A≡‘annihilation occurred at the ﬁnal toss’. What
probability P(A|x) should he assign?
When we try to answer this by application of probability theory, we come up immediately
against the difﬁculty that, in the problem as stated, the solution depends on a nuisanceparameter, the unspeciﬁed length nof the original sequence of tosses. This was pointed out
by Hill (1980), but KSS take no note of it. In fact, they do not mention nat all except by
implication, in a passing remark that the die is ‘rolled a very large number of times’. Weinfer that they meant the limit n→∞ , from later phrases such as ‘the countable set S’ and
‘every ﬁnite subset of S’.
In other words, once again an inﬁnite set is supposed to be something already accom-
plished, and one is trying to ﬁnd relations between probabilities by reasoning directly onthe inﬁnite set. Nonconglomerability enters through asking whether the prior probability
P(A) is conglomerable in the partition x, corresponding to the equation
P(A)=/summationdisplay
x∈XP(A|x)P(x). (15.12)
KSS denote by θ∈Sthe record just before the ﬁnal toss (thought of as a ‘parameter’ not
known by the player), where Sis the set of all possible such records, and conclude by
verbal arguments that:
(a) 0≤p(A|θ)≤1/4, allθ∈S;
(b) 3/4≤p(A|x)≤1, all x∈X.
It appears that another violent nonconglomerability has been produced; for if P(A)i s
conglomerable in the partition {x}of ﬁnal records, it must be true that 3 /4≤P(A)≤1,
while if it is conglomerable in the partition {θ}of previous records, we require 0 ≤P(A)≤
1/4; it cannot be conglomerable in both. So where is the error this time?
We accept statement (a); indeed, given the independence of different tosses, knowing
anything whatsoever about the earlier tosses gives us no information about the ﬁnal one, so

<<<PAGE 489>>>

15 Paradoxes of probability theory 457
the uniform prior assignment 1 /4 for the four possible results of the ﬁnal toss still holds.
Therefore, p(A|θ)=1/4, except when the record θis blank, in which case there is nothing
to annihilate, and so p(A|θ)=0. But this argument does not hold for statement (b); since
the result of the ﬁnal toss affects the ﬁnal record x, it follows that knowing xmust give
some information about the ﬁnal toss, invalidating the uniform 1 /4 assignment.
Also, the argument that KSS gave for statement (b) supposed prior information different
from that used for statement (a). This was concealed from view by the notation p(A|θ),
p(A|x) which fails to indicate prior information I. Let us repeat (15.12) with adequate
notation:
P(A|I)=/summationdisplay
x∈XP(A|xI)P(x|I). (15.13)
Now as Ivaries, all these quantities will in general vary. By ‘conglomerability’ we mean,
of course, ‘conglomerability with some particular ﬁxed prior information I .’ Recognizing
this, we repeat statements (a) and (b) in a notation adequate to show this difference:
(a) 0≤p(A|θIa)≤1/4,θ∈S;
(b) 3/4≤p(A|xIb)≤1, x∈X.
From reading KSS we ﬁnd that prior information Ia, in effect, assigned uniform probabilities
on the set Tof 4npossible outcomes of ntosses, as is appropriate for the case of ‘independent
repetitions of a random experiment’ assumed in the statement of the problem. But Ibassigned
uniform probabilities on the set Sof different previous records θ. This is very different; an
element of S(orX) may correspond to one element of T, or to many millions of elements
ofT, so a probability assignment uniform on the set of tosses is very nonuniform on the
set of records. Therefore it is not evident whether there is any contradiction here; they are
statements about two quite different problems.
Exercise 15.1. Inn=40 tosses there are 4n=1.21×1024possible sequences of
results in the set T. Show that, if those tosses give the expected number m=10 of
annihilations leading to a record x∈Xof length 20, the speciﬁc record xcorresponds to
about 1014elements of T. On the other hand, if there are no annihilations, the resulting
record xof length 40 corresponds to only one element of T.
Perhaps this makes clearer the reason for our seemingly fanatical insistence on indicating
the prior information Iexplicitly in every formal probability symbol P(A|BI). Those who
fail to do this may be able to get along without disaster for a while, judging the meaning
of an equation from the surrounding context rather than from the equation as written. But
eventually they are sure to ﬁnd themselves writing nonsense, when they start inadvertentlyusing probabilities conditional on different prior information in the same equation, or thesame argument, and their notation conceals that fact. We shall see presently a more famous

<<<PAGE 490>>>

458 Part 2 Advanced applications
and more serious error (the marginalization paradox) caused by failure to indicate the fact
that two probabilities are conditional on different prior information.
To show the crucial role that nplays in the problem, let Iagree with Iain assigning equal
prior probabilities to each of the 4noutcomes of ntosses. Then, if nis known, calculations
ofp(A|nI),p(x|nI),p(A|nxI) are determinate combinatorial problems on ﬁnite sets (i.e.
in each case there is one and only one correct answer), and the solutions obviously dependonn. So let us try to calculate P(A|xI); denoting summation over all nin (0≤n<∞)b y/summationtext, we have for the prior probabilities
p(A|I)=/summationdisplay
p(An|I)=/summationdisplay
p(A|nI)p(n|I)
p(x|I)=/summationdisplay
p(xn|I)=/summationdisplay
p(x|nI)p(n|I)(15.14)
and for the conditional one
p(A|xI)=/summationdisplay
p(A|nxI)p(n|xI)=/summationtextp(A|nxI)p(x|nI)p(n|I)
/summationtextp(x|nI)p(n|I), (15.15)
where we expanded p(n|xI) by Bayes’ theorem. It is evident that the problem is indetermi-
nate until the prior probabilities p(n|I) are assigned. Quite generally, failure to specify the
prior information makes a problem of inference just as ill-posed as does failure to specifythe data.
Passage to inﬁnite nthen corresponds to taking the limit of prior probabilities p(n|I)
that are nonzero only for larger and larger n. Evidently, this can be done in many different
ways, and the ﬁnal results will depend on which limiting process we use unless p(A|nI),
p(x|nI),p(A|nxI) all approach limits independent of n.
The number of different possible records xis less than 4
n(asymptotically, about 3n)
because many different outcomes with annihilation may produce the same ﬁnal record, asthe above exercise shows. Therefore, for any n<∞, there is a ﬁnite set Xof different
possible ﬁnal records x, and a fortiori a ﬁnite set Sof previous records θ, so the prior
probability of ﬁnal annihilation can be written in either of the forms:
p(A|nI)=/summationdisplay
x∈Xp(A|xnI)p(x|nI)=/summationdisplay
θ∈Sp(A|θnI)p(θ|nI), (15.16)
and the general theorem on weighted averages guarantees that nonconglomerability cannot
occur in either partition for any ﬁnite n, or for an inﬁnite set generated as a well-behaved
limit of a sequence of these ﬁnite sets.
A few things about the actual range of variability of the conditional probabilities p(A|nxI)
can be seen at once without any calculation. For any n, there are possible records of length
nfor which we know that no annihilation occurred; the lower bound is always reached for
some x, and it is p(A|nxI)=0, not 3 /4. The lower bound in statement (b) could never have
been found for any prior information, had the inﬁnite set been approached as a limit of asequence of ﬁnite sets. Furthermore, for any even nthere are possible records of length zero
for which we know that the ﬁnal toss was annihilated; the upper bound is always reachedfor some x, and it is p(A|nxI)=1.

<<<PAGE 491>>>

15 Paradoxes of probability theory 459
Likewise, for even nit is not possible for θto be blank, so from (15.16) we have p(A|nI)=
p(A|θnI)=1/4 for all θ∈S. Therefore, if nis even, there is no need to invoke even the
weighted average theorem; there is no possibility for nonconglomerability in either thepartition{x}or{θ}.
At this point it is clear that the issue of nonconglomerability is disposed of in the same
way as in our ﬁrst example; it is an artifact of trying to calculate probabilities directly on aninﬁnite set without considering any limit from a ﬁnite set. Then it is not surprising that KSSnever found any speciﬁc answer to their original question: ‘What can we infer about ﬁnalannihilation from the ﬁnal record x?’ But we would still like to see the answer (particularly
since it reveals an even more startling feature of the problem).
15.5 Solution for a ﬁnite number of tosses
Ifnis known, we can get the exact analytical solution easily from valid application of our
rules. It is a straightforward Bayesian inference in which we are asking only for the posteriorprobability for ﬁnal annihilation A. But this enables us to simplify the problem; there is no
need to draw inferences about every detail of the previous record θ.
If there is annihilation at the nth toss, then the length of the record decreases by one:
y(n)=y(n−1)−1. If there is no annihilation at the nth toss, the length increases by
one: y(n)=y(n−1)+1. The only exception is that y(n) is not permitted to become
negative; if y(n−1)=0, then the nth toss cannot give annihilation. Therefore, since the
available record xtells us the length y(n) but not y(n−1), any reasoning about ﬁnal
annihilation may be replaced immediately by reasoning about α≡y(n−1), which is the
sole parameter needed in the problem.
Likewise, any permutations of the symbols {e
±,µ±}inx(n) which keep the same y(n) will
lead to just the same inferences about A. But then nandy≡y(n) are sufﬁcient statistics; all
other details of the record xare irrelevant to the question being asked. Thus the scenario of
the tetrahedrons is more complicated than it needs to be in order to deﬁne the mathematicalproblem (in fact, so complicated that it seems to have prevented recognition that it is astandard textbook random walk problem).
At each nth toss we have the sampling probability 1/4 of annihilating, independently of
what happened earlier (with a trivial exception if y(n−1)=0). Therefore if we plot n
horizontally, y(n) vertically, we have the simplest random walk problem in one dimension,
with a perfectly reﬂecting boundary on the horizontal axis y=0. At each horizontal step,
ify>0 there is probability 3/4 of moving up one unit, 1/4 of moving down one unit; if
y=0, we can move only up. Starting with y(0)=0, annihilation cannot occur on step 1,
and immediately after the nth step, if there have been mannihilations, the length of the
record is y(n)=n−2m.
After the nth step we have a prior probability distribution for y(n) to have the value i:
p
(n)
i≡p(i|nI), 0≤i≤n, (15.17)

<<<PAGE 492>>>

460 Part 2 Advanced applications
with the initial vector
p(0)
i=
1
00
...
, (15.18)
and successive distributions are connected by the Markov chain relation
p
(n)
i=n−1/summationdisplay
j=0Mijp(n−1)
j0≤i≤n
1≤n<∞,(15.19)
with the transition matrix (number the rows and columns starting with zero)
M≡
01/40 0 ...
101 /40 ...
03/401 /4...
003 /40 ...
...............
. (15.20)
The reﬂecting boundary at y=0 is indicated by the element M
10=1, which would be 3/4
without the reﬂection.
The matrix Mis, in principle, inﬁnite-dimensional, but for the nth step only the ﬁrst n+1
rows and columns are needed. The vector p(n)is also, in principle, inﬁnite-dimensional,
butp(n)
i=0 when i>n. Then the exact solution for the prior probabilities p(n)
iis the ﬁrst
column of Mn:
p(n)
i=Mn
i,0 (15.21)
(note that this is intended to represent ( Mn)i,0, not ( Mi,0)n).
Now let us see how this prior is to be used in our Bayesian inference problem. Denote
the data and the hypothesis being tested by
D≡y(n)=i, H≡y(n−1)=α, (15.22)
which are the only parts of the data xand the parameter θthat are relevant to our problem.
From the above their prior probabilities are
p(D|I)=Mn
i,0, p(H|I)=Mn−1
α,0. (15.23)
The sampling distribution is
p(D|HI)=/braceleftBigg
3/4δ(i,α+1)+1/4δ(i,α−1)
δ(i,1)α> 0
α=0.(15.24)

<<<PAGE 493>>>

15 Paradoxes of probability theory 461
So, Bayes’ theorem gives the posterior probability for αas
p(H|DI)=p(H|I)p(D|HI)
p(D|I)=Mn−1
α,0
Mn
i,0/braceleftBigg
3/4δ(i,α+1)+1/4δ(i,α−1)
δ(i,1)α> 0
α=0.
(15.25)
Now, ﬁnal annihilation Aoccurs if and only if α=i+1, so the exact solution for ﬁnite nis
p(A|DnI)=Mn−1
i+1,0
4Mn
i,0, (15.26)
in which i=y(n) is a sufﬁcient statistic. Another way of writing this is to note that the
denominator of (15.26) is
4Mn
i,0=4/summationdisplay
jMi,jMn−1
j,0=3Mn−1
i−1,0+Mn−1
i+1,0, (15.27)
and so the posterior odds on Aare
o(A|DnI)≡p(A|xnI)
p(A|xnI)=1
3Mn−1
i+1,0
Mn−1
i−1,0, (15.28)
and it would appear, from their remarks, that the exact solution to the problem that KSS
had in mind is the limit of (15.26) or (15.28) as n→∞ .
This solution for ﬁnite nis complicated because of the reﬂecting boundary. Without it,
the aforementioned matrix element M1,0would be 3/4 and the problem would reduce to the
simplest of all random walk problems. That solution gives us a very good approximation to(15.26), which actually yields the exact solution to our problem in the limit. Let us examinethis alternative formulation because its ﬁnal result is very simple and the derivation isinstructive about a point that is not evident from the above exact solution.
The problem where at each step there is probability pto move up one unit, q=1−pto
move down one unit, is deﬁned by the recursion relation in which f(i|n) is the probability
to move a total distance iinnsteps:
f(i|n+1)=pf(i−1|n)+qf(i+1|n). (15.29)
With initial conditions f(i|n=0)=δ(i,0), the standard textbook solution is the binomial
forrsuccesses in ntrials; f
0(i|n)=b(r|np), with r=(n+i)/2. In our problem we know
that on the ﬁrst step we necessarily move up, y(1)=1, so our initial conditions are f(i|n=
1)=δ(i,1), and using the binomial recursion (15.29) after that the solution would be
f(i|n)=f0(i−1|n−1)=b(r|n−1,p), with again r=(n+i)/2.
But with p=3/4, this is not exactly the same as (15.19) because it neglects the reﬂecting
boundary. If too many ‘failures’ (i.e. annihilations) occur early in the sequence, this couldreduce the length of the record to zero, forcing the upward probability for the next step tobe one rather than 3/4; and (15.19) is taking all that into account. Put differently, in the
solution to (15.29), when nis small, some probability drifts into the region y<0; but if
p=3/4 the amount is almost negligibly small, and it all returns eventually to y>0.

<<<PAGE 494>>>

462 Part 2 Advanced applications
When nis very large, the solution drifts arbitrarily far away from the reﬂecting boundary,
putting practically all the probability into the region ( ˆy−√n<y<ˆy+√n), where ˆy≡
(p−q)n=n/2. So conclusions drawn from (15.29) become highly accurate (in the limit,
exact).
The sampling distribution (15.24) is unchanged, but we need binomial approximations
to the priors for iandα. The latter is the length of the record after n−1 steps, or tosses. No
annihilation is possible at the ﬁrst toss, so after n−1 tosses we know that there were n−2
tosses at which annihilation could have occurred, with probability 1/4 at each, so the priorprobability for mannihilations in the ﬁrst n−1 tosses is the binomial b(m|n−2,1/4):
f(m)≡p(m|n)=/parenleftbiggn−2
m/parenrightbigg/parenleftbigg1
4/parenrightbiggm/parenleftbigg3
4/parenrightbiggn−2−m
, 0≤m≤n−2. (15.30)
Then the prior probability for α, replacing the numerator in (15.28), is
p(α|n)=f/parenleftbiggn−1−α
2/parenrightbigg
, (15.31)
from which we ﬁnd the prior expectation E(α|I)=n/2. Likewise in the denominator we
want the prior for y(n)=i. This is just (15.31) with the replacements n−1→n,α→i.
Given y, the possible values of αareα=y±1, so the posterior odds on ﬁnal annihilation
are, writing m≡(n−y)/2,
o=p(A|yn)
p(A|yn)=p(α=y+1|yn)
p(α=y−1|yn)=(1/4)/parenleftbign−2
m−1/parenrightbig
(1/4)m−1(3/4)n−1−m
(3/4)/parenleftbign−2
m/parenrightbig
(1/4)m(3/4)n−2−m. (15.32)
But, at ﬁrst sight astonishing, the factors (1 /4),(3/4) cancel out, so the result depends only
on the factorials:
o=m!(n−2−m)!
(m−1)! (n−1−m)!=n−y
n−2+y, (15.33)
and the posterior probability of ﬁnal annihilation reduces simply to
p(A|yn)=o
1+o=n−y
2(n−1), (15.34)
which does not bear any resemblance to any of the solutions proposed by those who tried to
solve the problem by reasoning directly on inﬁnite sets. The sampling probabilities p=3/4,
q=1/4, which ﬁgured so prominently in previous discussions, do not appear at all in the
solution.
But now think about it. Given nandy(n), we know that annihilation might have occurred
in any of n−1 tosses, but that in fact it did occur in exactly ( n−y)/2 tosses. But we have
no information about which tosses, so the posterior probability for annihilation at the ﬁnaltoss (or at any toss after the ﬁrst) is, of course,
n−y
2(n−1). (15.35)

<<<PAGE 495>>>

15 Paradoxes of probability theory 463
0 1 02 03 04 05 06 07 08 09 0 1 0 00.00.20.40.60.81.0Probability
y=Length of record
↓
Fig. 15.1. Solution to the ‘strong inconsistency’ problem for n=100 tosses. Solid line =approxi-
mation, Eq. (15.34); dots =exact solution, Eq. (15.26).
We derived (15.34) directly from the principles of probability theory by a rather long
calculation; but with a modicum of intuitive understanding of the problem, we could havereasoned it out in our heads without any calculation at all!
In Figure 15.1 we compare the exact solution (15.26) with the asymptotic solution (15.34).
The difference is negligible numerically when n>20. So then, why did so many people
think the answer should be 1/4? Perhaps it helps to note that the prior expectation for yis
E(y|I)=(n+1)/2, so the predictive probability of ﬁnal annihilation is
p(A|nI)=n−E(y|I)
2(n−1)=1
4. (15.36)
The posterior probability of ﬁnal annihilation is indeed 1/4, if the observed record length y
is the expected value . If new information is only what we already expected, it does not
change our estimates; it only makes us more conﬁdent of them. But if yis observed
to be different from its prior expectation, this tells us the actual number of annihila-
tions, and of course this information takes precedence over whatever initial probabilityassignments (1 /4,3/4) we might have made. That is why they cancelled out in the pos-
terior odds.
1In spite of our initial surprise, then, Bayes’ theorem is doing exactly the
right thing here; and the exact solution of the problem originally posed is given also by
1This cancellation is the thing that is not evident at all in the exact solution (15.26), although it is still taking place out of sight.

<<<PAGE 496>>>

464 Part 2 Advanced applications
the limit of (15.35) as n→∞ :
p(A|xI)=1
2(1−z) (15.37)
where z≡limy(n)/n.
In summary, the common feature of these two claims of nonconglomerability is now
apparent. In the ﬁrst scenario, there was no mention of the existence of the ﬁnite numbers
M,Nwhose ratio M/Nis the crucial quantity on which the solution depends. In the
second scenario, essentially the same thing was done; failure to introduce the length n
of the sequence and, incredibly, even the length y(n) of the observed record, likewise
causes one to lose the crucial thing – in this case, the sufﬁcient statistic y/n– on which
the solution depends. In both cases, by supposing the inﬁnite limit as something already
accomplished at the start, one is throwing away the very information required to ﬁnd the
solution .
This has been a very long discussion, but it is hard to imagine a more instructive lesson
in how and why one must carry out probability calculations where inﬁnite sets are involved,or a more horrible example of what can happen if we fail to heed the advice of Gauss.
15.6 Finite vs. countable additivity
At this point, the reader will be puzzled and asking, ‘Why should anybody care about
nonconglomerability? What difference does it make?’ Nonconglomerability is, indeed, oflittle interest in itself; it is only a kind of red herring that conceals the real issue. A followerof de Finetti would say that the underlying issue is the technical one of‘ﬁnite additivity’.
To which we would reply that ‘ﬁnite additivity’ is also a red herring, because it is used fora purpose almost the opposite of what it sounds like.
In Chapter 2 we derived the sum rule (2.85) for mutually exclusive propositions: if as a
statement of Boolean algebra, A≡A
1+A2+···+ Anis a disjunction of a ﬁnite number
of mutually exclusive propositions, then
p(A|C)=n/summationdisplay
i=1p(Ai|C). (15.38)
Then it is a trivial remark that our probabilities have ‘ﬁnite additivity’. As n→∞ it seems
rather innocuous to suppose that the sum rule goes in the limit into a sum over a countablenumber of terms, forming a convergent series; whereupon our probabilities would be calledcountably additive. Indeed (although we do not see how it could happen in a real problem),
if this should ever fail to yield a convergent series we would conclude that the inﬁnite limit
does not make sense, and we would refuse to pass to the limit at all. In our formulation ofprobability theory, it is difﬁcult to see how one could make any substantive issue out of thisperfectly straightforward situation.
The conventional formulations, reversing our policy, suppose the inﬁnite limit already
accomplished at the beginning, before such questions as additivity are raised; and then are

<<<PAGE 497>>>

15 Paradoxes of probability theory 465
concerned with additivity over propositions about intervals on inﬁnite sets. To quote Feller
(1966, 1971 edn, p. 107):
LetFbe a function assigning to each interval Ia ﬁnite value F{I}. Such a function is called (ﬁnitely)
additive if for every partition of an interval Iinto ﬁnitely many non-overlapping intervals I1···In,
F{I}=F{I1}+···+ F{In}.
Then (p. 108) Feller gives an example showing why he wishes to replace ﬁnite additivity
by countable additivity:
InR1putF{I}=0 for any interval I=(a,b) with b<∞andF{I}=1 when I=(a,∞). This
interval function is additive but weird because it violates the natural continuity requirement that
F{(a,b)}should tend to F{(a,∞)}asb→∞ .
This last example shows the desirability of strengthening the requirement of ﬁnite additivity. We
shall say that an interval function Fis countably additive, or σ-additive, if for every partitioning of
an interval Iinto countably many intervals I1,In,..., F{I}=/summationtextF{Ik}.
He then adds that the condition of countable additivity is ‘manifestly violated’ in the above
weird example (let it be an exercise for the reader to explain clearly whythis is manifest).
What is happening in that weird example? Surely, the weirdness does not lie in lack of
continuity (since continuity is quite unnecessary in any event), but in something far worse.Supposing those intervals occupied by some variable xand the interval function F{I}to
be the probability p(x∈I), one is assigning zero probability to any ﬁnite range of x,b u t
unit probability to the inﬁnite range. This is almost impossible to comprehend when wesuppose the inﬁnite interval already accomplished, but we can understand what is happeningif we heed the advice of Gauss and think in terms of passage to a limit. Suppose we have aproperly normalized pdf:
p(x|r)=/braceleftBigg
1/r
00≤x<r
r≤x<∞.(15.39)
As long as 0 <r<∞, there is nothing strange, and we could describe this by an interval
function
F(a,b)≡/integraldisplay
b
adxp(x|r)=

(b−a)/r
(r−a)/r
00≤a≤b≤r<∞
0≤a≤r≤b<∞
0≤r≤a≤b<∞,(15.40)
which is, rather trivially, countably additive and a fortiori ﬁnitely additive. As rincreases,
the density function becomes smaller and spread over a wider interval; but as long as r<∞
we have a well-deﬁned and nonparadoxical mathematical situation.
If we try to describe the limit of p(x|r) as something already accomplished before
discussing additivity, then we have created Feller’s weird example. We are trying to makea probability density that is everywhere zero, but which integrates to unity. But there is no
such thing , according not only to all the warnings of classical mathematicians from Gauss
on, but according to our own elementary common sense.

<<<PAGE 498>>>

466 Part 2 Advanced applications
Invoking ﬁnite additivity is a sneaky way of approaching the real issue. To see why the
kind of additivity matters in the conventional formulation, let us note what happens whenone carries out the order of operations corresponding to our advice above. We assign acontinuous monotonic increasing cumulative probability function G(x) on the real line,
with the natural continuity property that
G(x)→/braceleftBigg
1 x→+∞
0 x→−∞ ;(15.41)
then, the interval function Ffor the interval I=(a,b) may be taken as F{I}=G(b)−
G(a), and it is ‘manifest’ that this interval function is countably additive in the sense deﬁned.
That is, we can choose x
ksatisfying a<x1<x2<···<bso as to break the interval ( a,b)
into as many nonoverlapping subintervals {I0,I1,..., In}={ (a,x1),(x1,x2),..., (xn,b)}
as we please, and it will be true that F{I}=/summationtextF{Ik}.I fG(x) is differentiable, then
its derivative f(x)≡G/prime(x) may be interpreted as a normalized probability density:/integraltext
dxf(x)=1.
We see, ﬁnally, what the point of all this is: ‘ﬁnite additivity’ is a euphemism for
‘reversing the proper order of approaching limits, and thereby getting into trouble withnon-normalizable probability distributions’. Feller saw this instantly, warned the readeragainst it, and proceeded to develop his own theory in a way that avoids the many uselessand unnecessary paradoxes that arise from it.
2
As we saw in Chapter 6, passage to the limit r→∞ at the end of a calculation can yield
useful results; some other probability derived from p(x|r) might approach a deﬁnite, ﬁnite,
and simple limiting value. We have now seen that trying to pass to the limit at the beginningof a calculation can generate nonsense because crucial information is lost before we havea chance to use it.
The real issue here is: do we admit such things as uniform probability distributions on
inﬁnite sets into probability theory as legitimate mathematical objects? Do we believe that aninﬁnite number of zeroes can add up to one? In the strange language in which these things arediscussed, to advocate ‘ﬁnite additivity’, as de Finetti and his followers do, is a deviousway of answering ‘yes’ without seeming to do so. To advocate ‘countable additivity’, asKolmogorov and Feller did, is an equally devious way to answer ‘no’ in the spirit of Gauss.
The terms are red herrings because ‘ﬁnite additivity’ sounds colloquially as if it were a
cautious assumption, ‘countable additivity’ a bit more adventurous. de Finetti does indeedseem to think that ﬁnite additivity is the weaker assumption; and he rails against thosewho, as he sees it, are intellectually dishonest when they invoke countable additivity onlyfor ‘mathematical convenience’, instead of for a compelling reason. As we see it, jumpingdirectly into an inﬁnite set at the very beginning of a problem is a vastly greater error ofjudgment, which has far worse consequences for probability theory; there is a little morethan just ‘mathematical convenience’ at stake here.
2Since we disagree with Feller so often on conceptual issues, we are glad to be able to agree with him on nearly all technical
ones. He was, after all, a very great contributor to the technical means for solving sampling theory problems, and practicallyeverything he did is useful to us in our wider endeavors.

<<<PAGE 499>>>

15 Paradoxes of probability theory 467
We noted the same psychological phenomenon in Chapter 3, when we introduced the
binomial distribution for sampling with replacement; those who committed the sin of throw-ing away relevant information invented the term ‘randomization’ to conceal that fact andmake it sound like they were doing something respectable. Those who commit the sin ofdoing reckless, irresponsible things with inﬁnity often invoke the term ‘ﬁnite additivity’ tomake it sound as if they are being more careful than others with their mathematics.
15.7 The Borel–Kolmogorov paradox
For the most part, the transition from discrete to continuous probabilities is uneventful, pro-
ceeding in the obvious way with no surprises. However, there is one tricky point concerningcontinuous densities that is not at all obvious, but can lead to erroneous calculations unlesswe understand it. The following example continues to trap many unwary minds.
Suppose Iis prior information according to which ( x,y) are assigned a bivariate normal
pdf with variance unity and correlation coefﬁcient ρ:
p(dxdy|I)=/radicalbig
1−ρ2
2πexp/braceleftbigg1
2(x2+y2−2ρxy)/bracerightbigg
dxdy. (15.42)
We can integrate out either xoryto obtain the marginal pdfs (to prepare for integrating out
x, write x2+y2−2ρxy=(x−ρy)2+(1−ρ2)y2, etc.):
p(dx|I)=/radicalBigg/parenleftbigg1−ρ2
2π/parenrightbigg
exp/braceleftbigg
−1
2(1−ρ2)x2/bracerightbigg
dx (15.43)
p(dy|I)=/radicalBigg/parenleftbigg1−ρ2
2π/parenrightbigg
exp/braceleftbigg
−1
2(1−ρ2)y2/bracerightbigg
dy. (15.44)
Thus far, all is routine. But now, what is the conditional pdf for x, given that y=y0?W e
might think that we need only set y=y0in (15.42) and renormalize:
p(dx|y=y0I)=Aexp/braceleftbigg
−1
2(x2+y2
0−2ρxy0)/bracerightbigg
dx, (15.45)
where Ais a normalizing constant. But there is no guarantee that this is valid, because we
have obtained (15.45) by an intuitive ad hoc device; we did not derive it from (15.42) by
applying the basic rules of probability theory, which we derived in Chapter 2 for the discretecase:
p(AB|X)=p(A|BX)p(B|X), (15.46)
from which a discrete conditional probability is given by the usual rule
p(A|BX)=p(AB|X)
p(B|X)(15.47)

<<<PAGE 500>>>

468 Part 2 Advanced applications
often taken as the deﬁnition of a conditional probability. But we can do the calculation by
strict application of our rules if we deﬁne the discrete propositions
A≡xin dx
B≡yin (y0<y<y0+dy).(15.48)
Then we should write instead of (15.45), using (15.42) and (15.44),
p(A|BI)=p(dx|dyI)=p(dxdy|I)
p(dy|I)=1√
2πexp/braceleftbigg
−1
2(x−ρy0)2/bracerightbigg
dx. (15.49)
Since d ycancels out, taking the limit d y→0 does nothing.
On working out the normalizing constant in (15.45), we ﬁnd that (15.45) and (15.49) are
in fact identical. So, why all this agony? Didn’t the quick argument leading to (15.45) giveus the right answer?
This is a good example of our opening remarks that a fallacious argument may lead to cor-
rect or incorrect results. The reasoning that led us to (15.45) happened to give a correct resulthere; but it can equally well yield any result we please instead of (15.45). It depends on the
particular form in which you or I choose to write our equations. To show this, and therefore
generate a paradox, suppose that we had used instead of ( x,y) the variables ( x,u), where
u≡y
f(x)(15.50)
with 0 <f(x)<∞; for example, f(x)=1+x2orf(x)=cosh( x), etc. The Jacobian is
∂(x,u)
∂(x,y)=/parenleftbigg∂u
∂y/parenrightbigg
x=1
f(x)(15.51)
so the pdf (15.42), expressed in the new variables, is
p(dxdu|I)=/radicalbig
1−ρ2
2πexp/braceleftbigg
−1
2(x2+u2f2(x)−2ρuf(x))/bracerightbigg
f(x)dxdu. (15.52)
Again, we can integrate out uorx, leading to a marginal distribution p(dx|I), which is
easily seen to be identical with (15.43), and p(du|I), which is found to be identical with
(15.44) transformed to the variable u, as it should be; so far, so good.
But now, what is the conditional pdf for x, given that u=0? If we follow the reasoning
that led us to (15.45); i.e. simply set u=0 in (15.52) and renormalize, we ﬁnd
p(dx|u=0I)=Aexp/braceleftbigg
−1
2x2/bracerightbigg
f(x)dx. (15.53)
Now from (15.50) the condition u=0 is the same as y=0; so it appears that this should
be the same as (15.45) with y0=0. But (15.53) differs from that by an extra factor f(x),
which could be arbitrary!
Many ﬁnd this astonishing and unbelievable; they repeat over and over: ‘But the condition
u=0i sexactly the same condition asy=0; how can there be a different result?’ We warned
against this phenomenon brieﬂy, and perhaps too cryptically, in Chapter 4; but there it did

<<<PAGE 501>>>

15 Paradoxes of probability theory 469
not actually cause an error because we had only one parameter in the problem. Now we
need to examine it carefully to see the error and the solution.
We noted in Chapter 1 that we shall make no attempt to deﬁne any probability conditional
on contradictory premises; there could be no unique solution to such a problem. We starteach problem by deﬁning a ‘sample space’ or ‘hypothesis space’ which sets forth the
range of conditions we shall consider in that problem . In the present problem, our discrete
hypotheses were of the form ‘ a≤y≤b’, placing yin an interval of positive measure b−a.
Then what could we mean by the proposition ‘ y=0’, which has measure zero? We could
mean only the limit of some sequence of propositions referring to positive measure, such as
A
/epsilon1≡|y|</epsilon1 (15.54)
as/epsilon1→0. The propositions A/epsilon1conﬁne the point ( x,y) to successively narrower horizontal
strips, but for any /epsilon1>0,A/epsilon1is a discrete proposition with a deﬁnite positive probability,
so by the product rule the conditional probability of any hypothesis H≡‘xin dx’,
p(H|A/epsilon1I)=p(HA/epsilon1|I)
p(A/epsilon1|I)(15.55)
is well-deﬁned, and the limit of this as /epsilon1→0 is also a well-deﬁned quantity. Perhaps that
limit is what one meant by p(H|y=0I).3
But the proposition ‘ y=0’ may be deﬁned equally well as the limit of the sequence
B/epsilon1≡|y|</epsilon1|x| (15.56)
of successively thinner wedges, and p(H|B/epsilon1I) is also unambiguously deﬁned as in (15.55)
for all/epsilon1>0. Although the sequences {A/epsilon1},{B/epsilon1}tend to the same limit y=0, the conditional
densities tend to different limits:
lim
/epsilon1→0p(H|A/epsilon1)∝g(x),
lim
/epsilon1→0p(H|B/epsilon1)∝|x|g(x),(15.57)
and in place of|x|we could put an arbitrary non-negative function f(x). As we see from
this, merely to specify ‘ y=0’ without any qualiﬁcations is ambiguous; it tells us to pass
to a measure-zero limit, but does not tell us which of any number of limits is intended.
We have here one more example showing why the rules of inference derived in Chapter 2
must be obeyed strictly, in every detail . Intuitive shortcuts have a potential for disaster,
which is particularly dangerous just because of the fact that it strikes only intermittently.An intuitive ad hockery that violates those rules will probably lead to a correct result in
some cases; but it will surely lead to disaster in others. Whenever we have a probabilitydensity on one space, and we wish to generate from it one on a subspace of measure zero,the only safe procedure is to pass to an explicitly deﬁned limit by a process like (15.55).In general, the ﬁnal result will and must depend on which limiting operation was speciﬁed.
3Note again what we belabor constantly: the rules of probability theory tell us unambiguously that it is the limit of the ratio, not
the ratio of the limits, that is to be taken in (15.55). The former quantity remains ﬁnite and well-behaved in conditions wherethe latter does not exist.

<<<PAGE 502>>>

470 Part 2 Advanced applications
This is extremely counter-intuitive at ﬁrst hearing; yet it becomes obvious when the reason
for it is understood.
A famous puzzle based on this paradox concerns passing from the surface of a sphere
to a great circle on it. Given a uniform probability density over the surface area, whatis the corresponding conditional density on any great circle? Intuitively, everyone saysimmediately that, from geometrical symmetry, it must be uniform also. But if we specifypoints by latitude ( −π/2≤θ≤π/2) and longitude (−π<φ≤π), we do not seem to
get this result. If that great circle is the equator, deﬁned by |θ|</epsilon1as/epsilon1→0, we have the
expected uniform distribution p(φ)=(2π)
−1(−π<φ≤π). But if it is the meridian of
Greenwich deﬁned by |φ|</epsilon1as/epsilon1→0, we have p(θ)=(1/2) cos( θ)(−π/2≤θ≤π/2),
with the density reaching a maximum on the equator and zero at the poles.
Many quite futile arguments have raged – between otherwise competent probabilists –
over which of these results is ‘correct’. The writer has witnessed this more than once atprofessional meetings of scientists and statisticians. Nearly everybody feels that he knows
perfectly well what a great circle is; so it is difﬁcult to get people to see that the term ‘greatcircle’ is ambiguous until we specify what limiting operation is to produce it. The intuitive
symmetry argument presupposes unconsciously the equatorial limit; yet one eating slicesof an orange might presuppose the other.
15.8 The marginalization paradox
The tumbling tetrahedrons problem ﬂared up into an even more spectacular case of probabil-
ity theory gone crazy, with the work of Dawid, Stone, and Zidek (1973), hereafter denotedby DSZ, which for a time seemed to threaten the consistency of all probability theory.The marginalization paradox is more complicated than the ones discussed above, becauseit arises not from a single error, but from a combination of errors of logic and intuition,insidious because they happened to support each other. When ﬁrst propounded it seems tohave fooled every expert in the ﬁeld, with the single exception of D. A. S. Fraser, who, asdiscussant of the DSZ paper, saw that the conclusions were erroneous and put his ﬁngercorrectly on the cause of this; but he was not listened to.
The marginalization paradox also differs from the others in that it received the immediate,
enthusiastic endorsement of the establishment, and therefore it has been able to do far moredamage to the cause of scientiﬁc inference than any, other; yet, when properly understood,the phenomenon has useful applications in scientiﬁc inference. Marginalization as a poten-tially useful means of constructing uninformative priors is discussed incompletely in Jaynes(1980); this rather deep subject still has the status of ongoing research, in which the maintheorems are probably not yet known.
In the present chapter we are concerned with the marginalization story only as a weird
episode of history which accomplished one good thing by forcing Bayesians to revise someeasy, shortcut inference procedures. We illustrate the original paradox by the scenario ofDSZ, again following their notation until we see why we must not. It starts as a conventional,and seemingly harmless, nuisance parameter problem.

<<<PAGE 503>>>

15 Paradoxes of probability theory 471
A conscientious Bayesian B1studies a problem with data x≡(x1,..., xn) and a multidi-
mensional parameter θwhich he partitions into two components, θ=(η,ζ), being interested
only in inferences about ζ. Thus his model is deﬁned by some speciﬁed sampling distribu-
tion p(x|ηζ) supposed given in the statement of the problem, and ηis a nuisance parameter
to be integrated out. With a prior π(η,ζ),B1thus obtains the marginal posterior pdf for ζ:
p(ζ|x)=/integraldisplay
dηp(ηζ|x)=/integraltext
dηp(x|ηζ)π(η,ζ)/integraltext
dζ/integraltext
dηp(x|ηζ)π(η,ζ), (15.58)
the standard result, which summarizes everything B1knows about ζ. The issue now turns
on what class of priors π(η,ζ) we may assign for this purpose. Our answer is, of course:
Any proper prior, or any limit of a sequence of such priors, such that the ratio of integrals
in (15.58) converges to yield a proper posterior pdf for ζ, may be admitted into our theory
as representing a conceivable state of prior knowledge about the parameters. Eq. (15.58)will then yield the correct conclusions that follow from that state of knowledge.
This need not be qualiﬁed by any special circumstances of the particular problem; we believe
that this policy, followed strictly, cannot generate ambiguities or contradictions. But failure
to follow it can lead to almost anything.
However, DSZ did not see it that way at all. They concentrate on a special circumstance,
noting that in many cases the data xmay be partitioned into two components: x=(y,z)i n
such a way that ‘the sampling distribution for zis independent of the nuisance parameter η’,
which property they write (DSZ, Eq. (1.2)) as
p(z|ηζ)=/integraldisplay
dyp(yz|ηζ)=p(z|ζ), (15.59)
which, by itself, would appear rather generally possible, but without any very deep signif-
icance. For example, if ηis a location parameter, then any function z(x) of the data that
is invariant under rigid translations will have a sampling distribution independent of η.I f
ηis a scale parameter, then any function z(x) invariant under scale changes will have this
property. If ηis a rotation angle, then any component of the data that is invariant under
those rotations will qualify. DSZ proceed to discover cases in which, when (15.59) holdsandB
1assigns an improper prior to η, he ﬁnds that his marginal posterior pdf for ζ‘is a
function of zonly’, which, in view of (15.59), DSZ would presumably write as
p(ζ|yz)=p(ζ|z). (15.60)
At this point there enters a lazy Bayesian B2, who ‘always arrives late on the scene of
inference’, and the combination of (15.59) and (15.60) sets off for him a curious train of
thought. From (15.60) as written it appears that the component yof the data can be discarded
as irrelevant to inferences about ζ. The appearance of (15.59) then suggests that ηmight
also be removed from the model as irrelevant. So he proposes to simplify the calculation;his intuitive judgment is that, given (15.59) and (15.60), we should be able to derive themarginal pdf for ζmore easily by direct application of Bayes’ theorem in a reduced model

<<<PAGE 504>>>

472 Part 2 Advanced applications
p(z|ζ) in which ( y,η) do not appear at all. Thus if B2assigns the prior π(ζ), he obtains the
posterior distribution
p(ζ|z)=p(z|ζ)π(ζ)/integraltext
dζp(z|ζ)π(ζ). (15.61)
But he ﬁnds to his dismay that he cannot reproduce B1’s result (15.58) whatever prior he
assigns to ζ. What conclusions should we draw from this?
For DSZ, the reasoning of B2seemed compelling; on grounds of this intuitive ‘reduction
principle’ they considered it obvious that B1and B2ought to get the same results, and
therefore that one of them must be guilty of some transgression. They point the accusingﬁnger at B
1thus: ‘ B2’s intervention has revealed the paradoxical unBayesianity of B1’s
posterior distribution for ζ.’ They place the blame on his use of an improper prior for η.
For us, the situation appears very different; B2’s result was not derived by application
of our rules. Eq. (15.61) was only an intuitive guess; as the reader may verify, it does not
follow mathematically from (15.58), (15.59) and (15.60). Therefore, (15.61) is not a valid
application of probability theory to B 1’sproblem . If intuition suggests otherwise, then that
intuition needs educating – just as it did in the other paradoxes.
At this stage we are faced not just with one confusion, but with three. The notation used
above conceals from view some crucial points:
(1) While the result (15.60) is ‘a function of zonly’ in the sense that ydoes not appear explicitly in
(15.60), it is a different function of zfor different η-priors. That is, it is still a functional of the
η-prior, as is clear from a glance at (15.58); through this dependence, probability theory is telling
us that prior information about ηstill matters. As soon as we realize this, we see that B2comes
to a different conclusion than B1not because B1is committing a transgression, but for just the
opposite reason: B1is taking into account relevant prior information that B2is ignoring.
(2) But the real trouble starts farther back than that. We need to be aware that current orthodox
notation has a more basic ambiguity that makes the meaning of (15.59) and (15.60) undeﬁned,and this is corrected only by the notation introduced by Harold Jeffreys (1939) and expoundedin our Chapter 2 and Appendix B. Thus, we understand that the symbol p(yz|ηζ) stands for the
joint probability (density) for y,zconditional on speciﬁc numerical values for the two parameters
η,ζ that are present in our model. But then what does p(z|ζ) stand for? Presumably this is not
intended to say that ηhas no numerical value at all!
Indeed, if he wished to refer to a different model in which ηis not present at all, the orthodoxian
would use the same notation p(z|ζ). So it seems that, strictly speaking, we should always interpret
the symbol p(z|ζ) as referring to that different model. But that is not the intention in (15.59);
reference is being made to a model in which ηis still present, but the probability for zis independent
of its numerical value. It seems that the only way this could be expressed in orthodox notation isto rewrite (15.59) as
∂
∂ηp(z|ηζ)=0. (15.62)
(3) This ambiguity, and still another one, is present in (15.60); here the intention is only to indicate
thatp(ζ|yz) is independent of the numerical value of y; but the symbol p(ζ|z), strictly speaking,
must be held to refer to a different model in which the datum ywas not given at all. Now we
have the additional ambiguity that any posterior probability depends necessarily on the prior

<<<PAGE 505>>>

15 Paradoxes of probability theory 473
information; yet the notation in (15.60) makes no reference to any prior information.4We begin
to see why the marginalization paradox was so confusing!
There is a better way of looking at this, which avoids all the above confusions while using
the mathematics that was intended by DSZ; we may take a more charitable view of B2if
we put these equations in a different scenario. The lazy Bayesian, B2, was introduced as
a fellow who invents a shortcut method that violates the rules of probability theory. Butwe may suppose equally well that, through no fault of his own, he is only an uninformedfellow who was given only the reduced model p(z|ζ) in which ηis not present; and he is
unaware of the existence of ( η,y). Then (15.61) is a valid inference for the different state of
knowledge thatB
2has; and it is valid whether or not the separation property (15.60) holds.5
Although the equations are the same because we deﬁned B2’s model by B1’s marginal
sampling distribution p(z|ζ), this avoids much confusion; viewed in this way, B1andB2
are both making valid inferences, but about two different problems.
Both of these new ambiguities arise from the fact that orthodox notation fails to indicate
which model is being considered. But both are corrected by including the prior information
symbol I, understood to be a proposition deﬁned somewhere in the surrounding context,
that includes full speciﬁcation of the model. If we follow the example of Jeffreys and writethe right-hand sides of (15.58) and (15.61) correctly as p(ζ|yzI
1) and p(ζ|zI2), thereby
making this difference in the problems clear, there can be no appearance of paradox. Theprior information I
1speciﬁes the full sampling distribution p(yz|ηζ), while I2speciﬁes a
model only by p(z|ζ), which makes no reference to ( η,y). That B1andB2came to different
conclusions from different prior information is no more strange than if they had come todifferent conclusions from different data.
Exercise 15.2. Consider the intermediate case of a third Bayesian, B3, who has the
same prior information as B1aboutη,ζbut is not given the data component y. Then y
never appears in B3’s equations at all; his model is the marginal sampling distribution
p(z|ηζI3). Show that, nevertheless, if (15.59) still holds (in the interpretation intended,
as indicated by (15.62)), then B2andB3are always in agreement, p(ζ|zI3)=p(ζ|zI2),
and that to prove this it is not necessary to appeal to (15.60). Merely withholding thedatum yautomatically makes any prior knowledge about ηirrelevant to inference about
ζ. Ponder this until you can explain in words why it is, after all, intuitively obvious.
4Yet, as we stress again, if you fail to specify the prior information, a problem of inference is just as ill-posed as if you had
failed to specify the data. In practice, orthodoxy is able to function in spite of this in some problems, by the tacit assumptionthat an uninformative prior is to be used. Of course, the dedicated orthodoxian will deny vehemently that he is making any such
assumption; nevertheless, it is a mathematical fact that his conclusions are what a Bayesian would obtain from an uninformative
prior . This was demonstrated already by Jeffreys (1939).
5The fact that (15.60) is not essential to the problem was not yet clearly seen in Jaynes (1980); the marginalization problem was
more subtle than any that Bayesians had faced up to that time. Because DSZ laid so much stress on (15.60), we followed them
in concentrating on ﬁnding conditions for its validity. Today, with the beneﬁt of hindsight, it is clear that there is in general
no reason to expect (15.60) to hold, so it loses its supposed importance. This deeper understanding enables us to ﬁnd usefulsolutions to current problems of inference far more subtle than marginalization, as demonstrated by Bretthorst (1988). But the
secret of success here is, as always, simply: absolutely strict adherence to the rules of conduct derived in Chapter 2. As these
paradoxes show, the slightest departure from them can generate gross absurdities.

<<<PAGE 506>>>

474 Part 2 Advanced applications
15.8.1 On to greater disasters
Up to this point, we had only a misreading of equations through inadequate notation; but
now a comedy of mutually reinforcing errors commenced. In support of their contentionthat B
1is the guilty party, DSZ offered a proof that this paradox (i.e. the discrepancy in
the results of B1andB2) ‘could not have arisen if B1had employed proper prior distri-
butions’. Let us examine their proof of this, still using their notation. With a general jointproper prior π(η,ζ) the integrals in (15.58) are separately convergent and positive, so if
we multiply through by the denominator, we are neither multiplying nor dividing by zero.Then
p(x|ηζ)=p(yz|ηζ)=p(y|zηζ)p(z|ηζ)=p(y|zηζ)p(z|ζ), (15.63)
where we used the product rule and (15.59). Then (15.58) becomes
p(ζ|yz)/integraldisplay
dζ/integraldisplay
dηp(y|zηζ)p(z|ζ)π(η,ζ)=/integraldisplay
dηp(y|zηζ)p(z|ζ)π(η,ζ).(15.64)
But now we assume that (15.60) still holds; because the integrals are absolutely convergent,
we may integrate out yfrom both sides of (15.64), whereupon/integraltext
dηπ(η,ζ)=π(ζ) and
(15.64) reduces to
p(ζ|z)/integraldisplay
dζp(z|ζ)π(ζ)=p(z|ζ)π(ζ), (15.65)
which is identical with (15.61). DSZ concluded that, if B
1uses a proper prior, then B1and
B2are necessarily in agreement – from which it would follow again, in agreement with
their intuition, that the paradox must be caused by B1’s use of improper priors.
But this proof of (15.65) has used mutually contradictory assumptions. As Fraser recog-
nized, if B1uses a proper prior, then (15.60) cannot be true and (15.65) does not follow; it
is no accident that DSZ had found (15.60) only with improper priors. This is easiest to seein terms of a speciﬁc example, after which it will become obvious why it is true in general.In the following we use the full notation of Jeffreys so that we always distinguish betweenthe two problems.
The change-point problem
Observations have been made of nsuccessive, independent, positive real, ‘exponentially
distributed’ quantities {x
1,..., xn}. It is known (deﬁnition of the model) that the ﬁrst ζof
these have expectations 1 /ηand the remaining ( n−ζ) have expectations 1 /(cη), where cis
known and c/negationslash=1, while ηandζare unknown. From the data, we want to estimate at what
point in the sequence the change occurred. The sampling density for x≡(x1,..., xn)i s
p(x|ηζI1)=cn−ζηnexp/braceleftBigg
−η/parenleftBiggζ/summationdisplay
i=1xi+cn/summationdisplay
i=ζ+1xi/parenrightBigg/bracerightBigg
, 1≤ζ≤n. (15.66)
Ifζ=n, then there is no change, the last sum in (15.66) is absent, and cdisappears from
the model. Since ηis a scale parameter, the sampling distribution for ratios of observations

<<<PAGE 507>>>

15 Paradoxes of probability theory 475
zi≡xi/x1should be independent of η. Indeed, separating the data x=(y,z) into
y≡x1, which sets the scale and the ratios ( z2,..., zn), and noting that the volume element
transforms as d x1···dxn=yn−1dydz2···dzn, we ﬁnd that the joint sampling distribution
forz≡(z2,..., zn) depends only on ζ:
p(z2···zn|ηζI1)=/integraldisplay∞
0dycn−ζηnyn−1exp{ηyQ(ζ,z)}=cn−ζ(n−1)!
Q(ζ,z)n=p(z|ζI1),
(15.67)
where z1≡1 and
Q(ζ,z)≡ζ/summationdisplay
1zi+cn/summationdisplay
ζ+1zi (15.68)
is a function that is known from the data. Let B1choose a properly normalized discrete
priorπ(ζ)i n( 1≤ζ≤n), and independently a prior π(η)dηin (0<η<∞). Then B1’s
marginal posterior distribution for ζis, from (15.66),
p(ζ|yzI 1)∝π(ζ)cn−ζ/integraldisplay∞
0dηexp{−ηyQ}π(η)ηn, (15.69)
and, from (15.67), B2’s posterior distribution (15.61) for ζis now
p(ζ|zI2)∝π(ζ)p(z|ζ)=π(ζ)c−ζ
[Q(ζ,z)]n, (15.70)
which takes no note of π(η). But, as expected from the above discussion, not only does
B1’s knowledge about ζdepend on both yandz, it depends just as strongly on what prior
π(η) he assigned to the nuisance parameter.
On meditation, we see that a little common sense would have anticipated this result at
once. If we know absolutely nothing about ηexcept that it is positive, then the only evidence
we can have about the change point ζmust come from noting the relative values of the xi;
for example, at which idoes the ratio xi/x1appear to change? On the other hand, suppose
that we knew ηexactly; then clearly not only the ratios xi/x1, but also the absolute values
of the xi, would be relevant to inference about ζ. Then, whether xiis closer to 1 /ηor to
1/(cη) tells us something about whether ( i<ζ)o r( i>ζ) that the ratio xi/x1does not tell
us, this extra information would enable us to make better estimates of ζ. If we had only
partial prior knowledge of η, then knowledge of the absolute values of the xiwould be less
helpful, but still relevant, so, as Fraser noted, (15.60) could not be valid.
But now B1discovers that use of the improper prior
π(η)=η−k, 0<η<∞, (15.71)
where kis any real number for which the integral (15.69) converges, leads to the separation
property (15.60), and to the posterior pdf
p(ζ|zI1)∝π(ζ)c−ζ
[Q(ζ,z)]n−k+1, (15.72)

<<<PAGE 508>>>

476 Part 2 Advanced applications
which still depends, through k, on the prior assigned to η. We see that for no prior π(ζ) can
B2agree with B1, except when k=1, in which case B2andB1ﬁnd themselves in agreement
after all, and with the same prior π(ζ). But this result is not peculiar to the change-point
model; it holds quite generally, as the following Exercise shows.
Exercise 15.3. Prove that the k=1 prior is always uninformative in this sense when-
everηis a scale parameter for y. That is, if the sampling distribution has the functional
form
p(yz|ηζ)=η−1h(z,ζ;y/η), (15.73)
then (15.59) follows at once, and B1and B2agree if and only if we use a prior
π(η)∝η−1.
It seems to us that this is an eminently satisfactory result without any trace of paradox.
For the case k=1 is just the Jeffreys prior, which we have already seen to be ‘completely
uninformative’ about any scale parameter η, by several different criteria. Then, of course,
with this prior B1has no extra information after all, and should, indeed, ﬁnd himself in
agreement with B2.
DSZ did not see it that way at all, and persisted in their intuitive judgment that there is a
serious paradox and that B1was at fault for using an improper prior; so the story continues.
DSZ proceed to exhibit many more examples in which this ‘paradox’ appears – invariablywhen an improper prior was used. The totality of all these demonstrations appeared to
mount up into overwhelming evidence that to use any improper prior is to generate in-consistencies. But, in the belief that their proof of (15.65) had already dealt with it, theyfailed to examine what happens in those examples in the case of proper priors, and so theymanaged to get through a long string of examples without discovering the error in thatproof.
6
To correct this omission, and reveal the error in (15.65) clearly, we need only to examine
any of the DSZ examples, to see what happens in the case of proper priors π(η). In the
change-point problem, whatever this prior, B1’s result (15.69) depends on yandzthrough
a function of the product yQ(ζ,z). Then for what functions f(yQ) will the separation
property (15.60) hold? Evidently, the necessary and sufﬁcient condition for this is that y
andζappear in separate factors: in the case where the integrals in (15.58) converge, we
6Another reason for this was their tendency to write the priors in terms of the ‘wrong’ parameters. Usually, a model was deﬁned
initially with certain parameters α, β. The parameters η,ζ for which the relations (15.59), (15.60) held were certain functions
of them: η=η(α, β) , etc. But DSZ continued to write the priors in terms of α,β, which made it seem that the Jeffreys prior
has no particular signiﬁcance; a wide variety of different priors appeared to ‘avoid the paradox’ in various different problems. In
Jaynes (1980) we showed that, had they transformed their parameters to the relevant ones η,ζ, they would have found in every
such case except one that ηwas a scale parameter for yand the ‘paradox’ disappeared for and only for the Jeffreys prior π(η).
Thus Exercise 15.3 includes, in effect, all their examples except the infamous Example #5, which requires a separate treatment
given below.

<<<PAGE 509>>>

15 Paradoxes of probability theory 477
require the integral to have the functional form
/integraldisplay∞
0dηexp{−ηyQ}π(η)ηn=f(yQ)=g(y,z)h(ζ,z), (15.74)
for then and only then will ycancel out upon normalization of p(ζ|yz). The answer is
obvious: if a function of [log( y)+logQ(ζ)] has the form [log g(y)+logh(ζ)], the only
possibility is a linear function: log f(yQ)=a[log( y)+log(Q)] or f(yQ)=(yQ)a, where
a(z,n) may depend on zandn. But then, noting that the Laplace transform is uniquely
invertible, and that
/integraldisplay∞
0dηexp{−ηyQ}ηa−1=(a−1)!
(yQ)a, (15.75)
we see that, contrary to the assumption of DSZ, (15.60) cannot hold unless the prior is of
the improper form π(η)=η−k,0<η<∞.
Exercise 15.4. Show that this result is also general; that is, not only in the change-
point problem, but in any problem like that of Exercise 15.3 where ηis a scale pa-
rameter for y, a prior of the form π(η)=η−kwill lead to a factorization of the form/integraltext
dηp(yz|ηζ)π(η)=g(y,z)h(ζ,z) for some functions g,h, whereupon (15.60) will
hold. For this reason, the many later examples of DSZ are essentially repetitious; theyare only making the same point over and over again.
Evidently, any value of kwhich makes the integral (15.74) converge will lead to a well-
behaved posterior distribution for ζ; but a still wider class of values of kmay do so if the
improper prior is approached, as it should be, as the limit of a sequence of proper priors, asexplained previously.
But use of a proper prior π(η) necessarily means that the separation property (15.60)
cannot hold. For example, choose the prior π(η)∝η
aexp{−bη}. Then (15.69) becomes
p(ζ|yzI 1)∝π(ζ)c−ζ
(b+yQ)n+a+1, (15.76)
and as long as the prior is proper (that is, b>0), the datum ycannot be disentangled, but
remains relevant; and so (15.60) does not hold, as we expected from (15.75). The ‘paradox’disappears, not because B
1and B2agree, but because B2cannot invoke his ‘reduction
principle’ at all. Indeed, in any of the DSZ examples, inserting any proper prior π(η) for
which we can do the integrals will yield an equally good counter-example to (15.65); howcould this have gone undetected for years? We note some of the circumstances that led tothis.

<<<PAGE 510>>>

478 Part 2 Advanced applications
15.9 Discussion
Some have denied that there is any such thing as ‘complete ignorance’, much less any
‘completely uninformative’ prior. From their introductory remarks, it appears that to demon-strate this was the original goal of DSZ, and several discussants continued to emphasize thepoint in agreement with them. But their arguments were verbal, expressing only intuitivefeelings; the mathematical facts conﬁrm the sense of the idea of ‘complete ignorance’ after
all. The Jeffreys prior is doing here what we should naturally suppose an uninformative
prior ought to do, and it does this quite generally (whenever ηis a scale parameter).
Technically, the concurrence of many different results like that of Exercise 15.3 shows
us that the notion of complete ignorance is consistent and useful; the fact that the sameJeffreys prior emerges uniquely from many different and independent lines of reasoningshows how impossible it would be to modify it or abandon it. As is invariably the case in
this ﬁeld, past difﬁculties with the ideas of Jeffreys signiﬁed not any defects in his ideas,
but only misapplications of probability theory by his critics.
Exercise 15.3 shows another sense in which our previous conclusion (that the prior d η/ηis
uninformative about a scale parameter η) is quite literally true; not as an intuitive judgment,
but now as a deﬁnite theorem that follows from the rules of probability theory. Of course,our ultimate goal is always to represent honestly the prior information that we actually have.But, both conceptually and mathematically, the notion of ‘complete ignorance’ is a validand necessary part of this program, as the starting point from which all inference proceeds;
just as the notion of zero is a necessary part of arithmetic.
In the discussion following the DSZ paper, nobody noticed that there was a counter-
example to their proof of (15.65) already in plain sight in the DSZ article (their Example #5,
where it is evident by inspection that B
1andB2remain in disagreement for all priors, proper
or improper), and only Fraser expressed any doubts about the DSZ conclusions. He notedthat DSZ
...propose that the confusion can be avoided by a restriction to proper priors. This is a strange
proposal as a resolution of the difﬁculties – for it means in the interesting cases that one cannot
eliminate a variable, and hence cannot go to the marginal likelihood.
But it seems that these words were, like the prophecies of Nostradamus, too cryptic for
anyone to understand until he had ﬁrst located the error for himself. Fraser’s point – andours above – is that when B
1uses a proper prior, then in general B2’s ‘reduction principle’
cannot be applied because (15.60) ceases to be true. In other words, when B1uses proper
priors, this does not bring B1and B2into agreement. In (15.74) and (15.75) we have
demonstrated that in the change-point problem, agreement of B1andB2requires thatB1
uses an improper prior; just the opposite of the DSZ conclusion.
It is evident, to one who has understood the above analysis, that the situation found in
the change-point problem is actually quite general. For, if one knew both yandη, that
information must be relevant to the inference about ζunless the sampling distributions
are completely independent; that is, unless p(yz|ηζ)=p(y|η)p(z|ζ). Except in this trivial

<<<PAGE 511>>>

15 Paradoxes of probability theory 479
case, if one knows y, any partial information about ηmust still be relevant for inference
aboutζor, similarly, if one knew η, any partial information about ywould be relevant.
But common sense should have told us that any proper prior π(η) on an inﬁnite domain
is necessarily informative about η, for it determines ﬁnite upper and lower bounds within
which ηis almost certain to lie. Seen in this way, Fraser’s cryptic remark becomes obvious –
and in full generality.
In any event, what happened was that nearly everybody accepted the DSZ conclusions
uncritically, without careful examination of their argument. Anti-Bayesians, who very muchwanted the DSZ conclusion to be true, seized upon it eagerly as sounding the death-knell ofall Bayesianity. Under this pressure the prominent Bayesian D. V . Lindley broke down andconfessed to sins of which he was not guilty, and the Royal Statistical Society bestowed awarm vote of thanks upon DSZ for this major contribution to our understanding of inference.
As a result, since 1973 a ﬂood of articles has appeared, rejecting the use of improper
priors under any and all circumstances, on the grounds that they have been proved by DSZ togenerate inconsistencies. Incredibly, the fact that proper priors never ‘correct’ the supposedinconsistencies never came out in all this discussion. Thus the marginalization paradoxbecame, like nonconglomerability, quite literally institutionalized in the literature of thisﬁeld, and taught as truth. Scientiﬁc inference thus suffered a setback from which it willrequire decades to recover.
Nobody noted that this same ‘paradox’ had been found and interpreted correctly long
before by Harold Jeffreys (1939, Sect. 3.8) in connection with estimating the correlationcoefﬁcient ρin a bivariate normal distribution, in which the location parameters are the
uninteresting nuisance parameters. He gives two examples of B
1’s result, corresponding to
different prior information about the nuisance parameters, in his equations (10) and (24),their difference indicating the effect of that prior information. Then he gives B
2’s result in
(28), the agreement with (24) indicating that a uniform prior for the location parameters isuninformative about ρ.
This was seen again independently by Geisser and Cornﬁeld (1963) in connection with
priors for multivariate normal distributions. They perceived that the difference between theresults of B
1andB2, their equations (3.10) and (3.26), was not a paradox, because B2’s result
was not a valid solution to the problem; they termed it, very properly, a ‘pseudoposteriordistribution’. DSZ refer to this work, but when faced with this discrepancy they still placemore conﬁdence in the ‘reduction principle’ than in the rules of probability theory.
In all these examples except one – that Example #5 again – an interesting phenomenon
occurred. While the paradox was present for general improper priors in some inﬁnite class
C, there was always one particular improper prior in that class for which the paradox
disappeared; B
1andB2found themselves in agreement after all. DSZ noted this curious
fact, but do not appear to have noticed its signiﬁcance. We suggest that this was by far themost important fact uncovered in all the marginalization work.
Any prior π(η) which leaves B
1andB2in agreement must be completely uninformative
aboutη(and, a fortiori , about ζ). This means that, far from casting doubt on the notion of
complete ignorance, in the marginalization phenomena we have for the ﬁrst time a purely

<<<PAGE 512>>>

480 Part 2 Advanced applications
objective deﬁnition of complete ignorance that springs directly out of the product and
sum rules of probability theory without appeal to any other notions like entropy or groupinvariance.
This is, again, an eminently satisfactory result; but why does it seem not to be true in
DSZ’s Example #5? There is still something new and important to be learned here.
15.9.1 The DSZ Example #5
We have data D={x
1,..., xn}consisting of nobservations from the standard normal
sampling distribution N(µ,σ). With prior information Idescribed by the proper prior
pdf
p(dµdσ|I)=f(µ,σ)dµdσ, (15.77)
we have the usual joint posterior pdf for the parameters:
p(dµdσ|DI)=g(µ,σ)dµdσ (15.78)
with
g(µ,σ)=f(µ,σ)L(µ,σ)/integraltext
dµ/integraltext
dσf(µ,σ)L(µ,σ)(15.79)
and the likelihood function
L(µ,σ)=σ−nexp/braceleftBig
−n
2σ2[s2+(µ−¯x)2]/bracerightBig
, (15.80)
in which, as usual, ¯x≡n−1/summationtextxiands2≡n−1/summationtext(xi−¯x)2are the sufﬁcient statistics.
Although we suppose the prior f(µ,σ) normalizable, it need not be actually normalized
in (15.79) because any normalization constant appears in both numerator and denominator,and cancels out.
As long as s
2>0, the likelihood is bounded throughout the region of integration −∞<
µ<∞,0≤σ<∞, and therefore with a proper prior the integral in (15.79) is guaranteed
to converge, leading to a proper posterior pdf. Furthermore, if the prior has moments oforder m,k,
/integraldisplay
∞
−∞dµ/integraldisplay∞
0dσµmσkf(µ,σ)<∞, (15.81)
the posterior distribution is guaranteed to have moments of higher order (in fact, all orders
forµand at least as high as order k+nforσ). The solution is therefore very well-behaved
mathematically.
But now we throw the proverbial monkey-wrench into this by declaring that we are
interested only in the quantity
ζ≡µ
σ. (15.82)

<<<PAGE 513>>>

15 Paradoxes of probability theory 481
Making the change of variables ( µ,σ)→(ζ,σ), the volume element transforms as d µdσ=
σdζdσ, so writing p(dζ|DI1)=h1(ζ)dζ,B1’s marginal posterior pdf is
h1(ζ)=/integraldisplay∞
0σdσg(σζ,σ ), (15.83)
and in view of the high moments of gthere are no convergence problems here, as long as
n>1. Thus far, there is no hint of trouble.
Now we examine the solution for a speciﬁc proper prior that can approach an improper
prior. Consider the conjugate prior probability element
f(µ,σ)dµdσ∝σ−γ−1exp{−β/σ−αµ2}dµdσ, (15.84)
which is proper when ( α, β, γ )>0, and tends to the Jeffreys uninformative prior d µdσ/σ as
(α, β, γ )→0. This leads to the joint posterior pdf, p(dµdσ|DI)=g(µ,σ)dµdσwith
density function
g(µ,σ)∝σ−n−γ−1exp/braceleftbigg
−β
σ−αµ2−n
2σ2[s2+(µ−x)2]/bracerightbigg
, (15.85)
from which we are to calculate the marginal posterior pdf for ζalone by the integration
(15.83). The result depends on both sufﬁcient statistics ( ¯x,s), but is most easily written in
terms of a different set. The quantities R,r, where
R2≡n(¯x2+s2)=/summationdisplay
x2
i, r≡n¯x
R=/summationtextxi/radicalBig/summationtextx2
i, (15.86)
also form a set of jointly sufﬁcient statistics, and from (15.85) and (15.83) we ﬁnd the
functional form p(dζ|DI1)=h1(ζ|r,R)dζ, where
h1(ζ|r,R)∝exp/braceleftbigg
−nζ2
2/bracerightbigg/integraldisplay∞
0dωωn+γ−1exp/braceleftbigg
−1
2ω2+rζω−βR−1ω−αζ2R2ω−2/bracerightbigg
.
(15.87)
As long as αorβis positive, the result depends on both sufﬁcient statistics, as Fraser
predicted; but, as α,βtend to zero and we approach an improper prior, the statistic R
becomes less and less informative about ζ, and when α,βboth vanish the dependence on
Rdrops out altogether:
h1(ζ|r,R)→h1(ζ|r)∝exp/braceleftbigg
−nζ2
2/bracerightbigg/integraldisplay∞
0dωωn+γ−1exp/braceleftbigg
−1
2ω2+rζω/bracerightbigg
.(15.88)
If then one were to look only at the limiting case α=β=0 and not at the limiting process,
it might appear that just ralone is a sufﬁcient statistic for ζ, as it did in (15.60). This
supposition is encouraged by noting that the sampling distribution for rin turn depends
only on ζ, not on µandσseparately:
p(r|µσ)∝(n−r2)(n−3)/2/integraldisplay∞
0dωωn−1exp/braceleftbigg1
2ω2+rζω/bracerightbigg
. (15.89)

<<<PAGE 514>>>

482 Part 2 Advanced applications
It might then seem that, in view of (15.88) and (15.89), we should be able to derive the
same result by applying Bayes’ theorem to the reduced sampling distribution (15.89). Butone who supposes this ﬁnds, to his dismay, that (15.89) is not a factor of (15.88); that is,the ratio h
1(ζ|r)/p(r|ζ) depends on ras well as ζ. The Jeffreys uninformative prior γ=0
does indeed make the two integrals equal, but there remains an uncompensated factorwith ( n−r
2), and so even the uninformative Jeffreys prior for ( µ,σ) cannot bring about
agreement of B1andB2. There is no prior p(ζ|I2) that can yield B1’s posterior distribution
(15.88) from B2’s sampling distribution (15.89).
Since the paradox is still present for a proper prior, this is another counter-example to
(15.65); but it has a deeper meaning for us. What is now the information being used by B1
but ignored by B2? It is not the prior probability for the nuisance parameter; the new feature
is that in this model the mere qualitative fact of the existence of the nuisance parameter in the
model already constitutes prior information relevant to B 1’sinference , which B2is ignoring.
Recognizing this, we suddenly see the whole subject in a much broader light. We found
above that (15.60) is not essential to the marginalization phenomenon; now we see that
concentration on the nuisance parameter ηis not an essential feature either! If there is any
prior information whatsoever that is relevant to ζ,whether or not it refers to η, that B1is
taking into account but B2is not, then we are in the same situation, and our two Bayesians
come, necessarily, to different conclusions. In other words, DSZ considered only a veryspecial case of the real phenomenon.
This situation is discussed in Jaynes (1980, following Eq. (79)), where the phenomenon
is called ‘ ζ-overdetermination’. Reverting to our original notation in (15.58) and denoting
B
1’s prior information by I1, it is shown that the general necessary and sufﬁcient condition
for agreement of B1andB2is that
/integraldisplay
dηp(y|zηζI1)π(η)=p(y|zζI1) (15.90)
shall be independent of ζfor all possible samples y,z. Denoting the parameter space and
our partitioning into subspaces by Sθ=Sζ⊗Sη, we may write this as
/integraldisplay
Sηdηp(yz|ηζ)π(η)=p(y|zI1)p(z|ζ)/braceleftBigg
ζ∈Sζ
ally,z(15.91)
or, more suggestively,/integraldisplay
SηdηK(ζ,η)π(η)=λf(ζ). (15.92)
This is a Fredholm integral equation in which the kernel is B1’s likelihood, K(ζ,η)=
p(yz|ζη), the ‘driving force’ is B2’s likelihood f(ζ)=p(z|ζ), and λ(y,z)≡p(y|zI1)
is an unknown function to be determined from (15.92). But now we see the meaning of‘uninformative’ much more deeply; for every different data set ( y,z) there is a different
integral equation. Therefore, for a single prior π(η) to qualify as ‘uninformative’, it must
satisfy many different (in general, an uncountable number) of these integral equations
simultaneously.

<<<PAGE 515>>>

15 Paradoxes of probability theory 483
At ﬁrst glance, it seems almost beyond belief that any prior could do this; from a math-
ematical standpoint the condition seems hopelessly overdetermined, casting doubt on thenotion of an uninformative prior. Yet we have many examples where such a prior doesexist. In Jaynes (1980) we analyzed the structure of these integral equations in some detail,showing that the different status of Example #5 is due to the ‘incompleteness’ of the kernel.
More speciﬁcally, the set of all L
2functions on Sζforms a Hilbert space Hζ. For any
speciﬁed data set x=(y,z), asηranges over Sη, the functions K(ζ,η), in their dependence
onζ, span a certain subspace H/prime
ζ(y,z)∈Hζ. The kernel is said to be complete ifH/prime
ζ=Hζ.
If it is incomplete, then if there is any data set ( y,z) for which f(ζ) does not lie in H/prime
ζ,
there can be no solution of (15.92). In such cases, the mere qualitative fact of the existence
of the components ( y,η) – irrespective of their numerical values – already constitutes prior
information relevant to B1’s inference, because introducing them into the model restricts
the space of B1’s possible likelihood functions (from different data sets y,z) from Hζto
H/prime
ζ. In this case the shrinkage of Hζcannot be restored by any prior on Sη, and there is no
possibility for agreement of B1andB2.
In general, the point is that the integral equation for any one data set ximposes only very
weak conditions on π(η), determining its projection on only a tiny subspace H(x)∈Hζ.
As we consider different data sets, the H(x) are scattered about, like stars in the sky, within
the full Hilbert space Hζ. There is room for all of them, so the system of integral equations
has nontrivial solutions after all.
15.9.2 Summary
Looking at the above equations with all this in mind, we now see that there was never any
paradox or inconsistency after all; one should not have expected (15.88) to be derivable from(15.89) by Bayes’ theorem because they are the posterior distribution and sampling distri-bution for two different problems, in which the model has different parameters. Eq. (15.88)is the correct marginal posterior pdf for ζin a problem P
1with two parameters ( ζ,σ);
but, although σis integrated out to form the marginal pdf, the result still depends on what
prior we have assigned to σ– as it should, since, if σis known, it is highly relevant to
the inference; if it is unknown, any partial prior information we have about it must still berelevant.
In contrast, (15.89) can be interpreted as a valid sampling distribution for a problem P
2
in which ζis the only parameter present; the prior information does not even include the
existence of the parameter σwhich was integrated out in P 1. With a prior density f2(ζ)i t
would yield a posterior pdf
h2(ζ)∝f2(ζ)/integraldisplay
dωωn−1exp/braceleftbigg
−1
2ω2+rζω/bracerightbigg
(15.93)
of a different functional form than (15.88). In view of the earlier work of Jeffreys and of
Geisser and Cornﬁeld, one could hardly claim that the situation was new and startling, muchless paradoxical.

<<<PAGE 516>>>

484 Part 2 Advanced applications
Forty years earlier, Harold Jeffreys was immune from such errors because (1) he perceived
that the product and sum rules of probability theory are adequate to conduct inference andthey take precedence over intuitive ad hoc devices like the reduction principle; (2) he had
recognized from the start that all inferences are necessarily conditional not only on thedata, but also on the prior information – therefore his formal probability symbols P(A|BI)
always indicated the prior information I, which included speciﬁcation of the model.
Today, it seems to us incredible that anyone could have examined even one problem of
inference without perceiving this necessary role of prior information; what kind of logiccould they have been using? Nevertheless, those trained in the ‘orthodox’ tradition of
probability theory did not recognize it. They did not have a term for prior information intheir vocabulary, much less a symbol for it in their equations; and a fortiori no way of
indicating when two probabilities are conditional on different prior information.
7So they
were helpless when prior information mattered.
15.10 A useful result after all?
In most paradoxes there is something of value to be salvaged from the debris, and we think
(Jaynes, 1980) that the marginalization paradox may have made an important and useful
contribution to the old problem of ‘complete ignorance’. How is the notion to be deﬁned,and how is one to construct priors expressing complete ignorance? We have discussed thisfrom the standpoint of entrop y and symmetry (transformation groups) in previous chapters;
now marginalization suggests still another principle for constructing uninformative priors.
Many cases are known, of which we have seen examples in DSZ, where a problem has
a parameter of interest ζand an uninteresting nuisance parameter η. Then the marginal
posterior pdf for ζwill depend on the prior assigned to ηas well as on the sufﬁcient
statistics. Now for certain particular priors p(η|I) one of the sufﬁcient statistics may drop
out of the marginal distribution p(ζ|DI), as Rdid in (15.88). It is at ﬁrst glance surprising
that the sampling distribution for the remaining sufﬁcient statistics may in turn depend onlyonζas in (15.89).
Put differently, suppose a problem has a set of sufﬁcient statistics ( t
1,t2) for the parameters
(ζ,η). Now, if there is some function r(t1,t2) whose sampling distribution depends only on ζ,
so that p(r|ζηI)=p(r|ζI), this deﬁnes a pseudoproblem with different prior information
I2, in which ηis never present at all. Then there may be a prior p(η|I) for which the posterior
marginal distribution p(ζ|DI)=p(ζ|rI) depends only on the component rof the sufﬁcient
7Indeed, in the period 1930–1960 nearly all orthodoxians, under the inﬂuence of R. A. Fisher, scorned Jeffreys’ work, and some
took a militant stand against prior information, teaching their students that it is not only intellectually foolish, but also morally
reprehensibl e – a deliberate breach of ‘scientiﬁc objectivity’ – to allow one’s self to be inﬂuenced by prior information at
all! This did little damage in the very simple problems considered in the orthodox literature, where there was no signiﬁcantprior information anyway. And it did relatively little damage in physical science where prior information is important, becausescientists ignored orthodox teaching and persisted in doing, qualitatively, the Bayesian reasoning using prior information thattheir own common sense told them was the right thing to do. But we think it was a disaster for ﬁelds such as econometrics andartiﬁcial intelligence, where adoption of the orthodox view of probability had the automatic consequence that the signiﬁcant
problems could not even be formulated, much less solved, because the orthodox view of probability theory does not recognize
probability as expressing information at all.

<<<PAGE 517>>>

15 Paradoxes of probability theory 485
statistic. This happened in the example studied above; but now, more may be true. It may
be that for that prior on ηthe pseudoposterior pdf for ζis identical with the marginal pdf
in the original problem. If a prior brings about agreement between the marginal posteriorand the pseudoposterior distributions, how should we interpret this?
Suppose we start from the pseudoproblem. It seems that if introducing a new parameter
ηand using the prior p(η|I) makes no difference, then it has conveyed no information at all
about ζ: that prior must express ‘complete ignorance’ of ηin a rather fundamental sense.
In all cases yet found the prior p(η|I) which does this on an inﬁnite domain is improper;
this lends support to that conclusion because, as noted, our common sense should have toldus that any proper prior on an inﬁnite domain is necessarily informative about η; it places
some ﬁnite limits on the range of values that ηcould reasonably have, whether we interpret
‘reasonably’ as ‘with 99% probability’ or ‘with 99.9% probability’ ...and so on.
Can this observation be extended to a general technique for constructing uninformative
priors beyond the location and scale parameter cases? This is at present an ongoing researchproject rather than a ﬁnished part of probability theory, so we defer it for the future.
15.11 How to mass-produce paradoxes
Having examined a few paradoxes, we can recognize their common feature. Fundamen-
tally, the procedural error was always failure to obey the product and sum rules of prob-ability theory. Usually, the mechanism of this was careless handling of inﬁnite sets andlimits, sometimes accompanied by attempts to replace the rules of probability theory byintuitive ad hoc devices like B
2’s ‘reduction principle’. Indeed, paradoxes caused by care-
less dealing with inﬁnite sets or limits can be mass-produced by the following simpleprocedure:
(1) Start from a mathematically well-deﬁned situation, such as a ﬁnite set, a normalized probability
distribution, or a convergent integral, where everything is well-behaved and there is no questionabout what is the correct solution.
(2) Pass to a limit – inﬁnite magnitude, inﬁnite set, zero measure, improper pdf, or some other kind –
without specifying how the limit is approached.
(3) Ask a question whose answer depends on how the limit was approached.
This is guaranteed to produce a paradox in which a seemingly well-posed question has more
than one seemingly right answer, with nothing to choose between them. The insidious thingabout it is that, as long as we look only at the limit, and not the limiting process, the sourceof the error is concealed from view.
Thus, it is not surprising that those who persist in trying to evaluate probabilities di-
rectly on inﬁnite sets have been able to study ﬁnite additivity and nonconglomerability fordecades – and write dozens of papers of impressive scholarly appearance about it. Like-wise, those who persist in trying to calculate probabilities conditional on propositions of
probability zero, have before them an unlimited ﬁeld of opportunities for scholarly looking
research and publication – without hope of any meaningful or useful results.

<<<PAGE 518>>>

486 Part 2 Advanced applications
In our opening quotation, Gauss had a situation much like this in mind. Whenever we ﬁnd
a belief that such inﬁnite sets possess some kind of ‘existence’ and mathematical propertiesin their own right, independent of any such limiting process, we can expect to see paradoxesof the above type. But note that this does not in any way prohibit us from using inﬁnite setsto deﬁne propositions . Thus the proposition
G≡1≤x≤2 (15.94)
invokes an uncountable set, but it is still a single discrete proposition, to which we may
assign a probability P(G|I) deﬁned on a sample space of a ﬁnite number of such propo-
sitions without violating our ‘probabilities on ﬁnite sets’ policy. We are not assigning anyprobability directly on an inﬁnite set.
But then if we replace the upper limit 2 by a variable quantity z, we may (and nearly
always do) ﬁnd that this deﬁnes a well-behaved function, f(z)≡P(G|zI). In calculations,
we are then free to make use of whatever analytic properties this function may have, as wenoted in Chapter 6. Even if f(z) is not an analytic function, we may be able to deﬁne other
analytic functions from it, for example by integral transforms. In this way, we are able todeal with any real application that we have been able to imagine, by discrete algebraic orcontinuum analytical methods, without losing the protection of Cox’s theorems.
15.12 Comments
In this chapter and Chapter 5, we have seen two different kinds of paradox. There are
‘conceptually generated’ ones, such as the Hempel paradox of Chapter 5, which arisefrom placing faulty intuition above the rules of probability theory, and ‘mathematicallygenerated’ ones, such as nonconglomerability, which arise mostly out of careless use ofinﬁnite sets. Marginalization is an elaborate example of a compound paradox, generatedby both conceptual errors and mathematical errors which happened to reinforce each other.It seems that nothing in the mathematics can protect us against conceptual errors, but wemight ask whether there are better ways of protection against mathematical ones.
Back in Chapter 2 we saw that the rules of probability theory can be derived as necessary
conditions for consistency, as expressed by Cox’s functional equations. The proofs appliedto ﬁnite-sets of propositions, but when the results of a ﬁnite-set calculation can be extendedto an inﬁnite set by a mathematically well-behaved passage to a limit, we also accept thatlimit.
It might be thought that it would be possible, and more elegant, to generalize Cox’s
proofs so that they would apply directly to inﬁnite sets; and indeed that is what the writerbelieved and tried to carry out for many years. However, since at least the work of Bertrand(1889), the literature has been turning up paradoxes that result from attempts to apply therules of probability theory directly and indiscriminately on inﬁnite sets; we have just seensome representative examples and their consequences. Since in recent years there has beena sharp increase in this paradoxing, one must take a more cautious view of inﬁnite sets.

<<<PAGE 519>>>

15 Paradoxes of probability theory 487
Our conclusion – based on some 40 years of mathematical efforts and experience with
real problems – is that, at least in probability theory, an inﬁnite set should be thought of onlyas the limit of a speciﬁc (i.e. unambiguously speciﬁed) sequence of ﬁnite sets. Likewise,an improper pdf has meaning only as the limit of a well-deﬁned sequence of proper pdfs.The mathematically generated paradoxes have been found only when we tried to departfrom this policy by treating an inﬁnite limit as something already accomplished, withoutregard to any limiting operation. Indeed, experience to date shows that almost any attemptto depart from our recommended ‘ﬁnite-sets’ policy has the potentiality for generating aparadox, in which two equally valid methods of reasoning lead us to contradictory results.
The paradoxes studied here stand as counter-examples to any hope that we can ever work
with full freedom on inﬁnite sets. Unfortunately, the Borel–Kolmogorov and marginalizationparadoxes turn up so seldom as to encourage overconﬁdence in the inexperienced. As longas one works on problems where they do not cause trouble, the psychological phenomenon:‘You can’t argue with success!’, noted at the beginning of this Chapter, controls the situation.Our reply to this is, of course, ‘You can and should argue with success that was obtainedby fraudulent means’.
Mea culpa
For many years, the present writer was caught in this error just as badly as anybody else,
because Bayesian calculations with improper priors continued to give just the reasonable andclearly correct results that common sense demanded. So warnings about improper priors
went unheeded; just that psychological phenomenon. Finally, it was the marginalization
paradox that forced recognition that we had only been lucky in our choice of problems. Ifwe wish to consider an improper prior, the only correct way of doing it is to approach it asa well-deﬁned limit of a sequence of proper priors. If the correct limiting procedure shouldyield an improper posterior pdf for some parameter α, then probability theory is telling us
that the prior information and data are too meager to permit any inferences about α. Then
the only remedy is to seek more data or more prior information; probability theory does notguarantee in advance that it will lead us to a useful answer to every conceivable question.
Generally, the posterior pdf is better behaved than the prior because of the extra informa-
tion in the likelihood function, and the correct limiting procedure yields a useful posteriorpdf that is analytically simpler than any from a proper prior. The most universally usefulresults of Bayesian analysis obtained in the past are of this type, because they tended to be
rather simple problems, in which the data were indeed so much more informative than the
prior information that an improper prior gave a reasonable approximation – good enoughfor all practical purposes – to the strictly correct results (the two results agreed typically tosix or more signiﬁcant ﬁgures).
In the future, however, we cannot expect this to continue because the ﬁeld is turning
to more complex problems in which the prior information is essential and the solutionis found by computer. In these cases it would be quite wrong to think of passing to animproper prior. That would lead usually to computer crashes; and, even if a crash is avoided,

<<<PAGE 520>>>

488 Part 2 Advanced applications
the conclusions would still be, almost always, quantitatively wrong. But, since likelihood
functions are bounded, the analytical solution with proper priors is always guaranteedto converge properly to ﬁnite results; therefore it is always possible to write a computerprogram in such a way (avoid underﬂow, etc.) that it cannot crash when given proper priors.So, even if the criticisms of improper priors on grounds of marginalization were unjustiﬁed,it remains true that in the future we shall be concerned necessarily with proper priors.
Note added
Preliminary versions of this chapter were made available to many interested persons, for
comments and suggestions. Several have expressed, both privately and publicly, their ap-preciation for these clariﬁcations of issues that have long been mysterious and confused,and even some compulsive nitpickers have failed to raise any objections. Only one sourcehas exhibited that psychological phenomenon noted in Chapter 5 in connection with theHempel paradox; someone asserts a principle that seems to him intuitively right, and whenprobability analysis reveals the error, instead of taking this opportunity to educate his intu-ition, he reacts by rejecting the probability analysis. For him, his intuitive ad hoc principle
takes precedence over the rules of probability theory.
If the issue is only which is to take precedence, there does not seem to be any way to
resolve it; if one is not convinced by Cox’s theorems and our great deal of experienceconﬁrming what they tell us, then we shall just ha ve to agree to disagree. But if the issue is
one of mathematically demonstrable fact, then it can be resolved at once – in the minds ofeveryone except the one who proposed the principle. One can be so deeply committed to
his position that mathematical proof to the contrary, and any number of counter-examples,carry no weight for him. That is just what has happened.
In the case of the tumbling tetrahedra problem, we pointed out the error in previous
discussions, gave the exact solution (15.26) according to the rules of probability theory, anasymptotic approximation (15.18) to it, and after a little thought could see that the ﬁnalresult (15.34) was really obvious from the start. That should be enough; this is an issue ofmathematically demonstrable fact, the mathematics is before us, and every reader can judgeit for himself.
The case of the marginalization paradox is very similar. The real purpose of this note is to
stress what is the issue here. DSZ (p. 194) purported to have proved that the disagreement of
B
1andB2‘could not have arisen if B1had employed proper prior distributions’. We pointed
out that their proof is based on mutually contradictory assumptions, and reinforced this by(1) pointing out that a counter-example to what they claimed to have proved was alreadypresent in plain sight in the original DSZ article (their Example #5, where it is evident byinspection that the disagreement is present for all priors, proper or improper), and (2) gave in(15.76) another counter-example, where B
1uses a proper prior, but B1andB2still disagree
because B1’s posterior distribution for ζdepends on the datum yand the prior p(η|I1), as
common sense tells us it must when B1uses a proper – therefore informative – prior for
η. In fact, we can leave it as an exercise for the reader to verify that every one of the DSZ

<<<PAGE 521>>>

15 Paradoxes of probability theory 489
examples is an equally good counter-example, if you look at what happens when B1uses
a proper prior. Of course, B1andB2agree when B1uses a proper prior in the trivial case
where we are concerned with two independent problems; then the sampling distributionfactors in the form p(yz|ηζ)=p(y|η)p(z|ζ) and the prior p(ηζ|I
1) also factors.
But if the basic theorem is invalid, then the entire marginalization tale collapses; if one
applies the rules of probability theory correctly, as explained long ago by Harold Jeffreys,there is no paradox. Again, this is an issue of mathematically demonstrable fact for whichwe have given the relevant mathematics, so we see no reason to engage in continuing debateover it; every reader can judge it for himself.

<<<PAGE 522>>>

16
Orthodox methods: historical background
With all this confounded trafﬁcking in hypotheses about invisible connec-
tions with all manner of inconcei vable properties, which have checked
progress for so many years, I believe it to be most important to openpeople’s eyes to the number of superﬂuous hypotheses they are making,and would rather exaggerate the opposite view, if need be, than proceedalong these false lines.
H. von Helmholtz (1868)
This chapter and Chapter 13 are concerned with the history of the subject rather than its
present status. There is a complex and fascinating history before 1900, recounted by Stigler(1986c), but we are concerned now with more recent developments. In the period from
about 1900 to 1970, one school of thought dominated the ﬁeld so completely that it has
come to be called ‘orthodox statistics’. It is necessary for us to understand it, because it iswhat most working statisticians active today were taught, and its ideas are still being taught,
and advocated vigorously, in many textbooks and universities.
In Chapter 17 we want to examine the ‘orthodox’ statistical practice thus developed
and compare its technical performance with that of the ‘probability as logic’ approachexpounded here. But ﬁrst, to understand this weird course of events, we need to knowsomething about the problems faced then, the sociology that evolved to deal with them, theroles and personalities of the principal ﬁgures, and the general attitude toward scientiﬁcinference that orthodoxy represents.
16.1 The early problems
The beginnings of scientiﬁc inference were laid in the 18th and 19th centuries out of the
needs of astronomy and geodesy. The principal ﬁgures were Daniel Bernoulli, Laplace,Gauss, Legendre, Poisson and others, whom we would describe today as mathematicalphysicists. This reached its highest technical development in the hands of Laplace, and itwas a ‘Bayesian’ theory.
Transitions in the dominant mode of thinking take place slowly over a few decades, the
working lifetime of one generation. The beginning of the period we are concerned with,
490

<<<PAGE 523>>>

16 Orthodox methods: historical background 491
1900, marks roughly the time when non-physicists moved in and proceeded to take over the
ﬁeld with quite different ideas. The end, 1970, marks roughly the time when those ideas inturn came under serious, concerted attack in our present ‘Bayesian revolution’.
During this period, as we analyzed in Chapter 10, the non-physicists thought that proba-
bility theory was a physical theory of ‘chance’ or ‘randomness’, with no relation to logic,while ‘statistical inference’ was thought to be an entirely different ﬁeld, based on entirelydifferent principles. But, having abandoned the principles of probability theory, it seemedthat they could not agree on what those new principles of inference were; or even on whetherthe reasoning of statistical inference was deductive or inductive.
The ﬁrst problems, dating back to the 18th century, were of course of the very sim-
plest kind, estimating one or more location parameters θfrom data D={x
1,..., xn}with
sampling distributions of the form p(x|θ)=f(x−θ). However, in practice this wa s not a
serious limitation, because even a pure scale parameter problem becomes approximately alocation parameter one if the quantities involved are already known rather accurately, as isgenerally the case in astronomy and geodesy.
Thus, if the sampling distribution has the functional form f(x/σ), and xandσare
already known to be about equal to x
0andσ0, we are really making inferences about the
small corrections q≡x−x0andδ≡σ−σ0. Expanding in powers of δand keeping only
the linear term, we have
x
σ=x0+q
σ0+δ=1
σ0(x−θ+··· ), (16.1)
where θ≡x0δ/σ 0. Thus we may deﬁne a new sampling distribution function
h(x−θ)∝f(x/σ), (16.2)
and we are considering, at least approximately, a location parameter problem after all. In this
way, almost any problem can be linearized into a location parameter one if the quantitiesinvolved are already known to fairly good accuracy. The 19th century astronomers tookgood advantage of this, as we should also.
Only toward the end of the 19th century did practice advance to the problem of estimating
simultaneously both a location and scale parameter θ, σ from a sampling distribution of
the form
p(x|θσ)=f/parenleftbiggx−θ
σ/parenrightbigg1
σ(16.3)
and to the marvellous developments by Galton (1886) associated with the bivariate Gaussian
distribution, which we studied in Chapter 7. Virtually all of the development of orthodoxstatistics was concerned with these three problems or their reverbalizations in hypothesistesting form, and most of it only with the ﬁrst. But even that seemingly trivial problemhad the power to generate fundamental differences of opinion and ﬁerce controversy overmatters of principle.

<<<PAGE 524>>>

492 Part 2 Advanced applications
16.2 Sociology of orthodox statistics
During the aforementioned period, the average worker in physics, chemistry, biology,
medicine, or economics with a need to analyze data could hardly be expected to under-stand theoretical principles that did not exist, and so the approved methods of data analysiswere conveyed to him in many different, unrelated ad hoc recipes in ‘cookbooks’ which, in
effect, told one to ‘Do this ...then do that ...and don’t ask why.’
R. A. Fisher’s Statistical Methods for Research Workers (1925) was the most inﬂuential
of these cookbooks. In going through 13 editions in the period 1925–1960 it acquired suchan authority over scientiﬁc practice that researchers in some ﬁelds such as medical testingfound it impossible to get their work published if they failed to follow Fisher’s recipes tothe letter.
Fisher’s recipes include maximum likelihood parameter estimation (MLE), analysis of
variance (ANOV A), ﬁducial distributions, randomized design of experiments, and a great
variety of signiﬁcance tests, which make up the bulk of his book. The rival Neyman–Pearsonschool of thought offered unbiased estimators, conﬁdence intervals, and hypothesis testing.The combined collection of the ad hoc recipes of the two schools came to be known
as orthodox statistics, although arguments raged back and forth between them over ﬁnedetails of their respective ideologies. It was just the absence of any unifying principles ofinference that perpetuated this division; there was no criterion acceptable to all for resolvingdifferences of opinion.
Whenever a real scientiﬁc problem arose that was not covered by the published recipes,
the scientist was expected to consult a professional statistician for advice on how to analyzehis data, and often on how to gather them as well. There de veloped a statistician –client
relationship rather like the doctor–patient one, and for the same reason. If there are simpleunifying principles (as there are today in the theory we are expounding), then it is easy tolearn them and apply them to whatever problem one has; each scientist can become his ownstatistician. But in the absence of unifying principles, the collection of all the empirical,logically unrelated procedures that a data analyst might need, like the collection of all thelogically unrelated medicines and treatments that a sick patient might need, was too largefor anyone but a dedicated professional to learn.
Undoubtedly, this arrangement served a useful purpose at the time in bringing about a
semblance of order into the way scientists analyzed and interpreted their data and publishedtheir conclusions. It was workable as long as scientiﬁc problems were simple enough so thatthe cookbook procedures could be applied and made some intuitive sense, even though theywere not derived from any ﬁrst principles. Then, had the proponents of orthodox methods
behaved with the professional standards of a good doctor (who notes that some treatmentshave been found to be effective, but admits frankly that the real cause of a disorder is notknown and welcomes further research to supply the missing knowledge) there could be nocriticism of the arrangement.
That is not how they behaved, however; they adopted a militant attitude, each defending
his own little bailiwick against intrusion and opposing every attempt to ﬁnd the missing

<<<PAGE 525>>>

16 Orthodox methods: historical background 493
unifying principles of inference. R. A. Fisher (1956) and M. G. Kendall (1963) attacked
Neyman and Wald for seeking unifying principles in decision theory. R. A. Fisher (innumerous articles, e.g. 1933), H. Cram´ er (1946), W. Feller (1950), J. Neyman (1952), R. von
Mises (1957) – and even the putative Bayesian L. J. Savage (1954, 1981) – accused Laplaceand Jeffreys of committing metaphysical nonsense for thinking that probability theory wasan extension of logic, and seeking the unifying principles of inference on that basis. We areat a loss to explain how they could have felt such a certainty about this, since they were allquite competent mathematically and presumably understood perfectly well what does andwhat does not constitute a proof. Yet they did not examine the consistency of probabilitytheory as logic, as R. T. Cox did; nor did they examine its qualitative correspondence withcommon sense, as P´ olya did. They did not even deign to take note of how it works out
in practice, as H. Jeffreys had shown so abundantly in works which were there for theirinspection. In fact, they offered no demonstrative arguments or factual evidence at all insupport of their position; they merely repeated ideological slogans about ‘subjectivity’ and‘objectivity’ which were quite irrelevant to the issues of logical consistency and useful
results.
We are equally helpless to explain why James Bernoulli and John Maynard Keynes (who
expounded essentially the same views as did Laplace and Jeffreys) escaped scorn. Evidently,the course of events must have had something to do with personalities; let us examine a fewof them.
16.3 Ronald Fisher, Harold Jeffreys, and Jerzy Neyman
Sir Ronald Aylmer Fisher (1890–1962) was by far the dominant personality in this ﬁeld in
the period 1925–1960. A personal account of his life is given by his daughter, Joan FisherBox (1978). On the technical side, Fisher had a deep intuitive understanding and produced asteady stream of important research in genetics. Sir Harold Jeffreys (1891–1989), workingin geophysics, wielded no such inﬂuence, and for most of his life found himself the objectof scorn and derision from Fisher and his followers.
Fisher’s early fame (1915–1925) rested on his mathematical ability: given data D≡
{x
1,..., xn}to which we assign a multivariate Gaussian sampling probability p(D|θ) with
parameters θ≡{θ1,...,θ m}, how shall we best estimate those parameters from the data?
Probability theory as logic considers it obvious that in any problem of inference we arealways to calculate the probability of whatever is unknown and of interest, conditional onwhatever is known and relevant; in this case, p(θ|DI).
But the orthodox view rejects this on the grounds that p(θ|DI) is meaningless because
it is not a frequency; θis not a ‘random variable’, only an unknown constant. Instead, we
are to choose some function of the data f(D) as our ‘estimator’ of θ. The merits of any
proposed estimator are to be determined solely from its sampling distribution p(f|θ). The
data are always supposed to be obtained by ‘drawing from a population’ urn-wise, and
p(f|θ) is always supposed to be a limiting frequency in many repetitions of that draw.

<<<PAGE 526>>>

494 Part 2 Advanced applications
A good estimator is one whose sampling distribution is strongly concentrated in a small
neighborhood of the true value of θ.
But, as we noted in Chapter 13, orthodoxy, having no general theoretical principles
for constructing the ‘best’ estimator, must in every new problem guess various functions
f(D) on grounds of intuitive judgment, and then test them by determining their sampling
distributions, to see how concentrated they are near the true value. Thus, calculation ofsampling distributions for estimators is the crucially important part of orthodox statistics;without it one has no grounds for choosing an estimator.
The sampling distribution for some complicated function of the data, such as the sample
correlation coefﬁcient, can become quite a difﬁcult mathematical problem; but Fisher wasvery good at this, and found many of these sampling distributions for the ﬁrst time. Technicaldetails of these derivations, in more modern language and notation, may be found in Feinbergand Hinkley (1980).
Many writers have wondered how Fisher was able to acquire the multidimensional space
intuition that enabled him to solve these problems. We would point out that, just beforestarting to produce those results, Fisher spent a year (1912–1913) as assistant to the theo-retical physicist Sir James Jeans, who was then preparing the second edition of his bookon kinetic theory and worked daily on calculations with high-dimensional multivariateGaussian distributions (called Maxwellian velocity distributions).
But nobody seemed to notice that Jeffreys was able to bypass Fisher’s calculations and
derive those parameter estimates in a few lines of the most elementary algebra. For Jeffreys,using probability theory as logic, in the absence of any cogent and detailed prior information,the best estimators were always determined by the likelihood function, which can be writtendown at once, merely by inspection of p(D|θ). This automatically constructed the optimal
estimator for him, with no need for intuitive judgment and without ever calculating asampling distribution for an estimator. Fisher’s difﬁcult calculations calling for all thatspace intuition, although interesting as mathematical results in their own right, were quiteunnecessary for the actual conduct of inference.
Fisher’s later dominance of the ﬁeld derives less from his technical work than from his
ﬂamboyant personal style and the worldly power that went with his ofﬁcial position, incharge of the work and destinies of many students and subordinates. For 14 years (1919–1933) he was at the Rothamsted agricultural research facility with an increasing number ofassistants and visiting students, then holder of the Chair of Eugenics at University College,London, and ﬁnally in 1943 Balfour Professor of Genetics at Cambridge, where he alsobecame President of Caius College. He was elected Fellow of the Royal Society in 1929,and was knighted in 1952.
Within his ﬁeld of geophysics, Harold Jeffreys also showed an outstandingly high com-
petence, was elected Fellow of the Royal Society in 1925, became Plumian Professor ofAstronomy at Cambridge in 1946, and was knighted in 1953. The treatise on mathematicalphysics by Sir Harold and Lady Jeffreys (1946) was for many years the standard textbookin the ﬁeld. But Jeffreys remained all his life as a Fellow of St John’s College, Cambridge,

<<<PAGE 527>>>

16 Orthodox methods: historical background 495
working quietly and modestly, and hardly visible outside his ﬁeld of geophysics; he had
only one doctoral student in probability theory (V . S. Huzurbazar).
In sharp contrast, Fisher, possessed of a colossal, overbearing ego, thrashed about in
the ﬁeld, attacking the work of everyone else1with equal ferocity. Somehow, early in life,
Fisher’s mind became captured by the dogma that by ‘probability’ one is allowed to meanonly limiting frequency in a random experiment. However, he usually stated this as the ratioof two inﬁnite numbers rather than the limit of a ratio of ﬁnite numbers, and said that anyother meaning is metaphysical nonsense, unworthy of a scientist. Conceivably, this viewmight have come from the philosopher John Venn, an earlier President of Caius College,Cambridge, where Fisher was an undergraduate from 1909 to 1912. In a very inﬂuentialwork, which went through three editions, Venn ridiculed Laplace’s conception of probabilitytheory as logic; and Fisher’s early work sounds very much like this.
However, we see a weakening of resolve in Fisher’s ﬁnal book (1956), where he actually
defends Laplace against the criticisms of Venn, and suggests that Venn did not understandmathematics well enough to comprehend what Laplace was saying. His criticisms of Jeffreysare now much toned down. Noting this, some have opined that, were Fisher alive today, hewould be a Bayesian.
2
In both science and art, every creative person must, at the beginning of his career, do battle
with an establishment that, not comprehending the new ideas, is more intent on putting him
down than understanding his message. Karl Pearson (1857–1936), as editor of Biometrika ,
performed that ‘service’ for Fisher in his early attempts at publication, and Fisher neverforgave him for this. But curiously, in his last book, Fisher’s attacks against Pearson are,if anything, more violent and personal than ever before. This is hard to understand, forby 1956 the battle was long since won; Pearson had been dead for 20 years, and it wasuniversally recognized that in all their disputes Fisher had been in the right. Why shouldthe bitterness remain 30 years after it had ceased to be relevant? This tells us much aboutFisher’s personality.
Fisher’s articles are most easily found today in two ‘collected works’ (Fisher, 1950,
1974). The ones on the principles of inference have an interesting characteristic pattern.They start with a paragraph or two of polemical denunciation of Jeffreys’ use of Bayes’theorem (at that time called inverse probability ). Then he formulates a problem, sees the
correct solution intuitively, and does the requisite calculations in a very efﬁcient, competentway. But, just at the point where one more step of the logical argument would have forcedhim to see that he was only rediscovering, in his own way, the results of applying Bayes’theorem, the article comes to an abrupt end.
1For the record, we consider Fisher’s criticisms of Karl Pearson on grounds of maximum likelihood vs. moment ﬁtting and
the proper number of degrees of freedom in chi-squared, and of Jerzy Neyman on grounds of conﬁdence intervals, unbiasedestimators, and the meaning of signiﬁcance levels, to be justiﬁed on grounds of technical fact. It is perhaps a measure of Fisher’sinﬂuence that the two disputes where we think that Fisher was in the wrong – the one with W. S. Gossett over randomizationand the one with Jeffreys on the whole meaning and philosophy of inference – are still of serious concern today.
2But against this supposition is the fact that in the last year of his life Fisher published an article (Fisher, 1962) examining thepossibilities of Bayesian methods, but with the prior probabilities to be determined experimentally ! This shows that he never
accepted – and probably never comprehended – the position of Jeffreys about the meaning and function of a prior probability.

<<<PAGE 528>>>

496 Part 2 Advanced applications
Harold Jeffreys (1939) was able to derive all the same results far more easily, by direct
use of probability theory as logic, and this automatically yielded additional informationabout the range of validity of the results and how to generalize them, that Fisher never didobtain. But whenever Jeffreys tried to point this out, he was buried under an avalanche ofcriticism which simply ignored his mathematical demonstrations and substantive resultsand attacked his ideology. His perceived sin was that he did not require a probability tobe also a frequency, and so admitted the notion of probability of an hypothesis. Nobodyseemed to perceive the fact that this broader conception of probability was just what wasgiving him those computational advantages.
Jerzy Neyman, whom we discussed in Chapter 14, also rejected Jeffreys’ work on the
same ideological grounds as did Fisher (but in turn had his own work rejected by Fisher).Neyman also directed scathing ridicule at Jeffreys, far beyond what would have been calledfor even if Neyman had been technically correct and Jeffreys wrong. For example, Neyman(1952, p. 11) becomes heated over a problem involving ﬁve balls in two urns, so simple thatit would not be considered worthy of being an undergraduate homework problem today, inwhich Jeffreys (1939, Sect. 7.02) is clearly in the right.
In view of all this, it is pleasant to be able to record that, in the end, Harold Jeffreys outlived
his critics, and the merit of his work, on both the theoretical and the pragmatic levels, wasﬁnally recognized. In the last years of his life he had the satisfaction of seeing CambridgeUniversity – from the Cavendish Physics Laboratory to the north to the Molecular BiologyLaboratory to the south – well populated with young scientists studying and applying hiswork and, with the new tool of computers, demonstrating its power for the current problemsof science.
The exchanges between Fisher and Jeffreys over these issues in the British journals of the
1930s were recalled recently by S. Geisser (1980) and D. Lane (1980), with many interestingdetails. But we want to add some additional comments to theirs, because a fellow physicistis in a better position to appreciate Jeffreys’ motivations, highly relevant for the applicationswe are concerned with today.
Firstly, we need to recognize that a large part of their differences arose from the fact that
Fisher and Jeffreys were occupied with very different problems. Fisher studied biologicalproblems, where one had no prior information and no guiding theory (this was long beforethe days of the DNA helix), and the data taking was very much like drawing from Bernoulli’surn. Jeffreys studied problems of geophysics, where one had a great deal of cogent priorinformation and a highly developed guiding theory (all of Newtonian mechanics giving thetheory of elasticity and seismic wave propagation, plus the principles of physical chemistryand thermodynamics), and the data taking procedure had no resemblance to drawing froman urn. Fisher, in his cookbook (1925, Sect. 1) deﬁnes statistics as the study of populations ;
Jeffreys devotes virtually all of his analysis to problems of inference where there is nopopulation.
Late in life, Jerzy Neyman was able to perceive this difference. His biographer, Constance
Reid (1982, p. 229), quotes Neyman thus: ‘The trouble is that what we statisticians callmodern statistics was developed under strong pressure on the part of biologists. As a

<<<PAGE 529>>>

16 Orthodox methods: historical background 497
result, there is practically nothing done by us which is directly applicable to problems of
astronomy.’
Fisher advanced, very aggressively, the opposite view: that the methods which were
successful in his biological problems must be also the general basis of all scientiﬁc inference.What Fisher was never able to see is that, from Jeffreys’ viewpoint, Fisher’s biologicalproblems were trivial, both mathematically and conceptually. In his early chapters, Jeffreys(1939) disposes of them in a few lines, obtaining Fisher’s inference results far more easilythan Fisher did, as the simplest possible applications of Bayes’ theorem,
3then goes on to
more complex problems beyond the ambit of Fisher’s methods. Jeffreys (1939, Chap. 7)then summarizes the comparisons with Fisher and Neyman in more general terms.
As science progressed to more and more complicated problems of inference, the short-
comings of the orthodox methods became more and more troublesome. Fisher would havebeen nearly helpless, and Neyman completely helpless, in a problem with many nuisance
parameters but no sufﬁcient or ancillary statistics. Accordingly, neither ever attempted to
deal with what is actually the most common problem of inference faced by experimentalscientists: linear regression with both variables subject to unknown error. Generations ofscientists in several different ﬁelds searched the statistical literature in vain for help on this;but for Bayesian methods (Zellner, 1971; Bretthorst, 1988) the nuisance parameters are onlyminor technical details that do not deter one from ﬁnding the straightforward and usefulsolutions. Scientists, engineers, biologists, and economists with good Bayesian training arenow ﬁnding for themselves the correct solutions appropriate to their problems, which canadapt effortlessly to many different kinds of prior information, thus achieving a ﬂexibilityunknown in orthodox statistics.
However, we recognize Fisher’s high competence in the problems which concerned him.
An honest man can maintain an ideology only as long as he conﬁnes himself to problemswhere its shortcomings are not evident. Had Fisher tried more complex problems, we thinkthat he would have perceived the superior power of Jeffreys’ methods rather quickly; as wedemonstrate in Chapters 13 and 17, the mathematics forces one to it, independently of allideology. As noted, it may be that he started to see this toward the end of his life.
Secondly, we note the very different personalities and habits of scholarly conduct of
the combatants. In any ﬁeld, the most reliable and instantly recognizable sign of a fanaticis a lack of any sense of humor. Colleagues have reported their experiences at meetings,where Fisher could ﬂy into a trembling rage over some harmless remark that others wouldonly smile at. Even his disciples (for example, Kendall, 1963) noted that the characterdefects which he attributed to others were easily discernible in Fisher himself; as one putit, ‘Whenever he paints a portrait, he paints a self-portrait’.
Harold Jeffreys maintained his composure, never took these disputes personally, and,
even in his 90s, when the present writer knew him, it was a delight to converse with him
3Of course, Fisher’s randomized planting methods – which we think to be not actually wrong, but hopelessly inefﬁcient in
information handling – were not reproduced by Jeffreys; nor would he wish to. It appears to be a quite general principle that,whenever there is a randomized way of doing something, then there is a nonrandomized way that delivers better performancebut requires more thought. We illustrate this by example in Chapter 17 under ‘The folly of randomization’.

<<<PAGE 530>>>

498 Part 2 Advanced applications
because he still retained a wry, slightly mischievous, sense of humor. The greatest theoretical
physicists of the 19th and 20th centuries, James Clerk Maxwell and Albert Einstein, showedjust the same personality trait, as testiﬁed by many who knew them.
Needless to say (since Fisher’s methods were mathematically only special cases of those
of Jeffreys), Fisher was never able to exhibit a speciﬁc problem in which his methods gavea satisfactory result and Jeffreys’ methods did not. Therefore we see in Fisher’s wordsalmost no pointing to actual results in real problems. Usually Fisher’s words convey only aspluttering exasperation at the gross ideological errors of Jeffreys and his failure to repent.His few attempts to address technical details only reveal his own misunderstandings ofJeffreys.
For example, Jeffreys (1932) gave a beautiful derivation of the d σ/σ prior for a scale
parameter, which we referred to in Chapter 12. Given two observations x
1,x2from a
Gaussian distribution, the predictive probability density for the third observation is
p(x3|x1x2I)=/integraldisplay
dµ/integraldisplay
dσp(x3|µσI)p(µσ|x1x2I). (16.4)
If initially σis completely unknown, then our estimates of σought to follow the data
difference|x2−x1|, with the result that the predictive probability for the third observation
to lie between them ought to be 1 /3, independently of x1andx2(with independent sampling,
every permutation of the three observations has the same probability). He shows that thiswill be true only for the d σ/σ prior.
But Fisher (1933), failing to grasp the concept of a predictive distribution, takes this to
be a statement about the sampling distribution p(x
3|µσI), which is an entirely different
thing; he jumps to the conclusion that Jeffreys is guilty of a ridiculous elementary error, andthen launches into seven pages of polemical attacks on all of Jeffreys’ work, which displayin detail his own total lack of comprehension of what Jeffreys was doing. All readers whowant to understand the conceptual hangups that delayed the progress of this ﬁeld for decadesshould read this exchange very carefully.
But in Jeffreys’ words there is no misunderstanding of Fisher, no heaping of scorn and
no ideological sloganeering; only a bemused sense of humor at the whole business. Theissue as Jeffreys saw i t was not any error of Fisher ’s actual procedures on his particular
biological problems, but the incompleteness of his methods for more general problems and
the lack of any justiﬁcation for his dogmatically asserted premises. In particular, that onemust conjure up some hypothetical inﬁnite population from which the data are drawn, andthat every probability must have an objectively ‘true’ value, independently of human infor-mation; Jeffreys’ whole objective was to use probability to represent human information.
Furthermore, Jeffreys always made his point quite gently.
For example, Jeffreys (1939, p. 325), perceiving what we noted above, writes of Fisher
that, ‘In fact, in spite of his occasional denunciations of inverse probability, I think thathe has succeeded better in making use of what it really says than many of its pro-fessed users have.’ As another example, in one of the exchanges Jeffreys complained thatFisher had ‘reduced his work to nonsense’. In reply, Fisher pounced upon this, and wrote,

<<<PAGE 531>>>

16 Orthodox methods: historical background 499
gleefully: ‘I am not inclined to deny it.’ Geisser (1980) concludes that Jeffreys came off
second best here; we see instead Jeffreys smiling at the fact that Fisher was deﬂected fromthe issue and fell headlong into the little trap that Jeffreys had set for him.
Having said something of their differences, we should add that, as competent scientists,
Fisher and Jeffreys were necessarily in close agreement on more basic things; in particularon the role of induction in science. Neyman, not a scientist but a mathematician, tried toclaim that his methods were entirely deductive. For example, in Neyman (1952, p. 210), hestates: ‘ ...in the ordinary procedure of statistical estimation there is no phase corresponding
to the description of “inductive reasoning” .... all the reasoning is deductive and leads to
certain formulae and their properties.’ But Neyman (1950) was willing to speak of inductivebehavior .
Fisher and Jeffreys, aware that all scientiﬁc knowledge has been obtained by inductive
reasoning from observed facts, naturally enough denied the claim of Neyman that inference
does not use induction, and of the philosopher Karl Popper that induction was impossible.We discussed this claim at the end of Chapter 9. Jeffreys expressed himself on this morein private conversations (at one of which the writer was present) than in public utterances;Fisher publicly likened Popper’s and Neyman’s strictures to political thought-control. Ashe put it (Fisher, 1956, p. 7): ‘To one brought up in the free intellectual atmosphere of anearlier time there is something rather horrifying in the ideological movement representedby the doctrine that reasoning, properly speaking, cannot be applied to empirical data tolead to inferences valid in the real world.’
Indeed, Fisher’s and Jeffreys’ reactions to Popper may be a repetition of what happened
in the 18th century. Fisher (1956, p. 10), Stigler (1983), and Zabell (1989) present quitegood evidence – which seems to us, in its totality, just short of proof – that Thomas Bayeshad found his result as early as 1748, and the original motivation for this work was hisannoyance at the claim of the 18th century philosopher David Hume of the impossibility ofinduction. We may conjecture that Bayes sought to give an explicit counter-example, butfound it a bit more difﬁcult than he had at ﬁrst expected, and so delayed publishing it. Thiswould give a neat and natural explanation of many otherwise puzzling facts.
16.4 Pre-data and post-data considerations
The basic pragmatic difference in the two approaches is in how they relate to the data;
orthodox practice is limited at the outset to pre-data considerations. That is, it gives correctanswers to questions of the form:
(A) Before you have seen the data, what data do you expect to get?
(B) If the as yet unknown data are used to estimate parameters by some known algorithm, how
accurate do you expect the estimates to be?
(C) If the hypothesis being tested is in fact true, what is the probability that we shall get data indicating
that it is true?

<<<PAGE 532>>>

500 Part 2 Advanced applications
Of course, probability theory as logic automatically includes all sampling distribution cal-
culations; so, in problems where such questions are the ones of interest, we shall do the samecalculations and reach the same numerical conclusions, with at worst a verbal disagreementover terminology.
As we have stressed repeatedly, virtually all real problems of scientiﬁc inference are
concerned with post-data questions:
(A/prime) After we have seen the data, do we have any reason to be surprised by them?
(B/prime) After we have seen the data, what parameter estimates can we now make, and what accuracy are
we entitled to claim?
(C/prime) What is the probability conditional on the data , that the hypothesis is true?
Orthodoxy is prevented from dealing with post-data questions by its different philosophy.
The basic tenet that determines the form of orthodox statistics is that the reason whyinference is needed lies not in mere human ignorance of the true causes operative, but in
a ‘randomness’ that is attributed instead to Nature herself; just what we call the ‘mind
projection fallacy’. This leads to the belief that probability statements can be made onlyabout random variables and not about unknown ﬁxed parameters. However, although the
property of being ‘random’ is considered a real objective attribute of a variable, orthodoxyhas never produced any deﬁnition of the term ‘random variable’ that could actually be usedin practice to decide whether some speciﬁc quantity, such as the number of beans in a can,is or is not ‘random’.
Therefore, although the question ‘Which quantities are random?’ is crucial to everything
an orthodox statistician does, we are unable to explain how he actually decides this; wecan only observe what decisions he makes. For some reason, data are always consideredrandom, almost everything else is nonrandom; but to the best of our knowledge, there is
no principle in orthodox statistics which would have enabled one to predict this choice.Indeed, in a real situation the data are usually the only things that aredeﬁnite and known,
and almost everything else in the problem is unknown and only conjectured; so the oppositechoice would seem far more natural.
This orthodox choice has the consequence that orthodox theory does not admit the exis-
tence of prior or posterior probabilities for a ﬁxed parameter or an hypothesis, because theyare not considered random variables. We want, then, to examine how orthodoxy managesto pass off the answer to a pre-data question as if it were the answer to a post-data one.
Mostly this is possible because of mathematical accidents, such as symmetry in parameterand estimator.
16.5 The sampling distribution for an estimator
We have noted why a major part of the orthodox literature is devoted, necessarily, to calcu-
lating, approximating, and comparing sampling pdfs for estimators; this is the only criterionorthodoxy has for judging estimators, and in a new problem one may need to ﬁnd samplingdistributions for a half-dozen different estimators before deciding which one is best.

<<<PAGE 533>>>

16 Orthodox methods: historical background 501
The sampling pdf for an estimator does not have the same importance in Bayesian analysis,
because we do have the needed theoretical principles; if an estimator has been derived fromBayes’ theorem and a speciﬁed loss function, then we know from perfectly general theoremsthat it is the optimal estimator for the problem as deﬁned, whatever its sampling distributionmay be. In fact, the sampling pdf for an estimator plays no functional role in post-datainference, and so we have no reason to mention it at all, unless pre-data considerations areof some interest; for example, in planning an experiment and deciding what kind of data totake and when to stop.
In addition to this negative (nonfunctionality) reason, there is a stronger positive reason for
diverting attention away from the sampling pdf for an estimator; it is not the proper criterion
of the quality of an inference. Suppose a scientist is estimating a physical parameter αsuch
as the mass of a planet. If the sampling pdf for the estimator is indeed equal to the long-run frequencies in many repetitions of the measurement, then its width would answer thepre-data question:
(Q1) How much would the estimate of αvary over the class of all data sets that we might conce-
ivably get?
This is not the relevant question for the scientist, however. His concern is with the post-
data one:
(Q2) How accurately is the value of αdetermined by the one data set Dthat we actually have?
According to probability theory as logic, the correct measure of this is the width of the
posterior pdf for the parameter, not the sampling pdf for the estimator. Since this is a major
bone of contention between the orthodox and Bayesian schools of thought, let us understandwhy they can sometimes be the same, with resulting confusion of pre-data and post-dataconsiderations. In the next chapter, we shall see some of the horrors that can arise whenthey are not the same.
Historically, since the time of Laplace, scientiﬁc inference has been dominated over-
whelmingly by the case of Gaussian sampling distributions which have the aforementionedsymmetry. Suppose we have a data set D={y
1,..., yn}and a sampling distribution
p(D|µσI)∝exp/braceleftBigg
−/summationdisplay
i(yi−µ)2
2σ2/bracerightBigg
(16.5)
withσknown. Then the Bayesian posterior pdf for µ, with uniform prior, is
p(µ|DσI)∝exp/braceleftbigg
−n(µ−y)2
2σ2/bracerightbigg
, (16.6)
from which the post-data (mean ±standard deviation) estimate of µis
(µ)est=y±σ√n, (16.7)
which shows that the sample mean y≡n−1/summationtextyiis a sufﬁcient statistic. Then, if the

<<<PAGE 534>>>

502 Part 2 Advanced applications
orthodoxian decided to use yas an estimator of µ, he would ﬁnd its sampling distribu-
tion to be
p(y|µσI)∝exp/braceleftbigg
−n(y−µ)2
2σ2/bracerightbigg
, (16.8)
and this would lead him to make the pre-data estimate
(y)est=µ±σ√n. (16.9)
But although (16.7) and (16.9) have entirely different meanings conceptually, they are
mathematically so nearly identical that the Bayesian and orthodoxian would make the sameactual numerical estimate of µand claim the same accuracy. In problems like this, which
have sufﬁcient statistics but no nuisance parameters, there is a mathematical symmetry(approximate or exact) which can make the answers to a pre-data question and a post-dataquestion closely related if we have no very cogent prior information which would breakthat symmetry.
This accidental equivalence has produced a distorted picture of the ﬁeld; the Gaussian
case is the one in which orthodox methods do best – not only for the reasons explained inChapter 7, but also because if there is no prior information the symmetry is exact, so pre-data and post-data results are numerically the same. On the basis of such limited evidence,orthodoxy tried to claim general validity for its methods. But had the early experiencereferred instead to Cauchy sampling distributions,
p(y|µ)=1
π/bracketleftbigg1
1+(y−µ)2/bracketrightbigg
, (16.10)
the distinction could never have been missed because the answers to the pre-data and post-
data questions are so different that common sense would never have accepted the answerto one as the answer to the other. In this case, with an uninformative prior the Bayesianposterior pdf for µis
p(µ|DI)∝
n/productdisplay
i=11
1+(µ−yi)2(16.11)
which is still straightforward, if analytically inconvenient. Numerically, the (posterior
mean±standard deviation) or (posterior median ±interquartile) estimates are readily
found by computer, but there is no sufﬁcient statistic and therefore no good analyticalsolution.
But orthodoxy has never found any satisfactory estimator at all for this problem! If we
try again to use the sample mean
yas an estimator, we ﬁnd, to our dismay, that its sampling
pdf is
p(y|µI)∝1
1+(y−µ)2, (16.12)
which is identical with (16.10); the mean of any number of observations is, according to

<<<PAGE 535>>>

16 Orthodox methods: historical background 503
this orthodox criteria, no better than a single observation. Although Fisher noted that, for
large samples, the sample median tends to be more strongly concentrated near the true µ
than does the sample mean, this gives no reason to think that it is the best estimator by
orthodox criteria, even in the limit of large samples, and the question remains open today.
We expect that both the Bayesian posterior mean and posterior median value estima-
tors would prove to be considerably better, by orthodox criteria of performance, than anypresently known orthodox estimator. Simple computer experiments would be able to con-ﬁrm or refute this conjecture; we doubt whether they will be done, because the question isof no interest to a Bayesian, while a well-indoctrinated orthodoxian will never voluntarilyexamine any Bayesian result.
4
16.6 Pro-causal and anti-causal bias
One criticism of orthodox methods that we shall ﬁnd in the next chapter is not ideological,
but that they have technical shortcomings (waste of information) which, in practice, all tend
to bias our inferences in the same direction. The result is that, when we are testing for a new
phenomenon, orthodoxy in effect considers it a calamity to give credence to a phenomenonthat is not real, but is quite unconcerned about the consequences of failing to recognize a
phenomenon that is real.
To be fair, at this point we should keep in mind the historical state of affairs, and the
far worse practices that the early workers in this ﬁeld had to counteract. As we noted inChapter 5, the uneducated mind always sees a causal relationship – even where there is noconceivable physical mechanism for it – out of the most far-fetched coincidence.
Johannes Kepler (1571–1630) was obliged to waste much of his life casting horoscopes
for his patron (and complained about it privately). No amount of evidence showing thefutility of this seems to shake the belief in it; even today, more people make their living asastrologers than as astronomers.
In the 18th and 19th centuries, science was still awash with superstitious beliefs in causal
inﬂuences that do not exist, and Laplace (1812) warned against this in terms that seemlike platitudes today, although they made him enemies then. Our opening quotation from
Helmholtz shows his exasperation at the fact that progress in physiology was made almostimpossible by common belief in all kinds of causal inﬂuences for which there was nophysical mechanism and no evidence. Louis Pasteur (1822–1895) spent much of his lifetrying to overcome the universal belief in spontaneous generation.
Although the state of public health was intolerable by present standards, hundreds of
plants were credited with possessing miraculous medicinal properties; at the same time,
4For example, many years ago the writer attempted to publish an article demonstrating the superior performance of Bayesian
estimation with a Cauchy distribution, in the small sample case which can be solved analytically – and had the work twice
rejected. The referee accused me of unfair tactics for bringing up the matter of the Cauchy distribution at all, because ‘ ...it
is well known that the Cauchy distribution is a pathological, exceptional case’. Thus did one orthodoxian protect the journal’sreaders from the unpleasant truth that Bayesian analysis does not break down on this problem. To the best of our knowledge,Bayesian analysis has no pathological, exceptional cases; a reasonable question always has a reasonable answer. Finally, after13 years of struggling, we did manage to get that analysis published after all by sneaking it into a longer article (Jaynes, 1976).

<<<PAGE 536>>>

504 Part 2 Advanced applications
tomatoes were believed to be poisonous. As late as 1910 it was still being reported as
scientiﬁc fact that poison ivy plants emit an ‘efﬂuvium’ which infects those who merelypass by them without actual contact, although the simplest controlled experiment wouldhave disproved this at once.
Today, science has advanced far beyond this state of affairs, but common understanding
has hardly progressed at all. On the package of a popular brand of rice, the cooking in-structions tell us that we must use a closed vessel, because ‘the steam does the cooking’.Since the steam does not come into contact with the rice, this seems to be on a par with thepoison ivy myth. Surely, a controlled experiment would show that the temperature of the
water does the cooking. But at least this myth does no harm.
Other spontaneously invented myths can do a great deal of harm. If we have a single
unusually warm summer, we are besieged with dire warnings that the Earth will soon betoo hot to support life. Next year we will have an unusually cold winter, and the samedisaster-mongers will be right there shouting about the imminent ice age. Both times theywill receive the most full and sympathetic coverage by the news media, who, with theirshort memory and in their belief that they are doing a public service, amplify 1000-fold thecapacity of the disaster-monger to do mischief. They encourage ever more irresponsibledisaster-mongering as the surest way to get free personal publicity.
In 1991 some persons without the slightest conception of what either electricity or cancer
are, needed only to hint that the weak 60 Hz electric and magnetic ﬁelds around homewiring or power lines are causing cancer; and the news media gave it instant credence andfull prime-time radio and television coverage, throwing the uneducated public into a panic.They set up picket lines and protest marches to prevent installation of power lines where they
were needed. The right of the public to be protected against the fraud of false advertising
is recognized by all; so when will we have the right to be free of the fraud of sensationallyfalse and irresponsible news reporting?
To counter this universal tendency of the untrained mind to see causal relations and trends
where none exist, responsible science requires a very skeptical attitude, which demands
cogent evidence for an effect; particularly one which has captured the popular imagination.Thus we can easily understand and sympathize with the orthodox conservatism in acceptingnew effects.
There is another side to this; skepticism can be carried too far. The orthodox bias against
a real effect does help to hold irresponsibility in check, but today it is also preventing recog-nition of effects that arereal and important. The history of science offers many examples
of important discoveries that had their origin in the perception of someone who saw a smallunexpected thing in his data, that an orthodox signiﬁcance test would have dismissed as arandom error.
5The discovery of argon by Lord Rayleigh and of cosmic rays by Victor Hess
are examples that come to mind immediately. Of course, they did not jump to sweeping
5Jeffreys (1939, p. 321) notes that there has never been a time in the history of gravitational theory when an orthodox signiﬁcance
test, which takes no note of alternatives, would not have rejected Newton’s law and left us with no law at all. Nevertheless,
Newton’s law did lead to constant improvements in the accuracy of our accounting of the motions of the moon and planets
for centuries, and it was only when an alternative (Einstein’s law) had been stated fully enough to make very accurate known
predictions of its own that a rational person could have thought of abandoning Newton’s law.

<<<PAGE 537>>>

16 Orthodox methods: historical background 505
conclusions from a single observation, as do the disaster-mongers; rather, they used the
single surprising observation to motivate a careful investigation that culminated in over-whelming evidence for the new phenomenon. It is fortunate that physicists and astronomersdo not, in practice, use orthodox signiﬁcance tests; their own innate common sense is asafer and more powerful reasoning tool.
In other ﬁelds we must wonder how many important discoveries, particularly in medicine,
have been prevented by editorial policies which refuse to publish that necessary ﬁrst evidencefor some effect, because the one data set that the researcher was able to obtain did not quiteachieve an arbitrarily imposed signiﬁcance level in an orthodox test. This could well defeatthe whole purpose of scientiﬁc publication; for the cumulative evidence of three or foursuch data sets might have yielded overwhelming evidence for the effect. Yet this evidencemay never be found unless the ﬁrst data set can manage to get published.
How can editors recognize that scientiﬁc discovery is not a one-step process, but a many-
step one, without thereby releasing a new avalanche of irresponsible, sensational publicityseekers? The problem is genuinely difﬁcult, and we do not pretend to know the full answer.
Throughout this work we note instructive case histories of science gone wrong, when
orthodox statistics was used to support either an unreasonable belief, or more often anunreasonable disbelief, in some phenomenon. In every case, a Bayesian analysis – takinginto account all the evidence, not just the evidence of one data set – would have led tofar more defensible conclusions; so editorial policies that required Bayesian standards ofreasoning would go a long way toward solving this problem.
This orthodox bias against an effect is seen in the fact that Feller and others heap ridicule on
‘cycle hunters’ as being irresponsible, seeing in phenomena, such as economic time series,weather, sunspot numbers and earthquakes, periodicities that are not there. It is conceivablethat there may be instances of this; but those who make the charge do not document speciﬁcexamples which we can verify, and so we do not know of any. In economics, belief inbusiness cycles goes in and out of style cyclically. Those who, like the economist ArthurBurns, merely look at a plot of the data, see the cycles at once. Those who, like Fisher,Feller, and Tukey (Blackman and Tukey, 1958), use orthodox data analysis methods, donot ﬁnd them. Those who, like Bretthorst (1988), use probability theory as logic are takinginto account more evidence than either of the above groups, and may or may not ﬁndthem. More generally, the reason why some orthodox skeptics do not see real effects isthat they use methods of data analysis which not only ignore prior information, but alsoviolate the likelihood principle, and therefore waste some of the information in the data.We demonstrate this in Chapter 17.
16.7 What is real, the probability or the phenomenon?
This orthodox reluctance to see causal effects, even when they are real, has another psy-
chological danger because eventually it becomes extrapolated into a belief in the existenceof ‘stochastic processes’ in which no causes at all are operative, and probability itself is

<<<PAGE 538>>>

506 Part 2 Advanced applications
the only real physical phenomenon. When the search for any causal relation whatever is
deprecated and discouraged, scientiﬁc progress is brought to a standstill.
Belief in the existence of ‘stochastic processes’ in the real world; i.e. that the property
of being ‘stochastic’ rather than ‘deterministic’ is a real physical property of a process,that exists independently of human information, is another example of the mind projectionfallacy: attributing one’s own ignorance to Nature instead. The current literature of probabil-ity theory is full of claims to the effect that a ‘Gaussian random process’ is fully determinedby its ﬁrst and second moments. If it were made clear that this is only the deﬁning propertyfor an abstract mathematical model, there could be no objection to this; but it is always pre-sented in verbiage that implies that one is describing an objectively true property of a realphysical process. To one who believes such a thing literally, there could be no motivationto investigate the causes more deeply than noting the ﬁrst and second moments, and so thereal processes at work might never be discovered.
This is not only irrational because one is throwing away the very information that is
essential to understand the physical process; if carried into practice it can have disastrousconsequences. Indeed, there is no such thing as a ‘stochastic process’ in the sense thatthe individual events have no speciﬁc causes. One who views human diseases or machinefailures as ‘stochastic processes’, as described in some orthodox textbooks, would be ledthereby to think that in gathering statistics about them he is measuring the one controllingfactor – the physically real ‘propensity’ of a person to get a disease or a machine to fail –and that is the end of it.
Yet where our real interests are involved, such foolishness is usually displaced rather
quickly. Every individual disease in every individual person has a deﬁnite cause; fortunately,Louis Pasteur understood this in the 19th century, and our medical researchers understandit today. In medicine one does not merely collect statistics about the incidence of diseases;there are large organized research efforts to ﬁnd their speciﬁc causes in individual cases.
Likewise, every machine failure has a deﬁnite cause; after every airplane crash the Federal
Aviation Ofﬁcials arrive and, if necessary, spend months sifting through all the evidencetrying to determine the exact cause. Only by this pursuit of each individual cause can thelevel of public health and the safety and reliability of our machines be improved.
16.8 Comments
One lesson from the considerations of this chapter is that a deep change in the sociology of
science – the relationship between scientist and statistician – is now underway. This is beingbrought about by the coincidence of recent improvements in both theoretical understandingand computation facilities.
The scientist who has learned the simple, uniﬁed principles of inference expounded here
would not consult a statistician for advice because he can now work out the details of hisspeciﬁc data analysis problem for himself, and if necessary write a new computer program,in less time than it would take to read about them in a book or hire it done by a statistician. He

<<<PAGE 539>>>

16 Orthodox methods: historical background 507
is also alert to the defects in orthodox methods, and will avoid all advice from a statistician
who continues to recommend them. Each scientist involved in data analysis can be his ownstatistician.
Another important general conclusion is that in analyzing data – particularly when search-
ing for new effects – scientists are obliged to ﬁnd a very careful compromise between seeingtoo little and seeing too much. Only methods of inference which realize all the ‘resolvingpower’ possible, by taking careful account of all the relevant prior information, all the pre-viously obtained data, and all the information in the likelihood function, can steer a safecourse between these dangers and yield justiﬁable conclusions. Probability theory as logicautomatically takes into account the full range of conditions consistent with our information(our basic desiderata require this); and so it cannot give us misleading conclusions unlesswe feed it false information or withhold true and relevant information from it.
For many years, orthodox methods of data analysis, through their failure to take into
account all the relevant evidence, have been misleading us in ways that have increasinglyserious economic and social consequences. Often, orthodox methods are unable to ﬁndsigniﬁcant evidence for effects so clear that they are obvious at once from a mere glance atthe data. More rarely, from failure to note cogent prior information orthodox methods mayhallucinate, seeing nonexistent effects. We document cases of both in this work, and seehow in all cases Bayesian analysis would have avoided the difﬁculty automatically.
16.8.1 Communication difﬁculties
As an example of the difﬁculties that Bayesians have trying to communicate with those
trained only in the sampling theory viewpoint, the writer once gave a talk in which he men-tioned in passing a very elementary and well-known theorem: that the posterior expectationof a parameter is the estimator that minimizes the expected square of the error.
6
A sampling theorist in the audience objected violently to this, for in his lexicon an
‘expectation’ and an ‘estimator’ were not only different things, but things of a totally
different qualitative nature: an estimator is a function of the data, but an expectation is anaverage over all possible data, a function of the parameter. So when I said that the bestestimator is the posterior expectation, it sounded to him like I had said that apples areoranges; he not only denied the theorem, but thought that I had taken leave of my senses,and was ignorant of the meaning of statistical terms.
How would you reply to this objection? The problem was that the term ‘posterior expec-
tation’ was, for him, meaningless, because he denied the existence of any such thing asa posterior distribution, and so could not comprehend that a posterior expectation is indeeda function of the data and is therefore a possible estimator. So unless he can be shifted into acompletely different mindset, the simple theorem will continue to seem like pure nonsenseto him. How can one explain this without offending – and thereby completely losing contactwith – the objector?
6Proof: let the data be ( x1,..., xn), and θ∗(x1,..., xn) any proposed estimator. Then the expected square of the error over the
posterior pdf for θis/angbracketleft(θ∗−θ)2/angbracketright=(θ∗−/angbracketleftθ/angbracketright)2+(/angbracketleftθ2/angbracketright−/angbracketleftθ/angbracketright2), which is minimized for the choice θ∗=/angbracketleftθ/angbracketright.

<<<PAGE 540>>>

508 Part 2 Advanced applications
L. J. Savage (1954), noting these communication blocks, caused by seemingly irrecon-
cilable differences in ideology growing into fundamental differences in terminology, wrotethat ‘...there has seldom been such complete disagreement and breakdown of commu-
nication since the Tower of Babel’. A more complete discussion of past communicationdifﬁculties is given in Jaynes (1986a). Today, with plentiful, powerful, and cheap computa-tion facilities, we can bypass this and settle these issues by demonstrating the facts of actualperformance. One of the purposes of the present work is to explain how such demonstrationscan be carried out.
In the 1930s and 1940s, there were not only communication blocks, but rampant statistical
gamesmanship. Everybody wants to be seen as taking a public stance for virtue and againstsin, so the frequentist statisticians adopted the simple device of inventing virtuous-soundingterms (like unbiased, efﬁcient, uniformly most powerful, admissible, robust) to describetheir own procedures, therefore almost forcing others to apply the sinful-sounding antonyms(like biased, inadmissible) to all other methods.
Those who played this game were, in the long run, only caught in their own trap; for
all their favored methods were arbitrary ad hockeries not derived from any ﬁrst principles.
It developed – inevitably in view of Cox’s theorems – that all of them had serious defectsthat are overcome only by the Bayesian methods that they rejected. It is now clear, as wedemonstrate in Chapter 17, that a ‘biased’ estimate may be considerably closer to the truththan an ‘unbiased’ one, an ‘inadmissible’ procedure may be far superior to an ‘admissible’one; and so on. Today those emotionally loaded terms are only retarding progress and doinga disservice to science.

<<<PAGE 541>>>

17
Principles and pathology of orthodox statistics
The development of our theory beyond this point, as a practical statisti-
cal theory, involves ...all the complexities of the use, either of Bayes’
law on the one hand, or of those terminological tricks in the theory oflikelihood on the other, which seem to avoid the necessity for the useof Bayes’ law, but which in reality transfer the responsibility for its useto the working statistician, or the person who ultimately employs his
results.
Norbert Wiener (1948)
To the best of our knowledge, Norbert Wiener never actually applied Bayes’ theorem in a
published work; yet he perceived the logical necessity of its use as soon as one builds beyondthe sampling distributions involved in his own statistical work. In the present chapter weexamine some of the consequences of failing to use Bayesian methods in some very simpleproblems, where the paradoxes of Chapter 15 ne ver arise.
In Chapter 16 we noted that the orthodox objections to Bayesian methods were al-
ways philosophical or ideological in nature, never examining the actual results that theygive, and we expressed astonishment that mathematically competent persons would usesuch arguments. In order to give a fair comparison, we need to adopt the oppositetactic here, and concentrate on the demonstrable facts that orthodoxians never men-tion. Since Bayesian methods have been so egregiously misrepresented in the orthodoxliterature throughout our lifetimes, we must lean over backwards to avoid misrepresent-ing orthodox methods now; whenever an orthodox method does yield a satisfactory re-sult in some problem, we shall acknowledge that fact, and we shall not deplore its usemerely on ideological grounds. On the other hand, when a common orthodox proce-dure leads to a result that insults our intelligence, we shall not hesitate to complainabout it.
Our present goal is to understand the following. In what circumstances, and in what
ways, do the orthodox results differ from the Bayesian results ?What are the pragmatic
consequences of this in real applications ? The theorems of Richard Cox provide all the
ideology we need, and all of our pragmatic comparisons only conﬁrm, in many differentcontexts, what those theorems lead us to expect.
509

<<<PAGE 542>>>

510 Part 2 Advanced applications
17.1 Information loss
It is not easy to cover all this ground, because orthodox statistics is not a coherent body
of theory that could be conﬁrmed or refuted by a single analysis. It is a loose collectionof independent ad hoc devices, invented and advocated by many different people on many
different intuitive grounds; and they are often in sharp disagreement with each other.
But one can see generally, once and for all, when and why orthodox methods, quite aside
from their failure to use prior information, must also waste some of the information in thedata. Consider estimation of a parameter θfrom a data set D≡{x
1,..., xn}represented
by a point in Rn. Orthodoxy requires us to choose a single estimator b(D)≡b(x1,..., xn)
before we have seen the data , and then use only b(x) for the estimation. Now, specifying
the observed numerical value of b(x) locates the sample on a manifold (subspace of Rn)
of dimension ( n−1). Specifying the actual data set Dtells us that, and also where on the
manifold we are. If position on the manifold is irrelevant to θ, then b(D) is a sufﬁcient statistic
forθ, and unless there are further circumstances, such as highly cogent prior information,
the orthodox method will be satisfactory pragmatically whatever its proclaimed rationale.Otherwise, specifying Dconveys additional information about θthat is not conveyed by
specifying the statistic b(D).
Put differently, given the actual data set D, all estimators that the orthodoxian might have
chosen{b
1,b2,...}are known, so Bayes’ theorem has available for its use simultaneously
all the information contained in the class of all possible estimators. If there is no suf ﬁcient
statistic, it is able to choose the optimal estimator for the present data set .
If the estimator is not a sufﬁcient statistic, its sampling distribution is irrelevant for us,
because with different data sets we shall use different estimators. We saw this in somedetail, from different viewpoints, in Chapters 8 and 13. The same considerations apply tohypothesis testing; the Bayesian procedure has available all the relevant information in thedata, but an orthodox procedure based on a single statistic does not unless it is a sufﬁcientstatistic. If it is not sufﬁcient, then we expect that the Bayesian procedure will be superior(in the sense of more accurate or more reliable) because it is extracting more informationfrom the data. Once one understands this, it is easy to produce any number of exampleswhich demonstrate it.
From the Neyman–Pearson camp of orthodoxy we have the devices of unbiased estima-
tors, conﬁdence intervals, and hypothesis tests which amount to a kind of decision theory.This line of thought was adopted more or less faithfully in the works of Herbert Simon(1977) in economics, Erich Lehmann (1986) in hypothesis testing, and David Middleton(1960) in electrical engineering.
From the Fisherian (sometimes called the piscatorial) camp, there are the principles of
maximum likelihood, analysis of variance, randomization in design of experiments, and amass of specialized ‘tail area’ signiﬁcance tests. Fortunately, the underlying logic is thesame in all such signiﬁcance tests, so they need not be analyzed separately. Adoption ofthese methods has been almost mandatory in biology and medical testing. Also, Fisher ad-vocated ﬁducial probability, which most statisticians rejected, and conditioning on ancillary

<<<PAGE 543>>>

17 Principles and pathology of orthodox statistics 511
statistics, which we discussed in Chapter 8, and showed that it is mathematically equivalent
to applying Bayes’ theorem without prior information.
17.2 Unbiased estimators
Given a sampling distribution p(x|α) with some parameter αand a data set comprising
nobservations D≡{x1,..., xn}, there are various orthodox principles for estimating α,
in the particular use of an unbiased estimator, and maximum likelihood. In the former wechoose some function of the observations β(D)=β(x
1,..., xn) as our ‘estimator’. The
Neyman–Pearson school holds that it should be ‘unbiased’, meaning that its expectation
over the sampling distribution is equal to the true value of α:
/angbracketleftβ/angbracketright=E(β)=/integraldisplay
dx1···dxnβ(x1,..., xn)p(x1···xn|α)=α. (17.1)
As noted in Chapter 13, Eq. (13.20), the expected square of the error, over the sampling
distribution, is the sum of two positive terms,
/angbracketleft(β−α)2/angbracketright=(/angbracketleftβ/angbracketright−α)2+var(β), (17.2)
where what the orthodoxian calls the ‘sampling variance of β’ (more correctly, the variance
of the sampling distribution for β)i sv a r ( β)=/angbracketleftβ2/angbracketright−/angbracketleftβ/angbracketright2. At present, we are not after
mathematical pathology of the kind discussed in Chapter 15 and Appendix B, but ratherlogical pathology – due to conceptual errors in the basic formulation of a problem – which
persists even when all the mathematics is well-behaved. So we suppose that the ﬁrst twomoments of that sampling distribution, /angbracketleftβ/angbracketright,/angbracketleftβ
2/angbracketright, exist for all the estimators to be considered.
If we introduce a fourth moment /angbracketleftβ4/angbracketright, we are automatically supposing that it exists also; this
is the general mathematical policy advocated in Appendix B. Then an unbiased estimatorhas, indeed, the merit that it makes one of the terms of (17.2) disappear. But it does notfollow that this choice minimizes the expected square of the error; let us examine this moreclosely.
What is the relative importance of removing bias and minimizing the variance? From
(17.2) it would appear that they are of equal importance; there is no advantage in decreasingone if in so doing we increase the other more than enough to compensate. Yet that iswhat the orthodox statistician usually does! As the most common speciﬁc example, Cram´ er
(1946, p. 351) considers the problem of estimating the variance µ
2of a sampling distribution
p(x1|µ2):
µ2=/angbracketleftx2
1/angbracketright−/angbracketleft x1/angbracketright2=/angbracketleftx2
1/angbracketright (17.3)
from nindependent observations {x1,..., xn}. We assume, in (17.3) and in what follows,
that/angbracketleftx1/angbracketright=0, since a trivial change of variables would in any event accomplish this. An
elementary calculation shows that the sample variance (now correctly called the varianceof the sample because it expresses the variability of the data within the sample, and does

<<<PAGE 544>>>

512 Part 2 Advanced applications
not make reference to any probability distribution)
m2≡x2−x2=1
nn/summationdisplay
i=1x2
i−/bracketleftBigg
1
nn/summationdisplay
i=1xi/bracketrightBigg2
(17.4)
has expectation, over the sampling distribution p(x1···xn|µ2)=p(x1|µ2)···p(xn|µ2), of
/angbracketleftm2/angbracketright=n−1
nµ2 (17.5)
and thus, as an estimator of µ2, it has a negative bias. So, goes the argument, we should
correct this by using the unbiased estimator
M2≡n
n−1m2. (17.6)
Indeed, this has seemed so imperative that in most of the orthodox literature, the term
‘sample variance’ is deﬁned asM2rather than m2.
Now, of course, the only thing that really matters here is the total error of our estimate;
the particular way in which you or I separate error into two abstractions labeled ‘bias’and ‘variance’ has nothing to do with the actual quality of the estimate. So, let’s lookat the full mean-square error criterion (17.2) with the choices β=m
2andβ=M2. Re-
placement of m2byM2removes a term (/angbracketleftm2/angbracketright−µ2)2=µ2
2/n2, but it also increases the
term var( m2) by a factor [ n/(n−1)]2, so it seems obvious that, at least for large n, this
has made things worse instead of better. More speciﬁcally, suppose we replace m2by the
estimator
β≡cm2. (17.7)
What is the best choice of cby orthodox criteria? The expected quadratic loss (17.2) is now
/angbracketleft(cm2−µ2)2/angbracketright=c2/angbracketleftm2
2/angbracketright−2c/angbracketleftm2/angbracketrightµ2+µ2
2
=/angbracketleft(m2−µ2)2/angbracketright−/angbracketleft m2
2/angbracketright(ˆc−1)2+/angbracketleftm2
2/angbracketright(c−ˆc)2,(17.8)
where
ˆc≡µ2/angbracketleftm2/angbracketright
/angbracketleftm2
2/angbracketright. (17.9)
Evidently, the best estimator in the class (17.7) is the one with c=ˆc, and the term−/angbracketleftm2
2/angbracketright
(ˆc−1)2in (17.8) represents the decrease in mean-square error obtainable by using ˆβ≡ˆcm2
instead of m2. Another short calculation shows that
/angbracketleftm2
2/angbracketright=n−3(n−1)[(n2−2n+3)µ2
2+(n−1)µ4], (17.10)
where
µ4≡/angbracketleft(x1−/angbracketleftx1/angbracketright)4/angbracketright=/angbracketleft x4
1/angbracketright (17.11)

<<<PAGE 545>>>

17 Principles and pathology of orthodox statistics 513
is the fourth central moment of p(x1|µ2). We must understand n>1 in all this, for if n=1,
we have m2=0; in sampling theory, a single observation gives no information about the
variance µ2.1
From (17.5) and (17.10) we then ﬁnd that ˆcdepends on the second and fourth moments
of the sampling distribution:
ˆc=n2
n2−2n+3+(n−1)K, (17.12)
where K≡µ4/µ2
2≥1. We see that ˆcis a monotonic decreasing function of K; so, if K≥2,
(17.12) shows that ˆc<1 for all n, instead of removing the bias in (17.5) we should always
increase it!
In the case of a Gaussian distribution, p(x|µ2)∝exp{−x2/2µ2},w eﬁ n d K=3. We
will seldom have K<3, for that would imply that p(x|µ2) cuts off even more rapidly than
Gaussian for large x.I fK=3, (17.12) reduces to
ˆc=n
n+1, (17.13)
which, by comparison with (17.6), says that rather than removing the bias we should ap-
proximately double it, in order to minimize the mean-square sampling error.
How much better is the estimator ˆβ=ˆcm2than M2? In the Gaussian case the mean-square
error of the estimator ˆβis
/angbracketleft(ˆβ−µ2)2/angbracketright=2µ2
2
n+1. (17.14)
The unbiased estimator M2corresponds to the choice
c=n
n−1(17.15)
and thus to the mean-square error
/angbracketleft(M2−µ2)2/angbracketright=µ2
2/bracketleftbigg2
n+1+2
n/bracketrightbigg
, (17.16)
which is over twice the amount incurred by use of ˆβ.2Most sampling distributions that arise
in practice, if not Gaussian, have wider tails than Gaussian, so that K>3; in this case the
difference will be even greater.
Up to this point, it may have seemed that we are quibbling over a very small thing –
changes in the estimator of one or two parts out of n. But now we see that the difference
between (17.14) and (17.16) is not at all trivial. For example, with the unbiased estimator
M2you will need n=203 observations in order to get as small a mean-square sampling
1In Bayesian theory a single observation could give information about µ2ifµ2is correlated, in the joint prior probability
p(µ2θ|I), with some other parameter θin the problem about which a single observation does give information; that is, p(µθ|I)/negationslash=
p(µ|I)p(θ|I). This kind of indirect information transfer can be helpful in problems where we have cogent prior information but
only sparse data.
2Editor’s footnote: It appears that Jaynes indavertantly calculated this expectation using /angbracketleftm2
2/angbracketright(c−c∗) rather than/angbracketleftM2
2/angbracketright(c−c2)2
and so arrived at (17.16) rather than /angbracketleft(M2−µ2)2/angbracketright=2µ2
2/(n−1).

<<<PAGE 546>>>

514 Part 2 Advanced applications
error as the biased estimator ˆβgives you with only 100 observations. This is typical of the
way orthodox methods waste information; in this example we have, in effect, thrown awayhalf of our data whatever the value of n, and therefore wasted half the work expended in
acquiring the data.
R. A. Fisher, who often thought in terms of information, perceived this long ago; but
modern orthodox practitioners seem never to perceive it, because they continue to fantasizeabout frequencies, and do not think in terms of information at all.
3There is a work on
econometrics (Valavanis, 1959, p. 60) where the author attaches such great importance to
removing bias that he advocates throwing away not just half the data but practically all ofthem, if necessary, to achieve this.
Why do orthodoxians put such exaggerated emphasis on bias? We suspect that the main
reason is simply that they are caught in a psychosemantic trap of their own making. When
we call the quantity ( /angbracketleftβ/angbracketright−α) the ‘bias’, that makes it sound like something awfully repre-
hensible, which we must get rid of at all costs. If it had been called instead the ‘componentof error orthogonal to the variance’, as suggested by the Pythagorean form of (17.2), itwould have been clear to all that these two contributions to the error are on an equal footing;
it is folly to decrease one at the expense of increasing the other. This is just the price one
pays for choosing a technical terminology that carries an emotional load, implying valuejudgments; orthodoxy falls constantly into this tactical error.
Chernoff and Moses (1959) give a more forceful example showing how an unbiased
estimate may be far from what we want. A company is laying a telephone cable across SanFrancisco Bay. They cannot know in advance exactly how much cable will be needed, andso they must estimate. If they overestimate, the loss will be proportional to the amount ofexcess cable to be disposed of; but if they underestimate, and the cable end falls into thewater, the result may be ﬁnancial disaster. Use of an unbiased estimate here could onlybe described as foolhardy; this shows why a Wald-type decision theory is needed to fullyexpress rational behavior.
Another reason for such an undue emphasis on bias is a belief that if we draw Nsuccessive
samples of nobservations each and calculate the estimators β
1,...,β N, the average β=
N−1/summationtextβiof these estimates will converge in probability to /angbracketleftβ/angbracketrightasN→∞ , and thus an
unbiased estimator will, on sufﬁciently prolonged sampling, give an arbitrarily accurateestimate of α. Such a belief is almost never justiﬁed, even for the fairly well-controlled
measurements of the physicist or engineer, not only because of unknown systematic error,but because successive measurements lack the logical independence required for these limittheorems to apply.
In such uncontrolled situations as economics, the situation is far worse; there is, in
principle, no such thing as ‘asymptotic sampling properties’ because the ‘population’ is
always ﬁnite, and it changes uncontrollably in a ﬁnite time. The attempt to use only sampling
3Note that this difﬁculty does not arise in the Bayesian approach, in spite of a mathematical similarity. Again choosing any
function β(x1,..., xn) of the data as an estimator, and letting the brackets /angbracketleft/angbracketrightstand now for expectations over the posterior
pdf for α, we have the expected square of the error of /angbracketleft(β−α)2/angbracketright=(β−/angbracketleftα/angbracketright)2+var(α), rather like (17.2). But now changing
the estimator βdoes not change var( α)=(/angbracketleftα2/angbracketright−/angbracketleftα/angbracketright2), and so, by this criterion, the optimal estimator over the class of all
estimators is always β=/angbracketleftα/angbracketright.

<<<PAGE 547>>>

17 Principles and pathology of orthodox statistics 515
distributions – always interpreted as limiting frequencies – in such a situation forces one to
expend virtually all his efforts on irrelevant fantasies. What is relevant to inference is notany imagined (that is, nonobserved) frequencies, but the actual state of knowledge that we
have about the real situation . To reject that state of knowledge – or any human information –
on the grounds that it is ‘subjective’ is to destroy any possibility of ﬁnding useful results;for human information is all we have.
4
Even if we accept these limit theorems uncritically, and believe faithfully that our sam-
pling probabilities are also the limiting frequencies, unbiased estimators are not the onlyones which approach perfect accuracy with indeﬁnitely prolonged sampling. Many biasedestimators approach the true value of αin this limit, and do it more rapidly . Our ˆβis an
example. Furthermore, asymptotic behavior of an estimator is not really relevant, becausethe real problem is always to do the best we can with a ﬁnite data set; therefore the im-portant question is not whether an estimator tends to the true value, but how rapidly it
does so.
Long ago, R. A. Fisher disposed of the unbiased estimate by a different argument that
we noted in Chapter 6, Eq. (6.94). The criterion of bias is not really meaningful, becauseit is not invariant under a change of parameters; the square of an unbiased estimate of α
is not an unbiased estimate ofα
2. With higher powers αk, the difference in conclusions
can become arbitrarily large, and nothing in the formulation of a problem tells us whichchoice of kis ‘right’. Thus, if you and I happen to choose kdifferently, the criterion of
an unbiased estimate will lead us to different conclusions about αfrom the same data.
However, many orthodoxians simply ignore these ambiguities (although they can hardlybe unaware of them) and continue to use unbiased estimators whenever they can, awarethat they are violating a rather basic principle of rationality, but unaware that they are alsowasting information.
5
Note, however, that, after all this argument, nothing in the above entitles us to conclude
that ˆβis the best estimator of µ2by the criterion of mean-square sampling error! We have
considered only the restricted class of estimators (17.7) constructed by multiplying thesample variance (17.4) by some preassigned number; we can say only that ˆβis the best
one in that class. The question whether some other function of the sample values, not amultiple of (17.4), might be still better by the criterion of mean-square sampling error,remains completely open. That the orthodox approach to parameter estimation does not tellus how to ﬁnd the best estimator, but only how to compare different intuitive guesses, wasnoted in Chapter 13 following Eq. (13.21); and we showed that the difﬁculty is overcome
4‘Objectivity’ in inference consists, then, in carefully considering all the information we have about the real situation, and carefully
avoiding fantasies about situations that do not actually exist. It seems to us that this should have been obvious to orthodoxiansfrom the start, since it was obvious already to ancient writers such as Herodotus ( c500 bc) in his discussion of the policy
decisions of the Persian kings.
5We noted in Chapter 6, Eqs. (6.94)–(6.98) that the Bayesian criterion of the posterior expectation has potentially the sameambiguity; different deﬁnitions of parameters will lead to different conclusions if we continue to use the criterion of posterior
expectation after a parameter transformation. Curiously, this problem did not arise with Laplace’s original criterion of posteriormedian and quartiles. But these were not entirely correct applications of Bayesian theory. When we completed the theoretical
apparatus with the decision theory of Chapter 13, a transformation of parameters was accompanied by a corresponding trans-formation of the loss function, with the result that our ﬁnal substantive conclusions are now invariant under arbitrary parameterredeﬁnitions.

<<<PAGE 548>>>

516 Part 2 Advanced applications
by a slight reformulation of the problem, which leads inexorably to the Bayesian algorithm
as the one which accomplishes what we really want.
Exercise 17.1. Try to extend sampling theory to deal with the many questions left
unanswered by the orthodox literature and the above discussion. Is there a generaltheory of optimal sampling theory estimators for ﬁnite samples? If so, does bias playany role in it? We know already, from the analysis in Chapter 13, that this cannot bea variational theory; but it seems conceivable that a theory somewhat like dynamicprogramming might exist. In particular, can you ﬁnd an orthodox estimator that isbetter than ˆβby the mean-square error criterion? Or can you prove that ˆβcannot be
improved upon within sampling theory?
In contrast to the difﬁculty of these questions in sampling theory, we have noted above and
in Chapter 13 that the Bayesian procedure automatically constructs the optimal estimator
for any data set and loss function, whether or not a sufﬁcient statistic exists; and it leads at
once to a simple variational proof of its optimality not within any restricted class, but withrespect to allestimators. And it does this without making any reference to the notion of
bias, which plays no role in Bayesian theory.
17.3 Pathology of an unbiased estimate
On closer examination, an even more disturbing feature of unbiased estimates appears.
Consider the Poisson sampling distribution: the probability that, in one time unit, we observe
nevents, or ‘counts’, is
p(n|l)=exp(−l)l
n
n!, n=0,1,2,..., (17.17)
in which the parameter lis the sampling expectation of n,/angbracketleftn/angbracketright=l. Then what function f(n)
gives an unbiased estimate of l? Evidently, the choice f(n)=nwill achieve this; to prove
that it is unique, note that the requirement /angbracketleftf(n)/angbracketright=lis
∞/summationdisplay
n=0exp(−l)ln
n!f(n)=l, (17.18)
and, from the formula for coefﬁcients of a Taylor series, this requires
f(n)=dn
dln{lexp(l)}/vextendsingle/vextendsingle/vextendsingle
l=0=n. (17.19)
A reasonable result. But suppose we want an unbiased estimator of some function g(l); by
the same reasoning, the unique solution is
f(n)=dn
dln/braceleftbig
exp(l)g(l)/bracerightbig/vextendsingle/vextendsingle/vextendsingle
l=0. (17.20)

<<<PAGE 549>>>

17 Principles and pathology of orthodox statistics 517
Thus the only unbiased estimator of l2is
f(n)=/braceleftBigg
0 n=0,1
n(n−1) n>1,(17.21)
which is absurd for n=1. Likewise, the only unbiased estimator of l3is absurd for n=1,2;
and so on. Here the unbiased estimator does violence to elementary logic; if we observen=2, we are advised to estimate l
3=0; but if l3were zero, it would be impossible to
observe n=2! The only unbiased estimator of exp {−l}is
f(n)=/braceleftBigg
1 n=0
0 n>0,(17.22)
which is absurd for all positive n. An unbiased estimator for (1 /l) does not exist; it is math-
ematically pathological. Unbiased estimators can stand in conﬂict with deductive logicnot just for a few data sets, but for all data sets. And if they can generate such pathol-ogy even in such a simple problem as this, what horrors await us in more complicatedproblems?
The remedy
In contrast, with uniform prior the Bayesian posterior mean estimate of any function g(l)i s
/angbracketleftg(l)/angbracketright=1
n!/integraldisplay∞
0dlexp(−l)lng(l), (17.23)
which is readily veriﬁed to be mathematically well-behaved and intuitively reasonable for
all the above examples. The Bayes estimate of (1 /l) is just (1 /n); no pathology here. It is
at ﬁrst surprising that the Bayes estimate of exp {−l}is
f(n)=2−(n+1). (17.24)
Why would it not be just exp {−n}? To see why, note the following points.
(1) The posterior distribution for lis skewed; the posterior probability that l>nis
P(l>n)=/integraldisplay∞
ndlexp{−l}ln
n!=exp(−n)n/summationdisplay
m=0nm
m!. (17.25)
This decreases monotonically from 1 at n=0t o1/2a sn→∞ . Thus, given n, the parameter l
is always more likely to be greater than nthan less.
(2) The posterior distribution for lis proportional to exp {−l}ln, which is concentrated mostly in the
interval ( n±√n). But exp{−l}is so rapidly varying that, in calculating its expectation, most of the
contribution to the integral/integraltext
dlexp{−2l}lncomes from the region ( n/2±√n/2 ) ;s oe x p{−n/2}
would be closer to the correct estimator than exp {−n}. Both of these circumstances affect the
numerical value, in such as way that (17.24) ﬁnally emerges as the balance between these opposing
tendencies. This is still another example where Bayes’ theorem detects a genuinely complicated

<<<PAGE 550>>>

518 Part 2 Advanced applications
situation and automatically corrects for it, but in such a slick, efﬁcient way that one is unaware
of what is happening.
Exercise 17.2. Consider the truncated Poisson distribution:
p(n|l)=/bracketleftbigg1
exp(l)−1/bracketrightbiggln
n!, n=1,2,.... (17.26)
Show that the unbiased estimator of lis now absurd for n=1, and the unbiased
estimator of exp(−l) is absurd for all even nand queer for all odd n.
Many other examples are known in which the attempt to ﬁnd unbiased estimates leads to
similar pathologies; several were noted by the orthodoxians Kendall and Stuart (1961). Buttheir anti-Bayesian indoctrination was so strong that they would not deign to examine thecorresponding Bayesian results; and so they never did learn that in all their cases Bayesian
methods overcome the difﬁculty easily.
6
17.4 The fundamental inequality of the sampling variance
A famous inequality, variously associated with the names Cram´ er, Rao, Darmois, Frech´ et
and others, ﬁnds a lower bound to the sampling variance that can be achieved for any
estimator – or, indeed, any statistic – with a continuous sampling distribution. Althoughthe result is nearly trivial mathematically, it is important because it is almost the only bit ofconnected theory that orthodoxy has to guide it. An extensive discussion with examples is
given by Cram´ er (1946, Chap. 32). Denote a data set of nobservations by x≡{x
1,..., xn}
and integration over the sample space by/integraltext
dx( ). With a sampling distribution p(x|α)
containing a parameter α, let
u(x,α)≡∂logp(x|α)
∂α. (17.27)
Mathematically, the result we seek is just the Schwartz inequality: given two functions
f(x),g(x) deﬁned on the sample space, write ( f,g)≡/integraltext
dxf(x)g(x). Then ( f,g)2≤
(f,f)(g,g) with equality if and only if f(x)=qg(x), where qis a constant independent
ofx, although it may depend on α.7Now make the choices
f(x)≡u(x,α)/radicalbig
p(x|α), g(x)≡[β(x)−/angbracketleftβ/angbracketright]/radicalbig
p(x|α). (17.28)
We ﬁnd that ( f,g)=/angbracketleftβu/angbracketright−/angbracketleftβ/angbracketright/angbracketleftu/angbracketright=/angbracketleftβu/angbracketright, since/angbracketleftu/angbracketright=/integraltext
dxu(x,α)p(x|α)=∂/∂α
[/integraltext
dxp(x|α)]=0. Likewise, ( f,f)=var(u), and ( g,g)=var(β), so the Schwartz
6Maurice Kendall could have learned this in ﬁve minutes from Harold Jeffreys, whom he saw almost daily for years because they
were both Fellows of St John’s College, Cambridge, and ate at the same high table.
7Proof:/integraltext
dx[f(x)−qg(x)]2≥0 for all constants q, in particular for the value q=(f,g)/(g,g) which minimizes the integral.
Then we have equality if and only if f(x)−qg(x)=0. Note that this remains true whatever the range of integration; it need
not be the entire sample space.

<<<PAGE 551>>>

17 Principles and pathology of orthodox statistics 519
inequality reduces to
/angbracketleftβu/angbracketright≤/radicalbig
var(β)var( u). (17.29)
But/angbracketleftβu/angbracketright=/integraltext
dxβ∂p(x|a)/∂α=d/angbracketleftβ/angbracketright/dα=1+b/prime(α), where b(α)≡(/angbracketleftβ/angbracketright−α)i st h e
bias of the estimator. Thus the famous inequality sought is
var(β)≥[1+b/prime(α)]2
/integraltext
dα(∂logp(x|α)/∂α)2p(x|α). (17.30)
Now, substituting (17.27) into the necessary and sufﬁcient condition for equality ( f=qg)
and making a change of parameters ( α→l), where lis deﬁned by q(α)=−∂l/∂α,w e
have
∂logp(x|α)
∂α=−l/prime(α)[β(x)−/angbracketleftβ/angbracketright], (17.31)
and, integrating over α, the condition for equality becomes
logp(x|a)=−l(α)β(x)+/integraldisplay
dl/angbracketleftβ/angbracketright+const. (17.32)
To put this into more familiar notation, note that the integral in (17.32) is a function of α;
let us call it−logZ(α), deﬁning the function Z(α). Likewise, the constant of integration in
(17.32) is independent of αbut may depend on x; so call it log m(x), deﬁning the function
m(x). With these changes of notation, the necessary and sufﬁcient condition for equality in
(17.30) becomes
p(x|α)=m(x)
Z(l)exp{−l(α)β(x)}. (17.33)
But we recognize this as just the distribution that we found in Chapter 11, produced by
the maximum entropy principle with a constraint ﬁxing /angbracketleftβ(x)/angbracketright. In (17.33) the denominator
Z(l) is evidently a normalizing constant, therefore equal to
Z(l)=/integraldisplay
dxm(x)e x p{−lβ(x)}, (17.34)
whereupon the constraint is just
/angbracketleftβ/angbracketright=−∂log(Z)
∂l, (17.35)
which is identical with (11.60). This generalizes at once to the case where α,βare vectors
of any dimensionality, the exponent becoming {−/summationtextli(α)βi(x)}as in (11.43); so we are
just rediscovering the maximum entropy formalism of Chapter 11!
These results teach us something very important about the basic unity and mutual con-
sistency of several principles that had seemed, up till now, distinct from each other. Wenoted in Chapter 14 that the notion of sufﬁciency, which was always associated with thenotion of information, is in fact deﬁnable in terms of Shannon’s information measure ofentropy. Long ago, the Pitman–Koopman theorem (Koopman, 1936; Pitman, 1936) proved

<<<PAGE 552>>>

520 Part 2 Advanced applications
that the condition for existence of a sufﬁcient statistic is just that the sampling distribution
be of the functional form (17.32). Therefore, if we use the maximum entropy principle toassign sampling distributions, this automatically generates the distributions with the mostdesirable properties from the standpoint of inference in either sampling theory (becausethe sampling variance of an estimator is then the minimum possible value) or Bayesiantheory (because then in applying Bayes’ theorem we need only calculate a single functionof the data).
Indeed, if we think of a maximum entropy distribution as a sampling distribution pa-
rameterized by the Lagrange multipliers l
j, we ﬁnd that the sufﬁcient statistics are pre-
cisely the data images of the constraints that were used in deﬁning that distribution.Thus, the maximum entropy distribution generated from the set of constraints ﬁxing{/angbracketleftβ
1(x)/angbracketright,/angbracketleftβ2(x)/angbracketright,...,/angbracketleftβk(x)/angbracketright}as expectations over the probability distribution, has ksuf-
ﬁcient statistics which are just {β1(x),...,β k(x)}, in which now xis the observed data
set. This is proved in Jaynes (1978, Eq. B82); we leave it as an exercise for the reader toreconstruct the proof.
If the sampling distribution does not have the form (17.33) or its generalization, there
are two possibilities. Firstly, if the sampling distribution is continuous in α, then the lower
bound (17.28) cannot be attained, and there seems to be no theory to determine the correct
lower bound, much less to construct an estimator that achieves it. Then if /angbracketleftβ/angbracketrightis unbiased,
the ratio of the minimum possible variance, right-hand side of (17.30), to the actual var ( β)
was called by Fisher the efﬁciency of the estimator β, and an estimator with efﬁciency of
one was called an efﬁcient estimator . Nowadays it is usually called an ‘unbiased minimum
variance’ (UMV) estimator.
8
Secondly, if p(x|α) has discontinuities, Cram´ er (1946, p. 485) ﬁnds that there are estima-
tors that actually achieve a lower variance than (17.28). But how is this possible, since theSchwartz inequality does not seem to admit to any exceptions? We consider this a mathe-matical error, for reasons explained in Appendix B (had Cram´ er approached a discontinuous
function as the limit of a sequence of continuous ones, another term, a delta-function, wouldhave appeared in the limit, which just accounts for the discrepancy and makes the inequality(17.30) correct whether p(x|α) is continuous or discontinuous). This is a typical case where
failure to recognize the necessary role of delta-functions in analysis leads one into errors.
17.5 Periodicity: the weather in Central Park
A common problem, important in economics, meteorology, geophysics, astronomy and
many other ﬁelds, is to decide whether certain data taken over time provide evidencefor a periodic behavior. Any clearly discernible periodic component (in births, diseases,rainfall, temperature, business cycles, stock market, crop yields, incidence of earthquakes,brightness of a star) provides an evident basis for improved prediction of future behavior,
8Note that the notion of efﬁciency is even more parameter-dependent than that of an unbiased estimate; if an efﬁcient estimator
ofαexists, then an efﬁcient estimator of α2does not.

<<<PAGE 553>>>

17 Principles and pathology of orthodox statistics 521
on the presumption (that is, inductive reasoning) that periodicities observed in the past are
likely to continue in the future. But even apart from prediction, the principle for analyzingthe data for evidence of periodicity in the past is still controversial: is it a problem ofsigniﬁcance tests, or one of parameter estimation? Different schools of thought come toopposite conclusions from the same data.
Consider an example from the recent literature of orthodox reasoning and procedure
here; this will also provide an easy introduction to Bayesian spectrum analysis. Bloomﬁeld(1976, p. 110) gives a graph showing mean January temperatures observed over about100 years in Central Park, New York. The presence of a periodicity of roughly 20 yearswith a peak-to-peak amplitude of about 4
◦F is perfectly evident to the eye, since the
irregular ‘noise’ is only about 0.5◦F. Yet Bloomﬁeld, applying an orthodox signiﬁcance test
introduced by Fisher, concludes that there is no signiﬁcant evidence for any periodicity!
17.5.1 The folly of pre-ﬁltering data
In trying to understand this we note ﬁrst that the data of Bloomﬁeld’s graph have been ‘pre-
ﬁltered’ by taking a 10 year moving average. What effect does this have on the evidence
for periodicity? Let the original raw data be D={y1,..., yn}and consider the discrete
Fourier transform
Y(ω)≡n/summationdisplay
t=1ytexp{iωt}. (17.36)
This is well-deﬁned for continuous values of ωand is periodic: Y(ω)=Y(ω+2π). There-
fore there is no loss of information if we conﬁne the frequency to |ω|<π. But even that
is more than necessary; the values of Y(ω)a ta n y nconsecutive and discrete ‘Nyquist’
frequencies9
ωk≡2πk/n,0≤k<n, (17.37)
already contain all the information in the data, for by the orthogonality n−1/summationtext
kexp{iωk(s−
t)}=δst, the data can be recovered from them by the Fourier inversion:
1
nn/summationdisplay
k=1Y(ωk)e x p{−iωkt}=yt, 1≤t≤n. (17.38)
Suppose the data were replaced with an myear moving average over past values, with
weighting coefﬁcient of wsfor lag s:
zt≡m−1/summationdisplay
s=0yt−sws. (17.39)
9Harry Nyquist was a mathematician at the Bell Telephone Laboratories who, in the 1920s, discovered a great deal of the
fundamental physics and information theory involved in electrical communication. The work of Claude Shannon is a continuation,20 years later, of some of Nyquist’s pioneering work. All of it is still valid and indispensable in modern electronic technology. In
Chapter 7 we have already considered the fundamental, irreducible ‘Nyquist noise’ in electrical circuits due to random thermal
motion of electrons.

<<<PAGE 554>>>

522 Part 2 Advanced applications
The new Fourier transform would be, after some algebra,10
Z(ω)=n/summationdisplay
t=1ztexp{iωt}=W(ω)Y(ω), (17.40)
where
W(ω)≡m−1/summationdisplay
s=0wsexp{iωs} (17.41)
is the Fourier transform of the weighting coefﬁcients. This is just the convolution theorem
of Fourier theory. Thus, taking any moving average of the data merely multiplies its Fouriertransform by a known function. In particular, for uniform weighting
w
s=1
m, 0≤s<m, (17.42)
we have
W(ω)=1
mm−1/summationdisplay
s=0exp{−iωs}=exp/braceleftBig
−iω
2(m−1)/bracerightBig/bracketleftbiggsin(mω/2)
msin(ω/2)/bracketrightbigg
. (17.43)
In the case m=10 we ﬁnd, for a 10 year and 20 year periodicity, respectively,
W(2π/10)=0; W(2π/20)=0.639 exp{−9πi/20}. (17.44)
Thus, taking a 10 year moving average of any time series data represents an irreversible
loss of information; it completely wipes out any evidence for a 10 year periodicity, andreduces the amplitude of a 20 year periodicity by a factor 0.639, while shifting its phaseby 9π/20=1.41 radian. In addition, the magnitude of W(ω) is decreasing at ω=2π/20
so the apparent frequency is shifted; the peak in Z(ω) occurs at a lower frequency than the
true peak in Y(ω). We conclude that the original data had a periodicity of roughly 20 years
with a peak-to-peak amplitude of about 4 /0.639=6.3
◦F, even more obvious to the eye
and nearly 90 degrees out of phase with the periodicity visible in Bloomﬁeld’s graph; andthe true frequency is somewhat higher than one would estimate from the graph. Taking themoving average has severely mutilated and distorted the information in the data.
At several places we warn against the common practice of pre-ﬁltering data in this way
before analyzing them. The only thing it can possibly accomplish is the cosmetic one of
making the graph of the data look prettier to the eye. But if the data are to be analyzed
10At this point, many authors get involved in a semantic hangup over exactly what one means by the term ‘ myear moving average’
for a series of ﬁnite length. If we have only ytfort>0, then it seems to many that the myear moving average (17.39) could
start only at t=m. But then they ﬁnd that their formulas are not exact, but require small ‘end-effect’ correction terms of order
m/n. We avoid this by a slight change in deﬁnitions. Consider the original time series {yt}augmented by ‘zero-padding’; we
deﬁne yt≡0 when t<1o rt>n, and likewise the weighting coefﬁcients are deﬁned to be zero when s<0o rs≥m. Then
we may understand the above sums over t,sto be over (−∞,+∞), and the ﬁrst few terms ( z1,..., zm−1), although averages
over myears of the padded data, are actually averages over less than myears of nonzero data. The differences are numerically
negligible when m/lessmuchn, but we gain the advantage that the simple formulas (17.36)–(17.42) with sums taken instead over
±∞ andtin (17.39) allowed to take all positive values, are all exact as they stand, without our having to bother with messy
correction terms. Furthermore, it is evident that failure to do this means that some of the information in the ﬁrst mand last
mdata values is lost. This particular deﬁnition of the term ‘moving average’ for a ﬁnite series (which was basically arbitrary
anyway) is thus the one appropriate to the subject.

<<<PAGE 555>>>

17 Principles and pathology of orthodox statistics 523
by a computer, this does not help in any way; it only throws away or distorts some of the
information that the computer could have extracted from the original, unaltered data. Itrenders the ﬁltered data completely useless for certain purposes. For all we know, theremight have been a strong periodicity of about 10 years in the original data, corresponding tothe well known 11 year periodicity in sunspot numbers; but, if so, taking a 10 year movingaverage has wiped out the evidence for it.
The periodogram of the data is then the power spectral density:
P(ω)≡1
n|Y(ω)|2=1
n/summationdisplay
t,sytysexp{iω(t−s)}. (17.45)
Note that P(0)=(/summationtextyt)2/n=ny2determines the mean value of the data, while the average
of the periodogram at the Nyquist frequencies is the mean-square value of the data:
P(ωk)av=1
nn/summationdisplay
k=1P(ωk)=y2. (17.46)
Fisher’s proposed test statistic for a periodicity is the ratio of peak/mean of the periodogram:
q=P(ωk)max
P(ωk)av, (17.47)
and one computes its sampling distribution p(q|H0) conditional on the null hypothesis H0
that the data are Gaussian white noise. Having observed the value q0from our data, we ﬁnd
the so-called ‘ P-value’, which is the sampling probability, conditional on H0, that chance
alone would have produced a ratio as great or greater:
P≡p(q>q0|H0)=/integraldisplay∞
q0dqp(q|H0), (17.48)
and if P>0.05 the evidence for periodicity is rejected as ‘not signiﬁcant at the 5% level’.11
This test looks only at probabilities conditional on the ‘null hypothesis’ that there is no
periodic term. It takes no note of probabilities of the data conditional on the hypothesis thata periodicity is present; or on any prior information indicating whether it is reasonable toexpect a periodicity! We commented on this kind of reasoning in Chapter 5; how can one
test any hypothesis rationally if he fails to specify (1) the hypothesis to be tested; (2) thealternatives against which it is to be tested; and (3) the prior information that we bring to
the problem? Until we have done that much, we have not asked any deﬁnite, well-posedquestion.
Equally puzzling, how can one expect to ﬁnd evidence for a phenomenon that is real,
if he starts with all the cards stacked overwhelmingly against it? The only hypothesis H
0
that this test considers is one which assumes that the totality of the data are part of a
11This is a typical orthodox ‘tail area’ signiﬁcance test; we discussed such tests in Chapter 9, and noted that the orthodox chi-
squared test has serious shortcomings, but there is a similar Bayesian ψ-test that is exact and is free of those difﬁculties. Many
other Bayesian ψ-tests can be set up, which test some hypothesis Hagainst a speciﬁed class Cof alternatives. But now we note
a different way of looking at this situation that is generally more useful: a signiﬁcance test can often be replaced by a parameter
estimation problem that is simpler and more informative.

<<<PAGE 556>>>

524 Part 2 Advanced applications
‘stationary Gaussian random process’ without any periodic component. According to that
H0, the appearance of anything resembling a sine wave would be purely a matter of chance;
even if the noise conspires, by chance, to resemble one cycle of a sine wave, it would stillbe only pure chance – equally unlikely according to the orthodox sampling distribution –that would make it resemble a second cycle of that wave; and so on.
In almost every application one can think of, our prior knowledge about the real world
tells us that in speaking of ‘periodicity’ we have in mind some systematic physical inﬂuencethat repeats itself; indeed, our interest in it is due entirely to the fact that we expect it to
repeat .
12Thus we expect to see some periodicity in the weather because we know that
this is affected by periodic astronomical phenomena; the rotation of the Earth on its axis,its yearly orbital motion about the Sun, and the observed periodicity in sunspot numbers,which affect atmospheric conditions on the Earth. So the hypothesis H
1that we want to test
for is quite unrelated to the hypothesis H0that is used in Fisher’s test.13
This is the kind of logic that underlies all orthodox signiﬁcance tests. In order to ar-
gue for an hypothesis H1that some effect exists, one does it indirectly: invent a ‘null
hypothesis’ H0that denies any such effect, then argue against H0in a way that makes
no reference to H1at all (that is, using only probabilities conditional on H0). To see how
far this procedure takes us from elementary logic, suppose we decide that the effect ex-ists; that is, we reject H
0. Surely, we must also reject probabilities conditional on H0;b u t
then what was the logical justiﬁcation for the decision? Orthodox logic saws off its ownlimb.
14
Harold Jeffreys (1939, p. 316) expressed his astonishment at such limb-sawing reasoning
by looking at a different side of it: ‘An hypothesis that may be true is rejected because ithas failed to predict observable results that have not occurred. This seems a remarkableprocedure. On the face of it, the evidence might more reasonably be taken as evidence forthe hypothesis, not against it.’
Thus, if we say that there is a periodicity in temperature, we mean by this that there
is some periodic physical inﬂuence at work, the nature of which may not be known withcertainty, but about which we could make some reasonable conjectures. For example, theaforementioned periodicity in solar activity, already known to occur by the 11 year periodic
variation in sunspot numbers (which many believe, with good reason, to be a rectiﬁed
12It is not necessary for successful prediction that the physical cause of the periodicity be actually understood; in ancient India
records of eclipses were maintained carefully over centuries. From these observations they ‘got the rhythm of it’ and were able
to predict future eclipses very accurately, although they had no conception of their causes.
13If an apparent periodicity were only a momentary artifact of the noise as supposed by H0, we would not consider it a real
periodicity at all, and would not want our statistical test to take any note of it. But, unfortunately, it is always possible for
noise artifacts to appear momentarily real to any test one can devise. The remedy is to check whether the apparent effect isreproducible; a noise artifact will in all probability never occur again in the same way. A physicist can, almost always, use this
remedy easily; an economist usually cannot.
14An historical study has suggested that the culprit who started this kind of reasoning was not a statistician, but the physicistArthur Schuster (1897), who invented the periodogram for the purpose of refuting some claims of periodicity in earthquakes
in Japan. Never thinking in terms of information, he achieved his preconceived goal by the simple device of analyzing thedata in a way that threw away the information about that periodicity! But then this was taken up by many others, including
Fisher, Feller, Blackman and Tukey, and Bloomﬁeld. Nevertheless, we shall see that the periodogram does contain basicinformation that Schuster and his followers failed to recognize. They thought that the information was contained in the sampling
distribution for the periodogram; whereas the analysis given here shows that it was actually contained in the shape of the
periodogram.

<<<PAGE 557>>>

17 Principles and pathology of orthodox statistics 525
22 year periodicity), would cause a periodic variation in the number of charged particles
entering our atmosphere (the reality of this is shown by the observed periodic variations intheaurora borealis ), varying the ion concentration and therefore the number of raindrop
condensation centers. This would cause periodic variations in the cloud cover, and hencein the temperature and rainfall, which might be very different in different locations on the
Earth because of prevailing atmospheric circulation patterns.
We do not mean to say that we ﬁrmly believe this mechanism to be the dominant one; only
that it is a conceivable one, which does not violate any known laws of physics, but whosemagnitude is difﬁcult to estimate theoretically. But already, this prior information preparesus not to be surprised by a periodic variation in temperature in Central Park somewhat likethat observed
15and leads us to conjecture that the July temperatures might give even better
evidence for periodicity.
Once a data set has given mild evidence for such a periodicity, its reality could be
deﬁnitely conﬁrmed or refuted by other observations, correlating other data (astronomical,atmospheric electricity, ﬁsh populations, etc.) with weather data at many different locations.A person trained only in orthodox statistics would not hesitate to consider all these phenom-ena ‘independent’; a scientist with some prior knowledge of astrophysics and meteorologywould not consider them independent at all.
If editors of scientiﬁc journals refuse to publish that ﬁrst mild evidence on the grounds
that it is not signiﬁcant in itself by an orthodox signiﬁcance test at the 5% level, the
conﬁrmatory observations will, in all probability, never be made; a potentially impor-tant discovery could be delayed by a century. Physicists and engineers have been largelyspared from such ﬁascos because they hardly ever took orthodox teachings seriously any-way; but others working in economics, artiﬁcial intelligence, biology, or medical researchwho, in the past, allowed themselves to be cowed by Fisher’s authority, have not been sofortunate.
Contrast our position just stated with that of Feller (II, p 76–77), who delivers another
polemic against what he calls the ‘old wrong way’. Suppose the data are expanded insinusoids:
y
t=n/summationdisplay
j=1(Ajcosωjt+Bjsinωjt). (17.49)
We can always approximate ytthis way. Then it seems that Aj,Bjmust be ‘random vari-
ables’ if the{yt}are. Feller warns us against that old wrong way: ﬁt such a series to the data
with well-chosen frequencies {ω1,...,ω n}and assume all Aj,Bj∼N(0,σ). If one of the
R2
j=A2
j+B2
jis big, conclude that there is a true period. He writes of this:
For a time it was fashionable to introduce models of this form and to detect ‘hidden periodici-
ties’ for sunspots, wheat prices, poetic creativity, etc. Such hidden periodicities used to be discov-
ered as easily as witches in medieval times, but even strong faith must be fortiﬁed by a statistical
15One who was also aware of the roughly 20 year periodicity in crop yields, well known to Kansas wheat farmers for a century,
would be even less surprised.

<<<PAGE 558>>>

526 Part 2 Advanced applications
test. A particularly large amplitude Rjis observed; One wishes to prove that this cannot be due
to chance and hence that ωjis a true period. To test this conjecture one asks whether the large
observed value of Ris plausibly compatible with the hypothesis that all ncomponents play the
same role.
Apparently, Feller did not even believe in the sunspot periodicity, which no responsible
scientist has doubted for over a century; the evidence for it is so overwhelming that nobodyneeds a ‘statistical test’ to see it. He states that the usual procedure was to assume the
A
j,Bjiid normal N(0,σ).16Then the R2
jare held to be independent with an exponential
distribution with expectation 2 σ2. ‘If an observed value R2
jdeviated ‘signiﬁcantly’ from
this predicted expectation it was customary to jump to the conclusion that the hypothesisof equal weights was untenable, and R
jrepresented a ‘hidden periodicity’. At this point,
Feller detects that we are using the wrong sampling distribution:
The fallacy of this reasoning was exposed by R. A. Fisher who pointed out that the maximum among
nindependent observations does not obey the same probability distribution as each variable taken
separately. The error of treating the worst case statistically as if it had been chosen at random isstill common in medical statistics, but the reason for discussing the matter here is the surprising andamusing connection of Fisher’s test of signiﬁcance with covering theorems.
Feller then states that the quantities
Vj=R2
j/summationtextR2
i, 1≤j≤n, (17.50)
are ‘distributed’ as the lengths of the nsegments into which the interval (0,1) is partitioned
by a random distribution of n−1 points. The probability that all Vj<ais then given by a
covering theorem noted by Feller.
Of course, our position is that both Feller’s ‘old wrong’ and ‘new right’ sampling distribu-
tions are irrelevant to the inference; the two quantities that are relevant (the prior informationthat expresses our knowledge of the phenomenon and the likelihood function that expressesthe evidence of the data) are not even mentioned.
In any event, the bottom line of this discussion is that Fisher ’s test fails to detect the
perfectly evident 20 year periodicity in the New York Central Park January temperatures.But this is not the only case where simple visual examination of the data is a more powerfultool for inference than the principles taught in orthodox textbooks. Crow, Davis and Maxﬁeld(1960) present applications of the orthodox F-test and t-test which we examine in Jaynes(1976) with the conclusions that (1) the eyeball is a more reliable indicator of an effectthan an orthodox equal-tails test, and (2) the Bayesian test conﬁrms quantitatively what theeyeball sees qualitatively. This is also relevant to the notions of domination and admissibilitydiscussed elsewhere.
16The abbreviation ‘iid’ is orthodox jargon standing for ‘independently and identically distributed’. For us, this is another form
of the mind projection fallacy. In the real world, each individual coefﬁcient Aj,Bjis a deﬁnite, ﬁxed quantity that is known
from the data; it is not ‘distributed’ at all!

<<<PAGE 559>>>

17 Principles and pathology of orthodox statistics 527
17.6 A Bayesian analysis
Now we examine a Bayesian analysis of these same data, and for pedagogical reasons
we want to explain its rationale in some detail. There may be various different Bayesiantreatments of data for periodicity, corresponding to different information about the phe-nomenon, expressed by different choices of a model, and different prior information con-cerning the parameters in a model. Our Bayesian model is as follows. We consider it possiblethat the temperature data have a periodic component due to some systematic physical in-ﬂuence on the weather:
Acosωt+Bsinωt, (17.51)
where, as noted, we may suppose |ω|≤π(with yearly data it does not make sense to
consider periods shorter than a year). In addition the data are contaminated with variablecomponents e
tthat we call ‘irregular’ because we cannot control them or predict them and
therefore cannot make allowance for them. This could be because we do not know theirreal causes or because, although we know the causes, we lack the data on initial conditionsthat would enable predictions.
17Then, as explained in Chapter 7, it will almost always do
justice to the real prior information that we have to assign a Gaussian sampling distributionwith parameters ( µ,σ) to the irregulars. There is hardly any real problem in which we
would have the detailed prior information that would justify any more structured samplingdistribution.
Thusµis the ‘nominal true mean temperature’ not known in advance; we can estimate
it from the data very easily (intuition can see already that the mean value of the data
yis
about as good an estimate of µthat we can make from the information we have); but it
is not of present interest and so we treat it as a nuisance parameter. We do not know σin
advance either, although we can easily estimate it too from the data. But that is not ourpresent interest, and so we shall let σalso be a nuisance parameter to be integrated out as
explained in Chapter 7. Our model equation for the data is then
y
t=µ+Acosωt+Bsinωt+et, 1≤t≤n, (17.52)
and our sampling distribution for the irregular component is
p(e1···en|µσI)=/parenleftbigg1
2πσ2/parenrightbiggn/2
exp/braceleftBigg
−1
2σ2/summationdisplay
te2
t/bracerightBigg
. (17.53)
Then the sampling (density) distribution for the data is
p(y1···yn|µσI)=/parenleftbigg1
2πσ2/parenrightbiggn/2
exp/braceleftbigg
−Q
2σ2/bracerightbigg
(17.54)
17In meteorology, although the principles of thermodynamics and hydrodynamics that determine the weather are well-understood,
weather data taken on a 50 mile grid are grossly inadequate to predict the weather 24 hours in advance. Partial differentialequations require an enormous amount of information on initial conditions to determine anything like a unique solution.

<<<PAGE 560>>>

528 Part 2 Advanced applications
with the quadratic form
Q(A,B,ω)≡/summationdisplay
(yt−µ−Acosωt−Bsinωt)2(17.55)
or
Q=n/bracketleftBig
y2−2yµ+µ2−2Aytcosωt−2Bytsinωt+2µAcosωt
+2µBsinωt+2ABcosωtsinωt+A2cos2ωt+B2sin2ωt/bracketrightBig
,(17.56)
where all the overbar symbols denote sample averages over t. A great deal of detail has
suddenly appeared that was not present in the orthodox treatment; but now all of this detailis actually relevant to the inference . In any nontrivial Bayesian solution we may encounter
much analytical detail because every possible contingency allowed by our information isbeing taken into account (as is required by our basic desiderata in Chapters 1 and 2). Mostof this detail is not perceived at all by orthodox principles, and it would be dif ﬁcult to handle
by paper-and-pencil calculation.
In practice, a Bayesian learns to recognize that much of this detail actually makes a
negligible difference to the ﬁnal conclusions, and so we can almost always make such good
approximations that we can do the special calculation needed for our present purpose withpencil and paper after all. But, fortunately, masses of details are no deterrent to a computer,which can happily grind out the exact solution.
18Now, in the present problem, ( A,B,ω) are
the interesting parameters that we want to estimate, while ( µ,σ) are nuisance parameters
to be eliminated. We see that of the nine sums in (17.56), four involve the data yt; and
since this is the only place where the data appear, these four sums are the jointly sufﬁcientstatistics for all the ﬁve parameters in the problem. The other ﬁve sums can be evaluatedanalytically once and for all, before we have the data.
Now, what is our prior information? Surely, we knew in advance that A,Bmust be less
than 200
◦F. If there were a temperature variation that large, New York City would not exist;
there would have been a panic evacuation of that area long before, by anyone who happenedto wander into it and survived long enough to escape. Thus the empirical fact that New YorkCity exists is highly cogent information relevant to the question being asked; it is already
sufﬁcient to ensure proper priors for ( A,B) in the Bayesian calculation. Also, we have no
prior information about the phase θ=tan
−1(B/A) of any periodicity, which we express by
a uniform prior over θ.
We could cite various other bits of relevant prior information, but we know already from
the results found in Chapter 6, Exercise 6.6, that, unless we have prior information thatreduces the possible range to something like 30
◦F, it will make a numerically negligible
difference in the conclusions (a strictly nil difference if we report our conclusions onlyto three decimal digits). So let us see what Bayesian inference gives with just this. By an
18Indeed, the exact general solution is often easier to program than is any particular special case of it or approximation to it,
because one need not go into the details that make the case special. And the program for the exact solution has the merit of
being crash-proof if written to prevent underﬂow or overﬂow (for approximations will almost surely break down for some data
sets, but the exact solution – with proper priors – must always exist for every possible data set.

<<<PAGE 561>>>

17 Principles and pathology of orthodox statistics 529
argument essentially the same as the Herschel derivation of the Gaussian distribution in
Chapter 7, we may assign a joint prior
p(AB|I)=1
2πδ2exp/braceleftbigg
−A2+B2
2δ2/bracerightbigg
, (17.57)
where δis of the order of magnitude of 100◦F; we anticipate that its exact numerical value
can have no visible effect on our conclusions (nevertheless, such a proper prior may beessential to prevent computer crashes).
Now the most general application of Bayes’ theorem for this problem would proceed as
follows. We ﬁrst ﬁnd the joint posterior distribution for all ﬁve parameters:
p(ABωµσ|DI)=p(ABωµσ|I)p(D|ABωµσ I)
p(D|I). (17.58)
Then integrate out the nuisance parameters:
p(ABω|DI)=/integraldisplay
dµ/integraldisplay
dσp(ABωµσ|DI). (17.59)
But this is a far more general calculation than we need for present purposes; it is prepared
to take into account arbitrary correlations in the prior probabilities. Indeed, we can alwaysfactor the prior thus:
p(ABωµσ|I)=p(ABω|I)p(µσ|ABωI); (17.60)
and so the most general solution appears formally simpler:
p(ABω|DI)=Cp(ABω|I)L
∗(A,B,ω), (17.61)
where Cis a normalization constant, and L∗is the quasi-likelihood
L∗(A,B,ω)≡/integraldisplay
dµ/integraldisplay
dσp(µσ|ABωI)p(D|ABωµσ I). (17.62)
In (17.61) the nuisance parameters are already out of sight. But in our present problem,
evidently knowledge of the parameters ( A,B,ω) of the systematic periodicity would tell
us nothing about the parameters ( µ,σ) of the irregulars; so the prior for the latter is just
p(µσ|ABωI)=p(µσ|I), (17.63)
so what is our prior information about ( µ,σ)? Surely we knew also, for the same ‘panic
evacuation’ reason, that neither of these parameters could be as large as 200◦F. And we
know that σcould not be as small as 10−6◦F, because, after all, our data are taken with a
real thermometer, and no meteorologist’s thermometer can be read to that accuracy (if itcould, it would not give reproducible readings to that accuracy). We could just as well ignorethat practical consideration and argue that σcould not be as small as 10
−20◦F because the
concept of temperature is not deﬁned, in statistical mechanics, to that accuracy. Numerically,it will make no difference at all in our ﬁnal conclusions, but it is still conceivable that aproper prior may be needed to avoid computer crashes in all contingencies. So, to be on the

<<<PAGE 562>>>

530 Part 2 Advanced applications
safe side, we assign the prior Gaussian in µ, because it is a location parameter, a truncated
Jeffreys prior for σ, because we have seen in Chapter 12 that the Jeffreys prior is uniquely
determined as the only completely uninformative prior for a scale parameter:
p(µσ|I)∝1
σ√
2πα2exp{−µ2/2α2}, a≤σ≤b, (17.64)
in which αandbare also of the order of 100◦F, while a/similarequal10−6; we are only playing it
extremely safe in the expectation that most of this care will prove in the end to have beenunnecessary.
Our quasi-likelihood is then
L
∗(A,B,ω)=/integraldisplay∞
−∞dµexp{−µ2/2α2}/integraldisplayb
adσ
σn+1exp{−Q/2σ2}. (17.65)
But now it is evident that the ﬁnite limits on σare unnecessary; for if n>0 the integral
overσconverges both at zero and inﬁnity, and
/integraldisplay∞
0dσ
σn+1exp{−Q/2σ2}=1
2(n/2−1)!
(Q/2)n/2, (17.66)
and the integral of this over µis also guaranteed to converge. For tactical reasons, let us do
the integration over µﬁrst. We begin by rewriting Qas
Q=n[s2+(µ−d)2]. (17.67)
Editor’s Exercise 17.3(a) The equation for Qis formally identical to (7.29); however,
as written, none of the quantities were deﬁned by Jaynes. Show that s2may be written
as
s2≡d2−d2, (17.68)
where dandd2are the mean and mean-square of an effective data deﬁned as
di=yi−Acos(ωti)−Bsin(ωt). (17.69)
(b)Evaluate the integral over uandσto obtain the marginal p(ABω|DI).
(c)Unfortunately, the p(ABω|DI) does not summarize all of the information in the data
concerning frequency estimation, to do that we need p(ω|DI); derive it in closed form.
(d)The posterior probability p(ω|DI) makes the implicit assumption that a resonance
is present and so will estimate the frequency reg ardless of whether or not such a
resonance exists. How would you use probability theory and the results derived so far
to determine if a resonance is present?19
19For an example of such a signal detection statistic, see my article: Bretthorst, G. L. (1990), J. Mag. Resonance 88,571–595.

<<<PAGE 563>>>

17 Principles and pathology of orthodox statistics 531
17.7 The folly of randomization
Many writers introduce randomized methods by the example of ‘Monte Carlo integration’.
Let a function y=f(x) have its domain of existence in the unit square 0 ≤x,y≤1; we
wish to compute numerically the integral
θ≡/integraldisplay1
0dxf(x). (17.70)
Perhaps this is too complicated analytically, or perhaps f(x) was only empirically deter-
mined; we do not have it in analytical form. Then let us just choose npoints at random
(x,y) in the unit square and determine for each whether it lies below the graph of f(x); that
is, whether y≤f(x). Let the number of such points be r; then we estimate the integral as
(θ)est=r/nand as n→∞ we might expect this to approach the correct Riemannian inte-
gral; but how accurate is it? Always, one would suppose independent binomial sampling:the sampling distribution for ris taken to be
p(r|nθ)=/parenleftbiggn
r/parenrightbigg
θ
r(1−θ)n−r(17.71)
which has (mean)±(standard deviation) of
θ±/radicalbigg
θ(1−θ)
n, (17.72)
and if the width of the sampling distribution is held to indicate the accuracy of our estimate,
one would think it reasonable to assign a probable error to ( θ)estgiven by
(θ)est=r
n±/radicalbigg
r(n−r)
n3. (17.73)
For example, suppose the true θis 1/2, and n=100. Then, having observed r=43 we
would get the estimate of
(θ)est=0.43±/radicalbigg
0.43×0.57
n=0.43±0.05, (17.74)
or an accuracy of about 11.5%. But the trouble with such methods is that they improve only
as 1/√n.
Now let’s take our nsampling points in a nonrandomized way on a uniform grid: divide
the unit square into√nsteps each way, take one sampling point at each grid point, and
again count how many ( r) are below the curve. The maximum error we can make in each
step is
[error in determining f(x)]×[width of step]=1
2√n×1√n=1
2n. (17.75)
Therefore the maximum possible error in the integral is
[number of steps]×[maximum error in each step] =1
2√n. (17.76)

<<<PAGE 564>>>

532 Part 2 Advanced applications
So ifθ/similarequal0.5, the probable error in the Monte Carlo method is about equal to the maximum
possible error in the uniform grid sampling method. But the probable error in the uniform
grid method is much less than this: the central limit theorem tells us that, with a rectangulardistribution of error probability in each step, the expected square of the error in determining
f(x) in that step is
√
n/integraldisplay√n
0dx/parenleftbigg
x−1
2√n/parenrightbigg2
=1
12n2. (17.77)
If the errors in different steps are independent, the expected square of the total error is
(mean square error per step) ×(number of steps)=1
12n3/2, (17.78)
and the probable error in the integral is about
±1√
12n3/4. (17.79)
Thus, if n=100 and θ/similarequal0.5, the Monte Carlo method gives a probable error of about
0.05, the uniform grid sampling gives 0.00913, less than one-ﬁfth as much. With n=1000,
the Monte Carlo probable error is 0.0158, the uniform grid probable error is 0.00162,
about one-tenth as much. The uniform grid calculation at n=100 points yields the same
probable error as does the Monte Carlo method at n=3000 points. This corresponds rather
nicely to the italicized statement following (17.16). Another example is given by Royall and
Cumberland (1981); this is particularly cogent because the authors are not Bayesian and did
not start out with the intention of exposing the folly of randomization, but did so anyway.
17.8 Fisher: common sense at Rothamsted
From the study of several such examples, we propose as a general principle: Whenever there
is a randomized way of doing something, there is a nonrandomized way that yields betterresults from the same data, but requires more thinking . Perhaps this principle does not have
quite the status of a theorem, but we are conﬁdent that, whenever one is willing to do therequired extra thinking, it will be conﬁrmed.
17.8.1 The Bayesian safety device
We note that Bayesian methods are not only more powerful than orthodox ones; they are also
safer (i.e. they have automatic built-in safety devices that prevent them from misleadingus with the over-optimistic or over-pessimistic conclusions that orthodox methods canproduce). It is important to understand why this is true. In parameter estimation, for example,whether or not there is a sufﬁcient statistic, the log-likelihood function is
logL(α)=
n/summationdisplay
i=1logp(xi|α)=nlogp(xi|α), (17.80)

<<<PAGE 565>>>

17 Principles and pathology of orthodox statistics 533
in which we see the average of the log-likelihoods over each individual data point. The log-
likelihood is always spread out over the full range of variability of the data, so if we happento get a very bad (spread out) data set, no good estimate is possible and Bayes’ theoremwarns us about this by returning a wide posterior distribution. With a location parameter
p(x|α)=h(x−α) and an uninformative prior, the width of the posterior distribution for α
is essentially ( R+W)
(range of the data)+(width of individual likelihoods). (17.81)
If we happen to get a very good (sharply concentrated) data set, a more accurate estimate of
αis possible and Bayes’ theorem takes advantage of this, returning a posterior distribution
whose width approaches a lower bound determined by that of the single-point likelihood
L
i(α)=p(xi|α) and the amount nof data.
In the orthodox method, the accuracy claim is essentially the width of the sampling
distribution for whatever estimator βwe have chosen to use. But this takes no note of the
range of the data! Orthodox estimation based on a single statistic will claim just the same
accuracy whether the data range is large or small. Far worse, that accuracy expresses entirelythe variability of the estimator over other data sets that we think might have been obtained
but were not . But again this concentrates attention on an irrelevancy, while ignoring what is
relevant; unobserved data sets are only a ﬁgment of our imagination. Surely, if we are onlyimagining them, we are free to imagine anything we please. That is, given two proposedconjectures about unobserved data, what is the test by which we could decide which one iscorrect?
In spite of its mathematical triviality, we stress the fundamental importance of (17.80) for
demonstrating the inner mechanism of Bayes’ theorem. It clariﬁes several other questionsoften raised about Bayesian methods. We note one of the most important.
17.9 Missing data
This is a problem that does not exist for us; Bayesian methods work by the same algorithm
whatever data we have. For example, in estimating a parameter θfrom a data set D≡{x
i},
where the indices irefer to the times{ti}of observation and take on values in some set T,
the data affect the result through the likelihood function L(θ), given by
logL(θ)=/summationdisplay
i∈Tlogp(xi|θ), (17.82)
where the sum is over whatever data values we have. The point is that, whether the times
{ti}are consecutive and equally spaced, or completely irregular with large gaps, makes no
difference; probability theory as logic tells us that (17.82) yields the optimal inference,which captures all the evidence in the data set that we happen to have. One can write asingle computer program which, once and for all, accepts whatever data (that is, whateverset of numbers{x
i;ti}) we give it, and proceeds to do the correct calculation for that
data set.

<<<PAGE 566>>>

534 Part 2 Advanced applications
In contrast, note what happens in orthodox statistics, where estimation is obliged to
proceed through the sampling distribution of some ‘statistic’ θ∗(xi). If any data are missing
from the set Twhich was assumed in setting up the problem, one has two ways of dealing
with this. Firstly, the theoretically correct procedure would recognize that this not onlychanges the sampling distribution for any statistic; it requires one to go back to the beginningand reconsider the whole problem. This can get us into a horrendous situation – everydifferent kind of missing data or extra data can oblige us to deﬁne a new sample space,choose a new statistic θ
∗∗and calculate a new sampling distribution p(θ∗∗|θ).
Alternatively, one can invent a new ad hockery and try to estimate the missing data values
from the ones we have, and use these as if they were real data. Obviously, this procedure isnot only unjustiﬁed logically, it is highly ambiguous because that estimation could be madein many different ways. These difﬁculties are seen at ﬁrst hand in Little and Rubin (1987).
The missing data problem was so cumbersome in orthodox statistics that some who saw
the light and moved over into the Bayesian camp failed to perceive that they had left this
problem behind them. Instead of applying such simple rules as (17.82) directly, whichwould have led them immediately to the correct solution whatever the data, they proceededout of force of habit to follow the orthodox custom and invent new ad hoc devices like
the one just noted, as ‘corrections’ to the Bayesian or maximum entropy methods, thusgrotesquely mutilating them and getting a worse inference by a bigger computation. Tothose accustomed to orthodox difﬁculties, the power and simplicity of the Bayesian methodin this application seems unbelievable; and one must think long and hard to understand howit is possible.
As a more general comment, there is a simple strategy that will serve in almost all of
these Bayes/orthodox comparisons: ‘magniﬁcation’, as demonstrated for the chi-squaredtest in Chapter 9. When we ﬁnd a quantitative difference in the orthodox and Bayesianconclusions, it may appear at ﬁrst glance so small that our common sense is unable to judgethe issue. But then we can usually ﬁnd some extreme problem in which the small differenceis magniﬁed into a large one, or preferably to a qualitative difference in the conclusions. Ourcommon sense will then tell us very clearly which procedure is giving reasonable results,and which one is not. Indeed, it is often possible to magnify to the point where one procedureis yielding an obvious violation of deductive reasoning or pathology like that noted abovefor an unbiased estimate. Now we examine another very important example where we can
compare orthodox and Bayesian results by magniﬁcation.
17.10 Trend and seasonality in time series
The observed time series generated by the real world seldom appear to be ‘stationary’ but
exhibit more complicated behavior. In most series, particularly demographic or economicdata, trend is the most common form of nonstationarity. Many economic time series are sodominated by trend (due, for example, to steadily rising population, inﬂation, or techno-logical advances) that any attempt to study other regularities, such as cyclical ﬂuctuationsor settling back after response to a shock – and, particularly, correlations between different

<<<PAGE 567>>>

17 Principles and pathology of orthodox statistics 535
time series – can be more misleading than helpful until we have a safe way of dealing with
trend.
The story is told – perhaps apocryphal – of a researcher who announced the discovery of
a strong positive correlation between membership in the Church of England and incidenceof suicide in England, and concluded that it would be safer to keep away from the Church.The true explanation was, of course, that the population of England was growing steadily,so membership in the Church, incidence of suicides – and almost any other demographicvariable – were all growing together. False correlations of this type have led many tononsensical conclusions because of the almost universal tendency to jump to the conclusionthat correlation implies causation.
The problem of contaminated data has been with us from the very beginning. We noted
in Chapter 9 how Edmund Halley (1693) was obliged to deal with it in compiling the ﬁrsttables of mortality. The real key to dealing with it is recognition of the useful functionalrole of nuisance parameters in probability theory.
Likewise, today many time series are so dominated by cyclic ﬂuctuations (seasonal effects
in economic data, periodicity in weather, hum in electrical circuits, synchronized growthin bacteriology, vibrations in helicopter blades) that the attempt to extract an underlying‘signal’, such as a long-term trend from a short run of data, is frustrated. We want to contrasthow orthodox statistics and probability theory as logic deal with the problem of extractingthe information one wants, in spite of such data contaminations.
17.10.1 Orthodox methods
The traditional procedures do not apply probability theory to this problem; instead, one
resorts to inventing the same kind of intuitive ad hoc devices that we have noted so often
before. The usual ones are called ‘detrending’ and ‘seasonal adjustment’ in the economicliterature, ‘ﬁltering’ in the electrical engineering literature. Like all such ad hockeries not
derived from ﬁrst principles, they capture enough of the truth to be usable in some problems;but they can generate disaster in others.
The almost universal detrending procedure in economics is to suppose the data (or the
logarithm of the data) to be y(t)=x(t)+Bt+e(t), composed additively of the component
of interest x(t), a linear ‘trend’ Bt, and a ‘random error’ or ‘noise’ e(t). We estimate the
trend component, subtract it from the data, and proceed to analyze the resulting ‘detrendeddata’ for other effects. However, many writers have noted that detrending may introduce
spurious artifacts that distort the evidence for other effects. Detrending may even destroy
the relevance of the data for our purposes, and we saw in the scenario of the weather inCentral Park that ﬁltering of data can also do this.
Similarly, the traditional way of dealing with seasonal effects is to produce ‘seasonally
adjusted’ data, in which one subtracts an estimate of the seasonal component from the truedata, then tries to analyze the adjusted data for other effects. Indeed, most of the economictime series data one can obtain have been rendered nearly useless because they have beenseasonally adjusted in an irreversible way that has destroyed information which probability

<<<PAGE 568>>>

536 Part 2 Advanced applications
theory could have extracted from the raw data. We think it imperative that this be recognized,
and that researchers be able to obtain the true data – free of detrending, seasonal adjustment,pre-ﬁltering, smoothing, or any other destructive mutilation of the information in the data.
Electrical engineers would think instead in terms of Fourier analysis and resort to ‘high-
pass ﬁlters’ and ‘band-rejection ﬁlters’ to deal with trend and seasonality. Again, the phi-losophy is to produce a new time series (the output of the ﬁlter) which represents in somesense an estimate of what the real series would be if the contaminating effect were absent.Then choice of the ‘best’ physically realizable ﬁlter is a difﬁcult and basically indeterminateproblem; fortunately, intuition has been able to invent ﬁlters good enough to be usable ifone knows in advance what kind of contamination will occur.
17.10.2 The Bayesian method
The direct application of probability theory as logic leads us to an entirely different philos-
ophy; always, the correct procedure is to calculate the probability of whatever is unknownand of interest, conditional on whatever is known. This means that we do not seek to removethe trend or seasonal component from the data: that is fundamentally impossible becausethere is no way to know the ‘true’ trend or seasonal term. Any assumption about them isnecessarily in some degree arbitrary, and is therefore almost certain to inject false informa-tion into the detrended or seasonally adjusted series. Rather, we seek to remove the effectof trend or seasonality from our ﬁnal conclusions , taking into account all the relevant infor-
mation we have, while leaving the actual data intact. We develop the Bayesian procedurefor this and compare it in detail with the conventional one.
Firstly, we analyze the simplest possible nontrivial model, which can be solv ed completely
from either point of view and will enable us to understand the exact relationship between
the two procedures. Having this understanding, the extension to the most complicatedmultivariate case will be an easy mathematical generalization – essentially, just promotionof numbers to matrices while retaining the same formal equations.
Suppose the model consists of only a single sinusoid and a linear trend: y(t)=Asinωt+
Bt+e(t), where Ais the amplitude of interest to be estimated and Bis the unknown trend
rate. If the data are monthly economic data and the sinusoid represents a yearly seasonaleffect, then ωwill be 2 π/12=0.524 months
−1. But, for example, if we are trying to
detect a cycle with a period of 20 years, ωwill be 0 .524/20=0.00262. Estimation of an
unknown ωfrom such data is the very important problem of spectrum analysis, considered
in the scenario of the weather in Central Park. But for the present we consider the casewhere ωis known (usually, because we know that the seasonality has a period of one year
for unchanging astronomical reasons). Writing for brevity s
t=s(t)≡sin(ωt), our model
equation is then
y(t)=As(t)+Bt+e(t), (17.83)
and the available data y≡(y1,..., yN) are values of this at Nequally spaced times t=
1,2,..., N. Assigning – for reasons already explained sufﬁciently – the noise components

<<<PAGE 569>>>

17 Principles and pathology of orthodox statistics 537
eian independent Gaussian prior probability density function et∼N(0,σ) with variance
σ2, the sampling pdf for the data is
p(y|ABσ)=/parenleftbigg1
2πσ2/parenrightbiggN/2
exp/braceleftbigg
−N
2σ2Q(A,B)/bracerightbigg
, (17.84)
and, as in any Gaussian calculation, the ﬁrst task is to rearrange the quadratic form
Q(A,B)≡1
N/summationdisplay
t(yt−Ast−Bt)2=y2+A2s2+B2t2−2Asy−2Bty+2ABst,
(17.85)
where
y2≡1
NN/summationdisplay
t=1y2
t, sy≡1
NN/summationdisplay
t=1styt, (17.86)
etc. denote averages over the data sample. Three of these averages, ( s2,t2,st) are determined
by the ‘design of the experiment’ and can be known before one has the data. In fact, wehave nearly
s2/similarequal1/2, t2/similarequalN2/3 (17.87)
with errors of relative order O(1/N). But stis highly variable; it is certainly less than N/2,
since that could be achieved only if s(t)=1 at every sampling point. Generally, stis much
less than this, of the order st/similarequal1/ωdue to near cancellation of positive and negative terms.
The other three averages ( y2,sy,ty) depend on the data, and, since they are the only
terms containing the data, they are the jointly sufﬁcient statistics for our problem, to becalculated as soon as one has the data.
Suppose that it is the seasonal amplitude Athat we wish to estimate, while the trend
rate Bis the nuisance parameter that contaminates our data. We want to make its effects
disappear, as far as is possible. We shall do this by ﬁnding the joint posterior distributionforAandB,
p(AB|DI), (17.88)
and integrating out Bto get the marginal posterior distribution for A,
p(A|DI)=/integraldisplay
dBp(AB|DI). (17.89)
This is the quantity that tells us everything the data Dand prior information Ihave to say
about A, whatever the value of B; this would be called ‘Bayesian detrending’. Conversely, if
we wanted to estimate B, then Awould be the nuisance parameter, and we would integrate
it out of (17.88) to get the marginal posterior distribution p(B|DI); and this would be called
‘Bayesian seasonal adjustment’.

<<<PAGE 570>>>

538 Part 2 Advanced applications
In the limit of diffuse priors for AandB(i.e. their prior densities do not vary appreciably
over the region of high likelihood), the appropriate integration formula for (17.89) is
/integraldisplay∞
−∞dBexp/braceleftbigg
−NQ(A,B)
2σ2/bracerightbigg
=(const.)×exp

−N
2σ2
/parenleftBig
s2/parenrightBig/parenleftBig
t2/parenrightBig
−/parenleftbig
st/parenrightbig2
t2
/parenleftbig
A−ˆA/parenrightbig2

,(17.90)
where
ˆA≡/parenleftBig
t2/parenrightBig
(sy)−/parenleftbig
st/parenrightbig/parenleftbig
ty/parenrightbig
/parenleftBig
s2/parenrightBig/parenleftBig
t2/parenrightBig
−/parenleftbig
st/parenrightbig2(17.91)
and the (const.) is independent ofA. Thus the marginal posterior distrib ution for Ais
proportional to (17.90), and the Bayesian posterior (mean) ±(standard deviation) estimate
ofA, regardless of the value of B,i s
(A)est=ˆA±σ/radicaltp/radicalvertex/radicalvertex/radicalvertex/radicalbt t2
N/bracketleftBig/parenleftBig
s2/parenrightBig/parenleftBig
t2/parenrightBig
−/parenleftbig
st/parenrightbig2/bracketrightBig=ˆA±σ/radicalBig
Ns2(1−r2), (17.92)
where
r≡st/radicalbig
s2t2(17.93)
is the correlation coefﬁcient of sandt.
Some orthodox writers have railed against this process of integrating out nuisance
parameters – in spite of the fact that it is uniquely determined by the rules of probabil-ity theory as the correct procedure – on the usual grounds that the probability of a parameteris meaningless because a parameter is not a ‘random variable’. Even worse, in the inte-gration we introduced a prior that they consider arbitrary (although for us it represents ourreal state of prior information which is clearly relevant to the inference, but is ignored byorthodoxy). But, independently of all such philosophical hangups, we can examine the factsof actual performance of the Bayesian and orthodox procedures.
The integration of a nuisance parameter may be related to the detrending procedure as
follows. The joint posterior pdf may be factored into marginal and conditional pdfs in twodifferent ways:
p(AB|DI)=p(A|DI)p(B|ADI ), (17.94)
or, equally well,
p(AB|DI)=p(A|BDI )p(B|DI). (17.95)

<<<PAGE 571>>>

17 Principles and pathology of orthodox statistics 539
From (17.94) we see that (17.89) follows at once, and from (17.95) we see that (17.89) can
be written as
p(A|DI)=/integraldisplay
dBp(A|BDI )p(B|DI). (17.96)
Thus the marginal pdf for Ais a weighted average of the conditional pdfs that we would
have if Bwere known:
p(A|BDI ). (17.97)
But if Bis known, then (17.97), in its dependence on A, is just (17.84) with Bheld ﬁxed.
This is, from (17.85),
p(A|BDI )∝exp/braceleftBigg
−Ns2
2σ2(A−A∗)2/bracerightBigg
, (17.98)
where
A∗≡sy−Bst
s2. (17.99)
This is just the estimate that one would make by ordinary least squares ﬁtting of As(t)t o
the detrended data y(t)det≡y(t)−Bt
A∗=(sy)det/parenleftBig
s2/parenrightBig. (17.100)
That is, A∗is the estimate the orthodoxian would make if he estimated the trend rate to be
B. Of course, if his estimate of Bwere exactly correct, then he would indeed ﬁnd the best
estimate possible; but any error in his estimate of the trend rate will bias his estimate of A.
The Bayesian estimate of Aobtained from (17.96) does not assume any particular trend
rate B; it is a weighted average over all possible values that the trend rate might have,
weighted according to their respective posterior probabilities. Thus, if the trend rate is verywell determined by the data, so that the probability p(B|DI) in (17.96) has a single very
sharp peak at B=B
∗, then the Bayesian and orthodoxian will be in essential agreement
on the estimate of Aif the orthodoxian also happens to estimate BasB∗. If the trend rate
is not well determined by the data, then the Bayes estimate is a more conservative one thattakes into account all possible values that Bmight have, while the orthodox estimate can
vary widely.
Although an orthodoxian might accept what we have done as mathematically consistent,
this argument would not convince him of the superiority of the Bayesian estimate (implicitlybased, as usual, on a quadratic loss function), because he judges estimates by a differentcriterion. So let us compare them more closely.

<<<PAGE 572>>>

540 Part 2 Advanced applications
17.10.3 Comparison of Bayesian and orthodox estimates
Having found a Bayesian estimator, which theorems demonstrate to be optimal by the
Bayesian criterion of performance, nothing prevents us from examining its performancefrom the orthodox sampling theory viewpoint and comparing it with orthodox estimates.We introduce a useful method of doing this, which makes it clear what the two methodsare doing. Let A
0andB0be the unknown true values of the parameters, and let us describe
the situation as it would appear to one who already knew A0andB0, but not what data we
shall ﬁnd. As he would know, but we would not, our data vector will in fact be
yt=A0st+B0t+et, (17.101)
and we shall calculate the statistic
sy=A0s2+B0st+se (17.102)
in which the ﬁrst two terms are ﬁxed (i.e. independent of the noise) and only the last varies
with different noise samples. Similarly, he knows that we shall ﬁnd the statistic
ty=A0st+B0t2+te. (17.103)
Although syandtyare known to us from the data, we cannot solve (17.102) and (17.103)
for (A0,B0) because seandteare unknown. We are obliged to continue using probability
theory to get the best possible estimates of A0,B0. Substituting (17.102) and (17.103) into
(17.91), we ﬁnd that the Bayes estimate that we shall get reduces to
(ˆA)Bayes=A0+/parenleftBig
t2/parenrightBig
(se)−/parenleftbig
st/parenrightbig/parenleftbig
te/parenrightbig
/parenleftBig
s2/parenrightBig/parenleftBig
t2/parenrightBig
−/parenleftbig
st/parenrightbig2, (17.104)
which is independent of the true trend rate, B0having cancelled out. Therefore the Bayesian
estimate does indeed eliminate the effect of trend entirely from our conclusions; one couldhardly do so more completely than that. But the unknown error vector emust, necessarily,
produce some error in our estimate of A, and (17.104) tells us exactly how much.
On the other hand, if the orthodoxian uses the conventional ordinary least squares es-
timator (17.100) from detrended data [ y
t−ˆBt] based on any estimate ˆB, he will ﬁnd
instead
(ˆA)orthodox=A0+se+(B0−ˆB)st
s2, (17.105)
and any error in the trend rate estimate ˆBcontributes to the error in his estimate of the
seasonal component. If, as is the usual practice, one uses the ordinary least squares estimate

<<<PAGE 573>>>

17 Principles and pathology of orthodox statistics 541
of the trend from the original data,
ˆB=/parenleftbig
ty/parenrightbig
/parenleftBig
t2/parenrightBig, (17.106)
(17.105) becomes
(ˆA)orthodox=A0+/parenleftBig
t2/parenrightBig
(se)−/parenleftbig
ty/parenrightbig/parenleftbig
st/parenrightbig
+B0/parenleftBig
t2/parenrightBig/parenleftbig
st/parenrightbig
/parenleftBig
t2/parenrightBig/parenleftBig
s2/parenrightBig=(1−r2)A0+(se)/parenleftBig
s2/parenrightBig,
(17.107)
where we have again used (17.102) and (17.103). Thus (17.107) is also exactly independent
of the true trend rate B0. But orthodox teaching would hold that the estimator (17.107) has
a negative bias, since seis, ‘on the average’, zero. One might wish to ‘correct’ for this by
thesame device as in (17.6): by multiplying by a suitable factor. But this is not obviously
the best procedure. It is far from clear that the optimal estimator can be found merely bymultiplying the ordinary least squares estimate by a constant.
Likewise, having recognized what he would consider a shortcoming of (17.107), and
perceiving that the Bayesian result (17.104) has at least the merit (from his viewpoint) of
being unbiased, it still would not follow that the Bayesian solution is the best possible one.Indeed, one who has absorbed a strong anti-Bayesian indoctrination would, we suspect,
reject any such suggestion and would say that we should be able to correct the defects of
(17.107) by a little more careful thinking about the problem from the orthodox viewpoint.Let us try.
17.10.4 An improved orthodox estimate
Starting back at the beginning of the problem, orthodox reasoning proceeded as follows. If
one had in mind only the seasonal term and was not aware of trend, one would be led toestimate the cyclic amplitude as
ˆA
(0)=(sy)/parenleftBig
s2/parenrightBig, (17.108)
the conventional regression solution. Many different lines of reasoning, including ordinary
least squares ﬁtting of the data to the sinusoid Ast, lead us to this result.
But then one realizes that (17.108) is not a very good estimate because it ignores the
disturbing effect of trend. A better seasonal estimate could be made from the detrendeddata
(y
t)det≡yt−ˆBt, (17.109)

<<<PAGE 574>>>

542 Part 2 Advanced applications
where ˆBis an estimate of the trend rate, and it seems natural to estimate it by the conventional
regression rule
ˆB(0)=/parenleftbig
ty/parenrightbig
/parenleftBig
t2/parenrightBig (17.110)
from ordinary least squares ﬁtting of a straight line Btto the data. Using the detrended data
(17.109) in (17.108) yields the ‘corrected’ cyclic amplitude estimate
ˆA(1)=sy−stˆB(0)
s2=/parenleftBig
t2/parenrightBig
(sy)−/parenleftbig
st/parenrightbig/parenleftbig
ty/parenrightbig
/parenleftBig
t2/parenrightBig/parenleftBig
s2/parenrightBig (17.111)
which is the conventional orthodox result for the problem.
But now we see that this is not the end of the story; for AandBenter into the model
on just the same footing. If it is true that we should estimate the cyclic amplitude Afrom
detrended data yt−ˆB(0)t, surely it is equally true that we should estimate the trend rate B
from the decyclized data yt−ˆA(0)st. Thus a better estimate of trend than (17.110) would be
ˆB(1)=/parenleftbig
ty/parenrightbig
−/parenleftbig
st/parenrightbigˆA(0)
/parenleftBig
t2/parenrightBig=/parenleftBig
s2/parenrightBig/parenleftbig
ty/parenrightbig
−/parenleftbig
st/parenrightbig
(sy)
/parenleftBig
t2/parenrightBig/parenleftBig
s2/parenrightBig , (17.112)
where we used (17.108). But now, with this better estimate of trend, we can obtain a better
estimate of the seasonal component than (17.111) by using (17.112):
ˆA(2)=(sy)−/parenleftbig
st/parenrightbigˆB(1)
/parenleftBig
s2/parenrightBig . (17.113)
This improved estimate of the seasonal amplitude will in turn enable us to achieve a still
better estimate of trend
ˆB(2)=/parenleftbig
ty/parenrightbig
−/parenleftbig
st/parenrightbigˆA(1)
/parenleftBig
t2/parenrightBig (17.114)
...and so on, forever!
Therefore, the reasoning underlying the conventional detrending procedure, if applied
consistently, does not stop at the conventional result (17.100). It leads us into an inﬁnite
sequence of back-and-forth revisions of our estimates, each set [ ˆA(n),ˆB(n)] better than the
previous [ ˆA(n−1),ˆB(n−1)]. Does this inﬁnite sequence converge to a ﬁnal ‘best of all’ set
of estimates [ ˆA(∞)ˆB(∞)]? If so, this is surely the optimal way of dealing with a nuisance
parameter from the orthodox viewpoint. But can we calculate these ﬁnal optimal estimatesdirectly without going through the inﬁnite sequence of updatings?

<<<PAGE 575>>>

17 Principles and pathology of orthodox statistics 543
To answer this deﬁne the (2 ×1) vector of nth order estimates:
Vn≡/parenleftbiggˆA(n)
ˆB(n)/parenrightbigg
. (17.115)
Then the general recursion relation is, as we see from (17.111)–(17.113),
Vn+1=V0+MV n, (17.116)
where the matrix Mis
M=
0−/parenleftbig
st/parenrightbig
/parenleftBig
s2/parenrightBig
/parenleftbig
st/parenrightbig
/parenleftBig
t2/parenrightBig 0
. (17.117)
The solution of (17.116) is
V
n=(1+M+M2+···+ Mn)V0. (17.118)
By the Schwartz inequality,/parenleftbig
st/parenrightbig2≤/parenleftBig
s2/parenrightBig/parenleftBig
t2/parenrightBig
, the eigenvalues of Mare less than unity, so
asn→∞ this inﬁnite series sums to
V∞=(I−M)−1V0. (17.119)
Now we ﬁnd readily that
(I−M)−1=1/parenleftBig
s2/parenrightBig/parenleftBig
t2/parenrightBig
−/parenleftbig
st/parenrightbig2
/parenleftBig
t2/parenrightBig/parenleftBig
s2/parenrightBig
−/parenleftBig
t2/parenrightBig/parenleftbig
st/parenrightbig
−/parenleftBig
s2/parenrightBig/parenleftbig
st/parenrightbig/parenleftBig
t2/parenrightBig/parenleftBig
s2/parenrightBig
, (17.120)
and so our ﬁnal, best of all, estimate is
ˆA(∞)=/parenleftBig
t2/parenrightBig/parenleftBig
s2/parenrightBig
ˆA(0)−/parenleftBig
t2/parenrightBig/parenleftbig
st/parenrightbigˆB(0)
/parenleftBig
s2/parenrightBig/parenleftBig
t2/parenrightBig
−/parenleftbig
st/parenrightbig2=/parenleftBig
t2/parenrightBig
(sy)−/parenleftbig
st/parenrightbig/parenleftbig
ty/parenrightbig
/parenleftBig
s2/parenrightBig/parenleftBig
t2/parenrightBig
−/parenleftbig
st/parenrightbig2. (17.121)
But this is precisely the Bayesian estimate that we calculated far more easily in (17.92)!
Likewise, the ﬁnal best possible orthodox estimate of trend rate is
ˆB(∞)=/parenleftBig
s2/parenrightBig/parenleftbig
ty/parenrightbig
−/parenleftbig
ty/parenrightbig
(sy)
/parenleftBig
s2/parenrightBig/parenleftBig
t2/parenrightBig
−/parenleftbig
st/parenrightbig2, (17.122)
which is just the Bayesian estimate that we ﬁnd by integrating out Aas a nuisance parameter
from (17.88).
This is another example of what we found in Chapter 13: if the orthodoxian will think
his estimation problems through to the end, he will ﬁnd himself obliged to use the Bayesianmathematical algorithm, even if his ideology still leads him to reject the Bayesian rationale

<<<PAGE 576>>>

544 Part 2 Advanced applications
for it. Independently of all philosophical hangups, this mathematical form is determined by
elementary requirements of rationality and consistency.
Now we see the relationship between the orthodox and Bayesian procedures in an entirely
different light. The Bayesian procedure of integrating out a nuisance parameter is summingan inﬁnite series of mutual updatings for us, and in such a slick way that, to the best of ourknowledge, no orthodox writer has yet realized that this is what is happening. What we havejust found is not limited to trend and seasonal parameters: it will generalize effortlessly tofar more complex problems.
As we noted before (Jaynes, 1976) in many other cases, it is a common phenomenon that
orthodox results, when improved to the maximum possible extent, become mathematicallyequivalent to the results that Bayesian methods give us far more easily. Indeed, it is oneof the problems we have that Bayesian and maximum entropy methods are so easy thatorthodoxians accuse us of trying to get something for nothing.
Thus, in the long run, attempts to evade the use of Bayes’ theorem do not lead to different
ﬁnal results; they only make us work an order of magnitude harder to get them.
17.10.5 The orthodox criterion of performance
In our endeavor to understand this situation fully, let us examine it from a different viewpoint.
According to orthodox theory, the accuracy of an estimation procedure is to be judged by
the sampling distribution of the estimator, while in Bayesian theory it should be judgedfrom the posterior pdf for the parameter. Let us compare these. For the orthodox analysis,note that in both (17.104) and (17.107) the terms containing the noise vector ecombine to
make a linear combination of the form
ge≡1
NN/summationdisplay
t=1gtet. (17.123)
Then over the sampling pdf for the noise we have
E(ge)=1
N/summationdisplay
tgtE(et)=0 (17.124)
E[(ge)2]=1
N/summationdisplay
gtgt/primeE(etet/prime)=g2σ2, (17.125)
since E(etet/prime)=σ2δ(t,t/prime). Thus, the sampling pdf would estimate this error term by
(mean)±(standard deviation):
(ge)est=0±σ/radicalBig
g2. (17.126)
For the Bayes estimator (17.104)
gt=/parenleftBig
t2/parenrightBig
(st)−/parenleftbig
st/parenrightbig
t
/parenleftBig
t2/parenrightBig/parenleftBig
s2/parenrightBig
−/parenleftbig
st/parenrightbig2, (17.127)

<<<PAGE 577>>>

17 Principles and pathology of orthodox statistics 545
and after some algebra we ﬁnd
g2=/parenleftBig
t2/parenrightBig/bracketleftBig/parenleftBig
s2/parenrightBig/parenleftBig
t2/parenrightBig
−/parenleftbig
st/parenrightbig2/bracketrightBig
/parenleftBig
s2/parenrightBig/parenleftbig
1−r2/parenrightbig , (17.128)
where ris the correlation coefﬁcient deﬁned before. Thus the sampling distribution for the
Bayes estimator (17.104) has (mean) ±(standard deviation) of
˜A±σ/radicalBig
ˆNs2(1−r2), (17.129)
while for the orthodox estimator this is
(1−r2)˜A±σ/radicaltp/radicalvertex/radicalvertex/radicalbt1−r2
N/parenleftBig
s2/parenrightBig. (17.130)
17.11 The general case
Having shown the nature of the Bayesian results from several different viewpoints, we now
generalize them to a fairly wide class of useful problems. We assume that the Ndata are
not necessarily uniformly spaced in time, but are taken at times in some set {t:t1,..., tN}
that the noise probability distribution, although Gaussian, is not necessarily stationary orwhite (uncorrelated) and that the prior probabilities for the parameters are not necessarilyindependent. It turns out that the computer programs to take all this into account are not
appreciably more difﬁcult to write, if the most general analytical formulas are in view when
we write them.
So now we have the model
y
ti=T(ti)+F(ti)+e(ti),1≤i≤N, (17.131)
in which we may write yi≡y(ti), etc., with data D=(y1,..., yN), where T(t) is the trend
function, not necessarily linear, F(t) is the periodic seasonal function, not necessarily sinu-
soidal, and e(t) is the irregular component. To deﬁne our matrices we suppose T(t) expanded
in some linearly independent basis functions /Phi1k(t) (for example, Legendre polynomials):
T(t)=/summationdisplay
γk/Phi1k(t). (17.132)
Similarly, F(t) is expanded in sinusoids:
F(t)=/summationdisplay
[Akcos(kt)+Bksin(kt)]. (17.133)
The joint likelihood of all the parameters is
L(γ,A,B,σ)=p(D|γABσ)=/parenleftbigg1
2πσ2/parenrightbiggN/2
exp/braceleftBigg
1
2σ2N/summationdisplay
i=1[yi−T(ti)−F(ti)]2/bracerightBigg
.
(17.134)

<<<PAGE 578>>>

546 Part 2 Advanced applications
The quadratic form may be written as
Q(αk,γj)≡N/summationdisplay
i=1/bracketleftBigg
yi−r/summationdisplay
j=1γjTj(ti)−m/summationdisplay
k=1αkFk(ti)/bracketrightBigg2
, (17.135)
where, in the seasonal adjustment problem, m=12 and
{α1,...,α m}={A0,A1,..., A6,B1,B2,..., B5}. (17.136)
Likewise,
Fk(t)=/braceleftbiggcos(kωt)0≤k≤6
sin([k−6]ωt)7≤k≤12.(17.137)
But if we combine α,γinto a single vector of dimension n=m+r:
q≡(α1,...,α m,γ1,...,γ r) (17.138)
and deﬁne the function
Gk(t)=/braceleftbiggFk(t)1≤k≤m
Tk(t)m+1≤k≤n,(17.139)
then the model is in the more compact form
y(t)=n/summationdisplay
j=1qjGj(t)+e(t), (17.140)
and the data vector is
yi=n/summationdisplay
j=1qjGj(ti)+e(ti),1≤i≤N (17.141)
or
y=qG+e. (17.142)
The ‘noise’ values e=e(ti) have the joint prior probability density
p(e1···eN)=√
detK
(2π)N/2exp/braceleftbigg
−1
2eTKe/bracerightbigg
, (17.143)
where K−1is the ( N×N) noise prior covariance matrix. For ‘stationary white noise’, it
reduces to
K−1=σ2δij, 1≤i,j≤N. (17.144)
Given Kand the parameters/braceleftbig
qj/bracerightbig
, the sampling pdf for the data takes the form
p(y1···yN|qKI )=√det(K)
(2π)N/2exp/braceleftbigg
−1
2(y−qG)TK(y−qG)/bracerightbigg
. (17.145)

<<<PAGE 579>>>

17 Principles and pathology of orthodox statistics 547
Likewise, a very general form of joint prior pdf for the parameters is
p(q1···qn|I)=√det(L)
(2π)n/2exp/braceleftbigg
−1
2(q−q0)TL(q−q0)/bracerightbigg
, (17.146)
where L−1is the ( n×n) prior covariance matrix and q0is the vector of prior estimates.
Almost always we shall take Lto be diagonal:
Lij=σ2
jδij, 1≤i,j≤n, (17.147)
andq0to be zero. But the general formulas without these simplifying assumptions are
readily found and programmed.
The joint posterior pdf for the parameters/braceleftbig
qj/bracerightbig
is then
p(q|yI)=exp{−Q/2}/integraltext
dq1···dqnexp{−Q/2}, (17.148)
where Qis the quadratic form
Q≡(y−Gq)TK(y−Gq)+(q−q0)TL(q−q0), (17.149)
which we may expand into eight terms:
Q=yTKy−yTKGq−qTGTKy+qTGTKGq+qTLq−qTLq0−qT
0Lq+qT
0Lq0.
(17.150)
We want to bring out the dependence on qby writing this in the form
Q=(q−ˆq)TM(q−ˆq)+Q0, (17.151)
where Q0is independent of q. Writing this out and comparing with (17.150), we have
M=GTKG+L,
Mˆq=GTKy+Lq0,
ˆqTMˆq+Q0=yTKy+qT
0Lq0.(17.152)
Thus M,ˆq, and Q0are uniquely determined, because the equality of (17.150) and (17.151)
must be an identity in q:
ˆq=M−1/bracketleftbig
GTKy+Lq0/bracketrightbig
(17.153)
Q0=yTKy+qT
0Lq0−ˆqTMˆq. (17.154)
The denominator of (17.148) is then found using (17.151), with the ﬁnal result
p(q1···qn|yKLI )=√det(M)
(2π)n/2exp/braceleftbigg
−1
2(q−ˆq)TM(q−ˆq)/bracerightbigg
. (17.155)
The components q1,..., qmare the seasonal amplitudes we wish to estimate, while
(qm+1,..., qn) are the trend nuisance parameters to be eliminated. From (17.155) the

<<<PAGE 580>>>

548 Part 2 Advanced applications
marginal pdf we want is
p(q1···qm|yKLI )=/integraldisplay
dqm+1···dqnp(q1···qn|yKLI )
=√det(M)
(2π)n/2(2π)(n−m)/2
/radicalbig
det(W)exp/braceleftbigg
−1
2(u−ˆu)TU(u−ˆu)/bracerightbigg
=√det(U)
(2π)m/2exp/braceleftbigg
−1
2(u−ˆu)TU(u−ˆu)/bracerightbigg(17.156)
where U,V,W,uare deﬁned by ( ), ( ), ( ), ( ).
Editor’s Exercise 17.4. Jaynes never deﬁned U,V,W,andu. In (17.155) multiply
out all of the terms in the exponent, obtain the appropriate sub-matrices, vectors, andscalars and then deﬁne each of these four quantities.
From the fact that the various probabilities are normalized, we see that
det(M)=det(W) det( U), (17.157)
a remarkable theorem not at all obvious from the deﬁnitions except in the case V=0. This is
another good example of the power of probabilistic reasoning to prove purely mathematicaltheorems.
Thus, the most general solution consists, computationally, of a string of elementary matrix
operations and is readily programmed. To summarize the ﬁnal computation rules:
K−1is the ( N×N) prior covariance matrix for the ‘noise’;
L−1is the ( n×n) prior covariance matrix for the parameters;
Fis the ( N×n) matrix of model functions.
Firstly, calculate the ( n×n) matrix
M≡FTKF+L (17.158)
and decompose it into block form representing the interesting and uninteresting subspaces:
M=/parenleftbiggU0V
VTW0/parenrightbigg
. (17.159)
Then calculate the ( m×m) and ( r×r) renormalized matrices
U≡U0−VW−1
0VT(17.160)
W≡W0−VTU−1
0V. (17.161)
This much is determined by the deﬁnition of the model; the computer can work all this out
in advance, before the data are known, and use the result on any number of data sets.
Now given y, the ( N×1) data vector and q0, the ( n×1) vector of prior estimates, the
computer should calculate the ( n×1) vector

<<<PAGE 581>>>

17 Principles and pathology of orthodox statistics 549
ˆq=M−1/bracketleftbig
FTKy+Lq0/bracketrightbig
(17.162)
of ‘best’ estimates of the parameters. Actually, the ﬁrst mof them are the interesting ones
wanted, and the remaining r=n−mcomponents are not needed unless one also wants an
estimate of the trend function. Then we can use the following result.
The inverse M−1can be written in the same block form as M:
M−1=/parenleftbiggU−1−U0VW−1
−W0VTU−1W−1/parenrightbigg
, (17.163)
where, analogous to U,
W≡W0−VTU−1
0V. (17.164)
Then FThas the same block form with respect to its rows:
(FT)ji=/bracketleftbig
Gj(ti)Ti(ti)/bracketrightbig1≤j≤m
1≤i≤N
(m+1)≤K≤n,(17.165)
where Gj(t) are the seasonal sinusoids and Tk(t) the trend functions.
Almost always, q0=0, and so the ‘interesting’ seasonal amplitudes are given by
ˆq=RKy, (17.166)
where Ris the reduced ( m×N) matrix
R≡U−1G−U−1
0VW−1T (17.167)
andU−1is the joint posterior covariance matrix for the interesting parameters {q1,..., qm}.
Note that RandU−1are also determined by the model, so the computer can calculate them
once and for all before the data are available.
Editor’s Exercise 17.5. Jaynes never ﬁnished this section, so we can only speculate
as to what he would have put in here. So let’s speculate. Firstly, look at (17.156): thisis the joint posterior probability for all of the seasonal amplitudes, but the amplitudesare not the same thing as the seasonal component itself. The seasonal component isgiven by
S(t)=
m/summationdisplay
k=1qkGk(t) (17.168)
and is a continuous function of time. Can (17.156) and (17.168) be used to compute
p(S(t)|yKLI ), the joint posterior probability for the seasonal? In other words, can a
simple change of variables plus marginalization over the remaining q’s be used to com-
pute p(S(t))|yKLI )? If not, how would you compute this joint posterior probability?

<<<PAGE 582>>>

550 Part 2 Advanced applications
17.12 Comments
Let us try to summarize and understand the underlying technical reasons for the facts noted
in the preceding two chapters. Sampling theory methods of inference were satisfactory forthe relatively simple problems considered by R. A. Fisher in the 1930s. These problemshad the features of:
(a) few parameters;
(b) presence of sufﬁcient statistics;
(c) no important prior information;
(d) no nuisance parameters.
When all these conditions are met, and we have a reasonably large amount of data (say, n≥
30), orthodox methods become essentially equivalent to the Bayesian ones, and it will makeno pragmatic difference which ideology we prefer. But today we are faced with importantproblems in which some or all of these conditions are violated. Only Bayesian methods havethe analytical apparatus capable of dealing with such problems without sacriﬁcing much ofthe relevant information available to us. Bayesian methods are more powerful; if there is nosufﬁcient statistic, they extract more information from the data for reasons explained at thebeginning of this chapter. Also, they take note of possibly highly important prior information,and deal easily with nuisance parameters, turning them into an important asset.
Today one wonders how it is possible that orthodox logic continues to be taught in
some places year after year and praised as ‘objective’, while Bayesians are charged with‘subjectivity’. Orthodoxians, preoccupied with fantasies about nonexistent data sets and, inprinciple, unobservable limiting frequencies – while ignoring relevant prior information –are in no position to charge anybody with ‘subjectivity’. If there is no sufﬁcient statistic,the orthodox accuracy claim based on a single ‘statistic’ simply ignores not only the priorinformation, but also all the evidence in the data that is relevant to that accuracy: hardlyan ‘objective’ procedure. If there are ancillary statistics and the orthodoxian follows Fisherby conditioning on them, he obtains just the estimate that Bayes’ theorem based on anoninformative prior would have given him by a shorter calculation. Bayes’ theorem wouldhave given also a defensible accuracy claim.
We shall illustrate this in later chapters with several examples, including interval estima-
tion, dealing with trend, linear regression, detection of cycles, and prediction of time series.In all these cases, ‘orthodox’ methods can miss important evidence in the data; but theycan also yield conclusions not justiﬁed by the evidence because they ignore highly cogentprior information. No case of such failure of Bayesian methods has been found; indeed, theoptimality theorems well known in the Bayesian literature lead one to expect this from the
start. Psychologically, however, practical examples seem to have more convincing powerthan do optimality theorems.
Historically, scientiﬁc inference has been dominated overwhelmingly by the case of
univariate or bivariate Gaussian sampling distributions. This has produced a distorted pictureof the ﬁeld: the Gaussian case is the one in which ‘orthodox’, or ‘sampling theory’ methods
do best, and the difference between pre-data and post-data procedures is the least. On the

<<<PAGE 583>>>

17 Principles and pathology of orthodox statistics 551
basis of this limited evidence, orthodox theory (in the hands of Fisher) tried to claim general
validity for its methods, and attacked Bayesian methods savagely without ever examiningthe results they give.
Even in the Gaussian case, there are important problems where sampling theory methods
fail for technical reasons. An example is linear regression with both variables subject to errorof unknown variance; indeed, this is perhaps the most common problem of inference facedby experimental scientists. Yet sampling theory is helpless to deal with it, because each newdata point brings with it a new nuisance parameter. The orthodox statistical literature offersus no satisfactory way of dealing with this problem. See, for example, Kempthorne andFolks (1971), in which the (for them) necessity of deciding which quantities are ‘random’and which are not, leads the authors to formulate 16different linear regression models to
describe what is only a single inference problem; then they ﬁnd themselves helpless to dealwith most of them, and give up with the statement that ‘It is all very difﬁcult.’
When we depart from the Gaussian case, we open up a Pandora’s box of new anomalies,
logical contradictions, absurd results, and technical dif ﬁculties beyond the means of sam-
pling theory to handle. Several examples were noted already by the devout orthodoxiansKendall and Stuart (1961).
These examples show the fundamental error in supposing that the quality of an estimate
can be judged merely from the sampling distribution of the estimator. This is true only in thesimpler Gaussian cases for reasons of mathematical symmetry; in general, as Fisher noted,many different samples which all lead to the same estimator nevertheless determine thevalues of the parameters to very different accuracy because they have different conﬁgurations(ranges). But Fisher’s remedy – conditioning on ancillary statistics – is seldom possible,and, when it is possible, we saw in Chapter 8 that it is mathematically equivalent to use ofBayes’ theorem. In the case of the ‘student’ t-distribution this was shown already by Jeffreys
in the 1930s. In Jaynes (1976) we demonstrate it in detail for the Cauchy distribution, whichorthodoxy regards as ‘pathological’.
What the orthodox literature invariably fails to recognize is that all of these difﬁculties are
resolved effortlessly by the uniform application of the single Bayesian method. In fact, oncethe Bayesian analysis has shown us the correct answer, one can often study it, understandintuitively why it is right, and, with this deeper understanding, see how that answer mighthave been found by some ad hoc device acceptable to orthodoxy.
We shall illustrate this in later chapters by giving the solution to the aforementioned
regression problem, and to some inference problems with the Cauchy sampling distribution.To the best of our knowledge, these solutions cannot be found in any of the orthodoxstatistical literature.
But we must note with sadness that, in much of the current Bayesian literature, very little
of the orthodox baggage has been cast off. For example, it is rather typical to see a Bayesianarticle start with such phrases as: ‘Let Xbe a random variable with density function p(x|θ),
where the value of the parameter θis unknown. Suppose this parametric family contains
the true distribution of X....’ Or, one describes a uniform prior p(θ|I) by saying: ‘ θis
supposed uniformly distributed’. The analytical solutions thus obtained will doubtless be a

<<<PAGE 584>>>

552 Part 2 Advanced applications
valid Bayesian result; but one is still clinging to the orthodox ﬁction of ‘random variables’
and ‘true distributions’. θis simply an unknown constant; it is not ‘distributed’ at all. What is
‘distributed’ is our state of knowledge about θ: again there is that persistent mind projection
fallacy that contaminates all of probability theory, leading inexperienced readers far astrayas to what we are doing. Equally bad, those who commit this fallacy seem unaware thatthis is restricting the application to a small fraction of the real situations where the solutionmight be useful. In the vast majority of real applications there are no ‘random variables’(What deﬁnes ‘randomness’?) and no ‘true distribution’ (What deﬁnes it? What test couldwe apply to decide whether some proposed distribution is or is not the ‘true’ one?); yetprobability theory as logic applies to all of them.
Unlike orthodox tests, Bayesian posterior probabilities or odds ratios can tell us quanti-
tatively how strong the evidence is for some effect taking into account allthe evidence at
hand, not merely the evidence of one data set.
L. J. Savage (1962, pp. 63–67) gives, by a tortuously long, closely reasoned argument
using only sampling probabilities, a rationale for the Bayesian algorithm. The Bayesian ar-gument expounded here, which he rejects as a ‘necessary’ view, derives the same conclusion,in greater generality, directly from ﬁrst principles.
These comparisons show that in order to deal successfully with current real problems, it
is essential to jettison tradition and authority, which have retarded progress throughout thiscentury. It is deplorable that orthodox methods and terminology continue to be taught at allto young statisticians, economists, biologists, psychologists, and medical researchers; thishas done serious damage in these ﬁelds for decades.
Yet everywhere we look there are glimmerings of hope. In physics, Bretthorst (1988) has
treated the analysis of magnetic resonance data, extracting by Bayesian methods far moreinformation from the data than was possible with the previous ad hoc Fourier analysis. In
econometrics Prof. Arnold Zellner is the founder of a large, active, and growing school ofBayesian analysis which has given rise to a vast literature. In medical diagnosis the greatphysician Sir William Osler (1849–1919) noted long ago that:
20Medicine is a science of
uncertainty and an art of probability . In recent years several people have started to take
this remark seriously. Lee Lusted (1968) gives worked-out examples, with ﬂow charts andsource code, of the Bayesian computer diagnoses of six important medical conditions, as
well as a great deal of qualitative wisdom in medical testing.
21Peter Cheeseman (1988) has
been developing expert systems for medical diagnosis based on Bayesian principles.
20Quoted by Bean (1950, p. 125).
21Lusted later founded the Society for Medical Decision Making in 1978, and served as the ﬁrst editor of its journal. At the time
of his death in February 1994, he was retired but still serving as Adjunct Professor at the Stanford University Medical School,advising medical students in problems of decision analysis.

<<<PAGE 585>>>

18
The Apdistribution and rule of succession
Inside every Non-Bayesian, there is a Bayesian struggling to get out.
Dennis V . Lindley
Up to this point, we have given our robot fairly general principles by which it can convert
information into numerical values of prior probabilities, and convert posterior probabilitiesinto deﬁnite ﬁnal decisions; so it is now able to solve lots of problems. But it still operates ina rather inefﬁcient way in one respect. When we give it a new problem, it has to go back intoits memory (this proposition that we have denoted by XorI, which represents everything
it has ever learned). It must scan its entire memory archives for anything relevant to the
problem before it can start working on it. As the robot grows older this gets to be a more
and more time-consuming process.
Now, human brains don’t do this. We have some machinery built into us which summarizes
our past conclusions, and allows us to forget the details which led us to those conclusions.We want to see whether it is possible to give the robot a deﬁnite mechanism by which it canstore general conclusions rather than isolated facts.
18.1 Memory storage for old robots
Note another thing, which we will see is closely related to this problem. Suppose you have
a penny and you are allowed to examine it carefully, and convince yourself that it is anhonest coin; i.e. accurately round, with head and tail, and a center of gravity where it oughtto be. Then you’re asked to assign a probability that this coin will come up heads on the
ﬁrst toss. I’m sure you’ll say 1 /2. Now, suppose you are asked to assign a probability to the
proposition that there was once life on Mars. Well, I don’t know what your opinion is there,but on the basis of all the things that I have read on the subject, I would again say about1/2 for the probability. But, even though I have assigned the same ‘external’ probabilities
to them, I have a very different ‘internal’ state of knowledge about those propositions.
To see this, imagine the effect of getting new information. Suppose we tossed the coin
ﬁve times and it comes up tails every time. You ask me what’s my probability for headson the next throw; I’ll still say 1 /2. But if you tell me one more fact about Mars, I’m
ready to change my probability assignment completely. There is something which makes
553

<<<PAGE 586>>>

554 Part 2 Advanced applications
my state of belief very stable in the case of the penny, but very unstable in the case of
Mars.1
This might seem to be a fatal objection to probability theory as logic. Perhaps we need
to associate with a proposition not just a single number representing plausibility, but twonumbers: one representing the plausibility, and the other how stable it is in the face of newevidence. And so, a kind of two-valued theory would be needed. In the early 1950s, thewriter gave a talk at one of the Berkeley statistical symposiums, expounding this viewpoint.
But now, with more mature reﬂection we think that there is a mechanism by which our
present theory automatically contains all these things. So far, all the propositions we haveasked the robot to think about are ‘Aristotelian’ ones of two-valued logic: they had to beeither true or false. Suppose we bring in new propositions of a different type. It doesn’tmake sense to say the proposition is either true or false, but still we are going to say that therobot associates a real number with it, which obeys the rules of probability theory. Now,these propositions are sometimes hard to state verbally; but we noticed before that if wegive the probabilities conditional on Xfor all propositions that we are going to use in a
given problem, we have told you everything about Xwhich is relevant to that mathematical
problem (although of course, not everything about its meaning and signiﬁcance to us,that may make us interested in the problem). So, we introduce a new proposition A
p,
deﬁned by
P(A|ApE)≡p, (18.1)
where Eis any additional evidence. If we had to render Apas a verbal statement, it would
come out something like this:
Ap≡regardless of anything else you may have been told,
the probability of Aisp. (18.2)
Now, Apis a strange proposition, but if we allow the robot to reason with propositions of
this sort, Bayes’ theorem guarantees that there’s nothing to prevent it from getting an Ap
worked over onto the left side in its probabilities: P(Ap|E). What are we doing here? It
seems almost as if we are talking about the ‘probability of a probability’.
Pending a better understanding of what that means, let us adopt a cautious notation that
will avoid giving possibly wrong impressions. We are not claiming that P(Ap|E) is a ‘real
probability’ in the sense that we have been using that term; it is only a number which is toobey the mathematical rules of probability theory. Perhaps its proper conceptual meaningwill be clearer after getting a little experience using it. So let us refrain from using the preﬁxsymbol p; to emphasize its more abstract nature, let us use the bare bracket symbol notation
(A
p|E) to denote such quantities, and call it simply ‘the density for Ap,g i v e n E’.
We deﬁned Apby writing an equation. You ask what it means, and we reply by writing
more equations. So let’s write the equations: if Xsays nothing about Aexcept that it is
1Note in passing a simple counter-example to a principle sometimes stated by philosophers, that theories cannot be proved true,
only false. We seem to have just the opposite situation for the theory that there was once life on Mars. To prove it false, it wouldnot sufﬁce to dig up every square foot of the surface of Mars; to prove it true one needs only to ﬁnd a single fossil.

<<<PAGE 587>>>

18 The A pdistribution and rule of succession 555
possible for Ato be true, and also possible for it to be false, then, as we saw in case of the
‘completely ignorant population’ in Chapter 12,
(Ap|X)=1, 0≤p≤1. (18.3)
The transformation group arguments of Chapter 12 apply to this problem. As soon as we
have this, we can use Bayes’ theorem to compute the density for Ap, conditional on the
other things. In particular,
(Ap|EX)=(Ap|X)P(E|ApX)
P(E|X)=P(E|Ap)
P(E|X). (18.4)
Now,
P(A|E)=/integraldisplay1
0dp(AA p|E). (18.5)
The propositions Apare mutually exclusive and exhaustive (in fact, every Apﬂatly and
dogmatically contradicts every other Aq), so we can do this. We’re just going to apply all of
our mathematical rules with total disregard of the fact that Apis a funny kind of proposition.
We believe that these rules form a consistent way of manipulating propositions. But nowwe recognize that consistency is a purely structural property of the rules, which could not
depend on the particular semantic meaning you and I might attach to a proposition. So nowwe can blow up the integrand of (18.5) by the product rule:
P(A|E)=/integraldisplay
1
0dpP(A|ApE)(Ap|E). (18.6)
But from the deﬁnition (18.1) of Ap, the ﬁrst factor is just p, and so
P(A|E)=/integraldisplay1
0dpp(Ap|E). (18.7)
The probability which our robot assigns to proposition Ais just the ﬁrst moment of the
density for Ap. Therefore, the density for Apshould contain more information about the
robot’s state of mind concerning A, than just the probability for A. Our conjecture is that
the introduction of propositions of this sort solves both of the problems mentioned, and alsogives us a powerful analytical tool for calculating probabilities.
18.2 Relevance
To see why we propose our conjecture, let’s note some lemmas about relevance. Suppose
this evidence Econsists of two parts, E=E
aEb, where Eais relevant to Aand, given Ea,
Ebis not relevant:
P(A|E)=P(A|EaEb)=P(A|Ea). (18.8)

<<<PAGE 588>>>

556 Part 2 Advanced applications
By Bayes’ theorem, it follows that, given Ea,Amust also be irrelevant to Eb, for
P(Eb|AE a)=P(Eb|Ea)P(A|EbEa)
P(A|Ea)=P(Eb|Ea). (18.9)
Let’s call this property ‘weak irrelevance’. Now, does this imply that Ebis irrelevant to Ap?
Evidently not, for (18.8) says only that the ﬁrst moments of ( Ap|Ea) and ( Ap|EaEb) are
the same. But suppose that, for a given Eb, (18.8) holds independently of what Eamight
be; call this ‘strong irrelevance’. Then we have
P(A|E)=/integraldisplay1
0dpp(Ap|EaEb)=/integraldisplay1
0dpp(Ap|Ea). (18.10)
But if this is to hold for all ( Ap|Ea), the integrands must be the same:
(Ap|EaEb)=(Ap|Ea), (18.11)
and from Bayes’ theorem it follows as in (18.9) that Apis irrelevant to Eb:
P(Eb|ApEa)=P(Eb|Ea) (18.12)
for all Ea.
Now, suppose our robot gets a new piece of evidence, F. How does this change its state
of knowledge about A? We could expand directly by Bayes’ theorem, which we have done
before, but let’s use our Apthis time:
P(A|EF)=/integraldisplay1
0dpp(Ap|EF)=/integraldisplay1
0dpp(Ap|E)P(F|ApE)
P(F|E). (18.13)
In this likelihood ratio, any part of Ethat is irrelevant to Apcan be struck out; because, by
Bayes’ theorem, it is equal to
P(F|ApEaEb)
P(F|EaEb)=P(F|ApEa)/bracketleftBig
P(Eb|FA pEa)
P(Eb|ApEa)/bracketrightBig
P(F|Ea)/bracketleftBig
P(Eb|FE a)
P(Eb|Ea)/bracketrightBig=P(F|ApEa)
P(F|Ea), (18.14)
where we have used (18.12).
Now if Eastill contains a part irrelevant to Ap, we can repeat this process. Imagine this
carried out as many times as possible; the part EaaofEthat is left contains nothing at
all that is irrelevant to Ap.Eaamust then be some statement only about A. But then, by
deﬁnition (18.1) of Ap, we see that Apautomatically cancels out Eaain the numerator:
(F|ApEaa)=(F|Ap). And so we have (18.13) reduced to
P(A|EF)=1
P(F|Eaa)/integraldisplay1
0dpp(Ap|E)P(F|Ap). (18.15)
The weak point in this argument is that we have not proved that it is always possible to
resolve Einto a completely relevant part and completely irrelevant part. However, it is easy
to show that in many applications it ispossible. So, let’s just say that the following results

<<<PAGE 589>>>

18 The A pdistribution and rule of succession 557
apply to the case where the prior information is ‘completely resolvable’. We have not shown
that it is the most general case; but we do know that it is not an empty one.
18.3 A surprising consequence
Now, ( F|Eaa) is a troublesome thing which we would like to eliminate. It’s really just a
normalizing factor, and we can eliminate it the way we did in Chapter 4: by calculating theodds on Ainstead of the probability. This is just
O(A|EF)=P(A|EF)
P(A|EF)=/integraltext1
0dpp(Ap|E)P(F|Ap)
/integraltext1
0dp(Ap|E)P(F|Ap)(1−p). (18.16)
The signiﬁcant thing here is that the proposition E, which for this problem represents our
prior information, now appears only in the density ( Ap|E). This means that the only property
of E which the robot needs in order to reason out the effect of new information is this density(A
p|E). Everything that the robot has ever learned which is relevant to proposition Amay
consist of millions of isolated separate facts. But when it receives new information, it doesnot have to go back and search its entire memory for every little detail of its informationrelevant to A. Everything it needs in order to reason about Afrom that past experience is
contained summarized in this one function, ( A
p|E).
So, for each proposition Aabout which it is to reason, the robot can store a density
function ( Ap|E) like that in Figure 18.1. Whenever it receives new information F, it will
be well advised to calculate ( Ap|EF), and then it can erase the previous ( Ap|E) and for
the future store only ( Ap|EF). By this procedure, every detail of its previous experience is
taken into account in future reasoning about A.
This suggests that in a machine which does inductive reasoning, the memory storage
problem may be simpler than it is in a machine which does only deductive reasoning. Thisdoes not mean that the robot is able to throw away all of its past experience, because there is
0 0.2 0.4 0.6 0.8 1(Ap|E)
p
↓
↓
Fig. 18.1. An example Apdistribution.

<<<PAGE 590>>>

558 Part 2 Advanced applications
always a possibility that some new proposition will come up which it has not had to reason
about before. And, whenever this happens, then of course it willhave to go back into its
original archives and search for every scrap of information it has relevant to this proposition.
With a little introspection, we would all agree that this is just what goes on in our minds. If
you are asked how plausible you regard some proposition, you don’t go back and recall all thedetails of everything that you ever learned about this proposition. You recall your previousstate of mind about it. How many of us can still remember the argument which ﬁrst convincedus that d sin( x)/dx=cos(x) ? But, unlike the robot, when you or I are confronted with some
entirely new proposition Z, we do not have the ability to carry out a full archival search.
Let’s look once more at (18.15). If the new information Fis to make any appreciable
change in the probability of A, we can see from this integral what has to happen. If the
density ( A
p|E) was already very sharply peaked at one particular value of p, then P(F|Ap)
will have to be even more sharply peaked at some other value of p, if we are going to get
any appreciable change in the probability. On the other hand, if the density ( Ap|E)i sv e r y
broad, any small slope in P(F|Ap) can make a big change in the probability which the
robot assigns to A.
So, the stability of the robot’s state of mind when it has evidence Eis determined,
essentially, by the width of the density ( Ap|E). There does not appear to be any single
number which fully describes this stability. On the other hand, whenever it has accumulatedenough evidence so that ( A
p|E) is fairly well peaked at some value of p, then the variance
of that distribution becomes a pretty good measure of how stable the robot’s state of mind is.The greater amount of previous information it has collected, the narrower its A
p-distribution
will be, and therefore the harder it will be for any new evidence to change that state of mind.
Now we can see the difference between the penny and Mars. In the case of the penny,
my ( Ap|E) density, based on my prior knowledge, is represented by a curve something like
that shown in Figure 18.2(a). In the case of previous life on Mars, my state of knowledge is
0 0.2 0.4 0.6 0.8 1
pMars
(b)
0 0.2 0.4 0.6 0.8 1
pPenny
(a)(Ap|E)
↓
(Ap|E)
↓↓
↓
Fig. 18.2. Two Apdistributions having the same ﬁrst moments, but representing very different states
of knowledge.

<<<PAGE 591>>>

18 The A pdistribution and rule of succession 559
described by an ( Ap|E) density something like that shown in Figure 18.2(b), qualitatively.
The ﬁrst moment is the same in the two cases, so I assign probability 1 /2 to either one;
nevertheless, there’s all the difference in the world between my state of knowledge aboutthose two propositions, and this difference is represented in the ( A
p|E) densities.
Ideas very much like this have arisen in other contexts. While the writer was ﬁrst spec-
ulating on these ideas, a newspaper story appeared entitled: ‘Brain Stockpiles Man’s MostInner Thoughts’. It starts out:
Everything you have ever thought, done, or said – a complete record of every conscious moment –
is logged in the comprehensive computer of your brain. You will never be able to recall more thanthe tiniest fraction of it to memory, but you’ll never lose it either. These are the ﬁndings of Dr WilderPenﬁeld, Director of the Montreal Neurological Institute, and a leading Neurosurgeon. The brain’sability to store experiences, many lying below consciousness, has been recognized for some time, butthe extent of this function is recorded by Dr Penﬁeld.
Now, there are several examples given, of experiments on patients suf fering from epilepsy.
Stimulation of a deﬁnite location in the brain recalled a deﬁnite experience from the past,
which the patients had not been able to recall to memory previously. Here are the concludingsentences of the article. Dr Pen ﬁeld now says:
This is not memory as we usually use the word, although it may have a relation to it. No man can
recall by voluntary effort such a wealth of detail. A man may learn a song so he can sing it perfectly,but he cannot recall in detail any one of the many times he heard it. Most things that a man is ableto recall to memory are generalizations and summaries. If it were not so, we might ﬁnd ourselvesconfused by too great a richness of detail.
This is exactly the hint we needed to form a clearer idea of what the Apdensity means
conceptually.
18.4 Outer and inner robots
We know from overwhelming evidence, of which the above is only a small part, that human
brains have two different functions: a conscious mind and a subconscious one. They worktogether in some kind of cooperation. The subconscious mind is probably at work continuallythroughout life. It solves problems and communicates information to the conscious mindunder circumstances not under our conscious control; everyone who has done originalthinking about difﬁcult problems has experienced this, and many (Henri Poincar´ e, Jacques
Hadamard, Wm. Rowan Hamilton, Freeman Dyson) have recorded the experience for othersto read. A communication from the subconscious mind appears to us as a sudden inspirationthat seems to come out of nowhere when we are relaxed and not thinking consciously aboutthe problem at all; instantly, we feel that we understand the problem that has perplexed usfor weeks.
2
2The writer has experienced this several times when, in unlikely situations like riding a tractor on his farm, he suddenly saw how
to prove something long conjectured. But the inspiration does not come unless the conscious mind has prepared the way for itby intense concentration on the problem.

<<<PAGE 592>>>

560 Part 2 Advanced applications
Now, if the human brain can operate on two different levels, so can our robot. Rather
than trying to think of a ‘probability of a probability’, we may think of two different levelsof reasoning: an ‘outer robot’ in contact with the external world and reasoning about it;and an ‘inner robot’ who observes the activity of the outer robot and thinks about it. Theconventional probability formulas that we used before this chapter represent the reasoningof the outer robot; the A
pdensity represents the inner robot at work. But we would like our
robot to have one advantage over the human brain. The outer robot should not be obliged aswe are to wait for the inspiration from within; it should have the power to call at will uponthe services of the inner robot.
Looking at the A
pdistribution this way makes it much less puzzling conceptually. The
outer robot, thinking about the real world, uses Aristotelian propositions referring to thatworld. The inner robot, thinking about the activities of the outer robot, uses propositionsthat are not Aristotelian in reference to the outer world, but they are still Aristotelian inits context, in reference to the thinking of the outer robot; so, of course, the same rules ofprobability theory will apply to them. The term ‘probability of a probability’ misses thepoint, since the two probabilities are at different le vels.
Having had this much of a glimpse of things, our imagination races on far beyond it. The
inner robot may prove to be more versatile than merely calculating and storing A
pdensities;
it may have functions that we have not yet imagined. Furthermore, could there be an ‘innerinner’ robot, twice removed from the real world, which thinks about the activity of the innerone? What prevents us from having a nested hierarchy of such robots, each inner to thenext? Why not several parallel hierarchies, concerned with different contexts?
Questions like this may seem weird, until we note that just this same hierarchy has
evolved already in the development of computers and computer programming methods.Our present microcomputers operate on three discernible hierarchical levels of activity,the inner ‘BIOS’ code which contacts the machine hardware directly, the ‘COMMANDSHELL’ which guards it from the outer world while sending information and instructionsback and forth between them, and the outer level of human programmers who provide the‘high level’ instructions representing the conscious ultimate purpose of the machine levelactivity. Furthermore, the development of ‘massively parallel’ computer architecture hasbeen underway for several years.
In the evolution of computers this represented such a natural and inevitable division of
labor that we should not be surprised to realize that a similar division of labor occurred inthe evolution of the human brain. It has an inner ‘BIOS’ level which in some way exerts
direct control over the body’s biological hardware (such as rate of heartbeat and levels ofhormone secretion), a ‘COMMAND SHELL’ which receives ‘high level’ instructions fromthe conscious mind and converts them into the ﬁnely detailed instructions needed to executesuch complex activities as walking or playing a violin, without any need for the consciousmind to be aware of all those details. Then in some aspects of the present organization ofthe brain, not yet fully understood, we may be seeing some aspects of the future evolutionof computers; in particular of our robot.
The idea of a nested hierarchy of robots, each thinking about propositions on a dif-
ferent level, is in some ways similar to Bertrand Russell’s ‘theory of types’, which he

<<<PAGE 593>>>

18 The A pdistribution and rule of succession 561
introduced as a means of avoiding some paradoxes that arose in the ﬁrst formulation of
hisPrincipia Mathematica . There may be a relationship between them; but these efforts at
what Peano and Poincar´ e called ‘logistic’ made in the early 20th century, are now seen as
so ﬂawed and confused – with an unlimited proliferation of weird and self-contradictorydeﬁnitions, yet with no recognition of the concept of information – that it seems safest toscrap this old work entirely and rebuild from the start using our present understanding ofthe role of information and our new respect for Kronecker’s warnings, so appropriate inan age of computers, that constructibility is the ﬁrst criterion for judging whether a newly
deﬁned set or other mathematical object makes any sense or can serve any useful purpose.
Our opening quotation from Dennis Lindley (made during a talk at a Bayesian seminar in
the early 1980s) ﬁts in nicely with these considerations and with our remarks in Chapter 5about visual perception. There we noted that any reasoning format whose results conﬂictwith Bayesian principles would place a creature at a decided survival disadvantage, soevolution by Darwinian natural selection would automatically produce brains which reasonin the Bayesian format. But the outer brain can become corrupted by false indoctrination
from contact with the outer world – even to the point of becoming anti-Bayesian – while the
inner brain, protected from this, retains its pristine Bayesian purity. Thus, Lindley’s remark,made as a kind of joke, may be quite literally true.
Here, however, we are treading on the boundaries of present knowledge, so the above
material is necessarily a tentative, preliminary exploration of a possibly large new territory(call it wild speculation if you prefer), rather than expounding a well-established theory.With these cautions in mind, let us examine some concrete examples which follow fromthe above line of thought, but can also be justiﬁed independently.
18.5 An application
Now let’s imagine that a ‘random’ experiment is being performed. From the results of the
experiment in the past, we want to do the best job we can of predicting results in the future.To make the problem a deﬁnite one, introduce the propositions:
X≡For each trial we admit two prior hypotheses: Atrue, and Afalse.
The underlying ‘causal mechanism’ is assumed the same at every trial. This means, for
example, that (1) the probability assigned to Aat the nth trial does not depend on n, and
(2) evidence concerning the results of past trials retains its relevance for all time; thus forpredicting the outcome of trial 100, knowledge of the result of trial 1 is just as relevant asis knowledge of the result of trial 99. There is no other prior evidence.
Nn≡Atruentimes in Ntrials in the past.
Mm≡Atruemtimes in Mtrials in the future.
The verbal statement of Xsuffers from just the same ambiguities that we have found before,
and which have caused so much trouble and controversy in the past. One of the importantpoints we want to put across here is that we have not deﬁned the prior information preciselyuntil we have given, not just verbal statements, but equations, which show how we have

<<<PAGE 594>>>

562 Part 2 Advanced applications
translated them into mathematics by specifying the prior probabilities to be used. In the
present problem, this more precise statement of Xis, as before,
(Ap|X)=1,0≤p≤1, (18.17)
with the additional understanding (part of the prior information for this particular problem)
that the same A pdistribution is to be used for calculations pertaining to all trials. What we
are after is P(Mm|Nn). Firstly, note that by many repetitions of our product and sum rules
in the same way that we found Eq. (9.34), we have the binomial distributions
P(Nn|Ap)=/parenleftbiggN
n/parenrightbigg
pn(1−p)N−n,
P(Mm|Ap)=/parenleftbiggM
m/parenrightbigg
pm(1−p)M−m,(18.18)
and at this point we see that, although Apsounds like an awfully dogmatic and indefensible
statement to us the way we introduced it, this is actually the way in which probabilityisintroduced in almost all present textbooks. One postulates that an event possesses some
intrinsic, ‘absolute’ or ‘physical’ probability, whose numerical value we can never determineexactly. Nevertheless, no one questions that such an ‘absolute’ probability exists. Cram´ er
(1946, p. 154), for example, takes it as his fundamental axiom. That is just as dogmatica statement as our A
p; and we think it is, in fact, just our Ap. The equations we see in
current textbooks are all like the two above; whenever pappears as a given number, an
adequate notation would show that there is an Aphiding invisibly in the right-hand side of
the probability symbols.
Mathematically, the main functional differences between what we are doing here and
what is done in current textbooks are: (1) we recognize the existence of that right-handside of allprobabilities, whether or not an A
pis hiding in them; and (2) thanks to Cox’s
theorems, we are not afraid to use Bayes’ theorem to work any proposition – including
Ap– back and forth from one side of our symbols to the other. In refusing to make free
use of Bayes’ theorem, orthodox writers are depriving themselves of the most powerfulsingle principle in probability theory. When a problem of inference is studied long enough,sometimes through a string of ad hockeries for decades, one is always forced eventually to a
conclusion that could have been derived in three lines from Bayes’ theorem. But those cases
refer to ‘external’ probabilities at the interface between the robot and the outside world; nowwe shall see that Bayes’ theorem is equally powerful and indispensable for manipulating‘inner’ probabilities.
Now we need to ﬁnd the prior probability P(N
n|X). This is determined already from
(Ap|X), for our trick of resolving a proposition into mutually exclusive alternatives
gives us
P(Nn|X)=/integraldisplay1
0dp(NnAp|X)=/integraldisplay1
0dpP(Nn|Ap)(Ap|X)=/parenleftbiggN
n/parenrightbigg/integraldisplay1
0dppn(1−p)N−n.
(18.19)

<<<PAGE 595>>>

18 The A pdistribution and rule of succession 563
The integral we have to evaluate is the complete Beta-function:
/integraldisplay1
0dxxr(1−x)s=r!s!
(r+s+1)!. (18.20)
Thus, we have
P(Nn|X)=

1
N+10≤n≤N
0 N<n,(18.21)
i.e. just the uniform distribution of maximum entropy; P(Mm|X) is found similarly. Now
we can turn (18.18) around by Bayes’ theorem:
(Ap|Nn)=(Ap|X)P(Nn|Ap)
P(Np|X)=(N+1)P(Nn|Ap), (18.22)
and so ﬁnally the desired probability is
P(Mm|Nn)=/integraldisplay1
0dp(MmAp|Nn)=/integraldisplay1
0dpP(Mm|ApNn)(Ap|Nn). (18.23)
Since P(Mm|ApNn)=P(Mm|Ap) by the deﬁnition of Ap, we have worked out everything
in the integrand. Substituting into (18.23), we have again an Eulerian integral, and ourresult is
P(M
m|Nn)=/parenleftbiggn+m
n/parenrightbigg/parenleftbiggN+M−n−m
N−n/parenrightbigg
/parenleftbiggN+M+1
M/parenrightbigg . (18.24)
Note that this is not the same as the hypergeometric distribution (3.22) of sampling theory.
Let’s look at this result ﬁrst in the special case M=m=1; it then reduces to the probability
ofAbeing true in the next trial, given that it has been true ntime in the previous Ntrials.
The result is
P(A|Nn)=n+1
N+2. (18.25)
We recognize Laplace’s rule of succession, which we found before and discussed brieﬂy
in terms of urn sampling in (6.29)–(6.46). Now we need to discuss it more carefully, in awider context.
18.6 Laplace’s rule of succession
This rule occupies a supreme position in probability theory; it has been easily the most
misunderstood and misapplied rule in the theory, from the time Laplace ﬁrst gave it in1774. In almost any book on probability, this rule is mentioned very brieﬂy, mainly in orderto warn the reader not to use it. But we must take the trouble to understand it, because inour design of this robot Laplace’s rule is, like Bayes’ theorem, one of the most important

<<<PAGE 596>>>

564 Part 2 Advanced applications
constructive rules we have. It is a ‘new’ rule (i.e. a rule in addition to the principle of
indifference and its generalization, maximum entropy) for converting raw information intonumerical values of probabilities, and it gives us one of the most important connectionsbetween probability and frequency.
Poor old Laplace has been ridiculed for over a century because he illustrated use of
this rule by calculating the probability that the sun will rise tomorrow, given that ithas risen every day for the past 5000 years.
3One obtains a rather large factor (odds of
5000×365.2426+1=1 826 214 : 1) in favor of the sun rising again tomorrow. With no
exceptions at all as far as we are aware, modern writers on probability have consideredthis a pure absurdity. Even Keynes (1921) and Jeffreys (1939) ﬁnd fault with the rule ofsuccession.
We have to confess our inability to see anything at all absurd about the rule of succession.
We recommend very strongly that you do a little independent literature searching, and readsome of the objections various writers have to it. You will see that in every case the samething has happened. Firstly, Laplace was quoted out of context, and secondly, in order todemonstrate the absurdity of the rule of succession, the author applies it to a case where itdoes not apply, because there is additional prior information which the rule of successiondoes not take into account.
But if you go back and read Laplace (1812) himself, you will see that in the very next
sentence after this sunrise episode, he warns the reader against just this misunderstanding:
But this number is far greater for him who, seeing in the totality of phenomena the principle regulating
the days and seasons, realizes that nothing at the present moment can arrest the course of it.
In this somewhat awkward phraseology he is pointing out to the reader that the rule of
succession gives the probability based only on the information that the event occurred n
times in Ntrials, and that our knowledge of celestial mechanics represents a great deal of
additional information. Of course, if you have additional information beyond the numbers n
andN, then you ought to take it into account. You are then considering a different problem,
the rule of succession no longer applies, and you can reach an entirely different answer.Probability theory gives the results of consistent plausible reasoning on the basis of theinformation which was put into it .
It has to be admitted that, in mentioning the sunrise at all, Laplace made a very unfortunate
choice of an example – because the rule of succession does not really apply to the sunrise,for just the reason that he points out. This choice has had a catastrophic effect on Laplace ’s
reputation ever since. His statements make sense when the reader interprets ‘probability’,as Laplace did, as a means of representing a state of partial knowledge. But to those whothought of probability as a real physical phenomenon, existing independently of humanknowledge, Laplace’s position was quite incomprehensible; and so they jumped to the
3Some passages in the Bible led early theologians to conclude that the age of the world is about 5000 years. It seems that Laplace
at ﬁrst accepted this ﬁgure, as did everyone else. But it was during Laplace’s lifetime that dinosaur remains were found almostunder his feet (under the streets of Montmartre in Paris), and interpreted correctly by the anatomist Cuvier. Had he written thisnear the end of his life, we think that Laplace would have used a ﬁgure vastly greater than 5000 years.

<<<PAGE 597>>>

18 The A pdistribution and rule of succession 565
conclusion that Laplace had committed a ludicrous error, without even bothering to read
his full statement.
Here are some famous examples of the kind of objections to the rule of succession which
may be found in the literature.
(1) Suppose the solidiﬁcation of hydrogen to have been once accomplished. According to the rule
of succession, the probability that it will solidify again if the experiment is repeated is 2 /3. This
does not in the least represent the state of belief of any scientist.
(2) A boy is 10 years old today. According to the rule of succession, he has the probability 11 /12 of
living one more year. The boy’s grandfather is 70; according to this rule he has the probability71/72 of living one more year. The rule violates qualitative common sense!
(3) Consider the case N=n=0. It then says that any conjecture without veriﬁcation has the proba-
bility 1 /2. Thus there is probability 1 /2 that there are exactly 137 elephants on Mars. Also there
is probability 1 /2 that there are 138 elephants on Mars. Therefore, it is certain that there are at
least 137 elephants on Mars. But the rule says also that there is probability 1 /2 that there are no
elephants on Mars. The rule is logically self-contradictory!
The trouble with examples (1) and (2) is obvious in view of our earlier remarks; in each
case, highly relevant prior information, known to all of us, was simply ignored, producing aﬂagrant misuse of the rule of succession. But let’s look a little more closely at example (3).Wasn’t the rule applied correctly here? We certainly can’t claim that we had prior informationabout elephants on Mars which was ignored. Evidently, if the rule of succession is to surviveexample (3), there must be some very basic points about the use of probability theory whichwe need to emphasize.
Now, what do we mean when we say that there is ‘no evidence’ for a proposition? The
question is not what you or I might mean colloquially by such a statement. The question is:What does it mean to the robot ? What does it mean in terms of probability theory?
The prior information we used in derivation of the rule of succession was that the robot
is told that there are only two possibilities: Ais true, or Ais false. Its entire ‘universe
of discourse’ consists of only two propositions. In the case N=0, we could solve the
problem also by direct application of the principle of indifference, and this will of coursegive the same answer P(A|X)=1/2, that we obtained from the rule of succession. But,
just by noting this, we see what is wrong. Merely by admitting the possibility of one ofthree different propositions being true, instead of only one of two, we have already speciﬁedprior information different from that used in deriving the rule of succession.
4
If the robot is told to consider 137 different ways in which Acould be false, and only one
way in which it could be true, and is given no other information, then its prior probabilityforAis 1/138, not 1 /2. So, we see that the example of elephants on Mars was, again, a
gross misapplication of the rule of succession.
4We see here only what should have been obvious: that our conclusions from some data can depend on the size of our hypothesis
space. We saw a very similar thing in our study of the marginalization paradox in Chapter 15, in the discussion following
Eq. (15.92), where we found that the size of a parameter space can affect our inferences. That is, introducing a new parameter
can make a difference in our conclusions, even when we have no knowledge of its numerical value.

<<<PAGE 598>>>

566 Part 2 Advanced applications
Moral
Probability theory, like any other mathematical theory, cannot give a deﬁnite answer unless
we ask it a deﬁnite question. We should always start a problem with an explicit enumerationof the ‘hypothesis space’ consisting of the different propositions that we are going to considerin that problem. That is part of the ‘boundary conditions’ which must be speciﬁed beforewe have a well-posed mathematical problem. If we say, ‘I don’t know what the possiblepropositions are’, that is mathematically equivalent to saying, ‘I don’t know what problemI want to solve’. The only answer the robot can give is: ‘Come back and ask me again whenyou do know’.
18.7 Jeffreys’ objection
As one would expect, the example used by Jeffreys (1939, p. 107) is more subtle. He writes:
I may have seen one in 1000 of the ‘animals in feathers’ in England; on Laplace’s theory the probability
of the propositions ‘all animals with feathers have beaks’ would be about 1 /1000. This does not
correspond to my state of belief, or anybody else’s.
Now, while we agree with everything Jeffreys said, we must point out that he failed to add
two important facts. Firstly, it is true that, on this evidence, P(all have beaks)≈1/1000
according to Laplace’s rule. But also P(all but one have beaks) ≈1/1000, P(all but two
have beaks)≈1/1000,..., etc. More speciﬁcally, if there are Nfeathered animals of
which we have seen r(all with beaks), then rewriting (18.24) in this notation we see that
P(all have beaks)=P0=(r+1)/(N+1)≈1/1000, while P(all but nhave beaks) is
Pn=P0(N−r)! (N−n)!
N!(N−n−r)!, (18.26)
and the probability that there are n0or more without beaks is
N/summationdisplay
n=n0Pn=(N−r)! (N−n0+1)!
(N+1)! (N−n0−r)!≈exp{−rn0/N}. (18.27)
Thus if there are one million animals with feathers, of which we have seen 1000 (all with
beaks), this leaves it an even bet that there are at least 1000 ln(2) =693 without beaks;
and, of course, an even bet that the number is less than that. If the only relevant informationone had was the aforementioned observation, we think that this would be just the proper
and reasonable inference.
Secondly, Laplace’s rule is not appropriate for this problem because we all have additional
prior information that it does not take into account: hereditary stability of form, the factthat a beakless feathered animal would, if it existed, be such an interesting curiosity thatwe all should have heard of it even if we had not seen it (as has happened in the conversecase of the duck-billed platypus), etc. To see fairly and in detail what Laplace’s rule (18.24)says, we need to consider a problem where our prior information corresponds better to thatsupposed in its derivation.

<<<PAGE 599>>>

18 The A pdistribution and rule of succession 567
18.8 Bass or carp?
A guide of unquestioned knowledge and veracity assures us that a certain lake contains
only two species of ﬁsh: bass and carp. We catch ten and ﬁnd them all to be carp – whatis then our state of belief about the percentage of bass? Common sense tells us that, if theﬁsh population were more than about 10% bass, then in ten catches we had a reasonablygood chance of ﬁnding one; so our state of belief drops off rapidly above 10%. On the otherhand, these data Dprovide no evidence against the hypothesis that the bass population is
zero. So common sense without any calculation would lead us to conclude that the basspopulation is quite likely to be in the range, say, (0%, 15%), but intuition does not tell usquantitatively how likely this is.
What, then, does Laplace’s rule say? Denoting the bass fraction by f, its posterior
cumulati ve pdf is P(f<f
0|DX)=1−(1−f0)11. Thus we have a probability of 1 −
(1−0.15)11=0.833, or odds of 5:1, that the bass population is indeed below 15%. Like-
wise, the data yield a probability of 2 /3, or odds of 2:1, that the lake contains less than 9.5%
bass, and odds of 10:1 that it is less than 19.6%, while the posterior median value is
f1/2=1−/parenleftbigg1
2/parenrightbigg1/11
=0.061, (18.28)
or 6.1%; it is an even bet that the bass population is less than this. The interquartile range is
(f1/4,f3/4)=(2.6%, 11.8%); it is as likely to be within as outside that interval. The ‘best’
estimate of fby the criterion of minimum mean-square error is Laplace’s posterior mean
value (18.25):/angbracketleftf/angbracketright=1/12, or 8.3%.
Suppose now that our 11th catch is a bass; ho w does this change our state of belief?
Evidently, we shall revise our estimate of fupward, because the data now doprovide
evidence against the hypothesis that fis very small. Indeed, if the bass population were
less than 5%, then we would be unlikely to ﬁnd one in only 11 catches, so our state of beliefdrops off rapidly below 5%, but less rapidly than before above 10%.
Laplace’s rule agrees, now saying that the best mean-square estimate is /angbracketleftf/angbracketright=2/13, or
15.4%, and the posterior density is P(df|DX)=132f(1−f)
10df. This yields a median
value of 13.6%, raised very considerably because the new datum has effectively eliminatedthe possibility that the bass population might be below about 3%, which was just the mostlikely region before. The interquartile range is now (8.3%, 20.9%).
It appears to us that all these numbers correspond excellently to our common sense
judgments. This, then, is the kind of problem to which Laplace’s rule applies very real-istically; i.e. there were known to be only two possibilities at each trial, and our priorknowledge gave no other information beyond assuring us that both were possible. When-ever the result of Laplace’s rule of succession conﬂicts with our intuitive state of belief,we suggest that the reason is that our common sense is making use of additional priorinformation about the real world situation that is not used in the derivation of the rule ofsuccession.

<<<PAGE 600>>>

568 Part 2 Advanced applications
18.9 So where does this leave the rule?
Mathematically, the rule of succession is the solution to a certain problem of inference,
deﬁned by the prior probability and the data. The 200 year old hangup has been over thequestion: what prior information is being described by the uniform prior probability (18.3)?
Laplace was not too clear about this – his discussion of it seemed to invoke the idea ofa ‘probability of a probability’ which may appear to be metaphysical nonsense until onehas the notion of an inner and outer robot – but his critics, instead of being constructiveand trying to deﬁne the conceptual problem more clearly, seized upon this to denounceLaplace’s whole approach to probability theory.
Of Laplace’s critics, only Jeffreys (1939) and Fisher (1956) seem to have thought it
through deeply enough to realize that the unclear deﬁnition of the prior information was thesource of the difﬁculty; the others, following the example of Venn (1866), merely produceexamples where common sense and Laplace’s rule are in conﬂict, and, without making anyattempt to understand the reason for it, reject the rule in any and all circumstances. As wenoted in Chapter 16, Venn’s criticisms were so unjust that even Fisher (1956) was impelledto come to Laplace’s defense on this issue.
In this connection we have to remember that probability theory never solves problems
of actual practice, because all such problems are inﬁnitely complicated. We solve onlyidealizations of the real problem, and the solution is useful to the extent that the idealizationis a good one. In the example of the solidi ﬁcation of hydrogen, the prior information, which
our common sense uses so easily, is actually so complicated that nobody knows how toconvert it into a prior probability assignment. There is no reason to doubt that probability
theory is, in principle, competent to deal with such problems; but we have not yet learned
how to translate them into mathematical language without oversimplifying rather drastically.
In summary, Laplace’s rule of succession provides a deﬁnite, useful solution to a deﬁnite,
real problem. Everybody denounces it as nonsense because it is not also the solution to somedifferent problem. The case where the problem can be reasonably idealized to one with onlytwo hypotheses to be considered, a belief in a constant ‘causal mechanism’, and no other
prior information , is the only case where it applies. But we can, of course, generalize it to
any number of hypotheses, as follows.
18.10 Generalization
We give the derivation in full detail, to present a mathematical technique of Laplace that
is useful in many other problems. There are Kdifferent hypotheses, {A
1,A2,..., AK},a
belief that the ‘causal mechanism’ is constant, and no other prior information. We performa random experiment Ntimes, and observe A
1true n1times, A2true n2times, etc. Of
course,/summationtext
ini=N. On the basis of this evidence, what is the probability that in the next
M=/summationtext
imirepetitions of the experiment, Aiwill be true exactly mitimes? To ﬁnd the
probability P(m1···mK|n1,..., nK) that answers this, deﬁne the prior knowledge by a
K-dimensional uniform prior Apdensity:
(Ap1···ApK|X)=Cδ(p1+···+ pK−1),pi≥0. (18.29)

<<<PAGE 601>>>

18 The A pdistribution and rule of succession 569
To ﬁnd the normalization constant C,w es e t
/integraldisplay∞
0dp1···dpK(Ap1···Apk|X)=1=CI(1), (18.30)
where
I(r)≡/integraldisplay∞
0dp1···dpkδ(p1+···+ pK−r). (18.31)
Direct evaluation of this would be rather messy, because all integrations after the ﬁrst would
be between limits that need to be worked out; so let’s use the following trick. Firstly, takethe Laplace transform of (18.31):
/integraldisplay
∞
0drexp{−αr}I(r)=/integraldisplay∞
0dp1···dpKexp{−α(p1+···+ pK)}=1
αK.(18.32)
Then, inv erting the Laplace transform by Cauchy ’s theorem,
I(r)=1
2πi/integraldisplay+i∞
−i∞dαexp{αr}
αK
=1
(K−1)!dK−1
dαK−1exp{αr}/vextendsingle/vextendsingle/vextendsingle
α=0
=rK−1
(K−1)!,(18.33)
where, according to the standard theory of Laplace transforms, the path of integration passes
to the right of the origin, and is closed by an inﬁnite semicircle over the left half-plane, theintegral over which is zero. Thus,
C=1
I(1)=(K−1)!. (18.34)
By this device, we avoided having to consider complicated details about different ranges of
integration over the different pi, that would come up if we tried to evaluate (18.31) directly.
The prior P(n1···nK|X) is then, using the same trick,
P(n1···nK|X)=N!
n1!...nK!/integraldisplay∞
0dp1···/integraldisplay∞
0dpKpn1
1···pnK
K(Ap1···ApK|X)
=N!(K−1)!
n1!···nK!J(1),(18.35)
where
J(r)≡/integraldisplay∞
0dp1···dpKpn1
1···pnK
Kδ(p1+···+ pk−r), (18.36)

<<<PAGE 602>>>

570 Part 2 Advanced applications
which we evaluate as before by taking the Laplace transform:
/integraldisplay∞
0dre−αrJ(r)=/integraldisplay∞
0dp1···dpKpn1
1···pnK
Kexp{−α(p1+···+ pK)}
=K/productdisplay
i=1ni!
αni+1.(18.37)
So, as in (18.33), we have
J(r)=n1!···nK!
2πi/integraldisplay+i∞
−i∞dαexp{αr}
αN+K=n1!···nK!
(N+K−1)!rN+K−1(18.38)
and
P(n1···nk|X)=N!(K−1)!
(N+K−1)!,ni≥0,n1+···+ nK=N. (18.39)
Therefore, by Bayes’ theorem
(Ap1···ApK|n1···nK)=(Ap1···ApK|X)P(n1···nK|Ap1···ApK)
P(n1···nK|X)
=(N+K−1)!
n1!···nK!pn1
1···pnK
Kδ(p1+···+ pK−1),(18.40)
and ﬁnally
P(m1···mK|n1···nK)
=/integraldisplay∞
0dp1···dpKP(m1···mK|Ap1···ApK)(Ap1···ApK|n1···nK)
=M!
m1!···mK!(N+K−1)!
n1!···nK!/integraldisplay∞
0dp1···dpKpn1+m1
1···pnK+mK
K
×δ(p1+···+ pK−1). (18.41)
The integral is the same as J(1) except for the replacement ni→ni+mi. So, from (18.38),
P(m1···mK|n1···nK)=M!
m1!···mK!(N+K−1)!
n1!···nK!(n1+m1)!···(nK+mK)!
(N+M+K−1)!
(18.42)
or, reorganizing into binomial coefﬁcients, the generalization of (18.24) is
P(m1···mK|n1···nK)=/parenleftbiggn1+m1
n1/parenrightbigg
···/parenleftbiggnK+mK
nK/parenrightbigg
/parenleftbiggN+M+K−1
M/parenrightbigg . (18.43)
In the case where we want just the probability that A1will be true on the next trial, we
need this formula with M=m1=1, all other mi=0. The result is the generalized rule

<<<PAGE 603>>>

18 The A pdistribution and rule of succession 571
of succession:
P(A1|n1NK)=n1+1
N+K. (18.44)
We see that, in the case N=n1=0, this reduces to the answer provided by the principle
of indifference, which it therefore contains as a special case. If Kis a power of 2, this is the
same as a method of inductive reasoning proposed by R. Carnap (1942), which he denotesc
∗(h,e)i nh i s Continuum of Inductive Methods .
Use of the rule of succession in cases where Nis very small is rather foolish, of course.
Not really wrong; just foolish. Because, if we have no prior evidence about A, and we
make such a small number of observations that we have practically no evidence, well, that’sjust not a very promising basis on which to do plausible reasoning. We can ’t expect to
get anything useful out of it. We do, of course, obtain deﬁnite numerical values for theprobabilities, but these values are very ‘soft,’ i.e. very unstable, because the A
pdistribution
is still very broad for small N. Our common sense tells us that the evidence Nnfor small
Nprovides no reliable basis for further predictions, and we’ll see that this conclusion also
follows as a consequence of the theory we are developing here.
The real reason for introducing the rule of succession lies in the cases where we doobtain
a signiﬁcant amount of information from the experiment; i.e. when Nis a large number. In
this case, fortunately, we can pretty much forget about these ﬁne points concerning priorevidence. The particular initial assignment ( A
p|X) will no longer have much inﬂuence on
the results, for the same reason as in the particle-counter problem of Chapter 6. This remainstrue for the generalized case leading to (18.43). You see from (18.44) that, as soon as thenumber of observations Nis large compared with the number of hypotheses K, then the
probability assigned to any particular hypothesis depends, for all practical purposes, only onwhat we have observed, and not on how many prior hypotheses there are. If you contemplatethis for ten seconds, your common sense will tell you that the criterion N/greatermuchKis exactly
the right one for this to be so.
In the literature starting with Venn (1866), those who issued polemical denunciations of
Laplace’s rule of succession have put themselves in an incredible situation. How is it possiblefor one human mind to reject Laplace’s rule – and then advocate a frequency deﬁnition ofprobability? Anyone who assigns a probability to an event equal to its observed frequencyin many trials is doing just what Laplace’s rule tells him to do! The generalized rule (18.44)supplies an obviously needed reﬁnement of this, small correction terms when the numberof observations is not large compared with the number of propositions.
18.11 Conﬁrmation and weight of evidence
A few new ideas – or rather, connections with familiar old ideas – are suggested by our
calculations involving A
p. Although we shall not make any particular use of them, it seems
worthwhile to point them out. We saw that the stability of a probability assignment in theface of new evidence is essentially determined by the width of the A
pdistribution. If Eis

<<<PAGE 604>>>

572 Part 2 Advanced applications
prior evidence and Fis new evidence, then
P(A|EF)=/integraldisplay1
0dpp(Ap|EF)=/integraltext1
0dpp(Ap|F)(Ap|E)
/integraltext1
0dp(Ap|F)(Ap|E). (18.45)
We might say that Fiscompatible with E, as far as Ais concerned, if having the new
evidence, F, doesn’t make any appreciable change in the probability of A;
P(A|EF)=P(A|E). (18.46)
The new evidence can make an enormous change in the distribution of Apwithout changing
the ﬁrst moment. It might sharpen it up very much, or broaden it. We could become eithermore certain or more uncertain about A, but if Fdoesn’t change the center of gravity of the
A
pdistribution, we still end up assigning the same probability to A.
Now, the stronger property: the new evidence F conﬁrms the previous probability assign-
ment, if Fis compatible with it, and at the same time, gives us more conﬁdence in it. In other
words, we exclude one of these possibilities, and with new evidence FtheApdistribution
narrows. Suppose Fconsists of performing some random experiment and observing the fre-
quency with which Ais true. In this case F=Nn, and our previous result, Eq. (18.22), gives
(Ap|Nn)=(N+1)!
n!(N−n)!pn(1−p)N−n≈(constant)·exp/braceleftbigg
−(p−f)2
2σ2/bracerightbigg
, (18.47)
where
σ2=f(1−f)
n, (18.48)
and f=(n/N) is the observed frequency of A. The approximation is found by expanding
log(Ap|Np) in a Taylor series about its peak value, and is valid when n/greatermuch1 and
(N−n)/greatermuch1. If these conditions are satisﬁed, then ( Ap|Nn) is very nearly symmetric
about its peak value. Then, if the observed frequency fis close to the prior probability
P(A|E), the new evidence Nnwill not affect the ﬁrst moment of the Apdistribution, but
will sharpen it up, and that will constitute a conﬁrmation as we have deﬁned it.
This shows one more connection between probability and frequency. We deﬁned the
‘conﬁrmation’ of a probability assignment according to entirely different ideas than areusually used to deﬁne it. We deﬁne it in a way that agrees with our intuitive notation ofconﬁrmation of a previous state of mind. But it turned out that the same experimental
evidence would constitute conﬁrmation on either the frequency theory or our theory.
Now, from this we can see another useful notion, which we will call weight of evidence.
Consider A
p, given two different pieces of evidence, EandF,
(Ap|EF)=(constant)×(Ap|E)(Ap|F). (18.49)
If the distribution ( Ap|F) was very much sharper than the distribution ( Ap|E), then the
product of the two would still have a peak at practically the value determined by F. In this
case, we would say intuitively that the evidence Fcarries much greater ‘weight’ than the
evidence E.I fw eh a v e F, it doesn’t really matter much whether we take Einto account or

<<<PAGE 605>>>

18 The A pdistribution and rule of succession 573
not. On the other hand, if we don’t have F, then whatever evidence Emay represent will
be extremely signiﬁcant, because it will represent the best we are able to do. So, acquiringone piece of evidence which carries a great amount of weight can make it, for all practicalpurposes, unnecessary to continue keeping track of other pieces of evidence which carryonly a small weight.
Of course, this is the way our minds operate. When we receive one very signiﬁcant piece
of evidence, we no longer pay so much attention to vague evidence. In so doing, we arenot being very inconsistent, because it wouldn’t make much difference anyway. So, ourintuitive notion of weight of evidence is bound up with the sharpness of the A
pdistribution.
Evidence concerning Athat we consider very signiﬁcant is not necessarily evidence that
makes a big change in the probability of A. It is evidence that makes a big change in our
density for Ap. Seeing this, we can gain a little more insight into the principle of indifference
and also make contact between this theory and Carnap’s methods of inductive reasoning.
18.11.1 Is indifference based on knowledge or ignorance?
Before we can use the principle of indifference to assign numerical values of probabilities,
there are two different conditions that must be satisﬁed: (1) we must be able to analyze thesituation into mutually exclusive, exhaustive possibilities; (2) having done this, we mustthen ﬁnd the available information gives us no reason to prefer any of the possibilities to anyother. In practice, these conditions are hardly ever met unless there’s some evident elementof symmetry in the problem. But there are two entirely different ways in which condition(2) might be satisﬁed. It might be satisﬁed as a result of ignorance, or it might be satisﬁedas a result of positive knowledge about the situation. To illustrate this, let’s suppose that aperson who is known to be very dishonest is going to toss a coin, and that there are twopeople watching him. Mr Ais allowed to examine the coin. He has all the facilities of the
National Bureau of Standards at his disposal. He performs hundreds of experiments withscales and calipers, magnetometers and microscopes, X-rays and neutron beams, and soon. Finally, he is convinced that the coin isperfectly honest. Mr Bis not allowed to do
this. All he knows is that a coin is being tossed by a shady character. He suspects the coinis biased, but he has no idea in which direction. Condition (2) is satisﬁed equally well forboth of them. Each would start out by assigning probability one-half to each face. The sameprobability assignment can describe a condition of complete ignorance or a condition ofvery great knowledge. This has seemed paradoxical for a long time. Why doesn’t Mr A’s
extra knowledge make any difference? Well, of course, it does make a difference. It makes
a very important difference, but one that doesn’t show up until we start performing thisexperiment. The difference is not in the probability for A, but in the density forA
p.
Suppose the ﬁrst toss is heads. To Mr B, that constitutes evidence that the coin is biased
to favor heads. And so, on the next toss, he would assign new probabilities to take that intoaccount. But to Mr A, the evidence that the coin is honest carries overwhelmingly greater
weight than the evidence of one throw, and he’ll continue to assign a probability of 1 /2.
You see what’s going to happen. To Mr B, every toss of the coin represents new evidence
about its bias. Every time it’s tossed, he will revise his assignment for the next toss; but,

<<<PAGE 606>>>

574 Part 2 Advanced applications
after several tosses, his assignment will get more and more stable, and in the limit n→∞
they will tend to the observed frequency of heads. To observer A, the prior evidence of
symmetry continues to carry greater weight than the evidence of almost any number ofthrows, and he persists in assigning the probability 1 /2. Each has done consistent plausible
reasoning on the basis of the information available to him, and our theory accounts for thebehavior of each.
If you assumed that Mr Ahad perfect knowledge of symmetry, you might conclude that
hisA
pdistribution is a δ-function. In that case, his mind could never be changed by any
amount of new data. Of course, that’s a limiting case that’s never reached in practice. Noteven the Bureau of Standards can give us evidence that good.
18.12 Carnap’s inductive methods
The philosopher Rudolph Carnap (1952) gives an inﬁnite family of possible ‘inductive
methods’ by which one can convert prior information and frequency data into a probabilityassignment and an estimate of frequencies for this future. His ad hoc principle (that is, a
principle that is found from intuition rather than from the rules of probability theory) isthat the ﬁnal probability assignment P(A|N
nX) should be a weighted average of the prior
probability P(A|X) and the observed frequency, f=n/N. Assigning a weight Nto the
‘empirical factor’ f, and an arbitrary weight λto the ‘logical factor’ P(A|X) leads to the
method which Carnap denotes by cλ(h,e). Introduction of the Apdistribution accounts for
this in more detail; the theory developed here includes all of Carnap’s methods as specialcases corresponding to different prior densities ( A
p|X), and leads us to reinterpret λas
the weight of prior evidence. Thus, in the case of two hypotheses, the Carnap λmethod is
the one you can calculate from the prior density ( Ap|X)=(constant)·[p(1−p)]r, with
2r=λ−2. The result is
P(A|NnX)=2n+λ
2N+2λ=(n+r)+1
(N+2r)+2. (18.50)
Greater λthus corresponds to a more sharply peaked ( Ap|X) density.
In our coin-tossing example, Mr A from the Bureau of Standards reasons according to
a Carnap method with λof the order of, perhaps, thousands; while Mr B, with much less
prior knowledge about the coin, would use aλof perhaps 5 or 6. (The case λ=2, which
gives Laplace’s rule of succession, is much too broad to be realistic for coin tossing; forMrBsurely knows that the center of gravity of a coin can’t be moved by more than half
its thickness from the geometrical center. Actually, as we saw in Chapter 10, this analysisisn’t always applicable to tossing of real coins, for reasons having to do with the laws ofphysics.)
From the second way we wrote Eq. (18.50), we see that the Carnap λmethod corresponds
to a weight of prior evidence which would be given by ( λ−2) trials, in exactly half of which
Awas observed to be true. Can we understand why the weighting of prior evidence is λ=
(number of prior trials +2), while that of the new evidence N
pis only (number of new
trials)=N? Well, look at it this way. The appearance of the ( +2) is the robot’s way of

<<<PAGE 607>>>

18 The A pdistribution and rule of succession 575
telling us this: prior knowledge that is possible forAto be either true or false is equivalent
to knowledge that Ahas been true at least once, and false at least once. This is hardly a
derivation, but it makes reasonably good sense.
Let’s pursue this line of reasoning a step further. We started with the statement X:i t
ispossible forAto be either true or false at any trial. But that is still a somewhat vague
statement. Suppose we interpret it as meaning that Ahas been observed true exactly once,
and false exactly once. If we grant that this state of knowledge is correctly describedby Laplace’s assignment ( A
p|X)=1, then what was the ‘pre-prior’ state of knowledge X 0
before we had the data X ? To answer this, we need only to apply Bayes’ theorem backwards,
as we did in the method of imaginary results in Chapter 5 and in urn sampling in Chapter 6.The result is: our ‘pre-prior’ A
pdistribution must have been
(Ap|X0)dp=(constant)dp
p(1−p). (18.51)
This is just the quasi-distribution representing ‘complete ignorance’, or the ‘basic measure’
of our parameter space, that we found by transformation groups in Chapter 12 and whichHaldane (1932) had suggested long ago. So, here is another line of thought that could haveled us to this measure. By the same line of thought we found the discrete version of (18.51)already in Chapter 6, Eq. (6.49).
It appears, then, that if we have deﬁnite prior evidence that it ispossible for Ato be either
true or false on any one trial, then Laplace’s rule ( A
p|X)=1 is the appropriate one to use.
But if initially we are so completely uncertain that we’re not even sure whether it is possible
forAto be true on some trials and false on others, then we should use the prior (18.51).
How different are the numerical results which the pre-prior assignment (18.51) gives us?
Repeating the derivation of (18.22) with this pre-prior assignment, we ﬁnd that, providednis not zero or N,
(A
p|NnX0)=(N−1)!
(n−1)! (N−n−1)!pn−1(1−p)N−n−1, (18.52)
which leads, instead of to Laplace’s rule of succession, to the mean-value estimate of p:
P(A|NnX0)=/integraldisplay1
0dpp(Ap|Nn)=n
N, (18.53)
equal to the observed frequency, and identical with the maximum likelihood estimate of p.
Likewise, provided 0 <n<N, we ﬁnd instead of (18.24) the formula
P(Mm|NnX0)=/parenleftbigm+n−1
m/parenrightbig/parenleftbigM−m+N−n−1
M−m/parenrightbig
/parenleftbigN+M−1
M/parenrightbig . (18.54)
All of these results correspond to having observed one less success and one less failure.

<<<PAGE 608>>>

576 Part 2 Advanced applications
18.13 Probability and frequency in exchangeable sequences
We are now in a position to say quite a bit more about connections between probabil-
ity and frequency. There are two main types of connections: (a) given an observed fre-quency in a random experiment, convert this information into a probability assignment; and(b) given a probability assignment, predict the frequency with which some condition will berealized. We have seen, in Chapters 11 and 12, how the principles of maximum entropy andtransformation groups lead to probability assignments which, if the quantity of interest hap-pens to be the result of some ‘random experiment’, correspond automatically to predictedfrequencies, and thus solve problem (b) in some situations.
The rule of succession gives us the solution to problem (a) in a wide class of problems.
If we have observed whether Awas true in a very large number of trials, and the only
knowledge we have about A is the result of this random experiment, and the consistencyof the ‘causal mechanism’, then it says that the probability we should assign to Aat the
next trial becomes practically equal to the observed frequency. Now, in fact, this is exactlywhat people who deﬁne probability in terms of frequency do: one postulates the existanceof an unknown ‘absolute’ probability, whose numerical value is to be found by performingrandom experiments. Of course, you must perform a very large number of experiments. Thenthe observed frequency of Ais taken as the estimate of the probability. As we saw earlier in
this chapter, even the +1 and+2 in Laplace’s formula turn up when the ‘frequentist’ reﬁnes
his methods by taking the center of a conﬁdence interval. So, I don’t see how even the mostardent advocates of the frequency theory of probability can damn the rule of successionwithout thereby damning his own procedures; after all polemics, there remains the simplefact that in his own procedures, he is doing exactly what Laplace’s rule of succession tellshim to do. Indeed, to deﬁne probability in terms of frequency i s equivalent to saying that
the rule of succession is the only rule which can be used for converting observational data
into probability assignments.
18.14 Prediction of frequencies
Now let’s consider problem (b) in this situation: to reason from a probability to a frequency.
This is simply a problem of parameter estimation, not different in principle from any other.Suppose that instead of asking for the probability that Awill be true in the next trial, we
wish to infer something about the relative frequency of Ain an indeﬁnitely large number
of trials, on the basis of the evidence N
n. We must take the limit of (18.24) as M→∞ ,
m→∞ , in such a way that ( m/M)→f. Introducing the proposition
Af=the frequency of Atrue in the indeﬁnitely large number
of trials is f,(18.55)
we ﬁnd in the limit that the probability density of Af,g i v e n Nn,i s
P(Af|Nn)=(N+1)!
N!(N−n)!fn(1−f)N−n, (18.56)

<<<PAGE 609>>>

18 The A pdistribution and rule of succession 577
which is the same as our ( Ap|Nn) in (18.22), with fnumerically equal to p. According
to (18.55), the most probable frequency is equal to ( n/N), the observed frequency in the
past. But we have noted before that in parameter estimation (if you object to my calling
fa ‘parameter’, then let’s just call it ‘prediction’), the most probable value is usually a
poorer estimate than the mean value in the small sample case, where they can be appreciablydifferent. The mean-value estimate of the frequency is
f=/integraldisplay1
0dffP(Af|Nn)=n+1
N+2, (18.57)
i.e. just the same as the value of P(A|Nn), (18.25), given by Laplace’s rule of succession.
Thus, we can interpret the rule in either way; the probability which Laplace’s theory assigns
to A at a single trial is numerically equal to the estimate of frequency which minimizes theexpected square of the error. You see how nicely this corresponds with the relationship
between probability and frequency which we found in the maximum entropy and transfor-mation group arguments.
Note also that the distribution P(A
f|Nn) is quite broad for small N, conﬁrming our
expectation that no reliable predictions should be possible in this case. As a numerical
example, if Ahas been observed true once in two trials, then f=P(A|Nn)=1/2, but
according to (18.55) it is still an even bet that the true frequency flies outside the interval
0.326<f<0.674. With no evidence at all ( N=n=0), it would be an even bet that f
lies outside the interval 0 .25<f<0.75. More generally, the variance of (18.55) is
varP(Af|Nn)=f2−f2=f(1−f)
N+3, (18.58)
so that the expected error in the estimate (18.56) decreases like 1 /√
N. More detailed
conclusions about the reliability of predictions, which we could make from (18.56), are,for all practical purposes, identical with those the statistician would make by the method ofconﬁdence intervals.
All these results hold also for the generalized rule of succession. Taking the limit of
(18.43) as M→∞ ,m
i/M→fi, we ﬁnd the joint probability density function for Aito
occur with frequency fito be
P(f1···fk|n1···nk)=(N+K)!
n1!···nk!(fn1
1···fnk
k)δ(f1+···+ fk−1). (18.59)
The probability that the frequency f1will be in the range d f1is found by integrating (18.59)
over all values of f2,..., fkcompatible with f1≥0, (f2+···+ fk)=1−f1. This can
be carried out by application of Laplace transforms in a well-known way, and the result is
P(f1|n1···nk)=(N+K−1)!
n1!(N−n1+K−2)!fn1
1(1−f1)N−n1+K−2, (18.60)
from which we ﬁnd the most probable value to be
/parenleftbigˆf1/parenrightbig
=n1
N+K−2(18.61)

<<<PAGE 610>>>

578 Part 2 Advanced applications
and the mean value to be
f1=n1+1
N+K, (18.62)
which is Laplace’s rule of succession (18.44).
Another interesting result is found by taking the limit of P(Mm|Ap) in (18.18) as
M→∞ ,(m/M)→f;w eﬁ n d
P(Mm|Ap)=δ(f−p). (18.63)
Likewise, taking the limit of ( Ap|Nn) in (18.22) as N→∞ ,w eﬁ n d
(Ap|Af)=δ(f−p), (18.64)
which follows from (18.63) by application of Bayes’ theorem. Therefore, if Bis any
proposition, we have, from our standard argument,
P(B|Af)=/integraldisplay1
0dp(BA p|Af)=/integraldisplay1
0dpP(B|ApAf)(Ap|Af)
=/integraldisplay1
0dpP(B|Ap)δ(p−f).(18.65)
In the last step we used the property (18.1) that Apautomatically neutralizes any other
statement about A. Thus, if fandpare numerically equal, we have P(B|Ap)=P(B|Ap);
ApandAfareequivalent statements in their implication for plausible reasoning.
To verify this equivalence in one case, note that in the limit N→∞ ,(n/N)→f,
P(Mm|Nn) in Eq. (18.24) reduces to the binomial distribution P(Mm|Ap) as given by
(18.18). The generalized formula (18.43), in the corresponding limit, goes into the multi-nomial distribution,
P(m
1···mk|f1···fk)=m!
m1!···mk!fm1
1···fmk
k. (18.66)
This equivalence shows why it is so easy to confuse the notion of probability and fre-
quency, and why in many problems this confusion does no harm. Whenever the availableinformation consists of observed frequencies in a large sample, and constancy of the ‘causalmechanism’, Laplace’s theory becomes mathematically equivalent to the frequency theory.Most of the ‘classical’ problems of statistics (life insurance, etc.) are of just this type; and
as long as one works only on such problems, all is well. The harm arises when we considermore general problems.
Today, physics and engineering offer many important applications for probability theory
in which there is an absolutely essential part of the evidence which cannot be stated in termsof frequencies, and/or the quantities about which we need plausible inference have nothingto do with frequencies. The axiom (probability) ≡(frequency), if applied consistently,
would prevent us from using probability theory in these problems.

<<<PAGE 611>>>

18 The A pdistribution and rule of succession 579
18.15 One-dimensional neutron multiplication
Our discussion so far has been rather abstract; perhaps too much so. In order to make amends
for this, I would like to show you a speciﬁc physical problem where these equations apply.This was ﬁrst described in a short note by Bellman, Kalaba and Wing (1957) and furtherdeveloped in a more recent book by Wing (1962). Neutrons are traveling in ﬁssionablematerial, and we want to estimate how many new neutrons will be produced in the long runas a consequence of one incident trigger neutron. In order to have a tractable mathematicalproblem, we make some drastic simplifying assumptions as follows.
(a) The neutrons travel only in the ±xdirection at a constant velocity.
(b) Each time a neutron, traveling either to the right or the left, initiates a ﬁssion reaction, the result
is exactly two neutrons, one traveling to the right, one to the left. The net result is therefore thatany neutron will from time to time emit a progeny neutron traveling in the opposite direction.
(c) The progeny neutrons are immediately able to produce still more progeny in the same manner.
We ﬁre a single trigger neutron into a thickness xof ﬁssionable material from the left,
and the problem is to predict the number of neutrons that will emerge from the left and fromthe right, over all time, as a consequence. At least, that is what we would liketo calculate.
But, of course, the number of emerging neutrons is not determined by any of the given data,
and so the best we can do is to calculate the probability that exactly nneutrons will be
transmitted or reﬂected. We want to make a detailed comparison of the Laplace theory andthe frequency theory of probability, as applied to the initial formulation of this problem. Weare concerned mainly with the underlying rationale by which we relate probability theory
to the physical model.
Many proponents of the frequency theory berate the Laplace theory on purely philosoph-
ical grounds that have nothing to do with its success or failure in applications. There isa more defensible position, held by some, who recognize that the present state of affairsgives them no reason for smugness, and a good reason for caution. While they believethat at present the frequency theory is superior, they also say, as one of my correspon-dents did to me, ‘I will most cheerfully renounce the frequency thoery for any theory thatyields me a better understanding and a more efﬁcient formalism.’ The trouble is that thecurrent statistical literature gives us no opportunity to see the Laplace theory in actualuse so that valid comparisions could be made; and that is the situation we are trying tocorrect here.
18.15.1 The frequentist solution
Firstly, let us formulate the problem as it would be done using the frequency theory. Here
is the way in which the ‘frequentist’ would reason:
The experimentalists have measured for us the relative frequency p=a/Delta1of ﬁssion
in a very small thickness /Delta1of this material. This means that they have ﬁred Ntrigger
neutrons at a thin ﬁlm of thickness /Delta1, and observed ﬁssion in ncases. Since Nis ﬁnite,
we cannot ﬁnd the exact value of pfrom this, but it is approximately equal to the observed

<<<PAGE 612>>>

580 Part 2 Advanced applications
frequency ( n/M). More precisely, we can ﬁnd conﬁdence limits for p. In similar situations,
we can expect about k% of the time, the limits (Cram´ er, 1946, p. 515)
N
N+λ2/bracketleftBigg
2n+λ2
2N±λ/radicalbigg
n(N−n)
N3+λ2
4N2/bracketrightBigg
(18.67)
will include the true value of p, where λis the (100−k)% value of a normal deviate. For
example, with λ=√
2, the range
n+1
N+2±N
N+2/radicalbigg
2n(N−n)
N3+1
N2=n+1
N+2±/radicalbigg
2n(N−n)
N3(18.68)
will cover the correct pin about 84% of similar cases. [Again, there’s that +1 and+2o f
Laplace’s rule of succession!] In general, the connection between λandkisgiven by
1√
2π/integraldisplayλ
−λdxexp/braceleftbigg
−x2
2/bracerightbigg
=k
100. (18.69)
Equation (18.67) is an approximation valid when the numbers nand ( N−n) are sufﬁciently
large; the exact conﬁdence limits are difﬁcult to express analytically, and for small N
one should consult the graphs of E.S. Pearson and Clopper (1934). The number pis, of
course, a deﬁnite, but imperfectly known, physical constant characteristic of the ﬁssionable
material.
Now, in order to calculate the relative frequency with which nneutrons will be reﬂected
from a thickness xof this material, we have to make some additional assumptions. We
assume that the probability of ﬁssion per unit length is always the same for each neutronindependent of its history. Due to the complexity of the causes operating, it seems reasonableto assume this; but the real test of whether it is a valid assumption can come only fromcomparison of the ﬁnal results of our calculation with experiment. This assumption meansthat the probabilities of ﬁssion in successive slabs of thickness /Delta1are independent, so that,
for example, the probability that an incident neutron will undergo ﬁssion in the second slabof thickness /Delta1, but not in the ﬁrst, is the product p(1−p).
At this point, we turn to the mathematics and solve the problem by any one of several
possible techniques, emerging with the relative frequencies p
n(x),qn(x) for reﬂection or
transmission of nneutrons, respectively. [Actually, the analytical solution has not yet been
found, but Wing (1962) gives the results of numerical integration, which is equally goodfor our purposes.]
We now compare these predictions with experiment. When the ﬁrst trigger neutron is
ﬁred into the thickness x, we observe r
1neutrons reﬂected and t1neutrons transmitted.
These data do not in any way affect the assignments pn(x) and qn(x), since the latter
have no meaning in terms of a single experiment, but are predictions only of limitingfrequencies for an indeﬁnitely large number of experiments. We therefore must repeat the

<<<PAGE 613>>>

18 The A pdistribution and rule of succession 581
experiment many times, and record the numbers ri,tifor each experiment. If we ﬁnd that
the frequency of cases for which ri=ntends sufﬁciently close to pn(x) (‘sufﬁciently close’
being determined by certain signiﬁcance tests such as chi-squared), then we conclude thatthe theory is satisfactory; or at least that it is not rejected by the data. If, however, the observedfrequencies show a wide departure from p
n(x), then we know that there is something wrong
with our initial set of assumptions.
Now, of course, the theory is either right or wrong. If it is wrong, then in principle the
entire theory is demolished, and we have to start all over again, trying to ﬁnd the right theory.In practice, it may happen that only one minor feature of the theory has to be changed, sothat most of the old calculations will be useful in the new theory.
18.15.2 The Laplace solution
Now let’s state this same problem in terms of Laplace’s theory. We regard it simply as
an exercise in plausible reasoning, in which we make the best possible guesses as to theoutcome of a single experiment, or of a ﬁnite number of them. We are not concerned with
the prediction, or even the existence, of limiting frequencies; because any assertion about
the outcome of an impossible experiment is obviously an empty statement, and cannot be
relevant to any applications. We reason as follows.
The experimentalists have provided us with the evidence N
n, by ﬁring Nneutrons at a
thin ﬁlm of thickness /Delta1, and observing ﬁssion in ncases. Since by hypothesis the only
prior knowledge was that a neutron either will or will not undergo ﬁssion, we have just thesituation where Laplace’s rule of succession applies and the probability, on this evidence,of ﬁssion for the ( N+1)th neutron in thickness /Delta1,i s
p≡P(F
N+1|Nn)=n+1
N+2, (18.70)
where
Fm≡thenth neutron will undergo ﬁssion. (18.71)
Whether Nis large or small, the question of the ‘accuracy’ of this probability does not
arise – it is exact by deﬁnition. Of course, we will prefer to have as large a value of Nas
possible, since this increases the weight of the evidence Nnand makes the probability p
not more accurate , but more stable . The probability pis manifestly nota physical property
of the ﬁssionable material, but is only a means of describing our state of knowledge aboutit, on the basis of the evidence N
n. If the preliminary experiment had yielded a different
result N/prime
n, then we would of course assign a different probability p/prime; but the properties of
the ﬁssionable material would remain the same.
We now ﬁre a neutron at a thickness x=Mδ, and deﬁne the propositions
Fn≡the neutron will cause ﬁssion in the nth slab of thickness /Delta1;
fn≡the neutron will not cause ﬁssion in the nth slab.

<<<PAGE 614>>>

582 Part 2 Advanced applications
The probability of ﬁssion in slab 1 is then
p≡P(F1|Nn)=n+1
N+2. (18.72)
But now the probability that ﬁssion will occur in the second but not the ﬁrst slab is not
p(1−p) as in the ﬁrst treatment. At this point we see one of the fundamental differences
between the theories. From the product rule, we have
P(F2F1|Nn)=P(F2|F1Nn)P(F1|Nn)
=n+1
N+2/bracketleftbigg
1−n+1
N+2/bracketrightbigg
=(n+1)(N−n+1)
(N+2)(N+3).(18.73)
The difference is that, in calculating the probability P(F2|F1Nn), we must take into account
the evidence, F1, that a neutron has passed through one more thickness /Delta1without ﬁssion.
This amounts to one more experiment in addition to that leading to Nn. The evidence F1
is fully as cogent as Nn, and it would be clearly inconsistent to take one into account and
ignore the other. Continuing in this way, we ﬁnd that the probability that the incident neutronwill emit exactly mﬁrst-generation progeny in passing through thickness M/Delta1is just the
expression
P(M
m|Nn)=/parenleftbiggM
m/parenrightbigg(n+m)!(N+1)!(N+M−n−m)!
n!(N−n)!(N+M+1)!, (18.74)
which we have derived before, Eq. (18.24). Now, if Nis not a very large number, this may
differ appreciably from the value
P(Mm|Ap)=/parenleftbiggM
m/parenrightbigg
pm(1−p)M−m, (18.75)
which one obtains in the frequency approach. However, note again that, as the weight of
evidence Nnincreases, we ﬁnd ( Ap/prime|Nn)→δ(p/prime−n/N), and
P(Mn|Nn)→P(Mm|Ap) (18.76)
in the limit N→∞ ,(n/N)→p. The difference in the two results is negligible whenever
N/greatermuchM; i.e. when the weight of evidence Nngreatly exceeds Mm. Now let’s study the
difference between (18.74) and (18.75) more closely. From (18.74) we have, for the mean-value estimate of m, on the Laplace theory,
m=Mn+1
N+2. (18.77)

<<<PAGE 615>>>

18 The A pdistribution and rule of succession 583
To state the accuracy of this estimate, we can calculate the variance of the distribution
(18.74). This is most easily done by using the representation (18.23):
m2=M/summationdisplay
m=0m2/integraldisplay1
0dpP(Mm|Ap)(Ap|Nn)
=(N+1)!
n!(N−n)!/integraldisplay1
0dp/bracketleftbig
Mp+M(M−1)p2/bracketrightbig
pn(1−p)N−n
=Mn+1
N+2+M(M−1)(n+1)(n+2)
(N+2)(N+3),(18.78)
which gives the variance
V≡M2−m2=M/bracketleftbiggN+M+2
N+3/bracketrightbigg/bracketleftbiggn+1
N+2/bracketrightbigg/bracketleftbigg
n−n+1
N+2/bracketrightbigg
; (18.79)
while, from (18.75), the frequency theory gives
m0=Mp (18.80)
V0≡/bracketleftBig
m2−m2/bracketrightBig
0=Mp(1−p). (18.81)
If the frequentist takes the center of the conﬁdence interval (18.68) as his ‘best’ estimate of
p, then he will take p=(n+1)/(N+2) in these equations. So, we both obtain the same
estimate, but the variance (18.79) is greater by the amount
V−V0=M−1
N+3Mp(1−p). (18.82)
Why this difference? Why is it that the Laplace theory seems to determine the value of m
less precisely then the frequency theory? Well, appearances are deceptive here. The fact isthat the Laplace theory determines the value of m more precisely than the frequency theory;
the variance (18.81) is not the entire measure of the uncertainty as to mon the frequency
theory, because there is still the uncertainty as to the ‘true’ value of p. According to (18.81),
pis uncertain by about ±√
2p(1−p)/N, so the mean value (18.80) is uncertain by about
±/radicalbigg
2p(1−p)
N(18.83)
in addition to the uncertainty represented by (18.81). If we suppose that the uncertainties
(18.81) and (18.83) are independent, the total mean-square uncertainty as to the value of m
on the frequency theory would be represented by the sum of (18.81) and
M22p(1−p)
N, (18.84)

<<<PAGE 616>>>

584 Part 2 Advanced applications
which more than wipes out the difference (18.82). The factor of 2 in (18.84) would of course
be changed somewhat by adopting a different conﬁdence level, but no reasonable choicecan change it very much.
In the frequency theory, the two uncertainties (18.81) and (18.84) appear as entirely
separate effects which are determined by applying two different principles: one by conven-tional probability theory, the other by conﬁdence intervals. In the Laplace theory no suchdistinction exists; both are given automatically by a single calculation. We found exactly
this same situation in our particle-counter problem in Chapter 6, when we compared ourrobot’s procedure with that of the orthodox statistician.
The mechanism by which the Laplace theory is able to do this is very interesting. It is
just the difference already noted; in the derivation of (18.74), we are continually taking intoaccount additional evidence accumulated in the new experiment, such as F
1in (18.73). In
the frequency theory, the uncertainty (18.83) in parises because only a ﬁnite amount of
data was provided by the preliminary experiment given Nn. It is just for that reason that new
evidence, such as F1, is still relevant. In giving a consistent treatment of allthe evidence,
the Laplace theory automatically includes the effect of the ﬁniteness of the preliminary data,which the frequency theory is able to do only crudely by the introduction of conﬁdenceintervals. In the Laplace theory there is no need to decide on any arbitrary ‘conﬁdence
level’ because probability theory, when consistently applied to the whole problem, already
tells us what weight should be given to the preliminary data N
n. What we get in return
for this is not merely a more uniﬁed treatment; in yielding a smaller net uncertainity in m,
the Laplace theory shows that the two sources of uncertainity (18.81) and (18.84) of thefrequency theory are notindependent: they have a small negative correlation, so that they
tend to compensate each other. That is the reason for Laplace’s smaller probable error. If youthink about this very hard, you will be able to see intuitively why this negative correlation
has to be ther e–Iw o n ’ t deprive you of the pleasure of ﬁguring it out for yourself. All this
subtlety is completely lost in the frequency theory.
‘But,’ someone will object, ‘you are ignoring a very practical consideration which was
the original reason for introducing conﬁdence intervals. While I grant that in principle it is
better to treat the whole problem in a single calculation, in practice we usually have to break
it up into two different ones. After all, the preliminary data N
nwere obtained by one group
of people, who had to communicate their results to another group, who then carried out thesecond calculation applying these data. It is a practical necessity that the ﬁrst group be ableto state their conclusions in a way that tells honestly what they found, and how reliable
it was. Their data can also be used in many other ways than in your second calculation,
and the introduction of conﬁdence intervals thus ﬁlls a very important practical need forcommunication between different workers.’
Of course, if you have followed everything so far, you know the answer to this. The
memory storage problem was our original point of departure, and the problem just discussedis a speciﬁc example of just what we pointed out more abstractly in Eq. (18.16). Yo u see from
(18.23), and also in our derivation of (18.79), that the only property of the preliminary datawhich we needed in order to analyze the whole problem was the A
pdistribution ( Ap|Nn)

<<<PAGE 617>>>

18 The A pdistribution and rule of succession 585
that resulted from the preliminary experiment. The principle of conﬁdence intervals was
introduced to ﬁll a very practical need. But there was no need to introduce any new principlefor this purpose; it is already contained in probability thoery, which shows that the exact
way of communicating what you have learned is not by specifying conﬁdence intervals, butby specifying your ﬁnal A
pdistribution.
As a further point of comparison, note that in the Laplace theory there was no need
to introduce any ‘statistical assumption’ about independence of events in successive slabsof thickness /Delta1. In fact, the theory told us, as in (18.73), that these probabilities are not
independent when we have only a ﬁnite amount of preliminary data; and it was just thisfact that enabled the Laplace theory to take account of the uncertainty which the frequencytheory describes by means of conﬁdence intervals.
This brings up a very fundamental point about probability theory, which the frequency
theory fails to recognize, but which is essential for applications to both communicationtheory and statistical mechanics, as we will show later. What do we mean by saying thattwo events are ‘independent’?
In the frequency theory, the only kind of independence recognized is causal independence;
i.e. the fact that one event occurred does not in itself exert any physical inﬂuence on theoccurrence of the other. Thus, in the coin-tossing example discussed in Chapter 6, the factthat the coin comes up heads on one toss of course doesn’t physically affect the result of
the next toss, and so on the frequency theory one would call the coin-tossing experiment atypical case of ‘independent repetitions of a random experiment’; the probability of a headsat both tosses must be the product of separate probabilities. But then we lose any way of
describing the difference between the reasoning of Mr Aand Mr B!
In Laplace’s theory, ‘independence’ means something entirely different, which we see
from a glance at the product rule: P(AB|C)=P(B|C)P(A|BC). Independence means that
P(A|BC)=P(A|C); i.e. knowledge thatBis true does not affect the probability we assign
toA. Thus, independence means not mere causal independence, but logical independence.
Even though heads at one toss does not physically predispose the coin to give heads at thenext, the knowledge that we got heads may have a very great inﬂuence on our predictions
as to the next toss.
The importance of this is that the various limit theorems, which we will say more about
later, require independence in their derivations. Consequently, even though there may bestrict causal independence, if there is not also logical independence, these limit theorems
will not hold. Writers of the frequency school of thought, who deny that probability the-ory has anything to do with inductive reasoning, recognize the existence only of causal
connections, and, as a consequence, they have long been applying these limit theoremsto physical and communications processes where, we claim, they are incorrect and com-pletely misleading. This was noted long ago by Keynes (1921), who stressed exactly thissame point.
I think these comparisons make it very clear that, at least in this kind of problem, the
Laplace theory does provide the ‘better understanding and more efﬁcient formalism’ that
my colleague asked for.

<<<PAGE 618>>>

586 Part 2 Advanced applications
18.16 The de Finetti theorem
So far we have considered the notion of an Apdistribution and derived a certain class of
probability distributions from it, under the restriction that the same A pdistribution is to be
used for all trials. Intuitively, this means that we have assumed the underlying ‘mechanism’as constant, but unknown. It is clear that this is a very restrictive assumption, and the question
arises: How general is the class of probability functions that we can obtain in this way? Inorder to state the problem clearly, let us deﬁne
x
n≡/braceleftbigg1i f Ais true on the nth trial
0i f Ais false on the nth trial.(18.85)
Then a state of knowledge about Ntrials is described in the most general way by a proba-
bility function P(x1...xN|N), which could, in principle, be deﬁned arbitrarily (except for
normalization) at each of the 2Npoints.
We now ask: What is a necessary and sufﬁcient condition on P(x1...xN|N) for it to
be derivable from an Apdistribution? What test could we apply to a given distribution
P(x1...xN|N) to tell whether it is included in our theory as given above? A necessary
condition is clear from our previous equations: any distribution obtainable from an Ap
distribution necessarily has the property that the probability that Ais true in n speciﬁed
trials, and false in the remaining ( N−n) trials, depends only on the numbers nandN; i.e.
not on which trials in 1≤n≤Nwere speciﬁed. If this is so, we say that P(x1...xN|N)
deﬁnes an exchangeable sequence.
An important theorem of de Finetti (1937) asserts that the converse is also true: any
exchangeable probability function P (x1...xN|N)can be generated by an A pdistribution.
Thus there is a function ( Ap|X)=g(p) such that g(p)≥0,/integraltext1
0dpg(p)=1, and the proba-
bility that in Ntrials Ais true in nspeciﬁed trials and false in the remaining ( N−n) trials,
is given by
P(n|N)=/integraldisplay1
0dppn(1−p)N−ng(p). (18.86)
This can be proved as follows. Note that pn(1−p)N−nis a polynomial of degree N:
pn(1−p)N−n=pnN−n/summationdisplay
m=0/parenleftbiggN−m
m/parenrightbigg
(−p)m
=N/summationdisplay
k=0αk(N,n)pk,(18.87)
which deﬁnes αk(N,n). Therefore, if(18.86) holds, we would have
P(n|N)=N/summationdisplay
k=0αk(N,n)βk, (18.88)

<<<PAGE 619>>>

18 The A pdistribution and rule of succession 587
where
βk=/integraldisplay1
0dppng(p) (18.89)
is the nth moment of g(p). Thus, specifying β0,...,β Nis equivalent to specifying all
theP(n|N) for n=0,..., N. Conversely, for given N, specifying P(n|N), 0≤n≤N,i s
equivalent to specifying {β0,...,β N}. In fact, βNis the probability that x1=x2=···=
xN=1, regardless of what happens in later trials, and its relation to P(n|N) can be estab-
lished directly without reference to any function g(p).
So, the problem reduces to this: if the numbers β0,...,β Nare speciﬁed, under what
conditions does a function g(p)≥0 exist such that (18.89) holds? This is just the well-
known Hausdorff moment problem, whose solution can be found in many places; for example
Widder (1941, Chap. 3). Translated into our notation, the main theorem is as follows. Anecessary and sufﬁcient condition that a function g(p)≥0 exists satisfying (18.89) (and
therefore also (18.86)) is that there exists a number Bsuch that
N/summationdisplay
n=0/parenleftbiggN
n/parenrightbigg
P(n|N)≤B, N=0,1,.... (18.90)
But, from the interpretation of P(n|N) as probabilities, we see that the equality sign always
holds in (18.90) with B=1, and the proof is completed.
Here is another way of looking at it, which might be made into a proof with a little more
work, and perhaps discloses more clearly the intuitive reason for the de Finetti theorem, aswell as showing immediately just how much we have said about g(p) when we specify the
P(n|N). Imagine g(p) expanded in the form
g(p)=∞/summationdisplay
n=0anφn(p), (18.91)
where φn(p) are the complete orthonormal set of polynomials in 0 ≤p≤1, essentially the
Legendre functions:
φn(p)=√
2n+1
n!dn
dpn[p(1−p)]n
=(−1)n√
2n+1Pn(2p−1),(18.92)
where φn(p) is a polynomial of degree n, and satisﬁes
/integraldisplay1
0dpφm(p)φn(p)=δmn. (18.93)
If we substitute (18.93) into (18.86), only a ﬁnite number of terms will survive, because
φk(p) is orthogonal to all polynomials of degree N<k. Then, it is easily seen that, for
given N, specifying the values of P(n|N), 0≤n≤N, is equivalent to specifying the ﬁrst
(n+1) expansion coefﬁcients {a0,..., aN}. Thus, as N→∞ , a function g(p), deﬁned
by (18.91), becomes uniquely determined to the same extent that a Fourier series uniquely

<<<PAGE 620>>>

588 Part 2 Advanced applications
determines its generating function; i.e. ‘almost everywhere’. The main trouble with this
argument is that the condition g(p)≥0 is not so easily established from (18.91).
18.17 Comments
The de Finetti theorem is very important to us because it shows that the connection between
probability and frequency which we have found in this chapter holds for a fairly wide classof probability functions P(x
1,..., xN|N), namely the class of all exchangeable sequences.
These results, of course, generalize immediately to the case where there are more than twopossible outcomes at each trial.
Possibly even more important, however, is the light which the de Finetti theorem sheds
on one of the oldest contro versies in probability theory – Laplace’s ﬁrst derivation of the
rule of succession. The idea of an A
pdistribution is not, needless to say, our own invention.
The way we have introduced it here is only our attempt to translate into modern languagewhat we think Laplace was trying to say in that famous passage, ‘When the probability ofa simple event is unknown, we may suppose all possible values of this probability between0 and 1 as equally likely.’ This statement, which we interpret as saying that, with no priorevidence, ( A
p|X)=const., has been rejected as utter nonsense by virtually everyone who
has written on probability theory in this century. And, of course, on any frequency de ﬁnition
of probability, Laplace’s statement would have no justiﬁcation at all. But on any theory it isconceptually difﬁcult, since it seems to involve the idea of a ‘probability of a probability’,and the use of an A
pdistribution in calculations has been largely avoided since the time of
Laplace.
The de Finetti theorem puts some much more solid ground under these methods. Inde-
pendently of all conceptual problems, it is a mathematical theorem that whenever you talk
about a situation where the probability of a certain sequence of results depends only on thenumber of successes, not on the particular trials at which they occur, all your probabilitydistributions can be generated from a single function g(p), in just the way we have done
here. The use of this generating function is, moreover, a very powerful technique mathemat-ically, as you will quickly discover if you try to repeat some of the above derivations (forexample, Eq. (18.24)) without using an A
pdistribution. So, it doesn’t matter what we might
think about the Apdistribution conceptually; its validity as a mathematical tool for dealing
with exchangeable sequences is a proven fact, standing beyond the reach of philosophicalobjections.

<<<PAGE 621>>>

19
Physical measurements
We have seen, in Chapter 7, how the great mathematician Leonhard Euler was unable to
solve the problem of estimating eight orbital parameters from 75 discrepant observationsof the past positions of Jupiter and Saturn. Thinking in terms of deductive logic, he couldnot even conceive of the principles by which such a problem could be solved. But, 38 years
later, Laplace, thinking in terms of probability theory as logic, was in possession of exactlythe right principles to resolve the great inequality of Jupiter and Saturn. In this chapter we
develop the solution as it would be done today by considering a simpler problem, estimating
two parameters from three observations. But our general solution, in matrix notation, will
include Laplace’s automatically.
19.1 Reduction of equations of condition
Suppose we wish to determine the charge eand mass mof the electron. The Millikan
oil-drop experiment measures edirectly. The deﬂection of an electron beam in a known
electromagnetic ﬁeld measures the ratio e/m. The deﬂection of an electron toward a metal
plate due to attraction of image charges measures e
2/m.
From the results of any two of these experiments we can calculate values of eandm. But
all the measurements are subject to error, and the values of eandmobtained from different
experiments will not agree. Yet each of the measurements does contain some informationrelevant to our question that is not contained in the others. How are we to process the data soas to make use of all the information available and get the best estimates of eandm? What is
the probable error remaining? How much would the situation be improved by including stillanother experiment of given accuracy? Probability theory gives simple and elegant answersto these questions.
More speciﬁcally, suppose we have the results of these experiments:
(1) measures ewith±2% accuracy;
(2) measures ( e/m) with±1% accuracy;
(3) measures ( e2/m) with±5% accuracy.
Supposing the values of eandmapproximately known in advance to be e≈e0,m≈m0,
the measurements are then linear functions of the corrections. Write the unknown true
589

<<<PAGE 622>>>

590 Part 2 Advanced applications
values of eandmas
e=e0(1+x1),
m=m0(1+x2);(19.1)
then, x1,x2are dimensionless corrections, small compared with unity, and our problem
is to ﬁnd the best estimates of x1andx2. The results of the three measurements are three
numbers M1,M2andM3, which we write as
M1=e0(1+y1),
M2=e0
m0(1+y2),
M3=e2
0
m0(1+y3),(19.2)
where the yiare also small dimensionless numbers which are deﬁned by (19.2) and are
therefore known in terms of the old estimates e0,m0and the new measurements M1,M2,
M3. On the other hand, the true values of e,e/m,e2/mare expressible in terms of the xj:
e=e0(1+x1),
e
m=e0(1+x1)
m0(1+x2)=e0
m0(1+x1−x2+··· ),
e2
m=e2
0(1+x1)2
m0(1+x2)=e0
m0(1+2x1−x2+··· ),(19.3)
where higher order terms are considered negligible. Comparing (19.2) and (19.3), we see
that if the measurements were exact we would have
y1=x1,
y2=x1−x2,
y3=2x1−x2.(19.4)
But, taking into account the errors, the known yiare related to the unknown xjby
y1=a11x1+a12x2+δ1,
y2=a21x1+a22x2+δ2,
y3=a31x1+a32x2+δ3,(19.5)
where the coefﬁcients aijform a (3×2) matrix:
A=
a11a12
a21a22
a31a32
=
10
1−1
2−1
, (19.6)
and the δiare the unknown fractional errors of the three measurements. For example, the
statement that δ2=−0.01 means that the second measurement gave a result 1% too small.

<<<PAGE 623>>>

19 Physical measurements 591
More generally, we have nunknown quantities {x1,..., xn}to be estimated from N
imperfect observations {y1,..., yN}, and the Nequations of condition,
yi=n/summationdisplay
j=1aijxj+δi, i=1,2,..., N, (19.7)
or, in matrix notation,
y=Ax+δ, (19.8)
where Ais an ( N×n) matrix. In the present discussion we suppose the problem ‘overde-
termined’ in the sense that N>n. This condition defeated Euler (1749), who was facing
the case N=75,n=8. But we keep in mind that the cases N=n(ostensibly well-posed)
andN<n(underdetermined) can also arise in real problems, and it will be interesting to
see what probability theory has to say about them.
In the early 19th century, it was common to reason as follows. It seems plausible that
the best estimate of each xjwill be some linear combination of all the yi, but if N>nwe
cannot simply solve equation (19.8) for x, since Ais not a square matrix and has no inverse.
However, we can get a system of equations solvable for xif we take nlinear combinations
of the equations of condition; i.e. if we multiply (19.8) on the left by some ( n×N) matrix
B. Then the product BAexists and is a square ( n×n) matrix. Choose Bso that ( BA)−1
exists. Then the linear combinations are the nrows of
By=BAx+Bδ, (19.9)
which has the unique solution
x=(BA)−1B(y−δ). (19.10)
If the probabilities of various fractional errors δiare symmetric: p(δi)=p(−δi) so that
/angbracketleftδi/angbracketright=0, then corresponding to any given matrix Bthe ‘best’ estimate of xjby almost any
reasonable loss function criterion will be the jth row of
ˆx=(BA)−1By, (19.11)
but by making different choices of B(i.e. taking different linear combinations of the equa-
tions of condition) we get different estimates. In Euler’s problem there were billions ofpossible choices. Which choice of Bis best?
In the above we have merely restated, in modern notation but old language, the problem
of ‘reduction of equations of condition’ described in Laplace’s Essai Philosophique (1812).
A popular criterion for solution was the principle of least squares: ﬁnd that matrix Bfor
which the sum of the squares of the errors in ˆx
jis a minimum; or perhaps use a weighted
sum. This problem can be solved directly; we shall ﬁnd the same solution by differentreasoning below.

<<<PAGE 624>>>

592 Part 2 Advanced applications
19.2 Reformulation as a decision problem
We really solved this problem in Chapter 13, where we have seen in generality that the
best estimate of any parameter, by the criterion of any loss function, is found by applyingBayes’ theorem to ﬁnd the probability, conditional on the data, that the parameter lies invarious intervals, then making that estimate which minimizes the expected loss taken overthe posterior probabilities.
Now in the original formulation of the problem, as given above, it was only a plausible
conjecture that the best estimate of x
jis a linear combination of the yias in (19.11).
The material in Chapter 13 shows us a much better way of formulating the problem, inwhich we don’t have to depend on conjecture. Instead of trying to take linear combinationswithout knowing which combinations to take, we should apply Bayes’ theorem directly tothe equations of condition. Then, if the best estimates are indeed of the linear form (19.11),
Bayes’ theorem should not only tell us that fact, it will give us automatically the best choice
of the matrix Band also tell us the accuracy of those estimates, which least squares does
not give at all.
Let’s do this calculation for the case that we assign independent Gaussian probabilities to
the errors δ
iof the various measurements. From our discussion in Chapter 7 we expect this
to be, nearly always, the best error law we can assign from the information we have. But inthe orthodox literature one would not see it that way; instead one would argue that in mostphysical measurements the total error is the sum of contributions from many small, causallyindependent imperfections, and the central limit theorem would then lead us to a Gaussianfrequency distribution of errors.
1There is nothing wrong with that argument, except that it
has been psychologically misleading to generations of workers, who concluded that if thefrequency distribution of errors is not in fact Gaussian, then to assign a Gaussian probabilitydistribution is to ‘assume’ something that is not true; and this will lead to some horriblekind of error in our ﬁnal conclusions.
19.2.1 Sermon on Gaussian error distributions
The considerations of Chapter 7 reassure us that this danger is grossly exaggerated. The
point is that, in probability theory as logic, the Gaussian probability assignment is not anassumption about the frequencies of the errors; it is a description of our state of knowledge
about the errors. We hardly ever have prior knowledge about the errors beyond the generalmagnitude to be expected, which we can interpret reasonably as specifying the ﬁrst two
moments of the error distribution. This leads, by the principle of maximum entropy, to anindependent Gaussian probability assignment as the one which agrees with that informa-tion without assuming anything else. The region /Omega1of reasonably probable noise vectors
(δ
1,...,δ N) or the region Ax+/Omega1of reasonably probable data vectors, is then as large as
1As noted in Chapter 14, this is subject to an important quali ﬁcation: that in general the Gaussian approximation will be good
only for those values of total error δwhich can arise in many different ways by combination of the individual elementary errors.
For unusually wide deviations we do not expect, and hardly ever observe, Gaussian frequencies.

<<<PAGE 625>>>

19 Physical measurements 593
it can be while agreeing with the second moment constraints. The frequency distribution of
errors is almost always unknown before seeing the data; but even if it is far from Gaussian,the Gaussian probability assignment will still lead us to the best inferences possible fromthe information we have.
The privileged status of a Gaussian frequency distribution lies in a more subtle fact:
acquisition of new information does not affect our inferences if that new information is onlywhat we would have predicted from our old information. Thus, if we assigned Gaussianprobabilities and then acquired new information that the true frequency distribution of errorsis indeed Gaussian with the speciﬁed variance, this would not help us because it is only what
we would have predicted. But if we had additional prior information about the speciﬁc wayin which the error frequencies depart from Gaussian, that would be cogent new informationconstraining the possible error vectors to a smaller domain ( /Omega1
1⊂/Omega1). This would enable us
to improve our parameter estimates over the ones to be obtained below, because data vectorsin the complementary set ( /Omega1−/Omega1
1), which were previously dismissed as noise, are now
recognized as indicating a real ‘signal’. Bayes’ theorem does all this for us automatically.
Thus the covenant that we have with Nature is considerably more favorable than is
supposed in orthodox teaching; for, given second moments, a non-Gaussian frequency dis-tribution will not make our inferences worse, but knowledge of a non-Gaussian distribution
would enable us to make them still better than the results to be found below.
Encouraged by the message of this sermon, we assign the probability for the errors
{δ
1,...,δ N}to lie in the intervals {dδ1,..., dδN}, respectively, as
p(δ1···δN)dδ1···dδN=(const.) exp/braceleftBigg
−1
2N/summationdisplay
i=1wiδ2
i/bracerightBigg
dδ1···dδN, (19.12)
where the ‘weight’ wiis the reciprocal variance of the error of the ith measurement. For
example, the crude statement that the ﬁrst measurement has ±2% accuracy now becomes
the more precise statement that the ﬁrst measurement has weight
w1=1
/angbracketleftδ2
1/angbracketright=1
(0.02)2=2500. (19.13)
For the time being, we suppose these weights known, as is generally the case with as-
tronomical and other physical data. From (19.7) and (19.12) we have immediately the
sampling probability density for obtaining measured values {y1,..., yN}given the true
values{x1,..., xN}:
p(y1···yN|x1···xn)=C1exp

−1
2N/summationdisplay
i=1wi/bracketleftBigg
yi−n/summationdisplay
j=1aijxj/bracketrightBigg2

, (19.14)
where C1is independent of the yi. According to Bayes’ theorem, if we assign uniform prior
probabilities to the xj, then the posterior probability density for the xj, given the actual

<<<PAGE 626>>>

594 Part 2 Advanced applications
measurements yi, is of the form
p(x1···xn|y1···yN)=C2exp

−1
2N/summationdisplay
i=1wi/bracketleftBigg
yi−n/summationdisplay
j=1aijxj/bracketrightBigg2

, (19.15)
where now C2is independent of the xj. Next, as in nearly all Gaussian calculations, we
need to reorganize this quadratic form to bring out the dependence on the xi. Expanding it,
we have
N/summationdisplay
i=1wi/parenleftBigg
yi−n/summationdisplay
j=1aijxj/parenrightBigg2
=N/summationdisplay
i=1wi/braceleftBigg
y2
i−2yin/summationdisplay
j=1aijxj+n/summationdisplay
j,k=1aijaikxjxk/bracerightBigg
=n/summationdisplay
j,k=1Kjkxixk−2n/summationdisplay
j=1Ljxj+N/summationdisplay
i=1wiy2
i,(19.16)
where
Kjk=N/summationdisplay
i=1wiaijaik, Lj=N/summationdisplay
i=1wiyiaij, (19.17)
or, deﬁning a diagonal ‘weight’ matrix Wij=wiδij, we have a matrix Kand a vector L:
K=˜AW A, L=˜AWy, (19.18)
where ˜Ais the transposed matrix. We want to write (19.15) in the form
p(x1···xn|y1···yN)=C3exp/braceleftBigg
−1
2n/summationdisplay
j,k=1Kjk(xj−ˆxj)(xk−ˆxk)/bracerightBigg
(19.19)
whereupon the ˆxjwill be the mean-value estimates desired. Comparing (19.16) and (19.19)
we see that
n/summationdisplay
k=1Kjkˆxk=Lj, (19.20)
so if Kis nonsingular we can solve uniquely for ˆx.
19.3 The underdetermined case: Kis singular
If we have fewer observations than parameters, N<n, then, from (19.17), Kis still an
(n×n) matrix, but it is at most of rank N, and so is necessarily singular. Then the trouble
is not that (19.20) has no solution; but rather that it has an inﬁnite number of them. Themaximum likelihood is attained not at a point, but on an entire linear manifold of dimen-sionality ( n−N). Of course, maximum-likelihood solutions still exist, as is seen from the
fact that, although ( ˜AW A )
−1does not exist, ( A˜A)−1does, and so the parameter estimate
x∗=˜A(A˜A)−1y (19.21)

<<<PAGE 627>>>

19 Physical measurements 595
now makes the quadratic form in (19.15) vanish: y=Ax∗, achieving the maximum possible
likelihood. This is called the canonical inverse solution, and the principle of maximumentropy may be used to calculate it. But the canonical inverse is far from unique, for wesee from (19.8) that if we add to the estimate (19.21) any solution zof the homogeneous
equation Az=0, we have another estimate x
∗+zwith just as high a likelihood; and there
is a linear manifold /Delta1of such vectors x∗+z, of dimensionality n−N.
Exercise 19.1. Show that the canonical inverse solution (19.21) is also a least squares
one, making/summationtext(x∗
i)2a minimum on the manifold /Delta1. Unfortunately, there seems to be
no compelling reason why one should want the vector of estimates to have minimumlength.
For a long time, no satisfactory way of dealing with such problems was recognized; yet we
are not entirely helpless, for the data do restrict the possible values of the parameters {xi}to
a ‘feasible set’ /Delta1satisfying (19.20). The data alone are incapable of picking out any unique
point in this set; but the data may be supplemented with prior information which enablesus to make a useful choice in spite of that. These are ‘generalized inverse’ problems, whichare of current importance in many applications, such as image reconstruction. In fact, inthe real world, generalized inverse problems probably make up the great majority, becausethe real world seldom favors us with all the information needed to make a well-posedproblem. Yet useful solutions may be found in many cases by maximum entropy, whichresolves the ambiguity in a way that is ‘optimal’ by several different criteria, as describedin Chapters 11 and 20.
19.4 The overdetermined case: Kcan be made nonsingular
By its deﬁnition (19.17), Kis an ( n×n) matrix, and for all real {q
1,..., qn}such that/summationtextq2
i>0,
n/summationdisplay
j,k=1Kjkqjqk=N/summationdisplay
i=1wi/parenleftBiggn/summationdisplay
j=1aijqj/parenrightBigg2
≥0, (19.22)
so if Kis of rank nit is not only nonsingular, but positive deﬁnite. If N≥nthis will be the
case unless we have done something foolish in setting up the problem – including a uselessobservation or an irrelevant parameter.
In the ﬁrst place, we suppose all the weights w
ito be positive: if any observation yihas
weight wi=0, then it is useless in our problem; i.e. it can convey no information about the
parameters and we should not have included it in the data set at all. We can reduce Nby one.
Secondly, if there is a nonzero vector qfor which/summationtext
jaijqjis zero for all i, then in (19.7),
for all c, the parameter sets {xj}and{xj+cqj}would lead to identical data, and so could

<<<PAGE 628>>>

596 Part 2 Advanced applications
not be distinguished whatever the data. In other words, there is an irrelevant parameter in
the problem which has nothing to do with the data; we can reduce nby one. Mathematically,
this means that the columns of the matrix Aare not linearly independent; then, if qk/negationslash=0,
we can remove the parameter xkand the kth column of Awith no essential change in the
problem (i.e. no change in the information we get from it).
Removing irrelevant observations and parameters if necessary, and ﬁnally, the number
of cogent observations is at least as great as the number of relevant parameters, then Kis a
positive deﬁnite matrix and (19.20) has a unique solution
ˆxk=n/summationdisplay
j=1(K−1)kjLj. (19.23)
From (19.18), we can write the result as
ˆx=(˜AW A )−1˜AWy, (19.24)
and, comparing with (19.11), we see that, in the Gaussian case with uniform prior proba-
bilities, the best estimates are indeed linear combinations of the measurements, of the form
(19.11), and the best choice of the matrix Bis
B=˜AW, (19.25)
a result perhaps ﬁrst found by Gauss, and repeated in Laplace’s Essai Philosophique . Let
us evaluate this solution for our simple problem.
19.5 Numerical evaluation of the result
Applying the solution (19.24) to our problem of estimating eandm, the measurements of
e,(e/m) and ( e2/m) were of 2%, 1% and 5% accuracy, respectively, and so
w2=1
(0.01)2=10 000
w3=1
(0.05)2=400,(19.26)
and we found w1=2500 before. Thus we have
B=˜AW=/parenleftbigg11 2
0−1−1/parenrightbigg
w100
0w20
00 w3
=/parenleftbiggw1w2 2w3
0−w2−w3/parenrightbigg
, (19.27)
K=˜AW A=/parenleftbigg[w1+w2+4w3]−[w2+2w3]
−[w2+2w3][ w2+w3]/parenrightbigg
, (19.28)
K−1=(˜AW A )−1=1
|K|/parenleftbigg[w2+w3][ w2+2w3]
[w2+2w3][w1+w2+4w3]/parenrightbigg
, (19.29)

<<<PAGE 629>>>

19 Physical measurements 597
where
|K|=det(K)=w1w2+w2w3+w3w1. (19.30)
Thus, the ﬁnal result is
(˜AW A )−1˜AW=1
|K|/parenleftbiggw1[w2+w3]−w2w3 w2w3
w1[w2+2w3]−w2[w1+2w3]w3[w2−w1]/parenrightbigg
,(19.31)
and the best point estimates of x1,x2are
ˆx1=w1(w2+w3)y1+w2w3(y3−y2)
w1w2+w2w3+w3w1,
ˆx2=w1w2(y1−y2)+w2w3(y3−2y2)+w3w1(2y1−y3)
w1w2+w2w3+w3w1.(19.32)
Inserting the numerical values of w1,w2andw3,w eh a v e
ˆx1=13
15y1+2
15(y2−y3),
ˆx2=5
6(y1−y2)+2
15(y3−2y2)+1
30(2y1−y3),(19.33)
which exhibits the best estimates as weighted averages of the estimates taken from all
possible pairs of experiments. Thus, y1is the estimate of x1obtained in the ﬁrst experiment,
which measures edirectly. The second and third experiments combined yield an estimate
ofeg i v e nb y( e2/m)(e/m)−1. Since
e2
0
m0(1+y3)
e0
m0(1+y2)≈e0(1+y3−y2), (19.34)
(y3−y2) is the estimate of x1given by experiments 2 and 3. Equation (19.33) says that
these two independent estimates of x1should be combined with weights 13 /15 and 2 /15.
Likewise, ˆx2is given as a weighted average of three different (although not independent)
estimates of x2.
19.6 Accuracy of the estimates
From (19.19) we ﬁnd the second central moments of p(x1···xn|y1···yN):
/angbracketleft(xj−ˆxj)(xk−ˆxk)/angbracketright=/angbracketleft xjxk/angbracketright−/angbracketleft xj/angbracketright/angbracketleftxk/angbracketright=(K−1)jk. (19.35)
Thus, from the ( n×n) inverse matrix
K−1=(˜AW A )−1(19.36)
already found in our calculation ofˆxj, we can also read off the probable errors, or, more
conveniently, the standard deviations. From (19.29) we can state the results in the form

<<<PAGE 630>>>

598 Part 2 Advanced applications
(mean)±(standard deviation) as
(xj)est=ˆxj±/radicalBig
(K−1)jj. (19.37)
Equations (19.24) and (19.37) represent the general solution of the problem, which Euler
needed. In the present case this is
(x1)est=ˆx1±/radicalbiggw2+w3
w1w2+w2w3+w3w1,
(x2)est=ˆx2±/radicalBigg
w1+w2+4w3
w1w2+w2w3+w3w1(19.38)
with numerical values
x1=ˆx1±0.0186,
x2=ˆx2±0.0216(19.39)
so that from the three measurements we obtain ewith±1.86% accuracy and mwith±2.16%
accuracy.
How much did the rather poor measurement of ( e2/m), with only±5% accuracy, help
us? To answer this, note that in the absence of this experiment we would have arrived atconclusions given by (19.28), (19.29) and (19.32) in the limit w
3→0. The results (also
easily veriﬁed directly from the statement of the problem) are
ˆx1=y1,
ˆx2=y1−y2,(19.40)
K−1=1
w1w2/parenleftbiggw2 w2
w2[w1+w2]/parenrightbigg
, (19.41)
or, the (mean)±(standard deviation) values are
x1=y1±1
w1=y1±0.020,
x2=y1−y2±/radicalbiggw1+w2
w1w2=y1−y2±0.024.(19.42)
As might have been anticipated by common sense, a low-accuracy measurement can add
very little to the results of accurate measurements, and if the ( e2/m) measurement had been
much worse than±5% it would hardly be worthwhile to include it in our calculations. But
suppose that an improved technique gives us an ( e2/m) measurement of±2% accuracy. How
much would this help? The answer is given by our previous formulas with w1=w3=2500,
w2=10 000. We ﬁnd now that the mean-value estimates give much higher weight to the

<<<PAGE 631>>>

19 Physical measurements 599
estimates using the ( e2/m) measurement:
ˆx1=0.556y1+0.444( y3−y2),
ˆx2=0.444( y1−y2)+0.444( y3−2y2)+0.112(2 y1−y3),(19.43)
which is to be compared with (19.33). The standard deviations are given by
x1=ˆx1±0.0149,
x2=ˆx2±0.020.(19.44)
The accuracy of e(x1) is improved roughly twice as much as that of m(x2), since the
improved measurement involves e2, but only the ﬁrst power of m.
Exercise 19.2. Write a computer program which solves this problem for general N
andn, with N≥n, and test it on the problem just solved. Estimate how long it would
require for the compiled program to solve Euler ’s problem.
In the above we supposed the weights wiknown from prior information. If this is not the
case, there are many different conceivable kinds of partial prior information about them,leading to many different possible prior probability assignments p(w
1···wn|I). This will
make some minor quantitative changes in details, but no new difﬁculties of principle; onlya straightforward mathematical generalization following the already established Bayesianprinciples.
19.7 Comments
19.7.1 A paradox
We can learn many more things from studying this problem. For example, let us note
something which you will ﬁnd astonishing at ﬁrst. If you study (19.32), which gives thebest estimate of mfrom the three measurements, you will see that y
3, the result of the
(e2/m) measurement, enters into the formula in a different way than y1andy2. It appears
once with a positive coefﬁcient, and once with a negative one. If w1=w2, these coefﬁcients
are equal, and (19.32) collapses to
ˆx2=y1−y2. (19.45)
Now, realize the full implications of this: it says that the only reason we make use of the
(e2/m)measurement in estimating m is that the (e)measurement and the (e/m)measurement
have different accuracy . No matter how accurately we know ( e2/m), if the ( e) and ( e/m)
measurements happen to have the same accuracy, however poor, then we should ignore thegood measurement and base our estimate of monly on the ( e) and ( e/m) measurements!

<<<PAGE 632>>>

600 Part 2 Advanced applications
We think that, on ﬁrst hearing, your intuition will revolt against this conclusion, and
your ﬁrst reaction will be that there must be an error in (19.32). So, check the derivationat your leisure. This is a perfect example of the kind of result which probability theorygives us almost without effort, but which our unaided common sense might not notice inyears of thinking about the problem. We won’t deprive you of the pleasure of resolving this‘paradox’ for yourself, and explaining to your friends how it can happen that consistentinductive reasoning may demand that you throw away your best measurement.
In Chapter 17, we complained about the fact that orthodox statisticians sometimes throw
away relevant data in order to ﬁt a problem to their preconceived model of ‘independentrandom errors’. Are we now guilty of the same offense? No doubt, it looks very muchthat way! Yet we plead innocence: the numerical value of ( e
2/m)i si nf a c t irrelevant to
inference about m, if we already have measurements of eande/mof equal accuracy. To
see this, suppose that we knew ( e2/m) exactly from the start. How would you make use
of that information in this problem? If you try to do this, you will soon see why ( e2/m)i s
irrele vant. But to clinch matters, try the following exercise.
Exercise 19.3. Consider a speciﬁc case: w1=w2=1,w3=100; the third measure-
ment is ten times more accurate than theﬁrst two. But if the problem is such that
the third measurement cancels out when we try to use all three as in (19.22), then it
seems that the only way we could use the accurate third measurement is by discardingeither the ﬁrst or second. Show that, nevertheless, in this case the estimates made by
(19.32) using only the ﬁrst and second measurements are more accurate than thosemade by using the ﬁrst and third; or the second and third. Now explain intuitively whythis is as it should be; there is no paradox.
As another example, it is important that we understand the way our conclusions depend on
our choice of loss functions and probability distributions for the errors δi. If we use instead
of the Gaussian distribution (19.12) one with wider tails, such as the Cauchy distribution
p(δ)∝(1+wδ2/2)−1, the posterior distribution p(x1x2|y1y2y3) may have more than one
peak in the ( x1,x2) plane. Then a quadratic loss function, or more generally any concave
loss function (i.e. doubling the error more than doubles the loss) will lead one to makeestimates of x
1andx2which lie between the peaks, and are known to be very unlikely. With
a convex loss function a different ‘paradox’ appears, in that the basic equation (19.26) forconstructing the best estimator may have more than one solution, with nothing to tell uswhich one to use.
The appearance of these situations is the robot’s way of telling us this: our state of
knowledge about x
1andx2is too complicated to be described adequately simply by giving
best estimates and probable errors. The only honest way of describing what we know is togive the actual distribution p(x
1x2|y1y2y3). This is one of the limitations of decision theory,
which we need to understand in order to use it properly.

<<<PAGE 633>>>

20
Model comparison
Entities are not to be multiplied without necessity.
William of Ockham, c 1330
We have seen in some detail how to conduct inferences – test hypotheses, estimate param-
eters, predict future observations – within the context of a preassigned model, representingsome working hypothesis about the phenomenon being observed. But a scientist must alsobe concerned with a bigger problem: how to decide between different models when bothseem able to account for the facts. Indeed, the progress of science requires comparison of
different conceivable models; a false premise built into a model that is never questionedcannot be removed by any amount of new data.
Stated very broadly, the problem is hardly new; some 650 years ago the Franciscan
Monk William of Ockham perceived the logical error in the mind projection fallacy.
1This
led him to teach that some religious issues might be settled by reason, but others only byfaith. He removed the latter from his discourse, and concentrated on the areas where reasonmight be applied – just as Bayesians seek to do today when we discard orthodox mindprojecting mythology (such as assertions of limiting frequencies in experiments that havenever been performed), and concentrate on the things that are meaningful in the real world.His propositions ‘amenable only to faith’ correspond roughly to what we should call non-Aristotelian propositions. His famous epigram quoted above, generally called ‘Ockham’srazor’, represents a good start on the principles of reasoning that he needed, and that westill need today. But it was also so subtle that only through modern Bayesian analysis hasit been well understood.
Of course, from our present vantage point it is clear that this is really the same problem as
that of compound hypothesis testing, considered already in Chapter 4. Here we need onlygeneralize that treatment and work out further details. Then we are able to see conventionalsigniﬁcance tests simply as model comparison in which we choose the best alternative in aprescribed class of alternative hypotheses.
1Ockham’s position, stated in the language of his time, was that ‘Reality exists solely in individual things, and universals are
merely abstract signs.’ Translated into 20th century language: the abstract creations of the mind are not realities in the external
world. Unfortunately for him, some of the cherished ‘realities’ of contemporary orthodox theology were just the things to which
he denied reality; so this got him into trouble with the Establishment. Evidently, Ockham was a forerunner of modern Bayesians,to whom all this sounds very familiar.
601

<<<PAGE 634>>>

602 Part 2 Advanced applications
But some extra care is needed. As long as we work within a single model, normalization
constants tend to cancel out and so need not be introduced at all in most cases. But whentwo different models appear in a single equation, the normalization constants do not cancelout, and it is imperative that all probabilities be correctly normalized.
20.1 Formulation of the problem
To see why the normalization constants no longer cancel, recall ﬁrst what Bayes’ theorem
tells us about parameter estimation. A model Mcontains various parameters denoted col-
lectively by θ. Given data Dand prior information I, to estimate its parameters we ﬁrst
apply Bayes’ theorem:
p(θ|DMI )=p(θ|MI)p(D|θMI)
p(D|MI), (20.1)
in which the presence of Mon the right-hand side signiﬁes that we are assuming the
correctness of model M. The denominator serves as the normalizing constant:
p(D|MI)=/integraldisplay
dθp(Dθ|MI)=/integraldisplay
dθp(D|θMI)p(θ|MI), (20.2)
which we see is the prior expectation of the likelihood L(θ)=p(D|θMI); i.e. its expectation
over our prior probability distribution p(θ|MI) for the parameters.
Now we move up to a higher level problem: to judge, in the light of the prior information
and data, which of a given set of different models {M1,..., Mr}is most likely to be the
correct one. Bayes’ theorem gives the posterior probability for the jth model as
p(Mj|DI)=p(Mj|I)p(D|MjI)
p(D|I), 1≤j≤r. (20.3)
But we may eliminate the denominator p(D|I) by calculating odds ratios as we did in
Chapter 4. The posterior odds ratio for model Mjover Mkis
p(Mj|DI)
p(Mk|DI)=p(Mj|I)
p(Mk|I)p(D|MjI)
p(D|MkI), (20.4)
and we see that the same probability p(D|MjI) that appears in the single-model parameter
estimation problem (20.1) only as a normalizing constant, now appears as the fundamentalquantity determining the status of model M
jrelative to any other.2The exact measure of
what the data have to tell us about this is always the prior expectation of its likelihoodfunction, over the prior probability p(θ
j|MjI) for whatever parameters θjmay be in that
2This logical structure is more general even than the Bayesian formalism; it persists in the pure maximum entropy formalism,
where in statistical mechanics the relative probability Pj/Pkof two different phases, such as liquid and solid, is the ratio of
their partition functions Zj/Zk, which are the normalization constants for the sub-problems of prediction within one phase. In
Bayesian analysis, the data are indifferent between two models when their normalization constants become equal; in statistical
mechanics the temperature of a phase transition is the one at which the two partition functions become equal. In Bayesiananalysis we shall usually prefer to express (20.4) in log-odds form; in chemical thermodynamics it has been customary for acentury to state the condition of indifference between phases as equality of the ‘free energies’ F
j∝log(Zj). This illustrates the
basic unity of Bayesian and maximum entropy reasoning, in spite of their superﬁcial differences arising from the different kindof information being processed.

<<<PAGE 635>>>

20 Model comparison 603
model (they are generally different for different models). Probabilities must be correctly
normalized here, otherwise we are violating our basic rules and the odds ratio in (20.4) isarbitrary.
Intuitively, the model favored by the data is the one that assigns the highest probability
to the observed data, and therefore ‘explains the data’ best. This is just a repetition, at ahigher level, of the likelihood principle for parameter estimation within a model.
But how can an Ockham principle emerge from this? The ﬁrst difﬁculty is that the
principle has never been stated in exact, well-deﬁned terms. Later writers have tried, almostuniversally, to interpret our opening quotation as saying that the criterion of choice is the‘simplicity’ of the competing models, although it is not clear that Ockham himself used thatterm. Perhaps we come closer to the notion of simplicity if we restate our opening quotationas: ‘Do not introduce details that do not contribute to the quality of your inferences.’ Butcenturies of discussion by philosophers brought no appreciable clariﬁcation of what is meantby ‘simplicity’.
3We think that concentration of attention exclusively on that undeﬁned term
has pre vented understanding of the real point, which is merely that a model with unspeci ﬁed
parameters is a composite hypothesis, not a simple one; and it requires the kind of analysisgiven in Chapter 4 for composite hypotheses. Then some new features appear, arising fromthe different internal structures of the parameter spaces for the models considered.
20.2 The fair judge and the cruel realist
Now consider under what conditions we want this model comparison to take place. There
are two possible positions. (1) We might adopt the posture of the scrupulously fair judge,
who insists that fairness in comparing models requires that each is delivering the bestperformance of which it is capable, by giving each the best possible prior probability for itsparameters (similarly, in Olympic games we would consider it unfair to judge two athletesby their performances when one of them is sick or injured; the fair judge wants to comparethem when both are doing their absolute best). (2) We might consider it necessary to becruel realists and judge each model taking into account the prior information we actuallyhave pertaining to it; that is, we penalize a model if we do not have the best possible priorinformation about its parameters, although that is not really a fault of the model itself.
It develops that the Ockham factors express the position of the cruel realist; they are just
the factors that convert the scrupulously fair comparison of the model itself – irrespectiveof the prior probability we are able to give it at the moment – into the comparisons of thecruel realist who insists on taking into account what is actually possible here and now. Anathlete who is sick or injured merits our sympathy, but we cannot use him in the ‘big game’tomorrow; likewise, a potentially superior model can be unusable if our prior informationplaces its parameters far from their maximum-likelihood values. When real results are atstake, we are obliged to be cruel realists.
3For a time, the notion of simplicity was given up for dead, because of the seeming impossibility of deﬁning it. The tedious details
are recounted by Rosenkrantz (1977).

<<<PAGE 636>>>

604 Part 2 Advanced applications
20.2.1 Parameters known in advance
To see this, suppose ﬁrst that there is no internal parameter space; the parameters of a
model are known exactly ( θ=θ/prime) in advance. Then the model becomes, in effect, a simple
hypothesis rather than a composite or compound one, and the simple form of Bayes’ theo-rem applies. This amounts to assigning a prior p(θ
j|MjI)=δ(θj−θ/prime
j), whereupon (20.2)
reduces to
p(D|MjI)=p(D|θ/prime
jMjI)=Lj(θ/prime
j), (20.5)
just the likelihood of θ/prime
jwithin the jth model. Evidently, the scrupulously fair judge will
note that this is a maximum if θ/prime
jhappens to be equal to the maximum-likelihood estimate
ˆθjfor that model and the data. Then his posterior odds ratio (20.4) reduces to
p(Mj|DI)
p(Mk|DI)=p(Mj|I)
p(Mk|I)(Lj)max
(Lk)max. (20.6)
But this extreme case, although fair in the aforementioned sense, may be very unrealistic;
usually, the parameters are unknown, and in the problems ‘amenable to reason’, whereuseful inferences are possible, our prior information concerning the parameters must begood enough to allow useful inferences.
We have seen already in previous chapters that, if we have a reasonable amount of data,
most models will give such sharply peaked likelihood functions that the prior is relativelyunimportant for inferences about the parameters . But it is still important for inferences about
themodels , so Ockham factors deﬁned by the priors remain important in model comparison.
The simple biological problems studied by R. A. Fisher are generally of this type.
When prior information is important even for inferences about the parameters – whether
from a loose model or sparse data – Ockham factors make a crucially important differencein our model comparisons. In the more complex problems studied by Harold Jeffreys andfaced by modern scientists and economists, we ignore these factors at our peril.
20.2.2 Parameters unknown
Let a model Mhave parameters θ≡{θ
1,...,θ m}. Then, comparing (20.4) and (20.6), we
write
p(D|MI)=LmaxW, (20.7)
and this deﬁnes the Ockham factor W; it is just the amount by which the model Mis
penalized by our nonoptimal prior information. Written explicitly,
W≡/integraldisplay
dθL(θ)
Lmaxp(θ|MI). (20.8)
If, as in Fisher’s problems, the data are much more informative about θthan the prior
information, then the likelihood function is sharply peaked and we could deﬁne a ‘high-likelihood region’ /Omega1
/primeas the smallest subregion of the whole parameter space /Omega1that contains

<<<PAGE 637>>>

20 Model comparison 605
a speciﬁed amount (say, 95%) of the integrated likelihood. Then, most of the contribution
to the integral (20.8) would come from the region /Omega1/prime. Better, the arbitrary number 0.95 can
be done away with by deﬁning ﬁrst the volume V(/Omega1/prime) by the condition that the integrated
likelihood is just
/integraldisplay
dθL(θ)=LmaxV(/Omega1/prime). (20.9)
Then/Omega1/primeis deﬁned as the region of volume V(/Omega1/prime) that contains the maximum possible
amount of integrated likelihood; that is, within /Omega1/primethe likelihood is everywhere greater than
some threshold value L0that is reached on the boundary of /Omega1/prime.
If the prior density p(θ|MI) is so broad that it is essentially constant over this high-
likelihood region /Omega1/primesurrounding the maximum-likelihood point, (20.8) reduces to
W/similarequalV(/Omega1/prime)p(ˆθ|MI), (20.10)
so in this case the Ockham factor is essentially just the amount of prior probability contained
in the high-likelihood region /Omega1/primepicked out by the data.
In any case, our fundamental model comparison rule (20.4) becomes
p(Mj|DI)
p(Mk|DI)=p(Mj|I)
p(Mk|I)(Lj)max
(Lk)maxWj
Wk, (20.11)
in which we see revealed, by comparison with (20.6), the net Ockham factor ( Wj/Wk) arising
from the internal parameter spaces of the models. In (20.11), the likelihood factor dependsonly on the data and the models. If two different models achieve the same likelihoods
(L
j)max, then they are potentially capable of accounting for the data equally well, and in
orthodox theory it would seem that we have no basis for choice between them. Yet Bayes’theorem tells us that there is an another quality to be considered: the prior information,which is ignored by orthodox theory, may still give strong grounds for preference of onemodel over the other. Indeed, the Ockham factor in (20.11) may be so strong that it reversesthe likelihood judgment in (20.6).
20.3 But where is the idea of simplicity?
The relation (20.11) has much meaning that unaided intuition could not (or at least, did
not) see. If the data are highly informative compared with the prior information, then therelative merit of two models is determined by two factors:
(1) how high a likelihood can be attained on their respective parameter spaces /Omega1j,/Omega1k;
(2) how much prior probability is concentrated in their respective high-likelihood regions /Omega1/prime
j,/Omega1/prime
k?
But neither of these seems concerned with the intuitive notion of simplicity (which seems
for most of us to refer to the number of different assumptions that are made – for example,the number of different parameters that are introduced – in deﬁning a model).

<<<PAGE 638>>>

606 Part 2 Advanced applications
To understand this, let us ask: ‘How do we all decide these things intuitively?’ Having
observed some facts, what is the real criterion that leads us to prefer one explanationof them over another? Suppose that two explanations, AandB, could account for some
proven historical facts equally well. But Amakes four assumptions, each of which seems to
us already highly plausible, while Bmakes only two assumptions, but they seem strained,
farfetched, and highly unlikely to be true. Every historian ﬁnds himself in situations likethis, and he does not hesitate to opt for explanation A, although Bis intuitively simpler.
Thus our intuition asks, fundamentally, not how simple the hypotheses are, but rather how
plausible they are.
Of course, there is a loose connection between plausibility and simplicity, because the
more complicated a set of possible hypotheses, the larger the manifold of conceivablealternatives to some particular hypothesis, and so the smaller must be the prior probabilityof any particular hypothesis in the set.
Now we see why ‘simplicity’ could never be given a satisfactory deﬁnition (that is, a
deﬁnition that accounted in a satisfactory way for these inferences); it was a poorly chosenword, directing one’s attention away from an essential component of the inference. Butfrom centuries of unquestioned acceptance, the idea of ‘simplicity’ became implanted withsuch an unshakeable mindset that some workers, even after applying Bayes’ theorem wherethe contrary fact stares you in the face, continued doggedly trying to interpret the Bayesiananalysis in terms of simplicity.
4
Generations of writers opined vaguely that ‘simple hypotheses are more plausible’ with-
out giving any logical reason for it. We suggest that this should be turned around: weshould say rather that ‘more plausible hypotheses tend to be simpler’. An hypothesis thatwe consider simpler is one that has fewer equally plausible alternatives.
None of this could be comprehended at all within the conﬁnes of orthodox statistical
theory, whose ideology did not allow the concept of a probability for a model or for a ﬁxedbut unknown parameter, because they were not considered ‘random variables’. Orthodoxytried to compare models entirely in terms of their different sampling distributions, whichtook no note of either the simplicity of the model orthe prior information! But it was
unable to do even that, because then all the parameters, within a model became nuisanceparameters, and that same ideology denied one any way to deal with them.
5Thus, orthodox
statistics was a total failure on this problem – it did not provide even the vocabulary inwhich the problem could be stated – and this held up progress for most of the 20th century.
It is remarkable that, although the point at issue is trivial mathematically, generations
of mathematically competent people failed to see it because of that conceptual mindset.But once the point is seen, it seems intuitively obvious and one cannot comprehend howanyone could ever have imagined that ‘simplicity’ alone was the criterion for judgingmodels. This just reminds us again that the human brain is an imperfect reasoning device;although it is quite good at drawing reasonable conclusions, it often fails to give a convincing
4Indeed, one author, for whom Ockham’s razor was by deﬁnition concerned with simplicity, rejected Bayesian analysis because
of its failure to exhibit that error!
5This and other criticisms of orthodox hypothesis testing theory were made long ago by Pratt (1961).

<<<PAGE 639>>>

20 Model comparison 607
rationale for those conclusions. For this we really do need the help of probability theory
as logic.
Of course, Bayes’ theorem does recognize simplicity as one component of the inference.
But by what mechanism does this happen? Although Bayes’ theorem always gives us thecorrect answer to whatever question we ask of it, it often does this in such a slick, efﬁcientway that we are left bewildered and not quite understanding how it happened. The presentproblem is a good example of this, so let us try to understand the situation better intuitively.
Denote by M
na model for which θ={θ1,...,θ n}isn-dimensional, ranging over a
parameter space /Omega1n. Now introduce a new model Mn+1by adding a new parameter θn+1
and going to a new parameter space /Omega1n+1, in such a way that θn+1=0 represents the old
model Mn. We shall presently give an explicit calculation with this scenario, but ﬁrst let us
think about it in general terms.
On the subspace /Omega1nthe likelihood is unchanged by this change of model:
p(D|θMn+1I)=p(D|θMnI). But the prior probability p(θ|Mn+1I) must now be spread
over a larger parameter space than before and will, in general, assign a lower probability to
a neighborhood /Omega1/primeof a point in /Omega1nthan did the old model.
For a reasonably informative experiment, we expect that the likelihood will be rather
strongly concentrated in small subregions /Omega1/prime
n∈/Omega1nand/Omega1/prime
n+1∈/Omega1n+1. Therefore, if with
Mn+1the maximum-likelihood point occurs at or near θn+1=0,/Omega1/prime
n+1will be assigned
less prior probability than is /Omega1/prime
nwith model Mn, and we have p(D|MnI)>p(D|Mn+1I);
the likelihood ratio generated by the data will favor Mnover Mn+1. This is the Ockham
phenomenon.
Thus, if the old model is already ﬂexible enough to account well for the data, then as a
general rule Bayes’ theorem will, like Ockham, tell us to prefer the old model. It is intuitivelysimpler if by ‘simpler’ we mean a model that occupies a smaller volume of parameter space,and thus restricts us to a smaller range of possible sampling distributions . Generally, the
inequality will go the other way only if the maximum-likelihood point is far from θ
n+1=0
(i.e. a signiﬁcance test would indicate a need for the new parameter), because then thelikelihood will be so much smaller on /Omega1
/primenthan on /Omega1/primen+1that it more than compensates for
the lower prior probability of the latter; as noted, Ockham would not disagree.
But intuition does not tell us at all, quantitatively, how great this discrepancy in likelihoods
must be in order to bring us to the point of indifference between the models. Furthermore,
having seen this mechanism, it is easy to invent cases (for example, if the introductionof the new parameter is accompanied by a redistribution of prior probability on the oldsubspace S
n) in which Bayes’ theorem may contradict Ockham because it is taking into
account further circumstances undreamt of in Ockham’s philosophy. So we need speciﬁccalculations to make these things quantitative.
20.4 An example: linear response models
Now we give a simple analysis that illustrates the above conclusions and allows us to cal-
culate deﬁnite numerical values for the likelihood and Ockham factors. We have a common

<<<PAGE 640>>>

608 Part 2 Advanced applications
scenario: a data set D≡{(x1,y1),..., (xn,yn)}consisting of measured values of ( x,y)i n
npairs of observations. We may think of xas the ‘cause’ and yas the ‘effect’, although
this is not required. For the general relations below, the ‘independent variables’ xineed
not be uniformly spaced or even monotonic increasing in the index i. From these data and
any prior information we have, we are to decide between two conceivable models for theprocess generating the data. For model M
1the responses are, but for irregular measurement
errors ei, linear in the cause:
M1:yi=αxi+ei, 1≤i≤n, (20.12)
while for model M2there is also a quadratic term:
M2:yi=αxi+βx2
i+ei, (20.13)
which represents, if βis negative, an incipient saturation or stabilizing effect (if βis positive,
an incipient instability). We may think, for concreteness, of xias the dose of some medicine
given to the ith patient, yias the resulting increase in blood pressure. Then we are trying
to decide whether the response to this medicine is linear or quadratic in the dosage. Butthis mathematical model applies equally well to many different scenarios.
6Whichever
model is correct, we assume that the xiare measured with negligible error, but the errors
of measurement of yiare supposed to be the same for either model, so we assign a joint
sampling distribution to them:
p(e1···en|I)=n/productdisplay
i=11√
2πσ2exp/braceleftbigg
−e2
i
2σ2/bracerightbigg
=/parenleftBigw
2π/parenrightBign/2
exp/braceleftBigg
−w
2/summationdisplay
ie2
i/bracerightBigg
(20.14)
where w≡1/σ2is the ‘weight’ parameter, more convenient in calculations than σ2.
This simple scenario has the merit that all calculations can be done exactly with pen-cil and paper, so that the ﬁnal result can be subjected to arbitrary extreme conditionsand will remain correct, and we can see which limiting operations are and are notwell-behaved.
20.4.1 Digression: the old sermon still another time
Again, we belabor the meaning of this, as discussed in Chapter 7. In orthodox statis-
tics, a sampling distribution is always referred to as if it represented an ‘objectivelyreal’ fact, the frequency distribution of the errors. But we doubt whether anybody hasever seen a real problem in which one had prior knowledge of any such frequencydistribution, or indeed prior knowledge that any limiting frequency distribution exists.
6For example, ximight be the amount of ozone in the air in the ith year, yithe average temperature in that year. Or, ximay be
the amount of some food additive ingested by the ith Canadian rat, yithe amount of cancer tissue that rat developed. Or, ximay
be the amount of acid rain falling on Northern Germany in the ith year, yithe number of pine trees that died in that year; and
so on. In other words, we are now in the realm of what were called ‘linear response models’ in the Preface, and the results of
these calculations have a direct bearing on many currently controversial health and environmental issues. Of course, most real
problems will require more sophisticated models than we are considering now, but having seen this simple calculation it will beclear how to generalize it in many different ways.

<<<PAGE 641>>>

20 Model comparison 609
How could one ever acquire information about the long-run results of an experiment
that has never been performed? That is part of the mind projecting mythology that wediscard.
We recognize, then, that assigning this sampling distribution is only a means of describing
our own prior state of knowledge about the measurement errors. The parameter σindicates
the general magnitude of the errors that we expect. The prior information Imight, for
example, be the variability observed in past examples of such data; or in a physics experimentit might not be the result of any observations, but rather obtained from the principles ofstatistical mechanics, indicating the level of Nyquist noise for the known temperature ofthe apparatus.
In particular, the absence of correlations in (20.14) is not an assertion that no cor-
relations exist in the real data; it is only a recognition that we have no prior knowl-edge of such correlations, and therefore to suppose correlations of either sign is aslikely to hurt as to help the accuracy of our inferences. In one sense, by being non-committal about it, we are only being honest and frankly acknowledging our ignorance.
But in another sense, we are taking the safest, most conservative, course; using a sam-
pling distribution which will yield reasonable results whether or not correlations ac-
tually exist . But if we knew of any such correlations, we would be able to make still
better inferences (although not much better) by use of a sampling distribution whichcontains them.
The reason for this is that correlations in a sampling distribution tell the robot that some
regions of the vector sample space are more likely than others, even though they have thesame mean-square error magnitudes
e2; then some details of the data that it would otherwise
have to dismiss as noise can be recognized as providing further evidence about systematic
effects in the model.
We return to the problem. The sampling distribution for model M1is
M1: p(D|αM1)=/parenleftBigw
2π/parenrightBign/2
exp/braceleftBig
−nw
2Q1(α)/bracerightBig
(20.15)
with the quadratic form
Q1(α)≡1
nn/summationdisplay
i=1(yi−αxi)2=y2−2αxy+α2x2, (20.16)
where the bars denote averages. The maximum-likelihood estimate of αis then found from
∂Q1/∂α=0, or,
α=ˆα≡xy
x, (20.17)
which in this case is also called the ‘ordinary least squares’ estimate. Supposing the weight
wis known; the likelihood (20.15) for model M1is then
L1(α)=/parenleftBigw
2π/parenrightBign/2
exp/braceleftBig
−nw
2/bracketleftbig
y2+x2(α−ˆα)2−x2ˆα2/bracketrightbig/bracerightBig
(20.18)

<<<PAGE 642>>>

610 Part 2 Advanced applications
in which we could discard any factor independent of α, but that will disappear presently
of its own accord, in (20.23). If we were using this to estimate αfrom the data alone, our
result would be
(α)est=ˆα±1/radicalbig
nwx2=ˆα±1√nσ
xrms=ˆα±δα, (20.19)
where xrms=/radicalbig
x2is the root-mean-square value of the xi. Thus the volume (in this case,
width) of the high-likelihood region /Omega1/primemay be taken as roughly V(/Omega1/prime)=2(δα).
Now, using (20.17), the ‘global’ sampling distribution for model M1in (20.3) contains
two factors:
p(D|M1I)=/integraldisplay
dαp(D|αM1)p(α|M1I)=Lmax(M1)W1, (20.20)
where
Lmax(M1)=L1(ˆα). (20.21)
The Ockham factor for model M1is therefore
W1=/integraldisplay
dαL1(α)
L1(ˆα)p(α|M1I), (20.22)
and we ﬁnd for the likelihood ratio
L1(α)
L1(ˆα)=exp/bracketleftBigg
−nwx2
2(α−ˆα)2/bracketrightBigg
. (20.23)
This makes it evident that W1≤1, since the likelihood ratio cannot exceed unity and the
prior is normalized.
Now we must assign a prior for α. Usually, we will have some reason, such as previous
experience with such problems, for guessing a value of the general order of magnitude ofsome quantity α
0, but we are not at all conﬁdent of the accuracy of that guess, except to
think that|α−α0|cannot be enormously large (else there would be such a catastrophe
that we would not be concerned with this problem); but we would seldom have any morespeciﬁc prior information about it. We can indicate this by assigning the normalized priordensity
p(α|M
1I)=/radicalbiggw0
2πexp/braceleftBig
−w0
2(α−α0)2/bracerightBig
, (20.24)
which says that we think it unlikely that |α−α0|is much greater than σ0=1/√w0. From
both the central limit theorem as discussed in Chapter 7 and the maximum entropy principleas discussed in Chapter 11, this Gaussian functional form of prior is preferred in principleover all others as representing the actual state of knowledge that we have in virtually all realproblems. Then it is fortunate that this form also enables us to do the integration (20.22)

<<<PAGE 643>>>

20 Model comparison 611
exactly, with the result
W1=/radicalbiggw0
nwx2+w0exp/braceleftBigg
−nwx2w0
2(nwx2+w0)(ˆα−α0)2/bracerightBigg
. (20.25)
Rewriting this in terms of the half-width δα=1//radicalbig
nwx2of the high-likelihood region and
the half-width σ0=1/√w0of the prior for α, it becomes
W1=1/radicalbig
1+(σ0/δα)2exp/braceleftbigg
−(ˆα−α0)2
2σ2
0/bracerightbigg
. (20.26)
This has several limiting forms. If the prior estimate α0is exactly equal to the ordinary least
squares estimate ˆ α, it reduces to
W1=1/radicalbig
1+(σ0/δα)2. (20.27)
Then, if σ0/greatermuchδα,w eh a v e
W1/similarequalδα
σ0, (20.28)
which is indeed just the amount of prior probability contained in the high-likelihood region.
In this case, the Ockham factor is the ratio by which the parameter space is contracted by the
information in the data, which expresses how much the vagueness of our prior informationdeteriorates the performance of model M
1, by placing prior probability outside its high-
likelihood region. If the prior estimate α0differs from the ordinary least squares estimate ˆ α
by less than σ0, this remains approximately correct.
If in (20.27), σ0→0, we have W1→1, the maximum possible value; if the prior infor-
mation already told us exactly the ordinary least squares estimate from the data, with zeroerror tolerance, model W
1is not penalized at all. But in all other cases there is some penalty.
For example, if|α0−ˆα|/greatermuchσ0, then the evidence of the data strongly contradicts the prior
information, and the model is severely penalized.
For model M2the sampling distribution is still given by (20.15), but now with the quadratic
form
Q2(α, β)≡1
n/summationdisplay
(yi−αxi−βx2
i)2=y2+α2x2+β2x4−2αxy−2βx2y+2αβx3,
(20.29)
and the maximum-likelihood estimates ( ˆ α,ˆβ) are now the roots of the simultaneous equa-
tions∂Q2/∂α=0,∂ Q2/∂β=0, or
x2ˆα+x3ˆβ=xy(20.30)
x3ˆα+x4ˆβ=x2y,

<<<PAGE 644>>>

612 Part 2 Advanced applications
of which the solution is
ˆα=(x4)(xy)−(x3)(x2y)
(x2)(x4)−(x3)2, ˆβ=(x2)(x2y)−(x3)(xy)
(x2(x4)−(x3)2, (20.31)
and we note that, as x3→0, these relax into estimates
ˆα→xy
x2, ˆβ→x2y
x4, (20.32)
where ˆ αis the ordinary least squares estimate found using model M1(20.17). Now, as in
(20.22), the Ockham factor for model M2is
W2=/integraldisplay
dα/integraldisplay
dβL2(α, β)
L2(ˆα,ˆβ)p(αβ|M2I), (20.33)
and, after some rather tedious algebra, we ﬁnd that the likelihood ratio just constructs a
familiar quadratic form:
L2(α, β)
L2(ˆα,ˆβ)=exp/braceleftBig
−nw
2Q(α, β)/bracerightBig
, (20.34)
where
Q(α, β)≡Q2(α, β)−Q2(ˆα,ˆβ)
=x2(α−ˆα)2+2x3(α−ˆα)(β−ˆβ)+x4(β−ˆβ)2.(20.35)
Now we assign a joint prior
p(αβ|M2I)=/radicalbiggw0
2πexp/braceleftBig
−w0
2(α−α0)2/bracerightBig/radicalbiggw1
2πexp/braceleftBig
−w1
2(β−β0)2/bracerightBig
(20.36)
in which w0,a0are the same as in (20.24), so that the marginal prior for αis the
same in the two models (otherwise we would be changing two different circumstancesinstead of one in going from M
1toM2, which would make the results very hard to
interpret):
p(α|M1I)=p(α|M2I). (20.37)
The Ockham factor for model M2is then
W2=√w0w1
2π/integraldisplay
dα/integraldisplay
dβexp/braceleftbigg
−1
2/bracketleftbig
nwQ(α, β)+w0(α−α0)2+w1(β−β0)2/bracketrightbig/bracerightbigg
,
(20.38)

<<<PAGE 645>>>

20 Model comparison 613
and again this integration can be carried out exactly, with the result
W2=/radicalBigg
w0w1
(w0+nwx2)(w1+nwx4)exp{x}. (20.39)
Editor’s Exercise 20.1. As written, the denominator in (20.39) is correct only if the
condition x3→0 is used. Using this simplifying assumption, derive W2and deﬁne x.
The net Ockham factor in favor of M1over M2is computed from (20.27) and (20.39):
W1
W2=1//radicalbig
1+(σ0/δα)2
/radicalBig
(w0w1)/(w0+nwx2)(w1+nwx4)e x p{x}. (20.40)
Editor’s Exercise 20.2. Rewrite (20.40) in terms of the half-widths: δα=
1//radicalbig
nwx2,σ0=1/√w0,δ β=1//radicalbig
nwx4, andσ1=1/√w1. Under what conditions
will model M2will be favored over M1?
20.5 Comments
Actual scientiﬁc practice does not really obey Ockham’s razor, either in its previous ‘sim-
plicity’ form or in our revised ‘plausibility’ form. As so many of us have deplored, theattractive new hypothesis or model, which accounts for the facts in such a neat, plausibleway that you want to believe it at once, is usually pooh-poohed by the ofﬁcial Establish-ment in favor of some drab, complicated, uninteresting one; or, if necessary, in favor of noalternative at all. The progress of science is carried forward mostly by the few fundamen-tal dissenting innovators, such as Copernicus, Galileo, Newton, Laplace, Darwin, Mendel,
Pasteur, Boltzmann, Einstein, Wegener, Jeffreys – all of whom had to undergo this initial
rejection and attack. In the cases of Galileo, Laplace, and Darwin, these attacks continuedfor more than a century after their deaths. This is not because their new hypotheses werefaulty – quite the contrary – but because this is part of the sociology of science (and, indeed,of all scholarship). In any ﬁeld, the Establishment is seldom in pursuit of the truth, becauseit is composed of those who sincerely believe that they are already in possession of it.
Progress is delayed also by another aspect of this. Scholars who failed to heed the
teachings of William of Ockham about issues amenable to reason and issues amenable onlyto faith, were – and still are – doomed to a lifetime of generating nonsense. We note themost common form this nonsense has taken in the past.

<<<PAGE 646>>>

614 Part 2 Advanced applications
20.5.1 Final causes
It seems that every discussion of scientiﬁc inference must deal, sooner or later, with the
issue of belief or disbelief in ﬁnal causes. Expressed views range all the way from JacquesMonod (1970) forbidding us even to mention purpose in the Universe, to the religiousfundamentalist who insists that it is evil not to believe in such a purpose. We are astonishedby the dogmatic, emotional intensity with which opposite views are proclaimed, by personswho do not have a shred of supporting factual evidence for their positions.
But almost everyone who has discussed this has supposed that by a ‘ﬁnal cause’ one
means some supernatural force that suspends natural law and takes over control of events(that is, alters positions and velocities of molecules in a way inconsistent with the equations
of motion) in order to ensure that some desired ﬁnal condition is attained. In our view,
almost all past discussions have been ﬂawed by failure to recognize that operation of aﬁnal
cause does not imply controlling molecular details.
When the author of a textbook says: ‘My purpose in writing this book was to ...’, he
is disclosing that there was a true ‘ﬁnal cause’ governing many activities of writer, pen,secretary, word processor, extending usually over several years. When a chemist imposesconditions on his system which forces it to have a certain volume and temperature, he is just
as truly the wielder of a ﬁnal cause dictating the ﬁnal thermodynamic state that he wished
it to have. A bricklayer and a cook are likewise engaged in the art of invoking ﬁnal causesfor deﬁnite purposes. But – and this is the point almost always missed – these ﬁnal causesaremacroscopic ; they do not determine any particular ‘molecular’ details. In all cases, had
those ﬁne details been different in any one of billions of ways, the ﬁnal cause would havebeen satisﬁed just as well.
The ﬁnal cause may then be said to possess an entropy, indicating the number of micro-
scopic ways in which its purpose can be realized; and the larger that entropy, the greater isthe probability that it will be realized. Thus the principle of maximum entropy applies alsohere.
In other words, while the idea of a microscopic ﬁnal cause runs counter to all the instincts
of a scientist, a macroscopic ﬁnal cause is a perfectly familiar and real phenomenon, whichwe all invoke daily. We can hardly deny the existence of purpose in the Universe whenvirtually everything we do is done with some deﬁnite purpose in mind. Indeed, anybodywho fails to pursue some deﬁnite long-run purpose in the conduct of his life is dismissed as anidler by his colleagues. Obviously, this is just a familiar fact with no religious connotations –and no anti-religious ones. Every scientist believes in macroscopic ﬁnal causes withoutthereby believing in supernatural contravention of the laws of physics. The wielder of theﬁnal cause is not suspending physical law; he is merely choosing the Hamiltonian with
which some system evolves according to physical law . To fail to see this is to generate the
most fantastic, mystical nonsense.

<<<PAGE 647>>>

21
Outliers and robustness
Probably everybody who has been involved in quantitative measurements has found himself
in the following situation. You are trying to measure some quantity θ(which might be, for
example, the right ascension of Sirius, the mass of a π-meson, the velocity of seismic
waves at a depth of 100 km, the melting point of a new organic compound, the elasticity of
consumer demand for apples, etc.). But the apparatus or the data taking procedure is always
imperfect and so, having made nindependent measurements of θ, you have ndifferent
results ( x1,..., xn). How are you to report what you now know about θ? More speciﬁcally,
what ‘best’ estimate should you announce, and what accuracy are you entitled to claim?
If these ndata values were closely clustered together making a reasonably smooth,
single-peaked histogram, you would accept the solutions given in the previous chapters, andmight feel that the problem of drawing conclusions from good data is not very difﬁcult,even without any probability theory. But your data are not nicely clustered: one value, x
j,
lies far away from the nice cluster made by the other ( n−1) values. How are you to deal
with this outlier? What effect does it have on the conclusions that you entitled to drawaboutθ?
We have seen in Chapters 4 and 5 how the appearance of astonishing, unexpected data
may cause the resurrection of dead hypotheses; it appears that something like that may be atwork here. In fact, any surprisingly ugly looking data with unexpected features might raisethe question in your mind. Here we consider only the special case of outliers, leaving it as an
exercise for the reader to work out the corresponding theory for other kinds of unexpectedstructure.
21.1 The experimenter’s dilemma
The problem of outliers in data has been a topic of lively discussion since the 18th century,
when it arose in astronomy, geodesy, calorimetry, and doubtless many other measurements.Let us interpret ‘apparatus’ broadly as meaning any method for acquiring data. On thephilosophical side, two opposite views have been expressed repeatedly.
(I) Something must have gone wrong with the apparatus; the outlier is not part of the good data and
we must throw it out to avoid getting erroneous conclusions.
615

<<<PAGE 648>>>

616 Part 2 Advanced applications
(II) No! It is dishonest to throw away any part of your data merely because it was unexpected. That
outlier may well be the most signiﬁcant datum you have, and it must be taken into account inyour data analysis, otherwise you are ‘fudging’ the data arbitrarily and you can make no pretenseof scientiﬁc objectivity.
From these statements we can understand why the issue can arouse controversy that is very
hard to resolve. Not only has an element of righteous ethical fervor crept in; it is also clearthat both positions do contain elements of truth. How can they be reconciled?
On the pragmatic side, several arbitrary ad hoc recipes were invented (such as the
Chauvenet criterion found in the astronomy textbooks of a century ago) to decide when toreject an outlier. It is curious that the arbitrary criteria for rejection (two standard deviations,etc.) seem to have taken no note of the following, which we think is essential for any rationalapproach to the problem.
Pondering the two statements above, we see that they reﬂect different prior information
about the apparatus. This is the crucial factor – ignored in all the aforementioned criteria.To take it into account properly requires, not still more ad hockeries , but straightforward
probability analysis.
Position (I) seems reasonable if we know that the means of gathering data is unreliable,
and it is indeed likely to break down without warning and give erroneous data. If we alreadyexpect this, then the appearance of a wild outlier seems far more likely to be due to ‘apparatusfailure’ than to a real effect.
1
Position (II), on the other hand, is the reasonable stance for one who has absolute conﬁ-
dence in his apparatus: he is sure that his voltmeter always gives readings reliable to ±0.5%,
and could not be in error by 5%; or that his telescope was aimed within 10 arc seconds ofthe recorded direction, and cannot be off by 1 degree. Then the appearance of an outliermust be accepted as a signiﬁcant event, however unexpected; to ignore it could be to missan important discovery.
But (I) and (II) are extreme positions, and the real experimenter is almost always in some
intermediate situation. Presumably, if he knew that his apparatus was very unreliable, hewould prefer not to take data with it at all; but in a ﬁeld like biology or economics onemay be obliged to use whatever ‘apparatus’ Nature has provided. On the other hand, fewscientists – even in the best laboratories of the National Bureau of Standards – are ever soconﬁdent of their apparatus that they will afﬁrm dogmatically that it cannot go awry.
One would like to see the estimate in the form of an unequivocal statement like
(θ)
est=A±B, where A,Bare two deﬁnite numbers, presumably two functions of the
data D≡(x1,..., xn). But what two functions? When the data are closely clustered to-
gether, it is surely a reasonable guess to take A=x≡n−1/summationtextxi, the sample mean, as the
estimated value. The observed scatter of the data values xiindicates the reproducibility of
the measurements, and one might suppose that this indicates also their accuracy . If so, it
might seem reasonable to calculate the mean-square deviation from the mean, or sample
1We saw another example of this phenomenon in Chapter 6, in the discussion following Eq. (6.97). There probability theory told
us that, if large ﬂuctuations in counting rate are to be expected as an artifact of the apparatus, then the observed ﬂuctuations
become less cogent for estimating changes in beam intensity.

<<<PAGE 649>>>

21 Outliers and robustness 617
variance: s2≡n−1/summationtext(xi−x)2=x2−x2and choose B=s, the sample standard devia-
tion. A more educated intuition familiar with elementary results of probability theory canimprove on this by taking B=s/√
n, and even if it is not shown to be optimal by any
clearly stated criterion, the conclusion
(θ)est=x±s√n(21.1)
would not be criticized as wildly unreasonable in location or accuracy.
Exercise 21.1. We have seen in Chapter 7 that, under rather general conditions,
a Gaussian sampling distribution, p(x|θ,σ)∝exp{−(x−θ)2/2σ2}, leads us to take
our point estimate of θas the data mean x. Show that any sampling distribution with a
rounded top (that is, p(x|θ)=a0−a1(x−θ)2+··· ) will lead us to the same mean-
value estimate in the limit where the data are closely clustered.
If the data are not closely clustered, the above discussion seems to consider only two possible
actions: keep the outlier and give it full credence; or throw it out altogether. Is there a moredefensible intermediate position?
21.2 Robustness
Another viewpoint toward such problems has arisen recently, represented by Huber (1981)
and noted brieﬂy in Chapter 6. It still seeks to deal with them by intuitive ad hoc procedures
that do not take explicit note of prior information or probability theory; but it does lookfor an intermediate position. One seeks data analysis methods that are robust , which means
insensitive to the exact sampling distribution of errors or, as it is often stated, insensitive tothe model, or are resistant , meaning that large errors in a small proportion of the data do
not greatly affect the conclusions.
The general idea, stated vaguely, is that theoretical ‘optimality’, in the sense we have
used it in previous chapters, is not always a good criterion in practice. Often we are unsureof the correct model; then a method which is useful for a variety of different models, eventhough not optimal for any, may be preferable to one that is exactly suited to one speciﬁcmodel, but misleading for others.
Evidently, there could be some merit in this view; but the ‘robustnik/exploratory’ school
of thought, represented by Tukey and Mosteller (for example, Tukey, 1977), carries this tothe point of deprecating all considerations of optimality. However, attempts to deﬁne thisposition less vaguely become troublesome. Given data Dand any two estimators f(D),
g(D) of some parameter, is there any explicit deﬁnition of the term ‘robust’ or ‘resistant’
which would make it meaningful to say that one is ‘more robust’ or ‘more resistant’ thanthe other? If so, then within a given set Sof feasible estimators there is necessarily

<<<PAGE 650>>>

618 Part 2 Advanced applications
an ‘optimally robust’ one a(D) and an ‘optimally resistant’ one b(D), not necessarily
unique.2
The point we make here is that if any intuitive property, such as robustness, is held to be
desirable, then as soon as this property is deﬁned with enough precision to allow transitivecomparisons, an optimality principle follows inexorably. So one cannot consistently advo-cate any well-deﬁned inference property and at the same time reject optimality principles.
Equally troublesome is the fact that robust/resistant qualities – however deﬁned – must
be bought at a price: the price of poorer performance when the model is correct. Indeed, thisperformance can be very much poorer; for it is clear that the most robust procedure of all –the ‘optimal’ procedure if one asks only for robustness – is the one that ignores the model, thedata, and the prior information altogether, and considers all parameters zero, all hypothesesfalse! There must be, inevitably, some trade-off between the conﬂicting requirements ofrobustness and accuracy.
3Advocates of robust/resistance have an obligation to show us just
what trade-off, i.e. how much deterioration of performance, they are asking us to accept.
In estimating a location parameter, for example, the sample median Mis often cited as
a more robust estimator than the sample mean. But here it is obvious that this ‘robustness’is bought at the price of insensitivity to much of the relevant information in the data. Manydifferent data sets all have the same median; the values above or below the sample median
may be moved about arbitrarily without affecting the estimate. Yet those data values surely
contain information highly relevant to the question being asked, and all this is lost. Wewould have thought that the whole purpose of data analysis is to extract all the informationwe can from the data.
Thus, while we agree that robust/resistant properties may be desirable in some cases,
we think it important to emphasize their cost in performance. In the literature, ad hoc
procedures have been advocated on no more grounds than that they are ‘robust’ or ‘resistant’,
with no mention of the quality of the inference they deliver, much less any comparison ofperformance with alternative methods; yet alternative methods such as Bayesian ones arecriticized on grounds of lack of robustness, without any supporting factual evidence.
Those who criticize Bayesian methods on such grounds are simply revealing that they do
not understand how to use Bayesian methods. We wish to show that Bayesian data analysis,properly applied, automatically delivers robustness and resistance whenever those qualitiesare desirable; in fact, it does so in a way that agrees qualitatively with what previous ad hoc
intuitive procedures have done, but improves on them quantitatively, because Bayesianmethods never throw away relevant information. In other words, present robust methods
are, like the other orthodox methods, only intuitive approximations to what a full Bayesian
analysis gives automatically.
Indeed, this situation is very much like that noted in Section 5.6, where we discussed horse
racing and weather forecasting. The new information – there called the data – was not known
2The term ‘robust /resistant estimator’ was coined by John W. Tukey; the present writer suggested to him that this must mean,
literally, ‘an estimator which resists being robust’, but he denied it.
3In parameter estimation, the orthodox criterion of admissibility suffers from just the same defect; a procedure which ignores
the data and always estimates θ∗=5 is admissible if the point θ=5 is in the parameter space; yet it is clear that almost any
‘inadmissible’ estimation rule would be superior to this ‘admissible’ one.

<<<PAGE 651>>>

21 Outliers and robustness 619
with certainty to be true, and we saw how Bayesian analysis takes that into account automat-
ically. Here it is the model – part of the prior information – that is in doubt, but that makesno difference in principle because the ‘data’ and the ‘prior information’ are just two compo-nents of our total evidence which enter into probability theory in the same way. In the presentcase, a detailed Bayesian analysis reveals some very interesting and unexpected insight.
Reasoning that is unresponsive to changes in the model must be also in some way
unresponsive to changes in the data. Is this what we really want? We think the answer is:Sometimes: that is, in problems where we are unsure of the model but nevertheless sure of
the meaning of the parameters in it. But if we are sure of the model, then robust/resistance
is the last thing we want in our data analysis procedure; it would waste data by throwingaway cogent information.
Again, we must take explicit note of the prior information before the issue can be judged.
As demonstrated below, if we choose our sampling distribution to represent properly ourprior knowledge of the phenomenon that is generating the data, Bayesian analysis givesus automatically both robustness/resistant qualities when we are unsure of the model, and
optimal performance when we are sure of it.
We may, however, make one concession. Intuitive devices of the Tukey genre can take into
account, after a fashion, all kinds of special, one-time transitory contingencies that wouldbe difﬁcult – and not even desirable – to build into a model. A formal probability modelought to describe nontransitory situations that deserve more careful treatment and recordingfor future use. As a mathematician once put it: ‘A method is adevice that you use twice.’
But this one-time intuition is necessarily also a one-man operation, because it offers no
rationale or criterion of optimality for what it does so that others could judge its suitability .
If your one-time intuition differs from mine, then, without a normative theory of rational
inference, we are at an impasse that cannot be resolved. But a logically consistent ‘normativetheory of rational inference’ means necessarily (because of the theorems of Cox) a Bayesiantheory.
Let us examine ﬁrst the Bayesian treatment of the most common situation, in which the
data are classiﬁed into only two categories: good and bad.
21.3 The two-model model
We have a ‘good’ sampling distribution
G(x|θ) (21.2)
with a parameter θthat we want to estimate. Data drawn urn-wise from G(x|θ) are called
‘good’ data. But there is also a ‘bad’ sampling distribution
B(x|η), (21.3)
possibly containing an uninteresting parameter η. Data from B(x|η) are called ‘bad’ data;
they appear to be useless or worse for estimating θ, since their probability of occurring has

<<<PAGE 652>>>

620 Part 2 Advanced applications
nothing to do with θ. Our data set consists of nobservations
D=(x1,..., xn). (21.4)
But the trouble is that some of these data are good and some are bad, and we do not know
which is which (however, we may be able to make guesses: an obvious outlier – far out inthe tails of G(x|θ) – or any datum in a region of xwhere G(x|θ)/lessmuchB(x|η) comes under
suspicion of being bad).
In various real problems we may, however, have some prior information about the
process that determines whether a given datum will be good or bad. Various probabilityassignments for the good/bad selection process may express that information. For example,
we may deﬁne
q
i≡/braceleftBigg
1 if the ith datum is good
0i fi ti sb a d ,(21.5)
and then assign joint prior probabilities
p(q1···qn|I) (21.6)
to the 2nconceivable sequences of good and bad.
21.4 Exchangeable selection
Consider the most common case, where our information about the good/bad selection
process can be represented by assigning an exchangeable prior. That is, the probabilityof any sequence of ngood/bad observations depends only on the numbers r,(n−r)o f
good and bad ones, respectively, and not on the particular trials at which they occur. Thenthe distribution (21.6) is invariant under permutations of the q
i, and by the de Finetti
representation theorem (Chapter 18), it is determined by a single generating function g(u):
p(q1···qn|I)=/integraldisplay1
0duur(1−u)n−rg(u). (21.7)
It is much like ﬂipping a coin with unknown bias where, instead of ‘good’ and ‘bad’, we
say ‘heads’ and ‘tails’. There is a parameter usuch that if uwere known we would say that
any given datum xmay, with probability u, have come from the good distribution; or with
probability (1−u) from the bad one. Thus, umeasures the ‘purity’ of our data; the closer
to unity the better. But uis unknown, and g(u) may, for present purposes, be thought of
as its prior probability density (as was, indeed, done already by Laplace; further technicaldetails about this representation are given in Chapter 18). Thus, our sampling distributionmay be written as a probability mixture of the good and bad distributions:
p(x|θ,η, u)=uG(x|θ)+(1−u)B(x|η), 0≤u≤1. (21.8)

<<<PAGE 653>>>

21 Outliers and robustness 621
This is just a particular form of the general parameter estimation model, in which θis the
parameter of interest, while ( η,u) are nuisance parameters; it requires no new principles
beyond those expounded in Chapter 6.
Indeed, the model (21.8) contains the usual binary hypothesis testing problem as a special
case, where it is known initially that all the observations are coming from G, or they are all
coming from B, but we do not know which. That is, the prior density for uis concentrated
on the points u=0,u=1:
p(u|I)=p0δ(1−u)+p1δ(u), (21.9)
where p0=p(H0|I),p1=1−p0=p(H1|I) are the prior probabilities for the two
hypotheses:
H0≡all the data come from the distribution G(x|θ),
H1≡allthe data come from the distribution B(x|η).(21.10)
Because of their internal parameters, they are composite hypotheses; the Bayesian analysis
of this case was noted brieﬂy in Chapter 4. Of course, the logic of what we are doing heredoes not depend on value judgments like ‘good’ and ‘bad’.
Now consider uunknown and the problem to be that of estimating θ. A full nontrivial
Bayesian solution tends to become intricate, since Bayes’ theorem relentlessly seeks out andexposes every factor that has the slightest relevance to the question being asked. But oftenmuch of that detail contributes little to the ﬁnal conclusions sought (which might be only theﬁrst few moments, or percentiles, of a posterior distribution). Then we are in a position toseek useful approximate algorithms that are ‘good enough’ without losing essential infor-mation or wasting computation on nonessentials. Such rules might conceivably be ones that
intuition had already suggested, but, because they are good mathematical approximations
to the full optimal solution, they may also be far superior to any of the intuitive devices thatwere invented without taking any note of probability theory; it depends on how good thatintuition was.
Our problem of outliers is a good example of these remarks. If the good sampling density
G(x|θ) is very small for |x|>1, while the bad one B(x|η) has long tails extending to
|x|/greatermuch1, then any datum yfor which|y|>1 comes under suspicion of coming from the
bad distribution, and intuitively one feels that we ought to ‘hedge our bets’ a little by givingit, in some sense, a little less credence in our estimate of θ. Put more speciﬁcally, if the
validity of a datum is suspect, then intuition suggests that our conclusions ought to be lesssensitive to its exact value. But then we have just about stated the condition of robustness(only now, this reasoning gives it a rationale that was previously missing). As |x|→∞ it
is practically certain to be bad, and intuition probably tells us that we ought to disregard italtogether.
Such intuitive judgments were long since noted by Tukey and others, leading to such
devices as the ‘redescending psi function’, which achieve robust/resistant performanceby modifying the data analysis algorithms in this way. These works typically either donot deign to note even the existence of Bayesian methods, or contain harsh criticism of

<<<PAGE 654>>>

622 Part 2 Advanced applications
Bayesian methods, expressing a belief that they are not robust/resistant and that the intuitive
algorithms are correcting this defect – but never offering any factual evidence in support ofthis position.
In the following we break decades of precedent actually examining a Bayesian calculation
of outlier effects, so that one can see – perhaps for the ﬁrst time – what Bayesianity has tosay about the issue, and thus give that missing factual evidence.
21.5 The general Bayesian solution
Firstly, we give the Bayesian solution based on the model (21.8) in full generality, then we
study some special cases. Let p(θηu|I) be the joint prior density for the parameters. Their
joint posterior density given the data Dis
f(θ,η, u|DI)=Af(θ,η, u|I)L(θ,η, u), (21.11)
where Ais a normalizing constant, and, from (21.8),
L(θ,η, u)=
n/productdisplay
i=1/bracketleftBig
uG(xi|θ)+(1−u)B(xi|η)/bracketrightBig
(21.12)
is their joint likelihood. The marginal posterior density for θis
p(θ|DI)=/integraldisplay/integraldisplay
dηduf(θ,η, u|DI). (21.13)
To write (21.12) more explicitly, factor the prior density:
f(θ,η, u|I)=h(η,u|θ,I)f(θ|I), (21.14)
where f(θ|I) is the prior density for θ, and h(η,u|θ,I) is the joint prior for ( η,u), given θ.
Then the marginal posterior density for θ, which contains all the information that the data
and the prior information have to give us about θ,i s
f(θ|D,I)=f(θ|I)L(θ)/integraltext
dθf(θ|I)L(θ), (21.15)
where we have introduced the quasi-likelihood
L(θ)≡/integraldisplay/integraldisplay
dηduL(θ,η, u)h(η,u|θ,I). (21.16)
Inserting (21.12) into (21.16) and expanding, we have
L(θ)=/integraldisplay/integraldisplay
dηduh(η,u|θ,I)/bracketleftBig
unL(θ)+un−1(1−u)n/summationdisplay
j=1B(xj|η)Lj(θ)
+un−2(1−u)2/summationdisplay
j<kB(xj|η)B(xk|η)Ljk(θ)+···
+(1−u)nB(x1|η)···B(xn|η)/bracketrightBig
,(21.17)

<<<PAGE 655>>>

21 Outliers and robustness 623
in which
L(θ)≡n/productdisplay
i=1G(xi|θ)
Lj(θ)≡/productdisplay
i/negationslash=jG(xi|θ) (21.18)
Ljk(θ)≡/productdisplay
i/negationslash=j,kG(xi|θ)... etc.
are a sequence of likelihood functions for the good distribution in which we use all the data,
all except the datum xj, all except xjandxk, and so on. To interpret the lengthy expression
(21.17), note that the coefﬁcient of L(θ),
/integraldisplay1
0du/integraldisplay
dηh(η,u|θ,I)un=/integraldisplay
duunh(u|θ,I), (21.19)
is the probability, conditional on θand the prior information, that all the data {x1,..., xn}
are good. This is represented in the Laplace–de Finetti form (21.7) in which the generatingfunction g(u) is the prior density h(u|θ,I) for u, conditional on θ. Of course, in most real
problems this would be independent of θ(which is presumably some parameter referring to
an entirely different context than u); but preserving generality for the time being will help
to bring out some interesting points later.
Likewise, the coefﬁcient of L
j(θ) in (21.17) is
/integraldisplay
duun−1(1−u)/integraldisplay
dηB(xj|η)h(η,u|θ,I). (21.20)
Now the factor
dη/integraldisplay
duun−1(1−u)h(η,u|θI) (21.21)
is the joint probability density, given Iandθ, that any speciﬁed datum xjis bad, that the
(n−1) others are good, and that ηlies in ( η,η+dη). Therefore the coefﬁcient (21.20) is
the probability, given Iandθ, that the jth datum would be bad and would have the value
xj, and the other data would be good. Continuing in this way, we see that, to put in it words,
our quasi-likelihood is:
L(θ)=prob(all the data are good) ×(likelihood using all the data)
+/summationdisplay
jprob(only xjbad)×(likelihood using all data except xj)
+/summationdisplay
j,kprob(only xj,xkbad)×(likelihood using all except xj,xk)
+···
+/summationdisplay
jprob(only xjgood)×(likelihood using only the datum xj)
+prob(all the data are bad) .(21.22)

<<<PAGE 656>>>

624 Part 2 Advanced applications
In shorter words: the quasi-likelihood L(θ) is a weighted average of the likelihoods for the
good distribution G(x|θ) resulting from every possible assumption about which data are
good, and which are bad, weighted according to the prior probabilities of those assumptions.We see how every detail of our prior knowledge about how the data are being generated iscaptured in the Bayesian solution.
This result has such wide scope that it would require a large volume to examine all its
implications and useful special cases. But let us note how the simplest ones compare withour intuition.
21.6 Pure outliers
Suppose the good distribution is concentrated in a ﬁnite interval
G(x|θ)=0,|x|>1, (21.23)
while the bad distribution is positive in a wider interval which includes this. Then any datum
xfor which|x|>1 is known with certainty to be an outlier, i.e. to be bad. If |x|<1, we
cannot tell with certainty whether it is good or bad. In this situation our intuition tells usquite forcefully: Any datum that is known to be bad is just not part of the data relevant toestimation of θand we shouldn’t be considering it at all. So just throw it out and base our
estimate on the remaining data.
According to Bayes’ theorem this is almost right. Suppose we ﬁnd x
j=1.432,xk=
2.176, and all the other x’s less than unity. Then, scanning (21.24) it is seen that only one
term will survive:
L(θ)=/integraldisplay
du/integraldisplay
dηh(η,u|θ,I)B(xj|η)B(xk|η)Ljk(θ)=Cjk(θ)Ljk(θ). (21.24)
As discussed above, the factor Cjkis almost always independent of θ, and since constant
factors are irrelevant in a likelihood, our quasi-likelihood in (21.15) reduces to just the oneobtained by throwing away the outliers, in agreement with that intuition.
But it is conceivable that in rare cases C
jk(θ) might, after all, depend on θ; and Bayes’
theorem tells us that such a circumstance would make a difference. Pondering this, we seethat the result was to be expected if only we had thought more deeply. For if the probabilityof obtaining two outliers with values x
j,xkdepends on θ, then the fact that we got those
particular outliers is in itself evidence relevant to inference about θ.
Thus, even in this trivial case Bayes’ theorem tells us something that unaided intuition did
not see: even when some data are known to be outliers, their values might still, in principle,
be relevant to estimation of θ. This is an example of what we meant in saying that Bayes’
theorem relentlessly seeks out and exposes every factor that has any relevance at all to thequestion being asked.
In the more usual situations, Bayes’ theorem tells us that whenever any datum is known to
be an outlier, then we should simply throw it out, if the probability of getting that particular

<<<PAGE 657>>>

21 Outliers and robustness 625
outlier is independent of θ. For, quite generally, a datum xican be known with certainty to
be an outlier only if G(xi|θ)=0 for all θ; but in that case every likelihood in (21.24) that
contains xiwill be zero, and our posterior distribution for θwill be the same as if the datum
xihad never been observed.
21.7 One receding datum
Now suppose the parameter of interest is a location parameter, and we have a sample of
ten observations. But one datum xjmoves away from the cluster of the others, eventually
receding out 100 standard deviations of the good distribution G. How will our estimate of
θfollow it? The answer depends on which model we specify.
Consider the usual model in which the sampling distribution is taken to be simply G(x|θ)
with no mention of any other ‘bad’ distribution. If Gis Gaussian, x∼N(θ,σ), and our
prior for θis wide (say >1000σ), then the Bayesian estimate for quadratic loss function
will remain equal to the sample average, and our far-out datum will pull the estimate aboutten standard deviations aw ay from the average indicated by the other nine data values. This
is presumably the reason why Bayesian methods are sometimes charged with failure to berobust/resistant.
However, that is the result only for the assumed model, which in effect proclaims dog-
matically: I know in advance that u=1; all the data will come from G, and I am so certain
of this that no evidence from the data could change my mind. If one actually had this muchprior knowledge, then that far-out datum would be highly signiﬁcant; to reject it as an ‘out-lier’ would be to ignore cogent evidence, perhaps the most cogent piece of evidence thatthe data provide. Indeed, it is a platitude that important scientiﬁc discoveries have resultedfrom an experimenter having that much conﬁdence in his apparatus, so that surprising newdata were believed; and not merely rejected as ‘accidental’ outliers.
If, nevertheless, our intuition tells us with overwhelming force that the deviant datum
should be thrown out, then it must be that we do not really believe that u=1 strongly
enough to adhere to it in the face of the evidence of the surprising datum. A Bayesian maycorrect this by use of the more realistic model (21.8). Then the proper criticism of the ﬁrstprocedure is not of Bayesian methods , but rather of the saddling of Bayesian methodology
with an inﬂexible, dogmatic model which denies the possibility of outliers. We saw inSection 4.4 on multiple hypothesis testing just how much difference it can make when wepermit the robot to become skeptical about an overly simple model.
Bayesian methods have inherent in them all the desirable robust/resistant qualities, and
they will exhibit these qualities automatically, whenever they aredesirable – if a sufﬁciently
ﬂexible model permits them to do so. But neither Bayesian nor any other methods can givesensible results if we put absurd restrictions on them. There is a moral in this, extendingto all of probability theory. In other areas of applied mathematics, failure to notice somefeature (like the possibility of the bad distribution B) means only that it will not be taken
into account. In probability theory, failure to notice some feature may be tantamount tomaking irrational assumptions about it.

<<<PAGE 658>>>

626 Part 2 Advanced applications
Then why is it that Bayesian methods have been criticized more than orthodox ones on
this issue? For the same reason that city B may appear in the statistics to have a highercrime rate than city A, when the fact is that city B has a lower crime rate, but more efﬁcientmeans for detecting crime. Errors undetected are errors uncriticized.
Like any other problem in this ﬁeld, this can be further generalized and extended endlessly,
to a three-model model, putting parameters in (21.6), etc. But our model is already generalenough to include both the problem of outliers and conventional hypothesis testing theory;and a great deal can be learned from a few of its simple special cases.

<<<PAGE 659>>>

22
Introduction to communication theory
We noted in Chapter 11 that one of the motivations behind this work was the attempt to
see Gibbsian statistical mechanics and Shannon’s communication theory as examples ofthe same line of reasoning. A generalized form of statistical mechanics appeared as soonas we introduced the notion of entropy, and we ought now to be in a position to treat
communication theory in a similar way.
One difference is that in statistical mechanics the prior information has nothing to do with
frequencies (it consists of measured values of macroscopic quantities such as pressure), and
so we have little temptation to commit errors. But in communication theory the prior infor-
mation consists, typically, of frequencies; this makes the probability–frequency conceptualpitfalls much more acute. For this reason it seemed best to take up communication theory
only after we had seen the general connections between probability and frequency, in a
variety of conceptually simpler applications.
22.1 Origins of the theory
Firstly, the difﬁcult matter of giving credit where credit is due. All major advances in
understanding have their precursors, whose full signiﬁcance is never recognized at thetime. Relativity theory had them in the work of Mach, Fitzgerald, Lorentz and Poincar´ e, to
mention only the most obvious examples. Communication theory had many precursors, inthework of Gibbs, Nyquist, Hartley, Szilard, von Neumann, and Wiener. But there is no
denying that the work of Shannon (1948) represents the arrival of the main signal, just asdid Einstein’s of 1905. In both cases ideas which had long been, so to speak, ‘in the air’ ina vague form, are grasped and put into sharp focus.
Shannon’s papers were so full of important new concepts and results that they exercised
not only a stimulating effect, but also a paralyzing effect. During the ﬁrst few years aftertheir appearance it was common to hear the opinion expressed, rather sadly, that Shannonhad anticipated and solved all the problems of the ﬁeld, and left nothing else for others to do.
The post-Shannon developments, with few exceptions, can be classed into efforts in
two entirely different directions. On the applications side, we have the expansionists (whotry to apply Shannon’s ideas to other ﬁelds, as we do here), the entropy calculator (who
works out the entropy of a television signal, the French language, a chromosome, or almost
627

<<<PAGE 660>>>

628 Part 2 Advanced applications
anything else you can imagine; and then ﬁnds that nobody knows what to do with it), and the
universalist (who assures us that Shannon’s work will revolutionize all intellectual activity;but is unable to offer a speciﬁc example of anything that has been changed by it).
We should not be overly critical of these efforts because, as J. R. Pierce has remarked, it is
very hard to tell at ﬁrst which ones make sense, which are pure nonsense, and which are thebeginning of something that will in time make sense. The writer’s efforts have received allthree classiﬁcations from various quarters. We expect that, eventually, the ideas introducedby Shannon will be indispensable to the linguist, the geneticist, the television engineer, theneurologist, the economist. But we share with many others a feeling of disappointment that40 years of effort along these lines has led to so little in the way of really useful advancesin these ﬁelds.
During this time there has been an overabundance of vague philosophy, and of abstract
mathematics; but, outside of coding theory, a rather embarrassing shortage of exampleswhere speciﬁc real problems have been solved by using this theory. We believe that thereason for this is that conceptual misunderstandings, almost all of which amount to the
mind projection fallacy, have prevented workers from asking the right questions. In order
to apply communication theory to other problems than coding, the ﬁrst and hardest step isto state precisely what is the speciﬁc problem that we want to solve ?
In almost diametric opposition to the above efforts, as far as aim was concerned, were
the mathematicians, who viewed communication theory simply as a branch of pure math-ematics. Characteristic of this school was a belief that, before introducing a continuousprobability distribution, you have to talk about set theory, Borel ﬁelds, measure theory, theLebesgue–Stieltjes integral, and the Radon–Nikodym theorem. The important thing was tomake the theorems rigorous by the criteria of rigor then fashionable among mathemati-
cians , even if in so doing we limit their scope for applications. The book on information
theory by A. I. Khinchin (1957) can serve as a typical example of the style prevalent in thisliterature.
Here again, severe criticism of these efforts is not called for. Of course, we want our
principles to be subjected to the closest scrutiny the human mind can bring to bear on them;if important applications exist, the need for this is so much the greater. However, the presentwork is not addressed to mathematicians, but to persons concerned with real applications.
So we shall dwell on this side of the story only to the extent of pointing out that the rigorized
theorems are not the ones relevant to problems of the real world. Typically, they refer only to
situations that do not exist (such as inﬁnitely long messages), and as a result they degenerateinto ‘nonsense theorems’ which assign probability one to an impossible event, and thereforezero to all possible events. We have no way of using such results, because our probabilitiesare always conditional on our knowledge of the real world. Now let’s turn to some of thespeciﬁc things in Shannon’s papers.
22.2 The noiseless channel
We deal with the transmission of information from some sender to some receiver. We shall
speak of them in anthropomorphic terms, such as ‘the man at the receiving end’, although

<<<PAGE 661>>>

22 Introduction to communication theory 629
either or both might actually be machines, as in telemetry or remote control systems.
Transmission takes place via some channel , which might be a telephone or telegraph circuit,
a microwave link, a frequency band assigned by the Federal Communication Commission(FCC), the German language, the postman, the neighborhood gossip, or a chromosome. If,after having received a message, the receiver can always determine with certainty whichmessage was intended by the sender, we say that the channel is noiseless .
It was recognized very early in the game, particularly by Nyquist and Hartley, that the
capability of a channel is not described by any property of the speciﬁc message it sends,but rather by what it could have sent. The usefulness of a channel lies in its readiness to
transmit any one of a large class of messages, which the sender can choose at will.
In a noiseless channel, the obvious measure of this ability is simply the maximum number,
W(t), of distinguishable (at the destination) messages which the channel is capable of
transmitting in a time t. In all cases of interest to us, this number goes eventually into an
exponential increase for sufﬁciently large t:W(t)∝exp{Ct}, so the measure of channel
performance which is independent of any particular time interval is the coefﬁcient Cof this
increase. We deﬁne the channel capacity as
C≡lim
t→∞/bracketleftbigg1
tlog[W(t)]/bracketrightbigg
. (22.1)
The units in which Cis measured will depend on which base we choose for our logarithms.
Usually one takes base 2, in which Cis given in ‘bits per second’, one bit being the amount
of information contained in a single binary (yes–no) decision. For easy interpretation ofnumerical values, the bit is by far the best unit to use; but in formal operations it may be
easier to use the base e of natural logarithms. Our channel capacities are then measured
in natural units, or ‘nits per second’. To convert, note that 1 bit =ln(2)=0.69315 nits, or
1 nit=1.4427 bits.
The capacity of a noiseless channel is a deﬁnite number, characteristic of the channel,
which has nothing to do with human information. Thus, if a noiseless channel can transmit n
symbols per second, chosen in any order from an alphabet of aletters, we have W(t)=a
nt,
orC=nlog2(a) bits/s=nloge(a) nits/s. Any constraint on the possible sequences of
letters can only lower this number. For example, if the alphabet is A1,A2,..., Aa, and it is
required that in a long message of N=ntsymbols the letter Aimust occur with relative
frequency fi, then the number of possible messages in time tis only
W(t)=N!
(Nf1)!···(Nfa)!, (22.2)
and from Stirling’s approximation, as we found in Chapter 11,
C=−n/summationdisplay
ifilog(fi) nits/s . (22.3)
This attains its maximum value, equal to the previous C=nlog(a), in the case of equal
frequencies, fi=1/a. Thus we have the interesting result that a constraint requiring all
letters to occur with equal frequencies does not decrease channel capacity at all. It does,of course, decrease the number W(t) by an enormous factor; but the decrease in log( W)i s

<<<PAGE 662>>>

630 Part 2 Advanced applications
what matters, and this grows less rapidly than t, so it makes no difference in the limit. In
view of the entropy concentration theorem of Chapter 11, this can be understood in anotherway: the vast majority of all possible messages are ones in which the letter frequencies are
nearly equal.
Suppose now that symbol A
ihas transmission time ti, but there is no other constraint on
the allowable sequences of letters. What is the channel capacity? Well, consider ﬁrst thecase of messages in which letter A
ioccurs nitimes, i=1,2,..., a. The number of such
messages is
W(n1,..., na)=N!
n1!···na!, (22.4)
where
N=a/summationdisplay
i=1ni. (22.5)
The total number of different messages that could have been transmitted in time tis then
W(t)=/summationdisplay
niW(n1,..., na), (22.6)
where we sum over all choices of ( n1,..., na) compatible with Ni≥0 and
a/summationdisplay
i=1niti≤t. (22.7)
The number K(t) of terms in the sum (22.6) satisﬁes K(t)≤(Bt)afor some B<∞. This
is seen most easily by imagining the nias coordinates in an a-dimensional space and noting
the geometrical meaning of K(t) as the volume of a simplex.
Exact evaluation of (22.6) would be quite an unpleasant job. But it’s only the limiting
value that we care about right now, and we can get out of the hard work by the followingtrick. Note that W(t) cannot be less than the greatest term W
m=Wmax(n1,..., na) in (22.6)
nor greater than WmK(t):
log(Wm)≤log[W(t)]≤log(Wm)+alog(Bt), (22.8)
and so we have
C≡lim
t→∞1
tlog[W(t)]=lim
t→∞1
tlog[Wm]; (22.9)
i.e. to ﬁnd the channel capacity, it is sufﬁcient to maximize log W(n1,..., na) subject to the
constraint (22.7). This rather surprising fact can be understood as follows. The logarithm of
W(t) is given, crudely, by log[ W(t)]=log(Wmax)+log [number of reasonably large terms
in (22.6)]. Even though the number of large terms tends to inﬁnity as ta, this is not rapid
enough to make any difference in comparison with the exponential increase of Wmax.A s
explained by Schr¨ odinger (1948), this same mathematical fact is the reason why, in statistical

<<<PAGE 663>>>

22 Introduction to communication theory 631
mechanics, the Darwin–Fowler method and the method of most probable distribution lead
to the same results in the limit of large systems.
We can solve the problem of maximizing log W(n1,..., na) by the same Lagrange mul-
tiplier argument used in Chapter 11. The problem is not quite the same, however, becausenow Nis also to be varied in ﬁnding the maximum. Using the Stirling approximation, which
is valid for large n
i,w eh a v e
logW(n1,..., na)≈Nlog(N)−a/summationdisplay
i=1nilog(ni). (22.10)
The variational problem, with λa Lagrangian multiplier, is
δ[log( W)+λ/summationdisplay
niti]=0, (22.11)
but since δN=/summationtextδniwe have
δlog(W)=δNlog(N)−δN−/summationdisplay
i(δnilog(ni)−δni)
=−/summationdisplay
δnilog(ni/N).(22.12)
Therefore (22.11) reduces to
a/summationdisplay
i=1[log( ni/N)+λti]δni=0 (22.13)
with the solution
ni=Nexp{−λti}. (22.14)
To ﬁx the value of λ, we require
N=/summationdisplay
ni=N/summationdisplay
exp{−λti}. (22.15)
With this choice of ni,w eﬁ n d
1
tlog(Wm)=−1
tlog(ni/N)=1
t/summationdisplay
ni(λti). (22.16)
In the limit, t−1/summationtextniti→1, and so
C=lim
t→∞1
tlog[W(t)]=λ. (22.17)
Our ﬁnal result can be stated very simply:
To calculate the capacity of a noiseless channel in which symbol A ihas transmission
time t iand which has no other constraints on the possible messages, deﬁne the partition
function Z (λ)≡/summationtext
iexp{−λti}. Then the channel capacity C is the real root of
Z(λ)=1. (22.18)
You see already a very strong resemblance to the reasoning and the formalism of statistical
mechanics, in spite of the fact that we have not yet said anything about probability.

<<<PAGE 664>>>

632 Part 2 Advanced applications
From (22.15) we see that W(n1,..., na) is maximized when the relative frequency of
symbol Aiis given by the canonical distribution
fi=ni
N=exp{−λti}=exp{−Cti}. (22.19)
Some have concluded from this that the channel is being ‘used most efﬁciently’ when we
have encoded our messages so that (22.19) holds. But that would be quite mistaken because,of course, in time tthe channel will actually transmit one message and only one; and this
remains true regardless of what relative frequencies we use. Equation (22.19) tells us onlythat – in accordance with the entropy concentration theorem – the overwhelming majorityof all possible messages that the channel could have transmitted in time tare ones where
the relative frequencies are canonical.
On the other hand, we have a generalization of the remark following (22.3): if we impose
an additional constraint requiring that the relative frequencies are given by (22.19), whichmight be regarded as deﬁning a new channel, the channel capacity would not be decreased.But any constraint requiring that all possible messages have letter frequencies different from
(22.19) will decrease channel capacity.
There are many other ways of interpreting these equations. For example, in our above ar-
guments we supposed that the total time of transmission is ﬁxed and we wanted to maximize
the number Wof possible messages which the sender can choose. In a practical communi-
cation system, the situation is usually the other way around: we know in advance the extentof choice which we demand in the messages which might be sent over the channel, so that
Wis ﬁxed. We then ask for the condition that the total transmission time of the message be
minimized subject to a ﬁxed W.
It is well known that variational problems can be transformed into several different
forms, the same mathematical result giving the solution to many different problems. Acircle has maximum area for a given perimeter; but also it has minimum perimeter for agiven area. In statistical mechanics, the canonical distribution can be characterized as onewith maximum entropy for a given expectation of energy; or equally well as the one withminimum expectation of energy for a given entropy. Similarly, the channel capacity foundfrom (22.18) gives the maximum attainable Wfor a given transmission time, or equally
well the minimum attainable transmission time for a ﬁxed W.
As another extension of the meaning of these equations, note that we need not interpret
the quantity t
ias a time; it can stand equally well for the ‘cost’, as measured by any
criterion, of transmitting the ith symbol. Perhaps the total length of time the channel is in
operation is of no importance, because the apparatus has to sit there in readiness whetherit is being used or not. The real criterion might be, for example, the amount of energythat a space probe must dissipate in transmitting a message back to Earth. In this case,we could deﬁne t
ias the energy required to transmit the ith symbol. The channel capacity
given by (22.18) would then be measured, not in bits per second but in bits per joule, and itsreciprocal is equal to the minimum attainable number of joules needed per bit of transmittedinformation.

<<<PAGE 665>>>

22 Introduction to communication theory 633
A more complicated type of noiseless channel, also considered by Shannon, is one where
the channel has a memory; it may be in any one of a set of ‘states’ {S1,..., Sk}and
the possible future symbols, or their transmission times, depend on the present state. Forexample, suppose that if the channel is in state S
i, it can transmit symbol An, which leaves
the channel in state Sj, the corresponding transmission time being tinj. Surprisingly, the
calculation of the channel capacity in this case is quite easy.
LetWi(t) be the total number of different messages the channel can transmit in time t,
starting from state Si. Breaking down Wi(t) into several terms according to the ﬁrst symbol
transmitted, we have the same difference equation that we used to introduce the partitionfunction in Chapter 8:
W
i(t)=/summationdisplay
jnWj(t−tinj), (22.20)
where the sum is over all possible sequences Si→An→Sj. As before, this is a linear
difference equation with constant coefﬁcients, so its asymptotic solution must be an expo-nential function:
W
i(t)≈Biexp{Ct}, (22.21)
andfrom the de ﬁnition (22.1) it is clear that, for ﬁnite k,the coef ﬁcient Cisthe channel
capacity. Substituting (22.21) into (22.20), we obtain
Bi=k/summationdisplay
j=1Zij(C)Bj, (22.22)
where
Zij(λ)=/summationdisplay
nexp{−λtinj} (22.23)
is the ‘partition matrix’. Compare this argument with our ﬁrst derivation of a partition
function in Chapter 8. If the sequence Si→An→Sjis impossible, we set tinj=∞ .B y
this device we can understand the sum in (22.23) as extending over all symbols in thealphabet.
Equation (22.22) says that the matrix Z
ijhas an eigenvalue equal to unity. Thus, the
channel capacity is simply the greatest real root of D(λ)=0, where
D(λ)≡det[Zij(λ)−δij]. (22.24)
This is one of the prettiest results given by Shannon. In the case of a single state, k=1, it
reduces to the previous rule, (22.18).
The problems solved above are, of course, only especially simple ones. By inventing
channels with more complicated types of constraints on the allowable sequences (i.e. witha long memory), we can generate mathematical problems as involved as we please. But itwould still be just mathematics – as long as the channel is noiseless, there would be nodifﬁculties of principle. In each case we simply have to count up the possibilities and apply

<<<PAGE 666>>>

634 Part 2 Advanced applications
the deﬁnition (22.1). For some weird channels, we might ﬁnd that the limit therein does
not exist, in which case we cannot speak of a channel capacity, but have to characterize thechannel simply by giving the function W(t).
22.3 The information source
When we take the next step and consider the information source feeding our channel,
fundamentally new problems arise. There are mathematical problems aplenty, but there arealso more basic conceptual problems which have to be considered before we can state whichmathematical problems are the signiﬁcant ones.
It was Professor Norbert Wiener who ﬁrst suggested the enormously fruitful idea of
representing an information source in probability terms. He applied this to some problemsof ﬁlter design. This work was an essential step in developing a way of thinking which ledto communication theory.
It is perhaps difﬁcult nowadays for us to realize what a big step this was. Previously,
communication engineers had considered an information source simply as a man with a
message to send; for their purposes an information source could be characterized simply
by describing that message. But Wiener suggested instead that an information source becharacterized by giving the probabilities p
ithat it will emit various messages Mi. Already
we see the conceptual difﬁculties faced by a frequency theory of probability – the man at thesending end presumably knows perfectly well which message he is going to send. What,then, could we possibly mean by speaking of the probability that he will send something?
There is nothing analogous to ‘chance’ operating here.
By the probability p
iof a message, do we mean the frequency with which he sends
that particular message? The question is absurd – a sane man sends a given message atmost once, and most messages never. Do we mean the frequency with which the message
M
ioccurs in some imaginary ‘ensemble’ of communication acts? Well, it’s all right to
state it that way if you want to, but it doesn’t answer the question. It merely leads us torestate the question as: What deﬁnes that ensemble? How is it to be set up? Calling it by adifferent name doesn’t help us. What information is that entropy H=−/summationtextp
ilog(pi) really
measuring?
We take a halting ﬁrst step toward answering this if we suppose that Shannon’s H
measures not the information of the sender, but the ignorance of the receiver, that is removedby receipt of the message. Indeed, most later commentators make this interpretation. Yet, onsecond thought, this does not make sense either; for Shannon proceeds to develop theoremsrelating Hto the channel capacity Crequired to transmit the messages M
i. But how well
a channel can transmit messages obviously depends on properties of the channel and themessages; and not at all on the state of ignorance of the receiver! You see the conceptualmess that the ﬁeld has been in for 40 years.
Right at this point we have to state clearly what the speciﬁc problem is that we want
solved . A probability distribution is a means of describing a state of knowledge. But whose
state of knowledge do we want to talk about? Evidently, not the man at the sending end

<<<PAGE 667>>>

22 Introduction to communication theory 635
or the one at the receiving end; and Shannon offers us no explicit help on this. But im-
plicitly, the answer seems to be clear; in view of the theorems Shannon gives, he cannotbe describing the ‘general philosophy’ of communication between sender and receiver, asso many have supposed. He is thinking of the theory as something of practical value to anengineer whose job is to design the technical equipment in the communication system. Inother words, the state of knowledge Shannon is describing is that of the communication engi-
neer when he designs the equipment .I ti s hisignorance about the messages to be sent that is
measured by H.
Although this viewpoint would seem perfectly natural for an engineer employed by the
Bell Telephone Laboratories, as Shannon was at the time, you will not ﬁnd it actuallyexpressed in his words, or in the later literature based on the viewpoint which sees nodistinction between probability and frequency. For on the frequentist view, the notion ofa probability for a person with a certain state of knowledge simply doesn’t exist, because
probability is thought to be a real physical phenomenon which exists independently ofhuman information. But the problem of choosing some probability distribution to represent
the information source still does exist; it cannot be evaded. It is now clear that the whole
content of the theory depends on how we do this.
We have already emphasized several times that in probability theory we never solve an
actual problem of practice. We solve only some abstract mathematical model of the realproblem. Setting up this model requires not only mathematical ability, but also a greatdeal of practical judgment. If our model does not correspond well to the actual situation,then our theorems, however rigorous the mathematicians may have made them, can bemore misleading than helpful. This is so with a vengeance in communication theory, be-cause not only the quantitative details, but even the qualitative nature of the theorems that
can be proved, depend on which probability model we use to represent an information
source.
The purpose of this probability model is to describe the communication engineer’s prior
knowledge about what messages his communication system may be called upon to send. In
principle, this prior knowledge could be of any sort; in particular, nothing prevents it frombeing semantic in nature. For example, he might know in advance that the channel will beused only to transmit stock market quotations, not quotations from the Bible, or obscene
limericks. That is a perfectly valid kind of prior information, which would have deﬁnite
implications for the probabilities p
iby restricting the sample space in deﬁnite, speciﬁc
ways, although they might be hard to state in general mathematical terms.
We stress this point because some critics harp away incessantly on the theme that infor-
mation theory does not consider semantic meaning, and hold this to be a basic defect ofour whole philosophy. They could not be more mistaken: the issue of semantic meaningis not a philosophical one but a technical one. The only reason why we do not considersemantic meaning is that we do not know how to do it as a general procedure , although we
could certainly do it ‘by hand’ in the context of a speciﬁc, ﬁnite set of possible messages.Probably all of us have tried to restore some corrupted text by drawing upon our perceptionof its semantic meaning; but how do you teach a computer to do this?

<<<PAGE 668>>>

636 Part 2 Advanced applications
So let us assure those critics: if you will show us a deﬁnite, usable algorithm for assessing
semantic meaning, we are most eager to incorporate this too into information theory. Infact, our present inability to do this is a serious handicap in many applications, from imagerestoration, to pattern recognition, to artiﬁcial intelligence. We need your constructive help,not your criticisms.
But in traditional Shannon-type communication theory the only kind of prior knowledge
considered is ‘statistical’ because this is amenable to mathematical treatment at once. That
is, it consists of frequencies of letters, or combinations of letters, which have been observedinpast samples of similar messages. Then a typical practical problem – indeed, the actual
problem of writers of those popular text compression computer programs – is to designencoding systems which will transmit binary digits representing English text, reliably andat the maximum possible rate, given an available channel with known properties. Thiswould be also the actual problem of designers of computer hardware such as disk drivesand modems, if they became a little more sophisticated. The designer will then, accordingto the usual viewpoint, need accurate data giving the correct frequencies of English text.Let’s think about that a little.
22.4 Does the English language have statistical properties?
Suppose we try to characterize the English language, for purposes of communication theory,
by specifying the relative frequencies of various letters, or combinations of letters. Nowwe all know that there is a great deal of truth in statements such as ‘the letter E occursmore frequently than the letter Z’. Long before the days of communication theory, manypeople made obvious common-sense use of this knowledge. One of the earliest examplesis the design of the Morse telegraphic code, in which the most frequently used letters arerepresented by the shortest codes – the exact prototype of what Shannon formalized andmade precise a century later.
The design of our standard typewriter keyboard makes considerable use of knowledge
of letter frequencies. This knowledge was used in a much more direct and drastic way byOttmar Mergenthaler, whose immortal phrase
ETAOIN SHRDLU (22.25)
was a common sight in the newspapers many years ago when Linotype machines ﬁrst came
into use (an inexperienced operator, who allowed his ﬁngers to brush lightly across the keys,automatically set this in type). But already we are getting into trouble, because there doesnot seem to be complete agreement even as to the relative order of the 12 most commonletters in English, let alone the numerical values of their relative frequencies. For example,according to Pratt (1942) the above phrase should read
ETANOR ISHDLF (22.26)

<<<PAGE 669>>>

22 Introduction to communication theory 637
while Tribus (1961) gives it as
ETOANI RSHDLC . (22.27)
As we go into the less frequently used letters, the situation becomes still more chaotic.
Of course, we readily see the reason for these differences. People who have obtained
different values for the relative frequencies of letters in English have consulted differentsamples of English text. It is obvious enough that the last volume of an encyclopedia willhave a higher relative frequency for the letter Z than the ﬁrst volume. The word frequencieswould be very different in a textbook on organic chemistry, a treatise on the history of Egypt,and a modern American novel. The writing of educated people would reveal systematicdifferences in word frequencies from the writing of people who had never gone beyondgrade school. Even within a much narrower ﬁeld, we would expect to ﬁnd signiﬁcantdifferences in letter and word frequencies in the writings of James Michener and ErnestHemingway. The letter frequencies in the transcript of a tape recording of a lecture willprobably be noticeably different from those one would produce if the lecturer sat down andwrote out the lecture verbatim.
The fact that statistical properties of a language vary with the author and circumstances
of writing is so clear that it has become a useful research tool. A doctoral thesis in classicssubmitted to Columbia University by James T. McDonough
1contains a computer-run sta-
tistical analysis of Homer’s Iliad . Classicists have long debated whether all parts of the Iliad
were written by the same man, and indeed whether Homer is an actual historical person.The analysis showed stylistic patterns consistent throughout the work. For example, 40.4%of the 15 693 lines end on a word with one short syllable followed by two long ones, and aword of this structure never once appears in the middle of a line. Such consistency in a thingwhich is not a characteristic property of the Greek language seems rather strong evidencethat the Iliad was written by a single person in a relatively short period of time, and it was
not, as had been supposed by some 19th century classicists, the result of an evolutionaryprocess over several centuries.
Of course, the evolutionary theory is not demolished by this evidence alone. If the Iliad
was sung, we must suppose that the music had the very monotonous rhythmic pattern of
primitive music, which persisted to a large extent as late as Bach and Haydn. Characteristic
word patterns may have been forced on the writers, by the nature of the music.
Archaeologists tell us that the siege of Troy, described in the Iliad , is not a myth but
an historical fact which occurred about 1200 bc, some four centuries before Homer. The
decipherment of Minoan Linear B script by Michel Ventris in 1952 (Ventris and Chadwick,1956; Chadwick, 1958; Ventris, 1988) established that Greek existed already as a spokenlanguage in the Aegean area several centuries before the siege of Troy; but the introductionof the Phoenician alphabet, which made possible a written Greek language in the modernsense, occurred at only about the time of Homer.
1‘The structural metrics of the Iliad’ , Ph. D., 1966, Columbia University.

<<<PAGE 670>>>

638 Part 2 Advanced applications
The considerations of the preceding two paragraphs still suggest an evolutionary devel-
opment. It is clear that the question is very complex and far from settled; but we ﬁnd itfascinating that a statistical analysis of word and syllable frequencies, representing evidencewhich has been there in the Iliad for some 28 centuries for anyone who had the wit to extract
it, is ﬁnally recognized as having a deﬁnite bearing on the problem.
Well, to get back to communication theory, the point we are making is simply this: it is
utterly wrong to say that there exists one and only one ‘true’ set of letter or word frequenciesfor English text. If we use a mathematical model which presupposes the existence of suchuniquely deﬁned frequencies, we might easily end up proving things which, while perfectlyvalid as mathematical theorems, are worse than useless to an engineer who is faced with thejob of actually designing a communication system to transmit English text most efﬁciently.
But suppose our engineer does have extensive frequency data, and no other prior knowl-
edge. How is he to make use of this in describing the information source? Many of thestandard results of communication theory can, from the viewpoint we are advocating, beseen as simple examples of maximum entrop y inference, i.e. as examples of the same kind
of reasoning as in statistical mechanics.
22.5 Optimum encoding: letter frequencies known
Suppose our alphabet consists of different symbols A
1,A2,..., Aa, and we denote a general
symbol by Ai,Aj, etc. Any message of Nsymbols then has the form Ai1Ai2···AiN.
We denote this message by M, which is a shorthand expression for the set of indices:
M={i1i2···iN}. The number of conceivable messages is aN.B y/summationtext
Mwe mean a sum
over all of them. Also, deﬁne
Nj(M)≡number of times the letter Ajappears in message M,
Nij(M)≡number of times the digram AiAjappears in M,(22.28)
and so on.
Consider ﬁrst an engineer E1, who has a set of numbers ( f1,..., fa) giving the relative
frequencies of the letters Aj, as observed in past samples of messages, but has no other
prior knowledge. What communication system represents rational design on the basis ofthis much information, and what channel capacity does E
1require in order to transmit
messages at a given rate of nsymbols per second?
To answer this, we need the probability distribution p(M) which E1assigns to the various
conceivable messages. Now, E1has no deductive proof that the letter frequencies in the
future messages will be equal to the fiobserved in the past. On the other hand, his state of
knowledge affords no grounds for supposing that the frequency of Aiwill be greater than
firather than less, or vice versa. So he is going to suppose that frequencies in the future
will be more or less the same as in the past, but he is not going to be too dogmatic about it.He can do this by requiring of the distribution p(M) only that it yields expected frequencies
equal to the known past ones. Put differently, if we say that our distribution p(M) ‘contains’

<<<PAGE 671>>>

22 Introduction to communication theory 639
certain information, we mean that that information can be extracted back out of it by the
usual rule of estimation. In other words, E1will impose the constraints
/angbracketleftNi/angbracketright=/summationdisplay
MNi(M)p(M)=Nfi,i=1,2,..., a. (22.29)
Of course, p(M) is not uniquely determined by these constraints, and so E1must at this
point make a free choice of some distribution.
We emphasize again that it makes no sense to say there exists any ‘physical’ or ‘objective’
probability distribution p(M) for this problem. This becomes especially clear if we suppose
that only a single message is ever going to be sent over the communication system, butwe still want it to be transmitted as quickly and reliably as possible, whatever that message
turns out to be (perhaps we know that the system will be destroyed by impact on Ganymedeimmediately afterward); thus there is no concei vable way in which p(M) could be measured
as a frequency. But this would in no way affect the problem of engineering design whichwe are considering.
In choosing a distribution p(M), it would be perfectly possible for E
1to assume some
message structure involving more than single letters. For example, he might suppose thatthe digram A
1A2is twice as likely as A2A3. But from the standpoint of E1this could not
be justiﬁed, for as far as he knows , a design based on any such assumption is as likely to
hurt as to help. From E1’s standpoint, rational conservative design consists just in carefully
avoiding any such assumptions. This means, in short, that E1should choose the distribution
p(M) by maximum entropy consistent with (22.29).
All the formalism of the maximum entropy inference developed in Chapter 11 now
becomes available to E1. His distribution p(M) will have the form
logp(M)+λ0+λ1N1(M)+λ2N2+···+ λaNa(M)=0, (22.30)
and, in order to evaluate the Lagrangian multipliers λi, he will use the partition function
Z(λ1,...,λ a)=/summationdisplay
Mexp{−λ1N1(M)−···− λaNa(M)}=zN, (22.31)
where
z≡exp{−λ1}+···+ exp{−λa}. (22.32)
From (22.29) and the general relation
/angbracketleftNi/angbracketright=−∂
∂λilogZ(λ1,...,λ a), (22.33)
we ﬁnd
λi=− log(zfi),1≤i≤a, (22.34)

<<<PAGE 672>>>

640 Part 2 Advanced applications
and, substituting back into (22.30), we ﬁnd the distribution which describes E1’s state of
knowledge is just the multinomial distribution,
p(M)=fN1
1fN2
2···fNa
a, (22.35)
which is a special case of an exchangeable sequence; the probability of any particular
message depends only on how many times the letters A1,A2,... appear, not on their
order. The result (22.35) is correctly normalized,/summationtext
Mp(M)=1, as we see from the fact
that the number of different messages possible for speciﬁed Niis just the multinomial
coefﬁcient
N!
N1!···Na!. (22.36)
The entropy per symbol of the distribution (22.35) is
H1=−1
N/summationdisplay
Mp(M) log p(M)=log(Z)
N+a/summationdisplay
i=1λifi=−a/summationdisplay
i=1filog(fi). (22.37)
Having found the assignment p(M),E1can encode into binary digits in the most efﬁcient
way by a method found independently by Shannon (1948, Sec. 9) and R. M. Fano. Arrangethe messages in order of decreasing probability, and by a cut separate them into two classesso the total probability of all messages to the left of the cut is as nearly as possible equalto the probability of the messages on the right. If a given message falls in the left class, theﬁrstbinary digit in its code is 0; if in the right, 1. By a similar division of these classes into
subclasses with as nearly as possible a total probability of 1/4, we determine the secondbinary digit, etc. It is left for you to prove that (1) the expected number of binary digitsrequired to transmit a symbol is equal to H
1, when expressed in bits, and (2) in order to
transmit at a rate of nof the original message symbols per second, E1requires a channel
capacity C≥nH 1, a result ﬁrst given by Shannon.
The preceding mathematical steps are so well-known that they might be called trivial.
However, the rationale which we have given them differs essentially from that of conven-tional treatments, and in that difference lies the main point of this section. Conventionally,one would use the frequency deﬁnition of probability, and say that E
1’s probability assign-
ment p(M) is the one resulting from the assumption that there are no intersymbol inﬂuences.
Such a manner of speaking carries a connotation that the assumption might or might not be
correct, and the implication that its correctness must be demonstrated if the resulting design
is to be justiﬁed; i.e. that the resulting encoding rules might not be satisfactory if there arein fact intersymbol inﬂuences unknown to E
1.
On the other hand, we contend that the probability assignment (22.30) is not an assumption
at all, but the opposite. Equation (22.30) represents, in a certain na¨ ıve sense which we shall
come back to later, the complete absence of any assumption on the part of E1, beyond
speciﬁcation of expected single-letter frequencies, and it is uniquely determined by thatproperty. Because of this, the design based on (22.30) is the safest one possible on E
1’s
state of knowledge.

<<<PAGE 673>>>

22 Introduction to communication theory 641
By that we mean the following. If, in fact, strong intersymbol correlations doexist
unknown to E1(for example, Q is always followed by U), his encoding system will still
be able to handle the messages perfectly well, whatever the nature of those correlations.This is what we mean by saying that the present design is the most conservative one; that itassumes nothing about correlations does not mean that it assumes nocorrelations and will
be in trouble if correlations are in fact present. On the contrary, it means that it is prepared inadvance for whatever kind of correlations might exist ; they will not cause any deterioration
in performance. We stress this point because it was not noted by Shannon, and it does notseem to be comprehended in the more recent literature.
But if E
1had been given this additional information about some particular kind of
correlations, he could have used it to arrive at a new encoding system which would be stillmore efﬁcient (i.e. would require a smaller channel capacity), as long as messages with
only the speciﬁed type of correlation were transmitted . But if the type of correlations in the
messages were suddenly to change, this new encoding system would likely become worsethan the one just found.
22.6 Better encoding from knowledge of digram frequencies
Here is a rather long mathematical derivation which has, however, useful applications
outside the particular problem at hand. Consider a second engineer, E
2. He has a set of
numbers fij,1≤i≤a,1≤j≤a, which represent the expected relative frequencies of
the digrams AiAj.E2will assign message probabilities p(M) so as to agree with his state
of knowledge,
/angbracketleftNij/angbracketright=/summationdisplay
MNij(M)p(M)=(N−1)fij, (22.38)
and, in order to avoid any further assumptions which are as likely to hurt as to help as far
as he knows , he will determine the probability distribution over messages p(M) which has
maximum entropy subject to these constraints. The problem is solved if he can evaluate thepartition function
Z(λ
ij)=/summationdisplay
Mexp/braceleftBigg
−a/summationdisplay
ij=1λijNij(M)/bracerightBigg
. (22.39)
This can be done by solving the combinatorial problem of the number of different messages
with given{Nij}, or by observing that (22.39) can be written in the form of a matrix product:
Z=a/summationdisplay
ij=1/parenleftbig
QN−1/parenrightbig
ij, (22.40)
where the matrix Qis deﬁned by
Qij≡exp{−λij}. (22.41)

<<<PAGE 674>>>

642 Part 2 Advanced applications
The result can be simpliﬁed formally if we suppose that the message Ai1...AiNis always
terminated by repetition of the ﬁrst symbol Ai1, so that it becomes Ai1...AiNAi1. The
digram AiNAi1is added to the message and an extra factor exp {−λij}appears in (22.39).
The modiﬁed partition function then becomes a trace:
Z/prime=Tr(QN)=a/summationdisplay
k=1qN
k, (22.42)
where the qkare the roots of|Qij−qδij|=0. This simpliﬁcation would be termed ‘use
of periodic boundary conditions’ by the physicist. Clearly, the modiﬁcation leads to nodifference in the limit of long messages; as N→∞ ,
lim1
Nlog(Z)=lim1
Nlog(Z/prime)=log(qmax), (22.43)
where qmaxis the greatest eigenvalue of Q. The probability of a particular message is now
a special case of (22.40):
p(M)=1
Zexp/braceleftBig
−/summationdisplay
λijNij(M)/bracerightBig
, (22.44)
which yields the entropy as a special case of (22.42):
S=−/summationdisplay
Mp(M) log p(M)=log(Z)+/summationdisplay
ijλij/angbracketleftNij/angbracketright. (22.45)
In view of (22.38) and (22.43), E2’s entropy per symbol reduces, in the limit N→∞ ,t o
H2=S
N=log(qmax)+/summationdisplay
ijλijfij, (22.46)
or, since/summationtext
ijfij=1, we can write (22.46) as
H2=/summationdisplay
ijfij(log[ qmax]+λij)=/summationdisplay
ijfijlog/parenleftbiggqmax
Qij/parenrightbigg
. (22.47)
Thus, to calculate the entropy we do not need qmaxas a function of the λij(which would be
impractical analytically for a>3), but we need ﬁnd only the ratio qmax/Qijas a function
of the fij. To do this, we ﬁrst introduce the characteristic polynomial of the matrix Q:
D(q)≡det(Qij−qδij) (22.48)
and note, for later purposes, some well-known properties of determinants. The ﬁrst is
D(q)δik=a/summationdisplay
j=1Mij(Qkj−qδkj)=/summationdisplay
jMijQkj−qM ik (22.49)
and, similarly,
D(q)δik=/summationdisplay
jMjiQjk−qM ki, (22.50)

<<<PAGE 675>>>

22 Introduction to communication theory 643
in which Mijis the cofactor of ( Qij−qδij) in the determinant D(q); i.e. (−)i+jMijis the
determinant of the matrix formed by striking out the ith row and jth column of the matrix
(Qkj−qδkj). Ifqis any eigenvalue of Q, the expression (22.49) vanishes for all choices
ofiandk.
The second identity applies only when qis an eigenvalue of Q. In this case, all minors
of the matrix Mare known to vanish. In particular, the second order minors are
MikMjl−MilMjk=0,ifD(q)=0. (22.51)
This implies that the ratios ( Mik/Mjk) and ( Mki/Mkj) are independent of k; i.e. that Mij
must have the form
Mij=aibj,ifD(q)=0. (22.52)
Substitution into (22.49) and (22.52) then shows that the quantities bjform the right eigen-
vectors ofQ, while aiis aleft eigenvector :
/summationdisplay
jQkjbj=qbk,ifD(q)=0 (22.53)
/summationdisplay
iaiQik=akq,ifD(q)=0. (22.54)
Suppose now that any eigenvalue qofQis expressed as an explicit function
q(λ11,λ12,...,λ aa) of the Lagrangian multipliers λij. Then, varying a particular λklwhile
keeping the other λijﬁxed, qwill vary so as to keep D(q) identically zero. By the rule for
differentiating the determinant (22.48), this gives
dD
dλkl=∂D
∂λkl+∂D
∂q∂q
∂λkl=− MklQkl−∂q
∂λklTr(M)=0. (22.55)
Using this relation, the condition (22.38) ﬁxing the Lagrangian multipliers λijin terms of
the prescribed digram frequencies fij, become
fij=−∂
∂λijlog(qmax)=MijQij
qmaxTr(M). (22.56)
The single-letter frequencies are proportional to the diagonal elements of M:
fi=a/summationdisplay
j=1fij=Mii
Tr(M), (22.57)
where we have used the fact that (22.49) vanishes for q=qmax,i=k. Thus, from (22.56)
and (22.57), the ratio needed in computing the entropy per symbol is
Qij
qmax=fij
fiMii
Mij=fij
fibi
bj, (22.58)

<<<PAGE 676>>>

644 Part 2 Advanced applications
where we have used (22.52). Substituting this into (22.47), we ﬁnd that the terms involving
biandbjcancel out, and E2’s entropy per symbol is just
H2=−/summationdisplay
ijfijlog/parenleftbiggfij
fi/parenrightbigg
=−/summationdisplay
ijfijlog(fij)+/summationdisplay
ifilog(fi). (22.59)
This is never greater than E1’sH1, for, from (22.42) and (22.59),
H2−H1=/summationdisplay
ijfijlog/parenleftbiggfifj
fij/parenrightbigg
≤/summationdisplay
ijfij/bracketleftbiggfifj
fij−1/bracketrightbigg
=0, (22.60)
where we used the fact that log( x)≤x−1i n0≤x<∞, with equality if and only if
x=1. Therefore,
H2≤H1, (22.61)
with equality if and only if fij=fifj, in which case E2’s extra information was only what
E1would have inferred. To see this, note that in the message M={i1...iN}, the number
of times the digram AiAjoccurs is
Nij(M)=δ(i,i1)δ(j,i2)+δ(i,i2)δ(i,i3)+···+ δ(i,iN−1)δ(j,iN), (22.62)
and so, if we ask E1to estimate the frequency of digram AiAjby the criterion of minimizing
the expected square of the error, he will make the estimate
/angbracketleftfij/angbracketright=/angbracketleftNij/angbracketright
N−1=1
N−1/summationdisplay
Mp(M)Nij(M)=fifj, (22.63)
using for p(M) the distribution (22.40) ofE1. In fact, the solutions found by E1andE2are
identical if fij=fifj, for then we have, from (22.56), (22.57) and (22.52),
Qij=exp{−λij}=qmax/radicalbig
fifj. (22.64)
Using (22.43), (22.62) and (22.64), we ﬁnd that E2’s distribution (22.44) reduces to (22.40).
This is a rather nontrivial example of what we noted in Chapter 11, Eq. (11.93).
22.7 Relation to a stochastic model
The quantities introduced above acquire a deeper meaning in terms of the following problem.
Suppose that part of the message has been received, what can E2then say about the remainder
of the message? This is answered by recalling our product rule
p(AB|I)=p(A|BI)p(B|I) (22.65)
or by noting that the conditional probability of A,g i v e n B,i s
p(A|BI)=p(AB|I)
p(B|I), (22.66)

<<<PAGE 677>>>

22 Introduction to communication theory 645
a relation which in conventional theory, which never mentions prior information I, is taken
as the deﬁnition of a conditional probability (i.e. the ratio of two ‘absolute’ probabilities).
In our case, let Istand for the general statement of the problem leading to the solution
(22.44), and let
B≡the ﬁrst ( m−1) symbols are{i1i2...im−1}, (22.67)
A≡the remainder of the message is {im...iN}. (22.68)
Then p(AB|I) is the same as p(M) in (22.44). Using (22.62), this reduces to
p(AB|I)=p(i1...iN|I)=Z−1Qi1i2Qi2i3...QiN−1iN, (22.69)
and in
p(B|I)=a/summationdisplay
im=1···a/summationdisplay
iN=1p(i1...iN|I) (22.70)
the sum generates a power of the matrix Q, just as in the partition function (22.40). Writing,
for brevity, im−1=i,im=j,iN=k, and
R≡1
ZQi1i2...Qim−2im−1, (22.71)
we have
p(B|I)=Ra/summationdisplay
k=1(QN+m+1)ik=Ra/summationdisplay
jk=1Qij(QN−m)jk (22.72)
and so
p(A|BI)=QijQimim+1...QiN−1iN/summationtexta
k=1(QN−m+1)ik(22.73)
since all the Qcontained in Rcancel out, we see that the probabilities for the remain-
der{im...iN}of the message depend only on the immediately preceding symbol Ai,
and not on any other details of B. This property deﬁnes a generalized Markov chain .
There is a huge literature dealing with this; it is perhaps the most thoroughly worked outbranch of probability theory, and we used a rudimentary form of it in calculating the con-ditional sampling distributions in Chapter 3. The basic tool, from which essentially allelse follows, is the matrix p
ijof ‘elementary transition probabilities’. This is the proba-
bility pij=p(Aj|AiI) that the next symbol will be Aj, given that the last one was Ai.
Summing (22.73) over im+1...iN, we ﬁnd that, for a chain of length N, the transition
probabilities are
p(N)
ij=p(Aj|AiI)=Qij−Tj/summationtext
kQikTk, (22.74)

<<<PAGE 678>>>

646 Part 2 Advanced applications
where
Tj≡a/summationdisplay
k=1(QN−m)jk. (22.75)
The fact that Tjdepends on Nandmis an interesting feature. Usually, one considers from the
start a chain indeﬁnitely prolonged, and so it is only the limit of (22.74) for N→∞
that is ever considered. This example shows that prior knowledge of the length of thechain can affect the transition probabilities; however, the limiting case is clearly of greatestinterest.
To ﬁnd this limit we need a little more matrix theory. The equation D(q)=det(Q
ij−
qδij)=0 has roots ( q1,q2,..., qa), not necessarily all different, or real. Label them so that
|q1|≥| qq|≥···≥| qa|. There exists a nonsingular matrix Asuch that AQA−1takes the
canonical ‘superdiagonal’ form:
AQA−1=Q=
C100···
0C20···
00 C3···
.........C
m
, (22.76)
where the Ciare submatrices which can have either the forms
Ci=
q
i100···
0qi10···
00 qi1···
000 qi1
.........0 q
i
orC
i=
qi
qi
...
qi
. (22.77)
The result of raising Qto the nth power is
Qn=AQnA−1, (22.78)
and, as n→∞ , the elements of Qnarising from the greatest eigenvalue qmax=q1become
arbitrarily large compared with all others. If q1is nondegenerate, so that it appears only in
the ﬁrst row and column of Q,w eh a v e
lim
N→∞/bracketleftBigg
Tj
qN−m
1/bracketrightBigg
=Aj1a/summationdisplay
k=1(A−1)1k, (22.79)
lim
N→∞/bracketleftbiggTj/summationtext
kQikTk/bracketrightbigg
=Aj1
q1Ai1, (22.80)
and the limiting transition probabilities are
p(∞)
ij=Qij
q1Aj1
Ai1=Qij
q1Mij
Mii, (22.81)

<<<PAGE 679>>>

22 Introduction to communication theory 647
where we have used the fact that the elements Aj1(j=1,2,..., a) from an eigenvector
ofQwith eigenvalue q1=qmax, so that, referring to (22.52), Aj1=Kb jwhere Kis some
constant. Using (22.56) and (22.57), we have, ﬁnally,
p(∞)
ij=fij
fi. (22.82)
From this long calculation we learn many things. In the ﬁrst place, for a sequence of ﬁnite
length (the only kind that actually exists), the exact solution has intricate ﬁne details thatdepend on the length. This, of course, could not be learned by those who try to jump directlyinto an inﬁnite set at the beginning of a problem. Secondly, it is interesting that standardmatrix theory was adequate to solve the problem completely. Finally, in the limit of inﬁnitelylong sequences, the exact solution of the maximum entropy problem does indeed go into thefamiliar Markov chain theory. This gives us a deeper insight into the basis of, and possiblelimitations on, Markov chain analysis.
Exercise 22.1. The exact meaning of this last statement might be unclear; in a classical
Markov chain the transition probabilities two steps down the chain would be given by
the square of the one-step matrix pij, three steps by the cube of that matrix, and so
on. But our solution determines those multistep probabilities by summing (22.73) overthe appropriate indices, which is not obviously the same thing. Investigate this anddetermine whether the maximum entropy multistep probabilities are the same as theclassical Markov ones, or whether they become the same in some limit.
We see that the maximum entropy principle sufﬁces to determine explicit solutions to
problems of optimal encoding for noiseless channels. Of course, as we consider morecomplicated constraints (trigram frequencies, etc.), pencil and paper methods of solutionwill become impossibly difﬁcult (there is no ‘standard matrix theory’ for them), and to thebest of our knowledge we must resort to computers.
Now, Shannon’s ostensibly strongest theorem concerns the limit as n→∞ of the problem
with n-gram frequencies given; his H≡limH
nis held to be the ‘true’ entropy of the English
language, which determines the ‘true’ minimum channel capacity required to transmit it.We do not question this as a valid mathematical theorem, but from our discussion aboveit is clear that such a theorem can have no relevance to the real world, because there is nosuch thing as a ‘true’ n-gram frequency for English, even when n=1.
Indeed, even if such frequencies did exist, think for a moment about how one would
determine them. Even if we do not distinguish between capital and small letters and in-clude no decimal digits or punctuation marks in our alphabet, there are 26
10=1.41×1014
ten-grams whose frequencies are to be measured and recorded. To store them all on paper
at 1000 entries per sheet would require a stack of paper about 7000 miles high.

<<<PAGE 680>>>

648 Part 2 Advanced applications
22.8 The noisy channel
Let us examine the simplest nontrivial case, where the noise acts independently (without
memory) on each separate letter transmitted. Suppose that each letter has independently theprobability /epsilon1of being transmitted incorrectly. Then in a message of Nletters the probability
that there are rerrors is the binomial
p(r)=/parenleftbiggN
r/parenrightbigg
/epsilon1
r(1−/epsilon1)N−r(22.83)
and the expected number of errors is /angbracketleftr/angbracketright=N/epsilon1. Then, if N/epsilon1< < 1, we might consider the
communication system satisfactory for most purposes. However, it may be essential that themessage be transmitted without any error at all (as in sending a computer code instructionto a satellite in orbit). The ﬁeld of fancy error-correcting codes has a large literature andmuch sophisticated theory; but a very popular and simple procedure is the checksum.
Suppose, as is usually the case in computer practice, that our ‘alphabet’ consists of
2
8=256 different characters sent as eight-bit binary numbers, called ‘bytes’. At the end of
the message one transmits one more byte, which is numerically the sum (mod 256) of the
Nprevious ones. The receiver recalculates this sum from the ﬁrst Nbytes received, and
compares it with the transmitted checksum. If they agree, then it is virtually certain thatthe transmission was error-free (if there is an error, then there must be at least two errorswhich just happened to cancel each other out in the checksum, and the probability of this
is astronomically small, far less than /epsilon1). If they disagree, then it is certain that there was a
transmission error, so the receiver sends back a ‘please repeat’ signal to the transmitter, andthe process is repeated until error-free transmission is achieved.
Let us see just how good the checksum procedure is according to probability theory.
Write, for brevity,
q≡(1−/epsilon1)
N+1. (22.84)
Then to achieve error-free transmission, there is
probability qthat it will require ( N+1) symbols transmitted;
probability (1−q)qthat 2( N+1) symbols will be required;
probability (1−q)2qthat 3( N+1) symbols will be required;
and so on.
The expected length of transmission to achieve error-free operation is then the sum
/angbracketleftL/angbracketright=(N+1)q[1+2(1−q)+3(1−q)2+4(1−q)3+··· ]. (22.85)
Since|1−q|<1, the series converges to 1 /q2, and so
/angbracketleftL/angbracketright=N+1
(1−/epsilon1)N+1/similarequalNexp{N/epsilon1}, (22.86)
the approximation holding reasonably well if N>>1. But if the message is so long that
N/epsilon1> > 1, this procedure fails; there is almost no chance that we could transmit it without
error in any feasible time.

<<<PAGE 681>>>

22 Introduction to communication theory 649
But now an ingenious device comes to the rescue, and shows how much a little probability
theory can help us to achieve exactitude. Let us break the long message into mshorter
blocks of length n=N/m, and transmit each block with its own checksum. From (22.86)
the expected total transmission length is now
/angbracketleftL/angbracketright=mn+1
(1−/epsilon1)n+1=Nn+1
n(1−/epsilon1)n+1. (22.87)
It is evident that if the blocks are too long, then we shall have to repeat too many of them;
if they are too short, then we shall waste transmission time sending many unnecessarychecksums. Thus there should be an optimal block length which minimizes (22.87). Prov-identially, this turns out to be independent of N; varying n, (22.87) reaches a minimum
when
1+n(n+1) log(1−/epsilon1)=0, or (1−/epsilon1)
n+1=exp{−1/n}. (22.88)
For all practical purposes, then, the optimal block length is
(n)opt=1√/epsilon1, (22.89)
and the minimum achievable expected length is
/angbracketleftL/angbracketrightmin=N/parenleftbiggn+1
n/parenrightbigg
exp/braceleftbigg1
n/bracerightbigg
/similarequalN(1+2√/epsilon1). (22.90)
By breaking a long message into blocks, we have made an enormous improvement. If /epsilon1/similarequal
10−4, then it would be impractical to send an error-free message of length N=100 000 bytes
in a single block; for one expects about ten errors in each transmission. The expectedtransmission length would be about 22 000 Nbytes, signifying that we would have to repeat
the message, on the average, about 22 000 times before achieving one error-free result. Butthe optimal block length is about n/similarequal100, and by using this the expected length is reduced to
/angbracketleftL/angbracketright=1.020N. This signiﬁes that we are sending 1000 blocks, of which each has one extra
byte (which accounts for the factor ( n+1)/n/similarequal1+√
/epsilon1) and about ten will probably need
to be repeated (which corresponds to the factor exp {1/n}/similarequal1+√/epsilon1). But the minimum in
(22.87) is very broad; if 40 ≤n≤250, we have/angbracketleftL/angbracketright≤1.030N.I f/epsilon1=10−6, then the block
technique allows us to transmit error-free messages of any length with virtually no penaltyin transmission time ( /angbracketleftL/angbracketright/similarequal1.002Nifnis anywhere near 1000).
To the best of our knowledge, the block technique is an intuitive ad hockery , not derived
uniquely from any optimality criterion; yet it is so simple to use and comes so close tothe best that could ever be hoped for ( /angbracketleftL/angbracketright=N), that there is hardly any incentive to seek
anything better.
In the early days of microcomputers, messages were sent to and from disks in block
lengths of 128 or 256 bytes, which would be optimal if the error probability for each byte
were of the order /epsilon1/similarequal10
−5. At the time of writing (1991) they are being sent instead in
blocks of 1024 to 4096 bytes, suggesting that disk reading and writing is now reliable toerror probabilities of the order of 10
−8or better. Of course, it is conservative design to use

<<<PAGE 682>>>

650 Part 2 Advanced applications
block lengths somewhat shorter than the above optimal value, to hedge against deterioration
in performance as the equipment wears out and the error rate increases.
But let us note a point of philosophy; in this discussion, have we abandoned our stance of
probability theory as logic, and reverted to frequency deﬁnitions? Not at all! It is perfectlytrue that ifthe error probability /epsilon1is indeed an ‘objectively real’ frequency of errors measured
in some class of repetitions of all this, then our /angbracketleftL/angbracketright
minis equally well the objectively real
minimum achievable average transmission length over that same class of repetitions .
But there are few cases where this is really known to be true; such experiments are costly
in time and resources. In the real world, they are never completed before the design becomesfrozen and the manufactured product is delivered to the customers. Indeed, reliability ex-periments on highly reliable systems can never be really completed at all, because, in thetime it requires to do them, our state of knowledge and technical capabilities will change,making the original purpose of the test irrelevant.
Our present point is that probability theory as logic works as well, in the following
sense, whether our probabilities are or are not known to be real frequencies. As we saw in
Chapter 8, it is an elementary derivable consequence of probability theory as logic that our
probabilities are the best estimates of those frequencies that we can make on the informationwe have.
Then, whatever the evidence on which that probability assignment /epsilon1was based, the above
equations still describe the most rational design that could have been made, here and now,
on the information we had . As noted, this remains true even if we know in advance that only
a single message is ever going to be sent over our communication system. Thus, probability
theory as logic has a wider range of applications, even in situations where one sometimespretends that he is using a frequency deﬁnition for psychological reasons.

<<<PAGE 683>>>

Appendix A
Other approaches to probability theory
Needless to say, the way we developed probability theory in Chapter 2 is not the only way it could
have been done. The particular conditions we used might have been chosen differently , and there are
several other approaches based on entirely different notions.
As an example of the former, many qualitative statements seem so obvious that one might think of
taking them as basic axioms or desiderata, instead of the ones we did use. Thus if Aimplies B, then
for all Cwe should expect intuitively to have P(A|C)≤P(B|C). Of course, our rules do have this
property, for the product rule is
P(AB|C)=P(B|AC)P(A|C)=P(A|BC)P(B|C). (A.1)
But if Aimplies B, then P(B|AC)=1 and P(A|BC)≤1, so the product rule reduces to the
intuitive statement. It may well be that a different choice of axioms would have simpliﬁed thederivations of Chapter 2. However, that was not the criterion we used. We chose the ones thatappeared to us the most primitive and most difﬁcult to quarrel with, in the belief that the resultingtheory would be seen thereby to have the greatest possible generality and range of application.
Now we examine brieﬂy some other approaches that have been advocated in the past.
A.1 The Kolmogorov system of probability
In our comments at the end of Chapter 2, we noted the Venn diagram and the relation to set theorythat it suggests, which became the basis of the Kolmogorov approach to probability theory. Thisapproach could hardly be more different from ours in general viewpoint and motivation; yet the ﬁnalresults are identical in several respects.
The Kolmogorov system of probability (henceforth denoted by KSP) is a game played on a
sample space /Omega1of elementary propositions ω
i(or ‘events’; it does not matter what we call them at
this level of abstraction). We may think of them as corresponding roughly to the individual points ofthe Venn diagram, although of course the abstract deﬁnition makes no such reference.
Then there is a ﬁeld Fconsisting of certain selected subsets f
jof/Omega1, corresponding roughly to our
propositions A,..., B,... represented by areas of the Venn diagram (although, again, the abstract
deﬁnition allows sets which need not correspond to areas). Fis to have basically three properties:
(I)/Omega1is in F;
(II)Fis aσ-ﬁeld, meaning that if fjis in F, then its complement with respect to /Omega1,¯fj=
/Omega1−fj, is also in F;
(III) Fis closed under countable unions, meaning that, if countably many fjare in F, their union is
also in F.
651

<<<PAGE 684>>>

652 Appendixes
Finally, there is to be a probability measure PonF, with the properties of:
(1) normalization: P(/Omega1)=1;
(2) non-negativity: P(fi)≥0 for all fiinF;
(3) additivity: if{f1···fn}are disjoint elements of F(i.e. they have no points ωiin common, then
P(f)=/summationtext
iP(fj), where f=∪ jfjis their union;
(4) continuity at zero: if a sequence f1⊇f2⊇f3⊇...tends to the empty set, then P(fj)→0.
There is nothing surprising in these axioms; they seem to be familiar echoes of just what we found
in Chapter 2, except that they state analogous properties of sets rather than propositions.
We are with Kolmogorov in spirit when he wants Fto be a σ-ﬁeld, for any proposition that can be
afﬁrmed can also be denied; the operation NOT was also one of our primitive ones. Indeed, we wentfurther by including the operation AND. Then it was a pleasant surprise that (AND, NOT), which
are an adequate set for deductive logic, turn out to be also adequate for our extended logic (i.e. given
a set of propositions {A
1,..., An}to be considered, our rules generate a system of inference that is
formally complete in the sense that it is adequate to assign consistent probabilities to allpropositions in the Boolean algebra generated from {A
1,..., An}.)
Kolmogorov’s closure under countable unions is also implied by this requirement, in the
following sense. Working fundamentally with ﬁnite sets, we are content fundamentally with ﬁniteunions; yet a well-behaved limit to an inﬁnite set may be a convenient simpliﬁcation, removingintricate but irrelevant details from a ﬁnite-set calculation. On the inﬁnite sets thus generated, ourﬁnite unions go into countable unions.
But, as noted in Chapter 2, a proposition Areferring to the real world cannot always be viewed as
a disjunction of elementary propositions ω
ifrom any set /Omega1that has meaning in the context of our
problem; and its denial Amay be even harder to interpret as set complementation. The attempt to
replace logical operations on the propositions A,B,... by set operations on the set /Omega1does not
change the abstract structure of the theory, but it makes it less general in respects that can matter inapplications. Therefore we have sought to formulate probability theory in the wider sense of anextension of Aristotelian logic.
Finally, the properties (1)–(4) of the probability measure Pwere stated by Kolmogorov as
seemingly arbitrary axioms; and KSP has been criticized for that arbitrariness. But we recognizethem as statements, in the context of sets, of just the four properties that we derived in Chapter 2from requirements of consistency. For example, the need for non-negativity is apparent from (2.35).Additivity also seems arbitrary when stated merely as an axiom; but in (2.85) we have derived it asnecessary for consistency.
Many writers have thought that normalization is merely an arbitrary convention, but (2.31) shows
that if certainty is not represented by p=1, then we must restate the sum and product rules, or we
shall have an inconsistency. For example, if we choose the convention that p=100 is to represent
certainty, then these rules take the form
p(A|B)+p(
A|B)=100, p(A|BC)p(B|C)=100p(AB|C). (A.2)
More generally, by any change of variables u=f(p) with some monotonic function f(p), we can
represent probability on a different scale than the one adopted; but then consistency will require thatthe product and sum rules also be modiﬁed in form, so that the content of our theory is not changed.For example, with the change of variables u=log[p/(1−p)] the sum rule takes the equally
simple form
u(A|B)+u(
A|B)=0, (A.3)
while the product rule becomes quite complicated. The substantive result is not that one is obliged to
use any particular scale; but rather that a theory of probability whose content differs from one in

<<<PAGE 685>>>

Appendix A Other approaches to probability theory 653
which there is a single scale that is normalized, non-negative, and additive, will contain
inconsistencies.
This should answer an objection sometimes raised (Fine, 1973, p. 65) that Kolmogorov’s scale
was arbitrary. In 1973, such a charge might have seemed reasonable, calling for furtherinvestigation. That further investigation has been made; since we now know that, in fact, he madethe only choices that will pass all our tests for consistency, the charge now seems to us unjustiﬁed.
We do not know how Kolmogorov was able to see the need for his axiom (4) of continuity at zero;
but our approach, in effect, derives it from a simple requirement of consistency. Firstly, let us dispela misunderstanding. Statement (4) in terms of sets seems to imply that an inﬁnite sequence ofsubsets is given. But its translation into a statement about propositions does not require that weassign probabilities to an inﬁnite number of propositions. What is essential is that we have aninﬁnite sequence of different states of knowledge , which may be about a single proposition, but
which tends to impossibility. Since Kolmogorov’s sets are not associated with any such idea as a‘state of knowledge’, there seems to be no way to say this in the context of sets; but in the context ofpropositions it is easy.
We note this to emphasize that it would be a serious error to suppose that we can dispense with
this axiom merely by limiting our discourse to a ﬁnite set of propositions. The resulting theorywould have an arbitrary character which allows one to commit all kinds of inconsistencies.
In our system, ‘continuity at zero’ takes the following form: given a sequence of probabilities
p(A)
1,p(A)2,... that tend to certainty, the probabilities p(A)1,p(A)2,... assigned to the denial
must tend to zero. Indeed, as we noted in (2.48), the functional equation that S(x) satisﬁes ties
values at different xtogether so strongly that the exact way in which S(x) tends to zero as x→1i s
the crucial thing that determines the function S(x) over its entire range (0 ≤x≤1), and therefore
determines the additivity property (2.58). Thus, from our viewpoint, Kolmogorov’s axioms (3) and(4) appear to be closely related; it is not obvious whether they are logically independent.
For all practical purposes, then, our system will agree with KSP if we are applying it in the
set-theory context. But in more general applications, although we have a ﬁeld of discourse Fand
probability measure PonFwith the same properties, we do not need, and do not always have, any
set/Omega1of elementary propositions into which the elements of Fcan be resolved. Of course, in many
of our applications such a set /Omega1will be present: for example, in equilibrium statistical mechanics the
elements ω
iof/Omega1can be identiﬁed with the stationary ‘global’ quantum states of a system, which
comprise a countable set. In these cases, there will be essentially complete agreement in the abstractformulation, although we carry out practical calculations with more freedom in one respect – andmore inhibition in another – for reasons noted below.
Our approach supports KSP in another way also. KSP has been criticized as lacking connection to
the real world; it has seemed to some that its axioms are deﬁcient because they contain no statementto the effect that the measure Pis to be interpreted as a frequency in a random experiment.
1But,
from our viewpoint, this appears as a merit rather than a defect; to require that we invoke somerandom experiment before using probability theory would have imposed an intolerable and arbitraryrestriction on the scope of the theory, making it inapplicable to most of the problems that wepropose to solve by extended logic.
Even when random experiments are involved in the real problem, propositions specifying
frequencies are properly considered, not as determinations of the measure P, but as elements of the
ﬁeld F. In both Kolmogorov’s system and ours, such propositions are not the tools for making
inferences, but the things about which inferences are being made.
There are some important differences, however, between these two systems of probability theory.
In the ﬁrst place, in KSP attention is concentrated almost exclusively on the notion of additive
1Indeed, de Finetti (1972, p. 89) argues that Kolmogorov’s system cannot be interpreted in terms of limits of frequencies.

<<<PAGE 686>>>

654 Appendixes
measure. The Kolmogorov axioms make no reference to the notion of conditional probability;
indeed, KSP ﬁnds this an awkward notion, really unwanted, and mentions it only reluctantly, as aseeming afterthought.
2Although Kolmogorov has a section entitled ‘Bayes’ theorem’, most of his
followers ignore it. In contrast, we considered it obvious from the start that all probabilities referringto the real world are necessarily conditional on the information at hand. In Chapter 2 the productrule, with conditional probability and Bayes’ theorem as immediate consequences, appeared in oursystem even before additivity.
Our derivation showed that, from the standpoint of logic, the product rule (and therefore Bayes’
theorem) expresses simply the associativity and commutativity of Boolean algebra. This is whatgives us that greater freedom of action in calculations, leading in later chapters to the unrestricteduse of Bayes’ theorem, in which we have complete freedom to move propositions back and forthbetween the left and right sides of our probability symbols in any way permitted by the product andsum rules. This is a superb computational device – and by far the most powerful tool of scientiﬁcinference – yet it is completely missing from expositions of probability theory based on the KSPwork (which do not associate probability theory with information or inference at all).
In return for this freedom, we impose on ourselves an inhibition not present in KSP. Having been
burned by de Finetti and his followers, we are wary of inﬁnite sets, and approach them only
cautiously, after ascertaining that in our problem there is a well-deﬁned and well-behaved limitingprocess that will not lead us into paradoxes and will serve a useful purpose.
In principle, we start always by enumerating some ﬁnite set of propositions A,B,... to be
considered. Our ﬁeld of discourse Fis then also ﬁnite, consisting of these and – automatically – all
propositions that can be ‘built up’ from them by conjunction, disjunction, and negation. We have noneed or wish to ‘tear down’ by resolving them into a disjunction of ﬁner propositions, much lesscarrying this to inﬁnite limits, except when this can be a useful calculational device due to thestructure of a particular problem.
We have three reasons for taking this stance. The ﬁrst was illustrated in Chapter 8 by the scenario
of Sam’s broken thermometer, where we saw that beyond a certain point this ﬁner and ﬁnerresolving serves no purpose. Secondly, i n Chapter 15 we saw some of the paradoxes that await those
who jump directly into inﬁnite sets without considering any limiting process from a ﬁnite set. But
even here, when we considered the so-called ‘Borel–Kolmogorov paradox’, we found ourselves inagreement with Kolmogorov’s resolution of it, and thus in disagreement with some of his critics.One must approach inﬁnite sets carefully; but once in an uncountable set, one must then approachsets of measure zero just as carefully.
A third reason is that a different resolution often appears more useful to us. Instead of resolving a
proposition Ainto the disjunction A=B
1+B2+··· of ‘smaller’ propositions and applying the
sum rule, one can equally well resolve it into a conjunction A=C1C2···of ‘larger’ propositions
and apply the product rule. This may be interpreted, in terms of sets, very simply. To specify thegeographical layout of a country, there are two possible methods: (1) specify the points that are in it;
(2) specify its boundary. Method (1) is the Venn–Kolmogorov viewpoint; but method (2) appears tous equally fundamental and often simpler and more directly related to the information we have in areal problem. In a Venn diagram the boundary of set Ais composed of segments of the boundaries
ofC
1,C2,... , just as that of a country is composed of segments of rivers, coastlines, and adjacent
countries.
These methods are not in conﬂict; rather, in each problem we may choose the one appropriate to
the job before us. But in most of our problems method (2) is the natural one. A physical theory isalways stated as a conjunction of hypotheses, not a disjunction; likewise a mathematical theory isdeﬁned by the set of axioms underlying it, which is always stated as a conjunction of elementary
2In the Kolmogorov system, conditional probability is such a foreign element that an entire book has been written (Rao, 1993)
trying to explain the idea of conditional probability by giving it a separate axiomatic approach!

<<<PAGE 687>>>

Appendix A Other approaches to probability theory 655
axioms. To express the foundations of any theory as disjunctions would be almost impossible; so we
must demand this freedom of choice.
In summary, we see no substantive conﬂict between our system of probability and Kolmogorov’s
as far as it goes; rather, we have sought a deeper conceptual foundation which allows it to beextended to a wider class of applications, required by current problems of science.
The theory expounded here is still far from its ﬁnal, complete form, however. In its present state
of development, there are many situations where the robot does not know what to do with itsinformation. For example, suppose it is told that ‘Jones was very pleased at the suggestion that θ
might be greater than 100’. By what principles is it to translate this into a probability statementaboutθ?
You and I, however, can make some use of that information to modify our opinions about θ
(upward or downward according to our opinions about Jones). Indeed we can use almost any kind ofprior information, and perhaps draw a free-hand curve which indicates roughly how it affects ourprobability distribution p(θ). In other words, our brains are in possession of more principles than
the robot’s for converting raw information, semiquantitatively, into something which the computercan use . This is the main reason why we are convinced that there must be more principles like
maximum entropy and transformation groups, waiting to be discovered by someone. Each suchdiscovery will open up a new area of useful applications of this theory.
A.2 The de Finetti system of probability
There is today an active school of thought, most of whose members call themselves ‘Bayesians’, butwho are actually followers of Bruno de Finetti and concerned with matters that Bayes never dreamtof. In 1937, de Finetti published a work which expressed a philosophy somewhat like ours andcontained not only his marvellous and indispensable exchangeability theorem, but also sought toestablish the foundations of probability theory itself on the notion of ‘coherence’. This means,roughly speaking, that one should assign and manipulate probabilities so that one cannot be made asure loser in betting based on them. He appears to derive the rules of probability theory very easilyfrom this premise (de Finetti, 1937).
Since 1937, de Finetti has published many more works on this topic (de Finetti, 1958, 1974a,b),
as cited in our general references. Note particularly the large work published in English translation(de Finetti, 1974b). Some have thought that we should have followed de Finetti’s coherenceprinciple in the present work. Certainly, that would have shortened our derivations. However, wethink that coherence is an unsatisfactory basis in three respects. The ﬁrst is admittedly only aesthetic;it seems to us inelegant to base the principles of logic on such a vulgar thing as expectation of proﬁt.
The second reason is strategic. If probabilities are thought to be deﬁned basically in terms of
betting preferences, then for assigning probabilities one’s attention is focused on how to elicit thepersonal probabilities of different people. In our view, that is a worthy endeavor, but one thatbelongs to the ﬁeld of psychology rather than probability theory; our robot does not have any bettingpreferences. When we apply probability theory as the normative extension of logic, our concern isnot with the personal probabilities that different people might happen to have, but with theprobabilities that they ‘ought to’ have, in view of their information – just as James Clerk Maxwellnoted in our opening quotation for Chapter 1.
In other words, at the beginning of a problem our concern is not with anybody’s personal
opinions, but with specifying the prior information on which our robot’s opinions are to be based, in
the context of the current problem. The principles for assigning prior probabilities consistently bylogical analysis of that prior information are for us an essential part of probability theory. Suchconsiderations are almost entirely absent from expositions of probability theory based on thede Finetti approach (although of course it does not forbid us to consider such problems).

<<<PAGE 688>>>

656 Appendixes
The third reason is thoroughly pragmatic: if any rules were found to possess the property of
coherence in the sense of de Finetti, but not the property of consistency in the sense of Cox, theywould be clearly unacceptable – indeed, functionally unusable – as rules for logical inference.There would be no ‘right way’ to do any calculation, and no ‘right answer’ to any question. Thenthere would be small comfort in the thought that all those different answers were at least ‘coherent’.
To the best of our knowledge, de Finetti does not mention consistency as a desideratum, or test for
it. Yet it is consistency – not merely coherence – that is essential here, and we ﬁnd that, when ourrules have been made to satisfy the consistency requirements, then they have automatically (andtrivially) the property of coherence.
Another point was noted in our Preface. Like Kolmogorov, de Finetti is occupied mostly with
probabilities deﬁned directly on arbitrary uncountable sets; but he views additivity differently, and isled to such anomalies as an unlimited sequence of layers, like an onion, of different orders of zeroprobabilities that add up to one, etc. It is the followers of de Finetti who have perpetrated most of theinﬁnite-set paradoxing that has forced us to turn to (and, like Helmholtz in Chapter 16, exaggerate ifnecessary) the opposite ‘ﬁnite-sets’ policy in order to avoid them. This line of thought continues,with technical details, in Chapter 15.
A.3 Comparative probability
In our Comments Section 1.8 at the end of Chapter 1, we noted a possible objection to our ﬁrstdesideratum:
(I) Degrees of plausibility are to be represented by real numbers.
Why must one do this? Our pragmatic reason was that we do not see how our robot’s brain can
function by carrying out deﬁnite physical operations – mechanical or electronic – unless, at somepoint, degrees of plausibility are associated with some deﬁnite physical quantity.
We recognize that this ignores some aesthetic considerations; for example, the geometry of Euclid
derives its elegance in large part from the fact that it is not concerned with numerical values, butwith recognizing qualitative conditions of equivalence or similarity. We had this very much in mindwhen choosing all our other axioms, being careful to ensure that ‘consistency’ and ‘correspondencewith common sense’ expressed qualitative rather than quantitative properties.
Of course, our one pragmatic argument carries no weight for those concerned with abstract
axiomatics rather than making something work, so let us consider the alternatives. If one wishes topick away at our desideratum I, it can be dissected into simpler axioms. In the following, read‘(A|C)>(B|C)’ not as a numerical comparison, but simply as the verbal statement, ‘given C,Ais
more plausible than B’, etc. Then desideratum I may be replaced by two more elementary ones:
(Ia) Transitivity. If ( A|X)≥(B|X) and ( B|X)≥(C|X) then ( A|X)≥(C|X).
(Ib) Universal comparability. Given propositions A,B,C, then one of the relations
(A|C)>(B|C),(A|C)=(B|C),(A|C)<(B|C) must hold.
To see this, note that, if we postulate both transitivity and universal comparability, then within any
ﬁnite set of propositions, we can always set up a representation by real numbers (in fact, by rationalnumbers) that obeys all the ordering relations. For, suppose we have a set {A
1,..., An}of
propositions with such numerical measures {x1,..., xn}. Adding a new proposition An+1, the
transitivity and universal comparability ensure that it ﬁts into a unique place in those orderingrelations. But since between any two rational numbers one can always ﬁnd another rational number,we can always assign a number x
n+1to it so that all the ordering relations of the new set
{A1,..., An+1}are also obeyed by our rational numbers {x1,..., xn+1}.

<<<PAGE 689>>>

Appendix A Other approaches to probability theory 657
At this point, therefore, it is all over with any comparative theory which embodies both
transitivity and universal comparability. Once the existence of a representation by real numbers isestablished, then Cox’s theorems take over and force that theory to be identical with the theory ofinference that we derived in Chapter 2. That is, either there is some monotonic function of the x
ithat
obeys the standard product and sum rules of probability theory; or else we can exhibitinconsistencies in the rules of the comparative theory.
Some systems of comparative probability theory have both of these axioms; then they have
assumed everything needed to guarantee the equivalence to the standard numerical valued theory.This being the case, it would seem foolish to refuse to use the great convenience of the numericalrepresentation. But now, can one drop transitivity or universal comparability and get an acceptableextension of logic with different content than ours?
No comparative probability theory is going to get far if it violates transitivity. Nobody would wish
to – or be able to – use it, because we would be trapped in endless loops of circular reasoning. Sotransitivity is surely going to be one of the axioms of a comparative probability theory; discovery ofan intransitivity would be grounds for immediate rejection of any system.
To many, universal comparability does not seem a compelling desideratum. By dropping it we
could create a ‘lattice’ theory, so called because we can represent propositions by points, relationsof comparability by lines connecting them in various ways. Then it is conceivable that AandCcan
be compared, and BandCcan be compared; but Ais not comparable to B. One might contemplate
a situation in which ( A|D)<(C|D) and ( B|D)<(C|D); but neither ( A|D)<(B|D) nor
(A|D)≥(B|D) could be established. This allows a looser structure which cannot be represented
faithfully by assigning a single real number to each proposition (although it can be so represented bya lattice of vectors); any attempt to introduce a single-valued numerical representation wouldgenerate false comparisons not present in the system.
Much effort has been expended on attempts to develop such looser forms of probability theory in
which one does not represent degrees of plausibility by real numbers, but admits only qualitativeordering relations of the form ( A|C)≥(B|C), and attempts to deduce the existence of a (not
necessarily unique) additive measure p(A|B) with the property (2.85). The work of L. J. Savage
(1954) is perhaps the best known example. A summary of such attempts is given by T. L. Fine(1973). These efforts appear to have been motivated only by an aesthetic feeling – that universalcomparability is a stronger axiom than we need – rather than from the hope that any particular
pragmatic advantage would be gained by dropping it. However, a restriction appeared incomparative probability theory, robbing it of its initial appeal.
Ordering relations may not be assigned arbitrarily because it must always be possible to extend
the ﬁeld of discourse, by adding more propositions and ordering relations, without generatingcontradictions. If adding a new ordering relation created an intransitive loop, it would be necessaryto modify some ordering relations to restore transitivity. But such extensions may be carried outindeﬁnitely, and, when a set of propositions with transitive ordering relations becomes, in a certainsense, ‘everywhere dense’ on the path from impossibility to certainty, consistency will require thatthe theory then approach the conventional numerical-valued probability theory expounded here.
In retrospect (i.e. in view of Cox’s consistency theorems) this is hardly surprising; a comparative
probability theory whose results conﬂict with those of our numerical probability theory necessarilycontains within it either overtly visible inconsistencies or the seeds of inconsistencies which willbecome visible when one tries to extend the ﬁeld of discourse.
Furthermore, it appears to us that any computer designed to carry out the operations of a
comparative probability theory must at some stage represent the ordering relations as inequalities ofreal numbers. So attempts to evade numerical representation not only offer no pragmatic advantage,they are futile. Thus in the end the study of comparative probability theories serves only to show usstill another aspect of the superiority of the Cox approach that we follow here.

<<<PAGE 690>>>

658 Appendixes
A.4 Holdouts against universal comparability
The arguments in the preceding sections, however, do not quite close the subject, because some of
the criticisms of probability theory as logic are from writers who have considered it absurd to
suppose that all propositions can be compared. This view seems to arise from two different beliefs:(1) human brains cannot do this; and (2) they think that they have produced examples where it isfundamentally impossible to compare all propositions.
Argument (1) carries no weight for us; in our view, human brains do many absurd things while
failing to do many sensible things. Our purpose in developing a formal theory of inference is not toimitate them, but to correct them. We agree that human brains have difﬁculty in comparing, andreasoning from, propositions that refer to different contexts. But we would observe also that theability to do this improves with education.
For example, is it more likely that (A) Tokyo will have a severe earthquake on June 1, 2230; or
that (B) Norway will have an unusually good ﬁsh catch on that day? To most people, the contexts ofpropositions A and B seem so different that we do not see how to answer this. But with a littleeducation in geophysics and astrophysics, one realizes that the moon could well affect bothphenomena, by causing phase-locked periodic variations in the amplitudes of both the tides andstresses in the Earth’s crust. Recognition of a possible common physical cause at work makes the
propositions seem comparable after all.
The second objection to universal comparability noted above appears to be a misunderstanding of
our present theory, but one which does point to cases in which universal comparability would indeedbe fundamentally impossible. These are the cases where we are trying to classify propositions withrespect to more than one attribute, as in the conceivable multidimensional models of mental activitynoted at the end of Chapter 1. All of the alleged counter-examples to comparability that we haveseen prove on examination to be of this type.
For example, a mineralogist may classify a collection of rocks with respect to two qualities, such
as density and hardness. If, within a certain subclass of them, density alone varies, then obviouslythere are transitive comparability relations that can be represented faithfully by real numbers d.I fi n
another subclass hardness alone varies, there is a similar comparability representable by realnumbers h. But if we classify rocks by both simultaneously, it requires two real numbers ( d,h)t o
represent them; any attempt to arrange them in a unique one-dimensional order would bearbitrary.
The arbitrariness could be removed if we also introduced some new value judgment or ‘objective
function’ f(d,h) that tells us by relations such as f(d
1,h1)=f(d2,h2) how to trade off a change
/Delta1d=d2−d1indagainst a change /Delta1h=h2−h1inh. But then we are classifying the rocks with
respect to only one attribute, namely f, and universal comparability is again possible.
In the theory of probability developed here we are, by deﬁnition, classifying propositions
according to only one attribute, which we call intuitively ‘degree of plausibility’. Once this isunderstood, we think that the possibility of representation by real numbers need never be
questioned, and the desirability of doing this is attested to by all the nice results and useful
applications of the theory.
Nevertheless, the general idea of a comparative probability theory might be useful to us in two
respects. Firstly, for many purposes one has no need for precisely deﬁned numerical probabilities;any values that preserve ordering relations within a small set of propositions may be adequate forour purpose. For example, if it is required only to choose between two competing hypotheses, or twofeasible actions, a wide range of numerical probability values must all lead to the same ﬁnal choice.Then the precise position within that range is irrelevant, and to determine it would be wastedcomputational effort. Something much like a comparative probability theory would then appear, notas a generalization of numerical probability theory, but as a simple, useful approximation to it.

<<<PAGE 691>>>

Appendix A Other approaches to probability theory 659
Secondly, the above observation about Tokyo and Norway suggests a possible legitimate
application for a lattice theory of probability. If our brains do not have automatically the property ofuniversal comparability, then perhaps a lattice theory might come much closer than theLaplace–Bayes theory to describing the way we actually think. What are some of the properties thatcan be anticipated of a lattice theory?
A.5 Speculations about lattice theories
One evident property is that we could do plausible reasoning only in certain ‘domains’ consisting ofsets of comparable propositions. We would not have any idea how to reason in cases involving ajump across widely separated parts of the lattice; unless we perceive some logical relationshipbetween propositions, we have no criterion for comparing their plausibilities. Our scale ofplausibility might be wildly different on different parts of the lattice, and we would have no way ofknowing this until we had learned to increase the degree of comparability.
Indeed, the human brain does not start out as an efﬁcient reasoning machine, plausible or
deductive. This is something which we require years to learn, and a person who is an expert in oneﬁeld of knowledge may do only rather poor plausible reasoning in another.
3What is happening in
the brain during this learning process?
Education could be deﬁned as the process of becoming aware of more and more propositions, and
of more and more logical relationships between them. Then it seems natural to conjecture that asmall child reasons on a lattice of very open structure: large parts of it are not interconnected at all.For example, the association of historical events with a time sequence is not automatic; the writerhas had the experience of seeing a child, who knew about ancient Egypt and had studied pictures ofthe treasures from the tomb of Tutankhamen, nevertheless coming home from school with a puzzledexpression and asking: ‘Was Abraham Lincoln the ﬁrst person?’
It had been explained to him that the Egyptian artifacts were over 3000 years old, and that
Abraham Lincoln was alive 120 years ago; but the meaning of those statements had not registered in
his mind. This makes us wonder whether there may be primitive cultures in which the adults have noconception of time as something extending beyond their own lives. If so, that fact might not havebeen discovered by anthropologists, just because it was so unexpected that they would not have
raised the question.
As learning proceeds, the lattice develops more and more points (propositions) and
interconnecting lines (relations of comparability), some of which will need to be modiﬁed forconsistency in the light of later knowledge. By developing a lattice with denser and denser structure,one is making his scale of plausibilities more rigidly deﬁned .
No adult ever comes anywhere near to the degree of education where he would perceive
relationships between all possible propositions, but he can approach this condition with some narrowﬁeld of specialization. Within this ﬁeld, there would be a ‘quasi-universal comparability’, and hisplausible reasoning within this ﬁeld would approximate that given by the Laplace–Bayes theory.
A brain might develop several isolated regions where the lattice was locally quite dense; for
example, one might be very well-informed about both biochemistry and musicology. Then forreasoning within each separate region, the Laplace–Bayes theory would be well-approximated, butthere would still be no way of relating different regions to each other.
3The biologist James D. Watson has remarked before TV cameras that professional physicists can be ‘rather stupid’ when they
have to think about biology. We do not deny this, although we wonder how far he would have got in ﬁnding the DNA structure
without the help of the physicists Rosalind Franklin, to acquire the data for him, and Francis Crick, to explain to him how to
interpret it.

<<<PAGE 692>>>

660 Appendixes
Then what would be the limiting case as the lattice becomes everywhere dense with truly universal
comparability? Evidently, the lattice would then collapse into a line, and some unique association ofallplausibilities with real numbers would then be possible. Thus, the Laplace–Bayes theory does
not describe the inductive reasoning of actual human brains; it describes the ideal limiting case ofan ‘inﬁnitely educated’ brain . No wonder that we fail to see how to use it in all problems!
This speculation may easily turn out to be nothing but science ﬁction; yet we feel that it must
contain at least a little bit of truth. As in all really fundamental questions, we must leave the ﬁnaldecision to the future.

<<<PAGE 693>>>

Appendix B
Mathematical formalities and style
We collect here a brief account of the various mathematical conventions used throughout this work,
and discuss some basic mathematical issues that arise in probability theory. Careless notation has
led to so many erroneous results in the recent literature that we need to ﬁnd rules of notation and
terminology that make it as difﬁcult as possible to commit such errors.
A mathematical notation, like a language, is not an end in itself but only a communication device.
Its purpose is best served if the notation, like the language, is allowed to evolve with use. Thisevolution usually takes the form of abbreviations for whatever expressions recur often, and reducingthe number of symbols when their meaning can be read from the context.
But a living, changing language still needs a kind of safe harbor in the form of a ﬁxed set of rules
of grammar and orthography, hidden away in a dictionary for use when ambiguities threaten.
Likewise, probability theory needs a ﬁxed set of normative rules on which we can fall back in caseof doubt. We state here our formal rules of notation and logical hierarchy; all chapters fromChapter 3 on start with these standard forms, and evolve from them. A notation which is soconvenient that it is almost a necessity in one chapter might be only confusing in the next; so eachseparate topic must be allowed its own independent evolution from the standard beginning.
B.1 Notation and logical hierarchy
In our formal probability symbols (those with a capital P)
P(A|B) (B.1)
the entries A,Balways stand for propositions , with a sufﬁciently clear meaning (at least to us) that
we are willing to use them as elements of Aristotelian logic, obeying a Boolean algebra. Thus
P(A|B) does not denote a ‘function’ in the usual sense.
We repeat the warning that a probability symbol is undeﬁned and meaningless if the conditioning
statement Bhappens to have zero probability in the context of our problem (for example, if
B=CD,b u t P(C|D)=0). Failure to recognize this can lead to erroneous calculations – just as
inadvertently dividing by an expression that happens to have the value zero can invalidate allsubsequent results.
To preserve the purity of our probability symbols (B.1) we must have also other symbols for
probabilities. Thus, if proposition Ahas the meaning
A≡the variable qhas the particular value q
/prime, (B.2)
there is a tendency to write, instead of P(A|B),
P(q/prime|B). (B.3)
661

<<<PAGE 694>>>

662 Appendixes
Butq/primeis not a proposition, and so the writer evidently intends the symbol (B.3) to stand now for an
ordinary mathematical function of the variable q/prime. In our system this is illegitimate, and so, when an
ordinary mathematical function is intended, we shall take the precaution of inventing a differentfunctional symbol such as f(|), writing (B.3) instead as
f(q
/prime|B). (B.4)
Now the distinction between (B.3) and (B.4) may appear to some readers as pedantic nitpicking; so
why do we insist on it? Many years ago, the present writer would also have dismissed this point astoo trivial to deserve mention; but later experience has brought to light cases where failure tomaintain the distinction in clear sight has tricked writers into erroneous calculations andconclusions. The amount of time and effort this has wasted – and which is still being wasted in thisﬁeld – justiﬁes our taking protective measures against it.
The point is that a proposition Ais a verbal statement that may indeed specify the value of some
variable q; but it generally contains qualifying clauses also:
A≡the variable qhas the value q
/primeif the proposition B is true . (B.5)
If we try to take the short-cut of replacing Abyq/primein the probability symbol, we lose sight of the
qualiﬁcation. Later in the calculation, the same variable qmay appear in a proposition A1with a
different qualiﬁcation B1; and again one may be tempted to replace A1byq/primein the probability
symbol. Still later in the calculation the same probability symbol will appear with two differentmeanings, and one is tricked into supposing that they represent the same quantity.
This is what happened in the famous ‘marginalization paradox’, in which the same probability
symbol was used to denote probabilities conditional on two different pieces of prior information,with bizarre consequences described in Jaynes (1980) and in Chapter 15. This confusion is stillcausing trouble in probability theory, for those who have not yet understood it.
Howe ver, we are not fanatics about this. In cases so simple that there is very little danger of error
anyway, we allow a compromise and follow the custom of most writers, even though it is not astrictly consistent notation. In probability symbols with a small p, we shall allow the arguments to be
either propositions or numbers, in any mix: thus, if Ais a proposition and qa number, the equation
p(A|B)=p(q|B) (B.6)
is permitted; but with the warning that when small psymbols are used, the reader must judge their
meaning from the context, and there is a possibility of error from failure to read them correctly.
A common and useful custom is to use Greek letters to denote parameters in a probability
distrib ution, the corresponding Latin letters for the corresponding functions of the data. For example,
one may denote a probability average (the mean of a probability distribution) by µ=/angbracketleftx/angbracketright=E(x),
and then the average over the data would be m=
x=n−1/summationtextxi. We shall adhere to this except when
it would be confusing because of a conﬂict with some other long established usage.
B.2 Our ‘cautious approach’ policy
The derivation of the rules of probability theory from simple desiderata of rationality andconsistency in Chapter 2 applied to discrete, ﬁnite sets of propositions. Finite sets are therefore oursafe harbor, where Cox’s theorems apply and nobody has ever been able to produce an inconsistencyfrom application of the sum and product rules. Likewise, in elementary arithmetic ﬁnite sets are thesafe harbor in which nobody has been able to produce an inconsistency from applying the rules ofaddition and multiplication.

<<<PAGE 695>>>

Appendix B Mathematical formalities and style 663
As soon as we try to extend probability theory to inﬁnite sets, we are faced with the need to
exercise the same kind of mathematical caution that one needs in proceeding from ﬁnite arithmeticexpressions to inﬁnite series. The ‘parlor game’ at the beginning of Chapter 15 illustrates how easyit is to commit errors by supposing that the operations of elementary arithmetic and analysis, that arealways safe on ﬁnite sets, may be carried out also on inﬁnite sets.
In probability theory, it appears that the only safe procedure known at present is to derive our
results ﬁrst by strict application of the rules of probability theory on ﬁnite sets of propositions; then,after the ﬁnite-set result is before us, observe how it behaves as the number of propositions increasesindeﬁnitely. There are, essentially, three possibilities:
(1) It tends smoothly to a ﬁnite limit, some terms just becoming smaller and dropping out, leaving
behind a simpler analytical expression.
(2) It blows up, i.e. becomes inﬁnite in the limit.(3) It remains bounded, but oscillates or ﬂuctuates forever, never tending to any deﬁnite limit.
In case (1) we say that the limit is ‘well-behaved’ and accept the limit as the correct solution on the
inﬁnite set. In cases (2) and (3) the limit is ill-behaved and cannot be considered a valid solution tothe problem. Then we refuse to pass to the limit at all.
This is the ‘look before you leap’ policy: in principle, we pass to a limit only after verifying that
the limit is well-behaved. Of course, in practice this does not mean that we conduct such a test anewon every problem; most situations arise repeatedly, and rules of conduct for the standard situationscan be set down once and for all. But in case of doubt, we have no choice but to carry out this test.
In cases where the limit is well-behaved, it may be possible to get the correct answer by operating
directly on the inﬁnite set, but one cannot count on it. If the limit is not well-behaved, then any
attempt to solve the problem directly on the inﬁnite set would have led to nonsense, the cause of
which cannot be seen if one looks only at the limit, and not the limiting process . The paradoxes
noted in Chapter 15 illustrate some of the horrors that have resulted from carelessness in this regard.
B.3 Willy Feller on measure theory
In contrast to our policy, many expositions of probability theory begin at the outset to try to assignprobabilities on inﬁnite sets, both countable or uncountable. Those who use measure theory are, ineffect, supposing the passage to an inﬁnite set already accomplished before introducing probabilities.
For example, Feller advocates this policy and uses it throughout his second volume (Feller, 1966).
In discussing this issue, Feller (1966) notes that specialists in various applications sometimes
‘deny the need for measure theory because they are unacquainted with problems of other types andwith situations where vague reasoning did lead to wrong results ’. If Feller knew of any case where
such a thing has happened, this would surely have been the place to cite it – yet he does not.Therefore we remain, just as he says, unacquainted with instances where wrong results could beattributed to failure to use measure theory.
But, as noted particularly in Chapter 15, there are many documentable cases where careless use of
inﬁnite sets has led to absurdities. We know of no case where our ‘cautious approach’ policy leads to
inconsistency or error; or fails to yield a result that is reasonable.
We do not use the notation of measure theory because it presupposes the passage to an in ﬁnite
limit already carried out at the beginning of a derivation – in deﬁance of the advice of Gauss, quotedat the start of Chapter 15. But in our calculations we often pass to an inﬁnite limit at the end of aderivation; then we are in effect using ‘Lebesgue measure’ directly in its original meaning. We thinkthat failure to use current measure theory notation is not ‘vague reasoning’; quite the opposite. It is amatter of doing things in the proper order.

<<<PAGE 696>>>

664 Appendixes
Feller does acknowledge, albeit grudgingly, the validity of our position. While he considers
passage to a well-deﬁned limit from a ﬁnite set unnecessary, he concedes that it is ‘logicallyimpeccable’ and has ‘the merit of a good exercise for beginners’. That is enough for us; for in thisﬁeld we are all beginners. Perhaps the beginners who have the most to learn are those who nowdecline to practice this very instructive exercise.
We note also that measure theory is not always applicable, because not all sets that arise in real
problems are measurable. For example, in many applications we want to assign probabilities tofunctions that we know in advance are continuous. But Mark Kac (1956) notes that the class ofcontinuous functions is not measurable; its inner measure is zero, its outer measure one.
1Being a
mathematician, he was willing to sacriﬁce some aspects of the real world in order to conform to hispreconception that his sets should be measurable. So to get a measurable class of functions heenlarges it to include the everywhere discontinuous functions. But then the resulting measure isconcentrated ‘almost entirely’ on just the class of functions that, for physical reasons, we need toexclude most strongly from our set! So, while Kac gets a solution that is satisfactory to him, it is notalways the solution to a real problem.
Our value judgment is just the opposite; being concerned with the real world, we are willing to
sacriﬁce preconceptions about measurable classes in order to preserve the aspects of the real worldthat are important in our problem. In this case, a form of our cautious approach policy will alwaysbe able to bypass measure theory in order to get the useful results we seek; for example, (1) expandthe continuous functions in a ﬁnite-number nof orthogonal functions, (2) assign probabilities to the
expansion coefﬁcients in a ﬁnite-dimensional space R
n; (3) do the probability calculation; (4) pass to
the limit n→∞ at the end. In a real problem we ﬁnd that increasing nbeyond a certain value makes
a numerically negligible change in our conclusions (i.e. if we are calculating to a ﬁnite number ofdecimal places, a strictly nil change). So we need never depart from ﬁnite sets after all.
2Useful
results, in various applications from statistical mechanics to radar detection, are found in this way.
It appears to us that most – perhaps all – of the paradoxes of inﬁnite sets that arise in calculations
are caused by the persistent tendency to pass to inﬁnite limits too soon. Usually, this means thatcrucially important information is lost before we have a chance to use it; the case ofnonconglomerabilty in Chapter 15 is a good example. In any event, whatever the cause and the cure,our position is that the paradoxes of inﬁnite sets belong to the ﬁeld of inﬁnite-set theory, and have no
place in probability theory. Our self-imposed inhibition of considering only ﬁnite sets and theirwell-behaved limits enables us to avoid all of the useless and unnecessary paradoxing that hasappeared in the recent statistical literature. From this experience, we conjecture that perhaps allcorrect results in probability theory are either combinatorial theorems on ﬁnite sets or well-behavedlimits of them.
But on this issue, too, we are not fanatics. We recognize that the language of set and measure
theory was a useful development in terminology , in some cases enabling one to state mathematical
propositions with a generality and conciseness that is quite lacking in 19th century mathematics.
Therefore we are happy to use that language whenever it contributes to our goal, and we couldhardly get along without an occasional ‘almost everywhere’ or ‘of measure zero’ phrase. However,when we use a bit of measure theory, it is never in the thought that this makes the argument morerigorous; but only a recognition of the compactness of that language.
Of course, we stand ready and willing to use set and measure theory – just as we stand ready and
willing to use number theory, projective geometry, group theory, topology, or any other part ofmathematics – wherever this should prove helpful for the technique of ﬁnding a result or for
1A continuous function is deﬁned everywhere by specifying it at each rational point, whose number is countable. Thus the class
of continuous functions is very much smaller than the class of everywhere discontinuous functions.
2But, even in the limit, the number of expansion coefﬁcients is only countable, corresponding nicely to the property of continuousfunctions noted in footnote 1.

<<<PAGE 697>>>

Appendix B Mathematical formalities and style 665
understanding it. But we see no reason why we must state every proposition in set/measure theory
terminology and notation in cases where plain English is clearer and, as far as we can see, not onlymore efﬁcient for our purposes but actually safer.
Indeed, an insistence that all of mathematics be stated in that language all of the time can place
unnecessary burdens on a theory, particularly one intended for application in the real world. It canalso degenerate into an affectation, used only linguistically rather than functionally. To give everyold, familiar notion a new, impressive name and symbol unknown to Gauss and Cauchy has nothingto do with rigor. It is, more often than not, a form of gamesmanship whose real purpose is to concealthe Mickey Mouse triviality of what is being done. One would blush to state it in plain English.
B.4 Kronecker vs. Weierstrasz
At this point, a question will surely be in the reader’s mind. After our emphasis on the safety ofﬁnite sets, it might appear that all of analysis, which seems to do everything on uncountable sets, issuspect. Let us explain why this is not the case, and why we do place full conﬁdence in the analysisof Cauchy and Weierstrasz.
3
In the late 19th century, both Karl Weierstrasz (1815–1897) and Leopold Kronecker (1823–1891)
were at the University of Berlin,4lecturing on mathematics. A difference developed between them,
which has been greatly exaggerated by later commentators, and it is only in the past few years that
the real truth about their relationship has started to emerge.
Brieﬂy, Weierstrasz was concerned with perfecting the tools of analysis – particularly power
series expansions – with the speciﬁc case of elliptic functions in mind as an application. Kroneckerwas more concerned with the foundations of mathematics in number theory, and questioned thevalidity of reasoning that does not start back at the integers. On a superﬁcial view, this might seemto deny us all the beautiful results of analysis. Even Morris Kline (1980) gives the impression thatKronecker’s asceticism denies us some of the important advances in modern mathematics. But therecord has been distorted.
For example, Bell (1937, p. 568) paints a picture of Weierstrasz as the great analyst, putting the
ﬁnal ﬁnishing touches on the work of Cauchy, and Kronecker as a mere gadﬂy, attacking the validityof everything he did without making any positive contribution. It is true that Kronecker annoyedWeierstrasz on at least one occasion, documented in Weierstrasz’s correspondence; yet there was notreally much conﬂict in their principles. To understand their positions, we just need a better witnessthan Eric Temple Bell, and fortunately we have two of them: Henri Poincar´ e and Harold M. Edwards.
When Weierstrasz died in 1897, Poincar´ e (1899) wrote a summary of his mathematical work, in
which he pointed out that: ‘...all the equations which are the object of analysis and which deal with
continuous magnitudes are nothing but symbols, replacing an inﬁnite collection of inequalitiesrelating whole numbers.’ In the words of H. M. Edwards (1989), ‘ ...both Weierstrasz and
Kronecker based their mathematics entirely on the whole numbers, so that all their work shared inthe certitude of arithmetic.’ Edwards notes also that several reactionary views commonly attributedto Kronecker are hearsay, for which no support can be found in Kronecker’s own words.
For example, Bell (1937, p. 568) tells us, without any supporting documentation, that Kronecker,
on hearing of Lindemann ’s proof thatπis transcendental, asked of what use that could be, ‘...since
3Indeed, the writer’s ﬁrst love in mathematics was not probability theory, but the use of Cauchy’s complex integration to solve
systems of differential equations and boundary conditions, choosing the integrand to satisfy the differential equation, and then
the contour of integration to satisfy the boundary conditions. Three generations of theoretical physicists have exploited this
method enthusiastically; it is great fun to teach.
4More speciﬁcally, Weierstrasz was there from 1856–1897 and Kronecker from 1861–1891. E. T. Bell (1937) gives a portrait ofthe young Weierstrasz and a photograph of the old Kronecker; H. M. Edwards (1989) gives photographs of the old Weierstraszand the young Kronecker.

<<<PAGE 698>>>

666 Appendixes
irrational numbers do not exist?’ The documentable fact is that Kronecker’s own work on number
theory (Kronecker, 1901, p. 4) describes the formula of Leibniz:
π
4=1−1
3+1
5−1
7+··· (B.7)
as ‘one of the most beautiful arithmetic properties of the odd integers, namely that of determining
this geometrical irrational number.’ Evidently, Kronecker considered irrational numbers aspossessing at least enough ‘existence’ to allow them to be precisely deﬁned. It is true that he did notconsider irrationals to be a necessary part of the foundations; indeed, how could he, or anybody else,think that, in view of relations like the above one, which allow irrationals to be deﬁned entirely interms of integers? Curiously, Weierstrasz also deﬁned irrationals from the integers in just the sameway; so where was the difference between them?
The difference between Kronecker and Weierstrasz was aesthetic rather than substantive:
Kronecker wants to keep ﬁrst principles (the origin in the integers) constantly in view, whileWeierstrasz, having made a new construction, is willing to forget the steps by which it was made,and use it as an element in its own right for further construction. Put in modern computerterminology, Weierstrasz did not deny Kronecker’s ‘machine language’ basis of all mathematics, butwanted to develop analysis in a higher level language. Edwards points out that Kronecker’sprinciples, ‘ ...in his mind and in fact, were no different from the principles of his predecessors,
from Archimedes to Gauss.’
Thanks largely to the historical research of H. M. Edwards, the truth is emerging and Kronecker is
being vindicated and rehabilitated. Perhaps Kronecker was overzealous, and perhaps hemisunderstood the position of Weierstrasz; but events since then suggest that he was not zealousenough in his own cause. His failure to respond to Georg Cantor (1845–1918) seems unfortunate,but easy to understand.
To Kronecker, Cantor’s ideas were so outr´ethat they had nothing to do with mathematics, and
there was no reason for a mathematician to take any note of them. If the editors of the mathematicaljournals made the mistake of publishing such stuff, that was their problem, not his. But the messagesthat Kronecker did communicate contained some very important truth; in particular, he complainedthat much of set theory was fantasy because it was not algorithmic (i.e. it contained no rule by whichone could construct a given element or decide, in a ﬁnite number of operations, whether a givenelement did or did not belong to a given set). Today, with our computer mentalities, this seems suchan obvious platitude that it is hard to imagine anyone ignoring it, much less denying it; yet that isjust what happened. We think that, had mathematicians paid more attention to this warning ofKronecker, mathematics might be in a more healthy state today.
B.5 What is a legitimate mathematical function?
Much of the difference between current pure and applied mathematics lies in their differentconceptions of the notion of a ‘function’. Historically, one started with the well-behaved analyticentire functions like f(x)=x
2orf(x)=sinx. Then these ‘good functions’ were generalized, but
in two different ways. In pure mathematics, the idea was generalized in such a way that set theorynotions remained valid; ﬁrst to piecewise continuous functions, then to quite arbitrary rules bywhich, given a number x, one can deﬁne another number f. Then, perceiving that a function or its
argument need not be limited to real or complex numbers, this was generalized further to anarbitrary mapping of one set Xonto another set F, the elements of which could be almost anything.
In applied mathematics, the notion of a function was generalized in a very different way, so that
the useful analytical operations that we perform on functions remain valid. Perhaps the most

<<<PAGE 699>>>

Appendix B Mathematical formalities and style 667
important hint was provided by the operation of the Fourier transform. This is still a mapping, but at
the higher level of mapping one function f(x) onto another F(k). This mapping was deﬁned by the
integrals
F(k)=/integraldisplay
dxeikxf(x), f(x)=1
2π/integraldisplay
dxe−ikxF(k). (B.8)
If we indicate this Fourier transform pair symbolically as
/bracketleftBig
f(x)↔F(k)/bracketrightBig
(B.9)
we ﬁnd the interesting properties that under translation, convolution, and differentiation,
/bracketleftBig
f(x−a)↔eikaF(k)/bracketrightBig
(B.10)
/bracketleftBig/integraldisplay
dyf(x−y)g(y)↔F(k)G(k)/bracketrightBig
(B.11)
/bracketleftBig
f/prime(x)↔ikF(k)/bracketrightBig
,/bracketleftBig
−ixf(x)↔F/prime(k)/bracketrightBig
. (B.12)
In other words, analytical operations on one function correspond to algebraic operations on the other.
In practice, these are very useful properties. Thus, to solve a linear differential equation, or
difference equation, or integral equation of convolution form [/integraltext
dyK(x−y)f(y)=λg(x)] , or,
indeed, a linear equation which contains all three of these operations, one may take its Fouriertransform, which converts it into an algebraic equation for F(k). If this can be solved directly for
F(k), then taking the inverse Fourier transform yields the solution f(y) of the original equation.
Thus the Fourier transform mapping reduces the solution of linear analytical equations to that ofordinary algebraic equations. In the early 20th century, the theoretical physicist Arnold Sommerfeld
in Munich became a great artist in the technique of evaluating these solutions by fancy contour
integrals, and some of the greatest of the next generation learned this from him. Today, physicistsand engineers could hardly survive without it.
This procedure seemed to apply only to a limited class of functions. In the Dirichlet form of
Fourier theory, one shows that, if f(x) is absolutely integrable, then the integral (B.8) surely
converges to a well-behaved continuous function F(k) on the real axis, and all is well. If f(x) also
vanishes for negative x, then F(k) is analytic and bounded in one-half of the complex plane, and all
is even better. But if f(x) is absolutely integrable, then f
/prime(x)o rf/prime/prime(x) may not be; and there is some
doubt whether the useful properties are still valid. In the early work on Fourier transforms, such asTitchmarsh (1937), virtually all one’s attention was concentrated on the theory of convergence of theintegrals, and any function for which the integral did not converge was held not to possess a Fouriertransform. This placed an intolerable restriction on the range of useful applications of Fourier theory.
Then a more sophisticated view emerged in theoretical physics. One realized that the usefulness
of the Fourier transform lies, not in convergence of any integral, but in the above properties(B.10)–(B.12) of the mapping. Therefore, as long as our functions are sufﬁciently well-behaved sothat the operations in (B.10)–(B.12) make sense, then, if by any means we can deﬁne the mappingsuch that those properties are preserved, then the customary use of Fourier transforms to solve linearintegrodifferential equations will be perfectly rigorous, and it does not make the slightest difference
whether the integrals (B.8) or the analogous Fourier series do or do not converge. A divergentFourier series is still a unique ordered sequence of numbers, conveying all the needed information(i.e. it is uniquely determined by, and uniquely determines, its Fourier transform). It was only anhistorical accident that this mapping was ﬁrst discovered through series and integral representations,which exist only in special cases.

<<<PAGE 700>>>

668 Appendixes
B.5.1 Delta-functions
Although its beginnings can be traced back to Duhamel and Green in the 19th century, this
movement is commonly held to start with P. A. M. Dirac, who in the 1920s invented the notation ofthe delta-function δ(x−y) generalizing Kronecker’s δ
ij, and showed how to use it to good
advantage in applications. It is the ‘Fourier transform of a constant’ in the sense that as F(k)→1,
we have f(x)→δ(x). Mathematicians thinking in terms of the set theory deﬁnition of a ‘function’
were horriﬁed and held this to be nonrigorous on the grounds that delta-functions do not ‘exist’. Butthat was only because of their inappropriate deﬁnition of the term ‘function’. A delta-function is nota mapping of any set onto any other. Laurent Schwartz (1950) tried to make the notion of adelta-function rigorous, but from our point of view awkwardly, because he persisted in deﬁning theterm ‘function’ in a way inappropriate to analysis.
Perceiving this, G. Temple (1955) and M. J. Lighthill (1957) showed how to remove the
awkwardness simply by adopting a deﬁnition of functions as meaning ‘good’ functions and limits ofsequences of good functions (thus, in our system, a discontinuous function is deﬁned as the limit of
a sequence of continuous functions). For this, there is almost no need to mention such things as openand closed sets. Lighthill saw that this deﬁnition of ‘function’ is the one appropriate to Fouriertheory. It is now clear that it is also the one appropriate to probability theory and to all of analysis;with it our theorems become simpler and more general, without a long list of exceptions and specialcases. For example, any Fourier series may now be differentiated term by term any number of timesand the result, whether convergent or not, identiﬁes (by 1:1 correspondence) a unique function inour sense of the word. Physicists had seen this intuitively and used it correctly long before the workof Schwartz, Temple, and Lighthill.
Lighthill produced a very thin book (1957) on the new form of Fourier analysis, which included a
table of Fourier transforms in which every entry is a function which was held formerly not to possessa Fourier transform. Yet that table is a gold mine for the useful solution of linear integro-differentialequations. In a famous review of Lighthill’s book, the theoretical physicist Freeman J. Dyson (1958),a former student of the Cambridge mathematician G. H. Hardy, stated that Lighthill’s book ‘ ...lays
Hardy’s work in ruins, and Hardy would have enjoyed it more than anybody.’ Throughout thepresent work, we take Lighthill’s approach for granted and assume that the reader is familiar with it.
5
B.5.2 Nondifferentiable functions
The issue of nondifferentiable functions arises from time to time in probability theory. In particular,when one solves a functional equation such as those studied in Chapter 2, to assume differentiabilityis to have a horde of compulsive mathematical nitpickers descend upon one, with claims that we are
excluding a large class of potentially important solutions. However, we noted that this is not the
case; Aczel demonstrated that Cox’s functional equations can all be solved without assumingdifferentiability (at the cost of much longer derivations) and with just the same solutions that wefound above.
Let us take a closer look at the notion of nondifferentiable functions in general. This was not
well-received at ﬁrst by mathematicians. Charles Hermite wrote to Stieltj` es: ‘I turn away in horror
from this awful plague of functions which have no derivatives.’ The one generally blamed for this
5Lighthill deﬁnes the term ‘good function’ in a different way than we did above, which seems to us unnecessarily restrictive in
its behavior at inﬁnity. Apparently, this was because he did not like integrals over ﬁnite domains, whereas we do like them. But
Lighthill’s deﬁnition is more general than ours in that a ‘good function’ need not be analytic; however, this generality seems to
us unnecessary because we have never seen a real problem in which the underlying good functions could not be chosen to be
analytic.

<<<PAGE 701>>>

Appendix B Mathematical formalities and style 669
plague was Henri Lebesgue (1875–1941), although Weierstrasz had noted them before him. The
Weierstrasz nondifferentiable function is
f(x)≡∞/summationdisplay
n=0ancos(mnx), (B.13)
where (0 <a<1) and mis a positive odd integer. It is an ordinary Fourier series with period 2 π,
since mnis always an integer. Furthermore, the series is uniformly convergent for all real x(since it
must converge at least as well as does/summationtextan), so it deﬁnes a continuous function. But if ma>1,
term-by-term differentiation yields a badly divergent series, whose coefﬁcients grow exponentiallyinn. The proof that the derivative
f
/prime(x)≡lim
h→0f(x+h)−f(x)
h(B.14)
then does not exist for any xis rather tedious.6Weierstrasz’s function is, in fact, the limit of a
sequence of good functions (the partial sums Skof the ﬁrst kterms), but it is not a very well-behaved
limit, and such functions are of no apparent use to us because they fail to satisfy condition (B.12).Nevertheless, functions like this do arise in applications; for example, in Chapter 7 our attempt tosolve the integral equation (7.49) by Fourier transform methods ran up against this difﬁculty if thekernel was too broad. Then our conclusion was that the integral equation does not have any usablesolution unless the kernel φ(x−y) is at least as sharp as the ‘driving force’ f(x).
B.5.3 Bogus nondifferentiable functions
The case most often cited as an example of a nondifferentiable function is derived from a sequence
fn(x) , each of which is a string of isosceles right triangles whose hypotenuses lie on the real axis
and have length 1 /n.A sn→∞ , the triangles shrink to zero size. For any ﬁnite n, the slope of
fn(x)i s±1 almost everywhere. Then what happens as n→∞ ? The limit f∞(x) is often cited
carelessly as a nondifferentiable function. Now it is clear that the limit of the derivative, f/prime
n(x), does
not exist; but it is the derivative of the limit that is in question here, f∞(x)≡0, and this is certainly
differentiable. Any number of such sequences fn(x) with discontinuous slope on a ﬁner and ﬁner
scale may be deﬁned. The error of calling the resulting limit f∞(x) nondifferentiable, on the
grounds that the limit of the derivative does not exist, is common in the literature. In many cases, thelimit of such a sequence of bad functions is actually a well-behaved function (although awkwardlydeﬁned), and we have no reason to exclude it from our system.
Lebesgue defended himself against his critics thus: ‘If one wished always to limit himself to the
consideration of well-behaved functions, it would be necessary to renounce the solution of many
problems which were proposed long ago and in simple terms.’ The present writer is unable to cite
any speciﬁc problem which was thus solved; but we can borrow Lebesgue’s argument to defend ourown position.
To reject limits of sequences of good functions is to renounce the solution of many current real
problems. Those limits can and do serve many useful purposes, which much current mathematicaleducation and practice still tries to stamp out. Indeed, the refusal to admit delta-functions aslegitimate mathematical objects has led mathematicians into error. For example, H. Cram ´er (1946,
Chap. 32) gives an inequality, which we derived in Chapter 17, placing a lower limit to the variance
6See Hardy (1911). Titchmarsh (1939, pp. 350–353) gives only a shorter proof valid when ma>1+3π/2. Some authors state
that f(x) is nondifferentiable only in this case; but, to the best of our knowledge, nobody has ever claimed that Hardy’s proof
contains an error.

<<<PAGE 702>>>

670 Appendixes
of the sampling distribution for a parameter estimator θ∗:
var(θ∗)≥(1+db/dθ)2
n/integraltext
dx(∂log(f)/∂θ)2f(x|θ), (B.15)
where we have made nobservations from a sampling distribution f(x|θ), and b(θ∗)≡E(θ∗−θ)i s
the bias of the estimator.
Then Cram´ er notes that, if f(x|θ) has discontinuities, then ‘the conditions for the regular case are
usually not satisﬁed. In such cases it is often possible to ﬁnd unbiased estimates of ‘abnormally high’precision, i.e. such that the variance is smaller than the lower limit [(B.15)] for regular estimates.’How could he have reached such a remarkable conclusion, since (B.15) is only the Schwartzinequality, which does not seem to admit of exceptions? We ﬁnd that he has used the set-theorydeﬁnition of a function, and concluded that the derivative ∂log(f)/∂θdoes not exist at points of
discontinuity. So he takes the integral in (B.15) only over those regions where f(x|θ) is continuous.
But the deﬁnition of a discontinuous function which is appropriate in analysis is our limit of a
sequence of continuous functions. As we approach that limit, the derivative develops a higher and
sharper spike. However close we are to that limit, the spike is part of the correct derivative of thefunction, and its contribution must be included in the exact integral. Thus the derivative of adiscontinuous function g(x) necessarily contains a delta-function [ g(y+)−g(y−)]δ(x−y)a t
points yof discontinuity, whose contribution is always present in the differentiated Fourier series
for g (x), and must be included in order to get the correct physical solution . Had Cram´ er included
this term, (B.15) would have reduced in the limit to var( θ
∗)≥0; hardly a useful statement, but at
least there would have been no anomaly and no seeming violation of the Schwartz inequality.
In a similar way, the solution of an integral equation with ﬁnite limits, of the form
/integraldisplayb
adyK(x,y)f(y)=λg(x), (B.16)
generally involves delta-functions like δ(y−a)o rδ/prime(y−b) at the end-points, and so those who do
not believe in delta-functions consider such integral equations as not having solutions. But in real
physical problems, exactly such integral equations occur repeatedly, and again the delta-functions
must be included in order to get the correct physical solution. Some examples are given byD. Middleton (1960); they are virtually ubiquitous in the prediction of irreversible processes instatistical mechanics. It is astonishing that so few non-physicists have yet perceived this need toinclude delta-functions, but we think it only illustrates what we have observed independently; thosewho think of fundamentals in terms of set theory fail to see its limitations because they almost neverget around to useful, substantive calculations.
So, bogus nondifferentiable functions are manufactured as limits of sequences of rows of tinier
and tinier triangles, and this is accepted without complaint. Those who do this while lookingaskance at delta-functions are in the position of admitting limits of sequences of bad functions aslegitimate mathematical objects, while refusing to admit limits of sequences of good functions! Thisseems to us a sick policy, for delta-functions serve many essential purposes in real, substantivecalculations, but we are unable to conceive of any useful purpose that could be served by anondifferentiable function. It seems that their only use is to provide trouble-makers with artiﬁciallycontrived counter-examples to almost any sensible and useful mathematical statement one couldmake. Henri Poincar´ e (1909) noted this in his characteristically terse way:
In the old days when people invented a new function they had some useful purpose in mind: now
they invent them deliberately just to invalidate our ancestors’ reasoning, and that is all they are evergoing to get out of them.
We would point out that those trouble-makers did not, after all, invalidate our ancestors’
reasoning; their pathology appeared only because they adopted, surreptitiously, a different deﬁnition

<<<PAGE 703>>>

Appendix B Mathematical formalities and style 671
of the term ‘function’ than our ancestors used. Had this been pointed out, it would have been clear
that there was no need to modify our ancestors’ conclusions.
Today, this fad of artiﬁcially contrived mathematical pathology seems nearly to have run its
course, and for just the reason that Poincar´ e foresaw; nothing useful can be done with it. While we
still see exhortations not to assume differentiability of an unknown function, it is difﬁcult to ﬁndeven one speciﬁc example of a nondifferentiable function appearing – much less actually being usedfor anything – in the recent literature. One must go back to old works like Titchmarsh (1939) to seethem at all.
Note, therefore, that we stamp out this plague too, simply by our deﬁning the term ‘function’ in
the way appropriate to our subject. The deﬁnition of a mathematical concept that is ‘appropriate’ tosome ﬁeld is the one that allows its theorems to have the greatest range of validity and usefulapplications, without the need for a long list of exceptions, special cases, and other anomalies. Inour work the term ‘function’ includes good functions and well-behaved limits of sequences of goodfunctions; but not nondifferentiable functions. We do not deny the existence of other deﬁnitionswhich do include nondifferentiable functions, any more than we deny the existence of ﬂuorescentpurple hair dye in England; in both cases, we simply have no use for them.
7
B.6 Counting inﬁnite sets?
It is well known that Lewis Carroll’s children’s books were really expositions of the principles oflogic, conveyed by the device of stating the opposite in a form that would appear ludicrous even tosmall children. One of his poems ends thus:
He thought he saw an Argument that proved he was the Pope:
He looked again and found it was a Bar of Mottled Soap.‘A fact so dread,’ he faintly said, ‘Extinguishes all hope!’
Indeed, many of the arguments seriously proposed in probability theory are seen, on second glance,
to be nothing but mottled soap. The idea was appropriated in a famous anecdote
8about the
Cambridge mathematician G. H. Hardy; J. E. McTaggart expressed doubt that from a false
proposition all propositions can be deduced, by challenging him thus: ‘Given 2 +2=5: prove that I
am the Pope.’ Whereupon Hardy replied: ‘Subtract 3 from each side and we have 1 =2. Now we
agree that the Pope and you are two; therefore the Pope and you are one!’ But that was only a playon words; inﬁnite-set theory gives us a superior grade of mottled soap, with which we can proveMcTaggart’s papacy much more convincingly.
We start from the premise that two sets have the same number of elements if they can be put into
1:1 correspondence with each other. Then by the association ( n↔2n),n=1,2,..., we can put
the positive integers into 1:1 correspondence with the positive even integers. And by the association(2n↔2n−1),n=1,2,..., we can, equally well, put the positive even integers into 1:1
correspondence with the positive odd integers; so by such logic it seems that we would be driven to
conclude that:
(A) (number of integers) =(number of even integers);
(B) (number of even integers) =(number of odd integers);
(C) (number of integers) =2×(number of even integers);
7On a different topic, in Chapter 17 (footnote 9 on p. 521) we follow the same policy by deﬁning the term ‘moving average’
for a ﬁnite time series in such a way that our theorems are all exact, without any need for messy ‘end effect’ corrections. Of
course, it then develops that this is the deﬁnition most directly useful in applications and that conserves information which would
otherwise be lost.
8Cited by Jeffreys (1931; 1957 edn, p. 18).

<<<PAGE 704>>>

672 Appendixes
and from (A) and (C) it follows that 1 =2. The reasoning here is not very different from that in
Eqs. (15.2)–(15.3).
Our view is that the ‘set of all integers’ is undeﬁned except as a limit of ﬁnite sets, and if it is
approached in that way, by introducing the explicit limiting process, no contradiction can beproduced whatever limiting process we choose, even though the limiting ratio of (number of evenintegers)/(number of integers) can be made to be any xwe please in 0≤x≤1. That is, the limit of
(number of odd integers)/(number of integers) will be (1 −x), and our counting will remain
consistent in the limit.
For example, every integer is included once and only once in the sequence {1, 3, 2, 5, 7, 4, ...},i n
which we take alternately two odd and one even. Then counting elements only in the ﬁnite setsconsisting of the ﬁrst nelements of this sequence, and passing to the limit n→∞ after doing the
counting, we would ﬁnd in place of the inconsistent statements (A), (B), (C) above, the consistentset
(A
/prime) (number of integers) =3×(number of even integers);
(B/prime) (number of even integers) =1/2×(number of odd integers);
(C/prime) (number of integers) =(number of even integers) +(number of odd integers).
These ideas are not as new as one might think. Galileo (1638), in his Dialogues Concerning Two
New Sciences , notes two curious facts. On the one hand, each integer has one and only one square,
and no two of them have the same square; from which it would seem that the number of integers andthe number of squares must be the same. On the other hand, it is evident that there are many integers(in a certain sense, the ‘great majority’ of them) which are not squares. From this he draws theeminently sensible conclusion:
This is one of the difﬁculties which arise when we attempt, with our ﬁnite minds, to discuss the
inﬁnite, assigning to it those properties which we give to the ﬁnite and limited; but this I think iswrong, for we cannot speak of inﬁnite quantities as being the one greater or less than or equal toanother.
Hermann Weyl, 300 years later, expressed almost exactly the same judgment, as noted below. See,
for example, Weyl (1949).
B.7 The Hausdorff sphere paradox and mathematical diseases
The inconsistent statements above are structurally almost identical with the Hausdorff paradoxconcerning congruent sets on a sphere, except for the promotion up to uncountable sets (here
X,Y,Zare disjoint sets which nearly cover the sphere, and Xis congruent to Y, in the sense that a
rotation of the sphere makes Xcoincide with Y, and likewise Yis congruent to Z. But what is
extraordinary is the claim that Xis also congruent to the union of YandZ, even though Y/negationslash=Z). We
are, like Poincar´ e and Weyl, puzzled by how mathematicians can accept and publish such results;
why do they not see in this a blatant contradiction which invalidates the reasoning they are using?
Nevertheless, L. J. Savage (1962) accepted this antinomy as literal fact and, applying it to
probability theory, said that someone may be so rash as to blurt out that he considers congruent setson the sphere equally probable; but the Hausdorff result shows that his beliefs cannot actually havethat property. The present writer, pondering this, has been forced to the opposite conclusion: mybelief in the existence of a state of knowledge which considers congruent sets on a sphere equallyprobable, is vastly stronger than my belief in the soundness of the reasoning which led to the
Hausdorff result.

<<<PAGE 705>>>

Appendix B Mathematical formalities and style 673
Presumably, the Hausdorff sphere paradox and the Russell Barber paradox have similar
explanations: one is deﬁning weird sets with self-contradictory properties, so, of course, from thatmess it will be possible to deduce any absurd proposition we please. Hausdorff entitled his work‘Mengenlehre ’, and Poincar´ e made the famous quip that ‘Future generations will regard
Mengenlehre as a disease from which one has recovered.’ But he would be appalled to see this
recovery not yet achieved 80 years later; nevertheless, Poincar´ e’s views are alive and well today
among users of applied mathematics.
For example, in 1983 the writer heard a talk by a very prominent statistician, reporting on an
historical investigation. He remarked: ‘I was surprised to learn that, before the days of Bourbaki, theFrench actually produced some useful mathematics.’ More recently, the Nobel Laureate theoreticalphysicist Murray Gell-Mann (1992), discussed this situation. He opined that there is still much inmodern mathematics of value to physics, and the divergence of pure mathematics from science is inpart only an illusion produced by the obscurantist language of Bourbakists and their reluctance towrite up any non-trivial example in explicit detail. He concludes: ‘Pure mathematics and science areﬁnally being reunited and, mercifully, the Bourbaki plague is dying out.’
We wish we could feel that optimistic. In our view, this plague is far more serious than mere
obscure language; it infects the substantive content of pure mathematics. A sane person can have noconﬁdence in any of it; rules of conduct must be found which prevent the appearance of these
ridiculous paradoxes, and then our mathematics textbooks must be rewritten. As is well known,
Russell’s theory of types can dispose of a few paradoxes, but far from all of them. We fear that, evenwith the best of good will on both sides, it will require at least another generation to bring about thereconciliation of pure mathematics and science. For now, it is the responsibility of those whospecialize in inﬁnite-set theory to put their own house in order before trying to export their productto other ﬁelds. Until this is accomplished, those of us who work in probability theory or any otherarea of applied mathematics have a right to demand that this disease, for which we are not
responsible, be quarantined and kept out of our ﬁeld.
In this view, too, we are not alone; and indeed have the support of many non-Bourbakist
mathematicians. In our Preface we quoted Morris Kline (1980) on the dangers of allowinginﬁnite-set theory to get a foothold in applied mathematics. He in turn (on his p. 237) quotesHermann Weyl. Both Brouwer and Weyl noted that classical logic had been developed forapplication to ﬁnite sets. The attempt to apply classical logic, without justiﬁcation, to inﬁnite sets is,in Weyl’s words: ‘ ...the Fall and original sin of set theory, for which it is justly punished by the
antinomies. It is not that such contradictions showed up that is surprising, but that they showed up atsuch a late stage of the game.’
But there is a simple explanation for this late appearance, noted with examples in Chapter 15: if
an erroneous argument leads to an absurd result immediately, it will be abandoned and we shallnever hear about it. If it yields a reasonable result on the ﬁrst two or three tries, then there is somerange of problems where it will succeed. One will continue using it, but at ﬁrst conservatively – onproblems that are quite similar, so it is likely to continue giving reasonable results. Only later, whenone becomes over-conﬁdent and tries to extend the application to different kinds of problems, do thecontradictions appear.
9
Just the same phenomenon occurred in orthodox statistics, where the ad hoc inventions such as
conﬁdence intervals yielded acceptable results for a long time because they were used at ﬁrst onlyon simple problems which were free of nuisance parameters, but suf ﬁcient statistics existed, and
there was no very important prior information. Nobody took any note of the fact that the numerical
9The writer knew Hermann Weyl, took his course in group theory at Princeton, and admired him as the ﬁnal authority on both
group theory and variational principles for general relativity. But the Bourbakist mathematicians at Princeton sneered at him
and called him ‘Holy Hermann’ behind his back, because of his Biblical exhortations to virtue like the one just quoted. They
would have been better advised to listen to him.

<<<PAGE 706>>>

674 Appendixes
results were then the same as the Bayesian posterior probability intervals at the same level (based on
the uninformative priors given by Jeffreys). Conﬁdence intervals were widely held, bymathematicians such as Neyman, Cram´ er and Wilks, to be great advances over Bayesian methods,
until their contradictions began to appear when one tried to apply them to more general problems.
10
Finally, we were able to show (Jaynes, 1976) that conﬁdence intervals are satisfactory as inferencesonly in those special cases where they happen to agree with the Bayesian intervals after all.
Kline (1980, p. 285) also quotes J. Willard Gibbs on this subject: ‘The pure mathematician can do
what he pleases, but the applied mathematician must be at least partially sane.’ In any event, no sane
person would try to use such anomalies as the Hausdorff sphere paradox in a real application.
Finally, we offer a few more general comments on mathematical style.
B.8 What am I supposed to publish?
L. J. Savage (1962) asked this question to express his bemusement at the fact that, no matter whattopic he chose to discuss, and no matter what style of writing he chose to adopt, he was sure to becriticized for not making a different choice. In this he was not alone. We would like to plead for alittle more tolerance of our individual differences.
If anyone wants to concentrate his attention on inﬁnite sets, measure theory, and mathematical
pathology in general, he has every right to do so. And he need not justify this by pointing to usefulapplications or apologize for the lack of them; as was noted long ago, abstract mathematics is worthknowing for its own sake.
But others in turn have equal rights. If we choose to concentrate on those aspects of mathematics
which areuseful in real problems and which enable us to carry out the important substantive
calculations correctly – but which the mathematical pathologists never get around to – we feel freeto do so without apology.
Ultimately, the mathematical level and depth of this work were chosen with the aim of making it
possible for all readers to extract what they want from it. Since those who approach a work with thesole purpose of ﬁnding fault with its style of presentation will always be able to do so no matter howit is presented, our aim was to ensure that those who approach it with sincere desire to understand itscontent will also be able to do so. Thus we try to give cogent reasons why the ideas we advocate are
‘obvious’, while those we deplore are not, when this can be done brieﬂy enough not to interrupt theline of argument. This inevitably leaves some lacunae, in part ﬁlled in by the Comments sections atthe end of most chapters.
In this connection, the question of what is and is not ‘obvious’ is a matter of gamesmanship that is
played in two opposite directions. On the one hand, the standard way of introducing notions that donot stand up to critical examination – or to deprecate those that stand up too well to be safelyopposed – is to call them ‘obvious’. On the other hand, to express grave doubts about simple matters
thatareobvious is the equally standard technique for imputing to one’s self deep critical faculties
not possessed by others. We try to steer a middle course between these, but like Savage do so in theknowledge that, whatever our choice, it will receive opposite criticisms from the two types of
gamesman.
But we avoid one common error: nothing could be more pathetically mistaken than the prefatory
claim of one author in this ﬁeld that mathematical rigor ‘guarantees the correctness of the results’.On the contrary, much experience teaches us that the more one concentrates on the appearance of
10Conﬁdence intervals are always correct as statements about sampling properties of estimators; yet they can be absurd as
statements of inference about the values of parameters. For example, the entire conﬁdence interval may lie in a region of the
parameter space which we know, by deductive reasoning from the data, to be impossible.

<<<PAGE 707>>>

Appendix B Mathematical formalities and style 675
mathematical rigor, the less attention one pays to the validity of the premises in the real world, and
the more likely one is to reach ﬁnal conclusions that are absurdly wrong in the real world.
B.9 Mathematical courtesy
A few years ago the writer attended a seminar talk by a young mathematician who had just receivedhis Ph.D. degree and, we understood, had a marvellous new limit theorem of probability theory. Hestarted to deﬁne the sets he proposed to use, but three blackboards were not enough for them, and henever got through the list. At the end of the hour, having to give up the room, we walked out inpuzzlement, not knowing even the statement of his theorem.
A ‘19th century mathematician’ like Poincar´ e would have been into the meat of the calculation
within a few minutes and would have completed the proof and pointed out its consequences in timefor discussion.
The young man is not to be blamed; he was only doing what he had been taught a ‘20th century
mathematician’ must do. Although he has perhaps now learned to plan his talks a little better, he issurely still wasting much of his own time and that of others in reciting all the preliminaryincantations that are demanded in 20th century mathematics before one is allowed to proceed to theactual problem. He is a victim of what we consider to be, not higher standards of rigor, but studiedmathematical discourtesy.
Nowadays, if you introduce a variable xwithout repeating the incantation that it is in some set or
‘space’ X, you are accused of dealing with an undeﬁned problem. If you differentiate a function
f(x) without ﬁrst having stated that it is differentiable, you are accused of lack of rigor. If you note
that your function f(x) has some special property natural to the application, you are accused of
lack of generality. In other words, every statement you make will receive the discourteous
interpretation.
Obviously, mathematical results cannot be communicated without some decent standards of
precision in our statements. But a fanatical insistence on one particular form of precision andgenerality can be carried so far that it defeats its own purpose; 20th century mathematics oftendegenerates into an idle adversary game instead of a communication process.
The fanatic is not trying to understand your substantive message at all, but only trying to ﬁnd fault
with your style of presentation. He will strive to read nonsense into what you are saying, if he canpossibly ﬁnd any way of doing so. In self-defense, writers are obliged to concentrate their attentionon every tiny, irrelevant, nitpicking detail of how things are said rather on what is said. The lengthgrows; the content shrinks.
Mathematical communication would be much more efﬁcient and pleasant if we adopted a
different attitude. For one who makes the courteous interpretation of what others write, the fact that
xis introduced as a variable already implies that there is some set Xof possible values. Why should
it be necessary to repeat that incantation every time a variable is introduced, thus using up twosymbols where one would do? (Indeed, the range of values is usually indicated more clearly at the
point where it matters, by adding conditions such as (0 <x<1) after an equation.)
For a courteous reader, the fact that a writer differentiates f(x) twice already implies that he
considers it twice differentiable; why should he be required to say everything twice? If he provesproposition Ain enough generality to cover his application, why should he be obliged to use
additional space for irrelevancies about the most general possible conditions under which Awould
be true?
A scourge as annoying as the fanatic is his cousin, the compulsive mathematical nitpicker. We
expect that an author will deﬁne his technical terms, and then use them in a way consistent with hisdeﬁnitions. But if any other author has ever used the term with a slightly different shade of meaning,

<<<PAGE 708>>>

676 Appendixes
the nitpicker will be right there accusing you of inconsistent terminology. The writer has been
subjected to this many times; and colleagues report the same experience.
Nineteenth century mathematicians were not being nonrigorous by their style; they merely, as a
matter of course, extended simple civilized courtesy to others, and expected to receive it in return.This will lead one to try to read sense into what others write, if it can possibly be done in view of thewhole context; not to pervert our reading of every mathematical work into a witch-hunt fordeviations from the Ofﬁcial Style.
Therefore, sympathizing with the young man’s plight but not intending to be enslaved like him,
we issue the following:
Emancipation Proclamation
Every variable xthat we introduce is understood to have some set Xof possible values. Every
function f(x) that we introduce is understood to be sufﬁciently well-behaved so that what we
do with it makes sense. We undertake to make every proof general enough to cover theapplication we make of it. It is an assigned homework problem for the reader who is interestedin the question to ﬁnd the most general conditions under which the result would hold.
We could convert many 19th century mathematical works to 20th century standards by making arubber stamp containing this Proclamation, with perhaps another sentence using the terms‘sigma-algebra, Borel ﬁeld, Radon–Nikodym derivative’, and stamping it on the ﬁrst page.
Modern writers could shorten their works substantially, with improved readability and no
decrease in content, by including such a Proclamation in the copyright message, and writingthereafter in 19th century style. Perhaps some publishers, seeing these words, may demand that theydo this for economic reasons; it would be a service to science.
In this appendix we have presented many short quotations without the references. Supporting
documentation and many further interesting details may be found in Bell (1937), F´ elix (1960), Kline
(1980), and Rowe and McCleary (1989).

<<<PAGE 709>>>

Appendix C
Convolutions and cumulants
Firstly we note some general mathematical facts which have nothing to do with probability theory.
Given a set of real functions f1(x),f2(x),..., fn(x) deﬁned on the real line and not necessarily
non-negative, suppose that their integrals (zeroth moments) and their ﬁrst, second, and thirdmoments exist:
Z
i≡/integraldisplay∞
−∞dxfi(x)<∞,
Fi≡/integraldisplay∞
−∞dxxf i(x)<∞Si≡/integraldisplay∞
−∞dxx2fi(x)<∞,
Ti≡/integraldisplay∞
−∞dxx3fi(x)<∞.(C.1)
The convolution of f1and f2is deﬁned by
h(x)≡/integraldisplay∞
−∞dyf1(y)f2(x−y) (C.2)
or, in condensed notation, h=f1∗f2. Convolution is associative: ( f1∗f2)∗f3=f1∗(f2∗f3),
so we can write a multiple convolution as ( h=f1∗f2∗f3∗···∗ fn) without ambiguity. What
happens to the moments under this operation? The zeroth moment of h(x)i s
Zh=/integraldisplay∞
−∞dx/integraldisplay∞
−∞dyf1(y)f2(x−y)=/integraldisplay
dyf1(y)Z2=Z1Z2. (C.3)
Therefore, if Zi/negationslash=0 we can multiply fi(x) by some constant factor which makes Zi=1, and this
property will be preserved under convolution. In the following we assume that this has been donefor all i. Then the ﬁrst moment of the convolution is
F
h=/integraldisplay∞
−∞dx/integraldisplay∞
−∞dyf1(y)xf2(x−y)=/integraldisplay
dyf1(y)/integraldisplay∞
−∞dq(y+q)f2(q)
=/integraldisplay∞
−∞dyf1(y)[yZ2+F2]=F1Z2+Z1F2(C.4)
so the ﬁrst moments are additive under convolution:
Fh=F1+F2. (C.5)
For the second moment, we have by a similar argument
Sh=/integraldisplay
dyf1(y)/integraldisplay
dq(y2+2yq+q2)f2(q)=S1Z2+2F1F2+Z1S2 (C.6)
or
Sh=S1+2F1F2+S2. (C.7)
677

<<<PAGE 710>>>

678 Appendixes
Subtracting the square of (C.5), the cross-product term cancels out, and we see that there is another
quantity additive under convolution:
[Sh−(Fh)2]=[S1−(F1)2]+[S2−(F2)2]. (C.8)
Proceeding to the third moment, we ﬁnd
Th=T1Z2+3S1F2+3F1S2+Z1T2, (C.9)
and after some algebra (subtracting off functions of (C.5) and (C.7)), we can conﬁrm that there is a
third quantity, namely
Th−3ShFh+2(Fh)3(C.10)
that is additive under convolution.
This generalizes at once to any number of such functions: let h(x)≡f1∗f2∗f3∗···∗ fn.
Then we have found the additive quantities
Fh=n/summationdisplay
i=1Fi
Sh−F2
h=n/summationdisplay
i=1(Si−F2
i)
Th−3ShFh+2F3
h=n/summationdisplay
i=1(Ti−3SiFi+2F3
i).(C.11)
These quantities, which ‘accumulate’ additively under convolution, are called the cumulants ;w e
have developed them in this way to emphasize that the notion has nothing, fundamentally, to do withprobability.
At this point, we deﬁne the nth cumulant as the nth moment, with ‘correction terms’ from lower
moments, so chosen as to make the result additive under convolution. Then two questions call outfor solution: (1) do such correction terms always exist; and (2) if so, how do we ﬁnd a generalalgorithm to construct them?
To answer these questions, we need a more powerful mathematical method. Introduce the Fourier
transform of f
i(x):
Fi(α)≡/integraldisplay∞
−∞dxfi(x)eiαxfi(x)=1
2π/integraldisplay∞
−∞dαFi(α)e−iαx. (C.12)
Under convolution it behaves very simply:
H(α)=/integraldisplay∞
−∞dxh(x)eiαx=/integraldisplay
dyf1(y)/integraldisplay
dxeiαxf2(x−y)
=/integraldisplay
dyf1(y)/integraldisplay
dqeiα(y+q)f2(q)
=F1(α)F2(α).(C.13)
In other words, log F(α) is additive under convolutions. This function has some remarkable
properties in connection with the notion of the ‘cepstrum’ discussed later. For now, examine thepower series expansions of F(α) and log F(α). The ﬁrst is
F(α)=M
0+M1(iα)+M2(iα)2
2!+M3(iα)3
3!+··· (C.14)

<<<PAGE 711>>>

Appendix C Convolutions and cumulants 679
with the coefﬁcients
Mn=1
indnF(α)
dαn/vextendsingle/vextendsingle/vextendsingle/vextendsingle
α=0=/integraldisplay∞
−∞dxxnf(x), (C.15)
which are just the nth moments of f(x); if f(x) has moments up to order N, then F(α)i s
differentiable Ntimes at the origin. There is a similar expansion for log F(α):
logF(α)=C0+C1(iα)+C2(iα)2
2!+C3(iα)3
3!+···. (C.16)
Evidently, all its coefﬁcients
Cn=1
indn
dαnlogF(α)/vextendsingle/vextendsingle/vextendsingle/vextendsingle
α=0(C.17)
are additive under convolution, and are therefore cumulants. In fact, the term ‘cumulant’ is often
deﬁned by this relation, rather than by the property of accumulating. The ﬁrst few are
C0=logF(0)=log/integraldisplay
dxf(x)=log(Z), (C.18)
C1=1
i/integraltext
dxixf(x)/integraltext
dxf(x)=F
Z, (C.19)
C2=d2
d(iα)2logF(α)=d
d(iα)/integraltext
dxxf(x)eiαx
/integraltext
dxf(x)eiαx=/integraltext
f/integraltext
x2f−(/integraltext
xf)2
(/integraltext
f)2, (C.20)
or
C2=S
Z−/parenleftbiggF
Z/parenrightbigg2
, (C.21)
which we recognize as just the cumulants found directly above; likewise, after some tedious
calculation, C3andC4prove to be equal to the third and fourth cumulants (C.10). Have we then
found in (C.17) all the cumulants of a function, or are there still more that cannot be found in thisway? We would argue that if all the C
iexist (i.e. f(x) has moments of all orders, so F(α)i sa n
entire function) then the Ciuniquely determine F(α) and therefore f(x), so they must include all
the algebraically independent cumulants; any others must be linear functions of the Ci. But if f(x)
does not have moments of all orders, the answer is not obvious, and further investigation isneeded.
C.1 Relation of cumulants and moments
While adhering to our convention Z=1, let us go to a more general notation for the nth moment of
a function:
Mn≡/integraldisplay∞
−∞dxxnf(x)=dn
d(iα)n/integraldisplay
dxf(x)eiαx/vextendsingle/vextendsingle/vextendsingle/vextendsingle
α=o=i−nF(n)(0), n=0,1,2,.... (C.22)
It is often convenient to use also the notation
Mn=xn, (C.23)

<<<PAGE 712>>>

680 Appendixes
indicating an average of xnwith respect to the function f(x). We stress that these are not in general
probability averages; we are indicating some general algebraic relations in which f(x) need not be
non-negative. For probability averages we always reserve the notation /angbracketleftx/angbracketrightorE(x).
If a function f(x) has moments of all orders, then its Fourier transform has a power series
expansion
F(α)=∞/summationdisplay
n=0Mn(iα)n. (C.24)
Evidently, the ﬁrst cumulant is the same as the ﬁrst moment:
C1=M1=x, (C.25)
while for the second cumulant we have C2=M2−M2
1; but this is
C2=/integraldisplay
dx[x−M1]2f(x)=(x−x)2=x2−x2, (C.26)
the second moment of xabout its mean value, called the second central moment off(x). Likewise,
the third central moment is/integraldisplay
dx(x−x)3f(x)=/integraldisplay
dx[x3−3xx2+3x2x−x3]f(x), (C.27)
but this is just the third cumulant (C.11):
C3=M3−3M1M2+2M3
1, (C.28)
and at this point we might conjecture that all the cumulants are just the corresponding central
moments. However, this turns out not to be the case: we ﬁnd that the fourth central moment is
(x−x)4=M4−4M3M1+6M2M2
1−3M4
1, (C.29)
but the fourth cumulant is
C4=M4−4M3M1−3M2
2+12M2M2
1−6M4
1. (C.30)
So they are related by
(x−x)4=C4+3C2
2. (C.31)
Thus the fourth central moment is not a cumulant; it is not a linear function of cumulants. However,
we have found it true that, for n=1,2,3,4 the moments up to order nand the cumulants up to
order nuniquely determine each other; we leave it for the reader to see, from examination of the
above relations, whether this is or is not true for all n.
If our functions f(x) are probability densities, many useful approximations are written most
efﬁciently in terms of the ﬁrst few terms of a cumulant expansion.
C.2 Examples
What are the cumulants of a Gaussian distribution? Let
f(x)=1√
2πσ2exp/braceleftbigg[x−µ]2
2σ2/bracerightbigg
. (C.32)
Then we ﬁnd the Fourier transform
F(α)=exp{iαµ−α2σ2/2} (C.33)

<<<PAGE 713>>>

Appendix C Convolutions and cumulants 681
so that
logF(α)=iαµ−α2σ2/2 (C.34)
and so
C0=0, C1=µ, C2=σ2, (C.35)
and all higher Cnare zero. A Gaussian distribution is characterized by the fact that is has only two
nontrivial cumulants, the mean and the variance.

<<<PAGE 714>>>



<<<PAGE 715>>>

References
Abel, N. H. (1826), ‘Untersuchung der Functionen zweier unabh¨ angig ver¨ anderlichen
Gr¨oszen xundy,w i e f(x,y), welche die Eigenschaft haben, dasz f[z,f(x,y)] eine
symmetrische Function von z,xundyist.’, J. Reine u. angew. Math. (Crelle’s Journal) ,1,
11–15.
First known instance of the associativity functional equation.
Acz´el, J. (1966), Lectures on Functional Equations and their Applications , Academic Press,
New York.
Acz´el, J. (1987), A Short Course on Functional Equations , D. Reidel, Dordrecht.
Aitken, G. A. (1892), The Life and Works of John Arbuthnot , Clarendon Press, Oxford.
Akaike, H. (1980), ‘The interpretation of improper prior distributions as limits of data dependent
proper prior distributions’, J. Roy. Stat. Soc. B42, 46–52.
A failed attempt to deal with the marginalization paradox, which never perceives that the paradox is just as
present for proper priors as for improper ones, as discussed in Chapter 15.
Andrews, D. R. & Mallows, C. L. (1974), ‘Scale mixtures of normal distributions’, J. Roy. Stat. Soc.
B3 6 , 99–102.
Anscombe, F. J. (1963), ‘Sequential medical trials’, JASA 58, 365.
Declares that the sequential analysis of Armitage (1960) is ‘a hoax’.
Arbuthnot, J. (1710), ‘An argument for Divine Providence’, Phil. Trans. Roy. Soc. 27, pp. 186–190.
Reprinted in Kendall & Plackett (1977), V ol. 2, pp. 30–34. First known example of rejection of a statistical
hypothesis on grounds of the improbability of the data, discussed in Chapter 5. John Arbuthnot
(1667–1735) was physician to Queen Anne and a proliﬁc writer on many topics. Biographical informationon Arbuthnot is given in Aitken (1892).
Armitage, P. (1960), Sequential Medical Trials , Thomas, Springﬁeld, Illinois; 2nd edn, Blackwell,
Oxford (1975).
One of the main origins of the ‘optional stopping’ controversy. See L. J. Savage (1962) and Anscombe
(1963) for extensive discussions.
Barnard, G. A. (1947), ‘Signiﬁcance test for 2 ×2 tables’, Biometrika 34, 123–137.
Barnard, G. A. (1983), ‘Pivotal inference and the conditional view of robustness (why have we for
so long managed with normality assumptions?)’, in Box, G. E. P., Leonard, T. & Wu, C-F.,eds. (1983), Scientiﬁc Inference, Data Analysis, and Robustness , Academic Press Inc.,
Orlando, FL.
Expresses somewhat the same surprise at the success of the normal distribution as Augustus de Morgan did
145 years earlier. We try to explain this in Chapter 7.
Bayes, Rev. T. (1763), ‘An essay toward solving a problem in the doctrine of chances’, Phil. Trans.
Roy. Soc. , pp. 370–418.
Photographic reproduction in Molina (1963). Reprint with biographical note by G. A. Barnard in
Biometrika 45, 293–313 (1958) and in Pearson & Kendall (1970). The date is slightly ambiguous; this
work was read before the Royal Society in 1763, but not actually published until 1764. Furtherbiographical information on Thomas Bayes (1702–61) is given by Holland (1962). Stigler (1983) and
683

<<<PAGE 716>>>

684 References
Zabell (1989) present evidence that Bayes may have found his result and communicated it to friends as
early as 1748, in response to a challenge from David Hume (1711–76).
Bean, W. B. (1950), Aphorisms from the Bedside Teaching and Writings of Sir William Osler,
(1849–1919). Henry Schumann, New York.
Osler perceived the reasoning format of medical diagnosis in a form essentially identical with that given
later by George P´ olya. This was taken up by L. Lusted (1968) as the basis for Bayesian medical diagnosis
computer programs.
Bell, E. T. (1937) Men and Mathematics , Dover Publications, Inc., New York.
One needs to read this collection of biographical sketches because no substitute for it seems to exist;
but let the reader be aware that Eric Temple Bell was also a well-known science ﬁction writer (under thepseudonym of John Taine), and this talent was not lost here. We can probably trust the accuracy of the names,dates, and documentable historical facts cited. But the interpretive statements tell us very little about thematter under discussion; they tell us a great deal about the fantasies and socio-political views of the writer,and the level of his comprehension of technical facts. For example (p. 167) he endorses , on the grounds of
‘social justice’ the beheading of Lavoisier, the father of modern chemical nomenclature. He makes blatantlyfalse accusations against Laplace, and, equally falsely, portrays Boole as a saint who could do no wrong.He displays (p. 256) a ridiculous misconception of the nature of Einstein’s work, getting the sequenceof facts backward, and tells us (p. 459) that Archimedes never cared for applications of mathematics!
Bellman, R. & Kalaba, R. (1956), ‘On the principle of invariant imbedding and propagation through
inhomogeneous media’, Proc. Natl Acad. Sci. USA 42, 629–632.
Bellman, R. & Kalaba, R. (1957), ‘On the role of dynamic programming in statistical
communication theory’, IRE Trans. PGIT-1 , 197.
Bellman, R., Kalaba, R. & Wing, G. M. (1957), ‘On the principle of invariant imbedding and
one-dimensional neutron multiplication’, Proc. Natl Acad. Sci. 43, 517–520.
Berger, J. O. (1985), Statistical Decision Theory and Bayesian Analysis , Springer-Verlag, New York.
Berger, J. O. & Wolpert, R. L. (1988), The Likelihood Principle , 2nd edn, Institute of Mathematical
Statistics, Hayward, CA.
Bernardo, J. M. (1980), ‘A Bayesian analysis of classical hypothesis testing’, in Bernardo, J. M.
et al. , eds., Bayesian Statistics , University Press, Valencia, Spain, pp. 606–47.
With discussion.
Bernoulli, D. (1738), ‘Specimen theoriae novae de mensura sortis’, in Bernoulli, D. (1730–1),
Comment Acad. Sci. Imp. Petropolitanae ,V, pp. 175–192; English translation by Sommer, L.
(1954) Econometrica 22, 23–36.
Bernoulli, D. (1777), Mem. St Petersburg Acad., Acta Acad. Petrop. , pp. 3–33; English translation,
‘The most probable choice between several discrepant observations’, Biometrika ,45, 1–18
(1961).
Reprinted in Pearson & Kendall (1970), pp. 157–167. Questions taking the mean of several observations;
discussed in Chapter 7.
Bernoulli, J. (1713), Ars Conjectandi , Thurnisiorum, Basel.
Reprinted in Die Werke von Jakob Bernoulli , V ol. 3, Birkhaeuser, Basel (1975), pp. 107–286. First modern
limit theorem. English translation of part IV (with the limit theorem) by Bing Sung, Harvard University
Dept of Statistics Technical Report #2, 1966.
Bertrand, J. L. (1889), Calcul des Probabilit ´es, Gauthier-Villars, Paris; 2nd edn, 1907; reprinted
(1972) by Chelsea Publishing Co., New York.
This work is usually cited only for the ‘Bertrand Paradox’ which appears on pp. 4–5; however, it is full of
neat, concise mathematics as well as good conceptual insight, both of which are often superior to the
presentations in recent works. Bertrand understood clearly how much our conclusions from given data must
depend on prior information, an understanding that was lost in the later ‘orthodox’ literature. We quote him
on this at the end of Chapter 6. However, we disapprove of his criticism of the Herschel–Maxwell
derivation of the Gaussian distribution that we give in Chapter 7; what he saw as a defect is what weconsider its greatest merit, and a forerunner of Einstein’s reasoning. Well worth knowing and reviving
today.
Birnbaum, A. (1962), ‘On the foundation of statistical inference (with discussion)’, J. Am. Stat.
Assoc. 57, 269–326.
The ﬁrst proof of the ‘likelihood principle’ to be accepted by anti-Bayesians.

<<<PAGE 717>>>

References 685
Blackman, R. B. & Tukey, J. W. (1958), The Measurement of Power Spectra , Dover Publications,
Inc., New York.
Periodograms mutilated by ad hoc smoothing, which wipes out much of the useful information in them.
We warn against this in several places.
Bloomﬁeld, P. (1976), Fourier Analysis of Time Series: An Introduction , J. Wiley & Sons, New York.
Blackman–Tukey methods carried to absurd extremes (some 50 db below the noise level!) on alleged
astronomical data on variable stars from Whittaker & Robinson (1924), which Bloomﬁeld fails to
recognize as faked (he sees no difﬁculty in the implied claim that an unidentiﬁed observatory had clearskies on 600 successive midnights and is untroubled by the fact that the authors give no reference to thesource of the alleged data). As a result, his periodogram is giving zero information about variable stars; its
top displays the two sine waves put into the simulated data, its bottom reveals only the spectrum of thedigitizing errors. A potent demonstration of the folly of blind, unthinking application of a statistical
procedure where it does not apply. A Bayesian would not be able to make such errors, because he would
be obliged to think about his prior information concerning the phenomenon and the data-taking procedure.
Boltzmann, L. W. (1871), Wiener Berichte 63, pp. 397–418, 679–711, 712–732.
First appearance of ‘ plog(p)’ type entropy expressions in these three articles.
Boole, G. (1854), An Investigation of The Laws of Thought , Macmillan, London; reprinted by Dover
Publications, Inc., New York (1958).
Boole, G. (1857), ‘On the application of the theory of probabilities to the question of the
combination of testimonies or judgments’, Edinburgh Phil. Trans. v, xxi.
Borel, E. (1909), ´Elements de la Th ´eorie des Probabilit ´es, Hermann et Fils, Paris.
Discusses the Bertrand paradox at some length and conjectures the correct solution, later found by group
invariance arguments.
Borel, E. (1924), ‘A propos d’un trait` e de probabiliti` es’,Rev. Philos. 98, 321–336.
Review of Keynes (1921). Reprinted in Kyburg & Smokler (1981). Borel, like Bertrand (1889), understood
very well how strongly probabilities must depend on our state of prior knowledge. It is a pity that neither
undertook to demonstrate the important consequences of this in realistic applications; they might haveaverted 50 years of false teaching by others.
Boring, E. G. (1955), ‘The present status of parapsychology’, Am. Sci. ,43, 108–16.
Concludes that the curious phenomenon to be studied is the behavior of parapsychologists. Points out that,
having observed any fact, attempts to prove that no natural explanation of it exists are logically impossible;one canot prove a universal negative (quantum theorists who deny the existence of causal explanations
please take note).
Bortkiewicz, L. V . (1898), Das Gesetz der Kleinen Zahlen , Teubner, Leipzig.
Contains his famous ﬁtting of the Poisson distribution to the number of German soldiers killed by the kick
of a horse in successive years.
Bortkiewicz, L. V . (1913), Die radioaktive Strahlung als Gegenstand
Warscheinlichkeitstheoretischer Untersuchungen , B. G. Teubner, Leipzig.
Box, G. E. P. (1962), ‘On the foundations of statistical inference: discussion’, J. Am. Stat. Assoc. 57,
(298), 311.
Box, G. E. P. & Tiao, G. C. (1973), Bayesian Inference in Statistical Analysis , Addison-Wesley,
Reading, MA.
G. E. P. Box is, like L. J. Savage, a curious anomaly in this ﬁeld; he was an assistant to R. A. Fisher and
married his daughter, but became a Bayesian in issues of inference while remaining a Fisherian in matters
of signiﬁcance tests, which he held to be outside the ambit of Bayesian methods. In Jaynes (1985) we arguethat, on the contrary, any rational signiﬁcance test requires the full Bayesian apparatus.
Box, J. F. (1978), R. A. Fisher: The Life of a Scientist , Wiley, New York.
Joan Fisher Box, being the youngest daughter of R. A. Fisher, gives many personal anecdotes that nobody
else could know, interspersed with accounts of the problems he worked on.
Bredin, J.-D. (1986), The Affair: The Case of Alfred Dreyfus , G. Braziller, New York.
A famous example of the psychological divergence phenomenon discussed in Chapter 5.
Bretthorst, G. L. (1988), Bayesian Spectrum Analysis and Parameter Estimation , Lecture Notes in
Statistics, V ol. 48, Springer-Verlag, Berlin.
A revised and expanded version of his 1987 Ph.D. Thesis. Important new developments in detrending in
econometrics, and spectrum analysis of nuclear magnetic resonance data.

<<<PAGE 718>>>

686 References
Buck, B. & Macaulay, V . A., eds. (1991), Maximum Entropy in Action , Clarendon Press, Oxford.
Eight lectures given at Oxford University, covering introductory notions and applications in magnetic
resonance, spectroscopy, plasma physics, X-ray crystallography, and thermodynamics. The best source todate for an introduction elementary enough to be useful to beginners; yet proceeding to enough technicaldetail to be useful to practicing scientists. Be warned that what is called ‘maximum entropy’ is in placesdistorted by ad hoc devices such as ‘windowing’ or ‘preﬁltering’ the data – a practice that we condemn
as destructive of some of the information in the data. Probability theory, correctly applied, is quite capable
of extracting all the relevant information from the raw, unmutilated data and does best, with the least totalcomputation, when it is allowed to do so freely.
Cantril, H. (1950), The ‘Why’ of Man’s Experience , Macmillan, New York.
Carnap, R. (1952), The Continuum of Inductive Methods , University of Chicago Press.
Chadwick, J. (1958), The Decipherment of Linear B , Cambridge University Press.
Cheeseman, P. (1988), ‘An inquiry into computer understanding’, Comput. Intell .4, 58–66.
See also the following 76 pages of discussion. This attempt to explain Bayesian principles to the artiﬁcial
intelligence community ran into incredible opposition from discussants who had no comprehension ofwhat the author was doing. The situation is desribed in Jaynes (1990b).
Chernoff, H. & Moses, L. E. (1959), Elementary Decision Theory , J. Wiley & Sons, Inc.,
New York.
When ﬁrst issued, this work was described as ‘the only textbook on statistics that is not 20 years behind the
times’. It is now about 40 years behind the times because the authors could not accept the notion of aprobability that is not a frequency, and so did not appreciate the fact that a straight Bayesian approach leads
to all the same results with an order of magnitude less formal machinery. Still, it is an interesting and
entertaining exposition of Wald’s original ideas, far easier to read than Wald (1950).
Copi, I. M. (1994), Introduction to Logic , 9th edn, Macmillan, New York.
Cournot, A. A. (1843), Exposition de la Theorie des Chances et des Probabilit ´es, L. Hachette, Paris.
Reprinted (1984) in Oeuvres Compl `etes, J. Vrin, Paris. One of the ﬁrst of the attacks against Laplace,
which were carried on by Ellis, Boole, Venn, E. T. Bell, and others to this day.
Cox, R. T. (1946), ‘Probability, frequency, and reasonable expectation’, Am. J. Phys .14, 1–13.
In our view, this article was the most important advance in the conceptual (as opposed to the purely
mathematical) formulation of probability theory since Laplace.
Cox, R. T. (1961), The Algebra of Probable Inference , Johns Hopkins University Press, Baltimore
MD.
An extension of Cox (1946), with additional results and more discussion. Reviewed by E. T. Jaynes, Am.
J. Phys. 31, 66 (1963).
Craig, J. (1699), Theologiae Christianae Principia Mathematica , Timothy Child, London.
Reprinted with commentary by Daniel Titus, Leipzig (1755). See also Stigler (1986a) for more comments.
Cram´ er, H. (1946), Mathematical Methods of Statistics , Princeton University Press.
This marks the heyday of supreme conﬁdence in conﬁdence intervals over Bayesian methods, asserted as
usual on purely ideological grounds, taking no note of the actual results that the two methods yield.Comments on it are in Appendix B and Jaynes (1976, 1986a).
Crick, F. (1988), What Mad Pursuit , Basic Books, Inc., New York.
A reminiscence of Crick’s life and work, full of important observations and advice about the conduct of
science in general, and fascinating technical details about his decisively important work in biology – most
of which occurred several years after the famous Crick–Watson discovery of the DNA structure. Almost
equally important, this is an antidote to Watson (1968; see this bibliography); we have here the other sideof the DNA double helix story as Crick recorded it in 1974, with a different recollection of events. From
our viewpoint, this work is valuable as a case history of important scientiﬁc discoveries made without helpof probabilistic inference in our mathematical form, but – at least in Crick’s mind – obeying its principlesstrictly, in the qualitative form given by P´ olya. We wish that theoretical physicists reasoned as well.
Crow, E. L., Davis, F. A. & Maxﬁeld, M. W. (1960), Statistics Manual , Dover Publications, Inc.,
New York.
Has many useful tables and graphs, but expounds straight orthodox methods, never thinking in terms of
information content, and therefore never perceiving their weakness in extracting information from the data.
We have some fun with it in Jaynes (1976).

<<<PAGE 719>>>

References 687
Dawid, A. P., Stone, M. & Zidek, J. V . (1973), ‘Marginalization paradoxes in Bayesian and
structural inference’, J. Roy Stat. Soc. B35, 189–233.
Discussed in Chapter 15.
Dawkins, R. (1987), The Blind Watchmaker , W. W. Norton & Co., New York.
An answer to the unceasing attacks on Darwin’s theory, by religious fundamentalists who do not understand
what Darwin’s theory is. Richard Dawkins, Professor of Zoology at Oxford University, goes patiently intomuch detail to explain, as did Charles Darwin 120 years earlier, why the facts of Nature can be accounted
for as the operation of natural law, with no need to invoke teleological purpose; and we agree entirely.
Unfortunately, Dawkins’ enthusiasm seem to outrun his logic; on the cover he claims that it also explains a
very different thing: ‘Why the evidence of evolution reveals a universe without design.’ We do not see how
any evidence could possibly do this; elementary logic warns us of the folly of trying to prove a universalnegative.
Dawkins’ struggle against fundamentalist religion has continued; in 1993 the Starbridge Lectureship of
Theology and Natural Science was established in the Faculty of Divinity of Cambridge University. Dawkins
wrote in the national press to deplore this and to stress the vacuity of theology contrasted with the value
of science. This prompted the Cambridge Nobel Laureate chemist Max Perutz to issue an unperceptive
rejoinder, saying: ‘Science teaches us the laws of nature, but religion commands us how we should live ....
Dr Dawkins does a disservice to the public perception of scientists by picturing them as the demolition squadof religious beliefs.’ It appears to us that Dawkins was deploring arbitrary systems of theology, rather thanethical teachings; these are very different things. Our own views on this are given at the end of Chapter 20.
de Finetti, B. (1937), ‘La prevision: ses lois logiques, ses sources subjectives’, Ann. Inst. H.
Poincar ´e,7, 1–68.
English translation: ‘Prevision, its logical laws, its subjective sources’, in Kyburg & Smokler (1981).
de Finetti, B. (1972), Probability, Induction and Statistics , John Wiley & Sons, New York.
de Finetti, B. (1974a), ‘Bayesianism’, Intern. Stat. Rev. 42, 117–130.
de Finetti, B. (1974b), Theory of Probability , 2 vols., J. Wiley & Sons, Inc., New York.
Adrian Smith’s English translation could not hide the wit and humor of this work. Bruno de Finetti was
having great fun writing it; but he could scarcely write two sentences without injecting some parentheticremark about a different topic, that suddenly popped into his mind, and this is followed faithfully in thetranslation. Full of interesting information that all serious students of the ﬁeld ought to know; but impossibleto summarize because of its chaotic disorganization. Discussion of any one topic may be scattered overa half-dozen different chapters without cross-references, so one may as well read the pages at random.
de Groot, M. H. (1970), Optimal Statistical Decisions , McGraw-Hill Book Co., New York.
de Groot, M. H. (1975), Probability and Statistics , Addison-Wesley Publishing Co., Reading, MA;
2nd edn. (1986).
This textbook is full of useful results, but represents an intermediate transitional phase between orthodox
statistics and modern Bayesian inference. Morrie de Groot (1931–1989), a Ph.D. student of the transitional
Bayesian L. J. Savage, saw clearly the technical superiority of Bayesian methods and was a regular
attendant and speaker at our twice-yearly NSF-NBER Bayesian Seminars; but he still retained theterminology, notation, and general absolutist mindset of orthodoxy. Thus he still speaks of ‘true
probabilities’ and ‘estimated probabilities’ as if the former had a real existence, and distinguishes sharplybetween ‘probability theory’ and ‘statistical inference’ as if they were different topics. This does not
prevent him from obtaining the standard useful results, often by continuing the orthodox habit of inventing
ad hoc devices instead of application of the rules of probability theory. (Our present relativist theory
recognizes that there is no such thing as an ‘absolute’ probability, because all probabilities express, and are
necessarily conditional on, the user’s state of information. This makes the general principles applicable
uniformly to all problems of inference, with no need for ad hockeries .) A biography and bibliography of
Morris de Groot may be found in Statistical Science ,v o l 6, pp. 4–14 (1991).
de Groot, M. H. & Goel, P. (1980), ‘Only normal distributions have linear posterior expectations in
linear regression’, J. Am. Stat. Assoc. 75, 895–900.
Still another connection of the kind ﬁrst found by Gauss (1809) and discussed in Chapter 7.
de Moivre, A. (1718), The Doctrine of Chances: or, A Method of Calculating the Probability of
Events in Play , W. Pearson, London; 2nd edn, Woodfall, London (1738); 3rd edn, Millar,
London (1756); reprinted by Chelsea Publishing Co., New York (1967).

<<<PAGE 720>>>

688 References
de Moivre, A. (1733), Approximatio ad Summam Terminorum Binomii (a+b)nin Seriem expansi ;
Photographic reproduction in Archibald, R. C., Isis8, 671–683, (1926).
de Morgan, A. (1838), An Essay on Probabilities , Longman & Co., London.
de Morgan, A. (1847), Formal Logic: or the Calculus of Inference Necessary and Probable , Taylor
& Watton, London.
An enthusiastic exposition of Laplace’s views.
de Morgan, A. (1872), A Budget of Paradoxes , 2 V ols, de Morgan, S., ed., London; 2nd edn,
Smith, D. E., ed. (1915).
Reprinted in one volume by Dover Publications, Inc. (1954). Augustus de Morgan (1806–1871) was a
mathematician and logician, at University College, London, from 1828 to 1866. He collected notes
concerning not only logic, but anomalies of logic; the latter are preserved in this delightful account of theactivities of circle-squarers, anti-Copernicans, anti-Newtonians, religious fanatics, numerologists, andother demented souls that abounded in 19th century England. It gives a vivid picture of the difﬁculties that
serious scholars had to overcome in order to make any forward progress in science. An inexhaustiblesupply of amusing anecdotes.
de Morgan, S. (1882), Memoir of Augustus de Morgan , Longman, Green, London.
Further biographical and anecdotal material on de Morgan.
Devinatz, A. (1968), Advanced Calculus , Holt, Rinehart and Winston, New York.
Dyson, F. J. (1958), ‘Review of Lighthill (1957)’, Phys. Today 11, 28.
Edwards, A. W. F. (1974), ‘The history of likelihood’, Int. Stat. Rev. 42, 9–15.
Edwards, A. W. F. (1991), Nature Aug. 1, p. 386.
Edwards, H. M. (1989), ‘Kronecker’s philosophical views’, in Rowe, D. E. & McCleary, J., eds.,
The History of Modern Mathematics , V ol. 1, pp. 67–77.
Einstein, A. (1905a), ‘On the electrodynamics of moving bodies’, Ann. Phys. Leipzig 17,
891–921.
Einstein, A. (1905b), ‘Does the inertia of a body depend on its energy contend?’, Ann. Phys. Leipzig
18, 639–641.
Elias, P. (1958), ‘Two famous papers’, Editorial, IEEE Trans. IT-4,p .9 9 .
Ellis, R. L. (1842), ‘On the foundations of the theory of probability’, Camb. Phil. Soc. , vol. viii.
Ellis was the British counterpart of Cournot, in starting the anti-Laplace movement which set scientiﬁc
inference back a century.
Ellis, R. L. (1863), The Mathematical and Other Writings of Robert Leslie Ellis M. A. , Wm. Walton,
ed., Deighton, Bell, Cambridge.
Erickson, G. J. & Smith, C. R. (1988), eds., Maximum-Entropy and Bayesian Methods in Science
and Engineering ,Vol. 1, Foundations; Vol. 2, Applications , Kluwer Academic Publishers,
Dordrecht, Holland.
Euler, L. (1749), Recherches sur la Question des In ´egaliti ´es du Mouvement de Saturne et de Jupiter,
Sujet Propos ´e pour le Prix de l’Anne ´e 1748 pas l’Acad ´emie Royale des Sciences de Paris ;
reprinted in Leonhardi Euleri, Opera Omnia , ser. 2, V ol. 25, Turici, Basel, (1960).
Euler gave up at the problem of estimating eight unknown parameters from 75 discrepant observations, but
won the prize anyway.
Feinberg, S. E. & Hinkley, D. V . (1980), R. A. Fisher: An Appreciation , 2nd edn, Lecture Notes in
Statistics #1, Springer-Verlag, Berlin.
This is the second printing of the work, which appeared originally in 1979. A valuable source, if it is
regarded as an historical document rather than an account of present statistical principles. Rich in technicaldetails of Fisher’s most important derivations, it gives a large bibliography of his works, including fourbooks and 294 published articles. But in its adulation of Fisher it fails repeatedly to note something thatwas already well established in 1979: the simpler and uniﬁed methods of Jeffreys, which Fisher rejected
vehemently, actually accomplished everything that Fisher’s methods did, with the same or better results,and almost always more easily. In addition, they deal easily with technical difﬁculties (such as nuisance
parameters or lack of sufﬁcient statistics) which Fisher was never able to overcome. Thus this work tends
also to perpetuate harmful myths.
F´elix, L. (1960), The Modern Aspect of Mathematics , Basic Books, Inc., New York.
A Bourbakist view; for the contrary view, see Kline (1980).

<<<PAGE 721>>>

References 689
Feller, W. (1950), An Introduction to Probability Theory and its Applications , V ol. 1, J. Wiley &
Sons, New York; 2nd edn, 1957; 3rd edn, 1968.
Feller, W. (1966), An Introduction to Probability Theory and its Applications, Volume 2 ,J .W i l e y&
Sons, New York.
See also the second edition, 1971.
Fine, T. L. (1973), Theories of Probability , Academic Press, New York.
Fisher, R. A. (1922), ‘On mathematical foundations of theoretical statistics’, Phil. Trans. Roy. Soc.
Lond. Ser. A ,222, 309–368.
Introduction of the term ‘sufﬁcient statistic’.
Fisher, R. A. (1925), Statistical Methods for Research Workers , Oliver & Boyd, Edinburgh.
Twelve later editions followed.
Fisher, R. A. (1930b), The Genetical Theory of Natural Selection , Oxford University Press; 2nd
(rev) edn, Dover Publications, Inc., New York (1958).
Here Fisher shows that Mendelian genetics is not in conﬂict with Darwinian evolution theory, as
Mendelians supposed in the early 20th century; on the contrary, the ‘particulate’ or ‘discrete’ nature of
Mendelian inheritance clears up some outstanding difﬁculties with Darwin’s theory, resulting from the
assumption of blending inheritance, which most biologists – including Darwin himself – took for grantedin the 1860s. Recall that Mendel’s work, with its lore of dominant and recessive genes, etc., was later thanDarwin’s; but Darwin (1809–1882) never knew of it, and it was not generally known until after 1900. Thereinterpretation of Darwin’s theory in these terms, by Fisher and others, is now known as neo-Darwinism.By the time of Fisher’s second (1958) edition, the existence of mutations caused by radioactivity was wellestablished, those caused by failures of DNA replication had become highly plausible, and geneticrecombination (which had been suggested by August Weismann as early as 1886) was recognized as still
another mechanism to provide the individual variations on which natural selection feeds, but whose origin
was puzzling to Darwin. So Fisher added many new paragraphs, in smaller type, pointing out this newerunderstanding and its implications; how Darwin would have enjoyed seeing these beautiful solutions to his
problems! Fisher’s real, permanent contributions to science are in works like this, not in his statistical
teachings, which were an advance in the 1920s, but have been a retarding force since the 1939 work ofJeffreys.
Fisher, R. A. (1933), ‘Probability, likelihood and quantity of information in the logic of uncertain
inference’, Proc. Roy. Soc. 146, 1–8.
A famous attempt to demolish Jeffreys’ work, which we discuss in Chapter 16.
Fisher, R. A. (1934), ‘Two new properties of mathematical likelihood’, Proc. Roy. Soc. London A
144, 285–307.
Fisher, R. A. (1950), Contributions to Mathematical Statistics , W. A. Shewhart, ed., J. Wiley &
Sons, Inc., New York.
A collection of his best known early papers.
Fisher, R. A. (1956), Statistical Methods and Scientiﬁc Inference , Oliver & Boyd, London; second
revised edition, Hafner Publishing Co., New York (1959).
Fisher’s ﬁnal book on statistics, in which he tries to sum up his views of the logical nature of uncertain
inference. One discerns a considerable shift of position from his earlier works – he even admits,occasionally, that he had been wrong before. He is now more sympathetic toward the role of priorinformation, saying that recognizable subsets should be taken into account and that prior ignorance is
essential for the validity of ﬁducial estimation. He shows his old power of intuitive insight in his neat
explanation of G¨ odel’s theorem, but also some apparent lapses of memory and numerical errors. Every
serious student of the subject should read this work slowly and carefully at least twice, because the depth of
thinking is so great that Fisher’s meaning will not be grasped fully on a single reading. Also, Fisher goes
into several specialized topics that we do not discuss in the present work.
Fisher, R. A. (1962), ‘Some examples of Bayes’ method of the experimental determination of
probability a priori’, J. Roy. Stat. Soc. B2 4 , 118–124.
Fisher, R. A. (1974), Collected Papers of R. A. Fisher , J. H. Bennett, ed., University of Adelaide.
Fowler, R. H. (1929), Statistical Mechanics ;The Theory of the Properties of Matter in Equilibrium ,
Cambridge University Press.
Fraser, D. A. S. (1966), ‘On ﬁducial inference’, Ann. Math. Stat. 32, 661–676.

<<<PAGE 722>>>

690 References
Fraser, D. A. S. (1980), ‘Comments on a paper by B. Hill’, in J. M. Bernardo et al. , eds., Bayesian
Statistics , University Press, Valencia, Spain, pp. 56–58.
Claims to have a counter-example to the likelihood principle. But it is the same as the tumbling
tetrahedrons problem solved by Bayesian methods in Chapter 15; the correct solution to that problem was
not known in 1980.
Galilei, Galileo (1638), Dialogues Concerning Two New Sciences ; English translation by Henry
Crew & Alfonso de Salvio, MacMillan Company, London (1914).
Paperback reprint by Dover Publishing Co., New York, undated ( c1960).
Galton, F. (1886), ‘Family likeness in stature’, Proc. Roy. Soc. Lond. 40, 42–73.
Galton, F. (1908), Memories of My Life , Methuen, London.
More biographical and technical details are in Pearson (1914–1930).
Gardner, M. (1957), Fads and Fallacies in the Name of Science , Dover Publications, Inc., New York.
A kind of 20th century sequel to de Morgan (1872), with attention directed more to fakers in science than
to their colleagues in mathematics. Here we meet both the sincere but tragically misguided souls, and thedeliberate frauds out to make a dishonest dollar from the gullible.
Gardner, M. (1981), Science – Good, Bad, and Bogus , Paperbound edition (1989), Prometheus
Books, Buffalo NY; paperbound edn (1989).
A sequel to Gardner (1957), with a sobering message that everyone ought to note. Particular details on
several recent trends: the Creationist who utilizes TV to carry attacks on Darwin’s theory to millions, while
grossly misrepresenting what Darwin’s theory is; the ESP advocate who invades scientiﬁc meetings to tryto invoke quantum theory in his support, although he has no comprehension of what quantum theory is; the
Gee Whiz publicist who turns every tiny advance in knowledge (artiﬁcial intelligence, chaos, catastrophe
theory, fractals) into a revolutionary crusader cult; the professional disaster-monger who seeks personalpublicity through inventing ever more ridiculous dangers out of every activity of Man; and, mostfrightening of all, the eagerness with which the news media give instant support and free publicity to allthis. Today, our airwaves are saturated with bogus science and medieval superstitions belittling andmisrepresenting real, responsible science. In the Introduction, Gardner documents the indignant refusal ofnetwork executives to correct this, on grounds of its proﬁtability. Then at what point does persistent,deliberate abuse of freedom of speech for proﬁt become a clear and present danger to society? See alsoRothman (1989) and Huber (1992).
Gauss, K. F. (1809), Theoria Motus Corporum Celestium , Perthes, Hamburg; English translation,
Theory of the Motion of the Heavenly Bodies Moving About the Sun in Conic Sections , Dover
Publications, Inc., New York (1963).
Gauss, K. F. (1823), Theoria Combinationis Observationum Erroribus Minimis Obnoxiae ,
Dieterich, G¨ ottingen; Supplementum (1826).
Geisser, S. & Cornﬁeld, J. (1963), ‘Posterior distribution for multivariate normal parameters’,
J. Roy. Stat. Soc. B25, 368–376.
Gives the correct treatment of a problem which was later corrupted into the marginalization paradox, as
explained in Chapter 15, and more fully in Jaynes (1983, pp. 337–339, 374).
Geisser, S. (1980), ‘The contributions of Sir Harold Jeffreys to Bayesian inference’, in Zellner, A.,
ed.,Bayesian Analysis in Econometrics and Statistics , North-Holland Publishing Co.,
Amsterdam, pp. 13–20.
Gell-Mann, M. (1992) ‘Nature conformable to Herself’, Bull. Santa Fe Inst. 7, 7–10.
Some comments on the relationship between mathematics and physics; this Nobel Laureate theoretical
physicist is, like us, happy that the ‘plague of Bourbakism’ is ﬁnally disappearing, raising the hope thatmathematics and theoretical physics may become once more mutually helpful partners instead ofadversaries.
Gibbs, J. W. (1875), ‘On the equilibrium of heterogeneous substances’; reprinted in The Scientiﬁc
Papers of J. Willard Gibbs , V ol. I, Longmans, Green & Co. (1906), and Dover Publications,
Inc., New York (1961).
Gibbs, J. W. (1902), Elementary Principles in Statistical Mechanics , Yale University Press, New
Haven, Connecticut.
Reprinted in The Collected Works of J. Willard Gibbs , V ol. 2, by Longmans, Green & Co. (1928), and by
Dover Publications, Inc., New York (1960).
Glymour, C. (1985), ‘Independence assumptions and Bayesian updating’, Artiﬁcial Intell. 25, 25–99.

<<<PAGE 723>>>

References 691
Gnedenko, B. V . (1962), The Theory of Probability, Chelsea Publ. Co., New York, pp. 40–41.
G¨odel, K. (1931), ‘ ¨Uber formal unendscheidbare S¨ atze der Principia Mathematica und verwandter
Systeme I’, Monatshefte f ¨ur Math. & Phys. ,38, 173–198.
English translation, ‘On formally undecidable propositions of Principia Mathematica and related systems’,
Basic Books, Inc., New York (1962); reprinted by Dover Publications, Inc., New York (1992).
Goldman, S. (1953), Information Theory , Prentice-Hall, Inc., New York.
We would like to put in a friendly plug for this work, even though it has a weird reputation in the ﬁeld. The
author, in recounting the work of Norbert Wiener and Claude Shannon, explains it for the beneﬁt ofbeginners much more clearly than Wiener did, and somewhat more clearly than Shannon. Its weirdness isthe result of two unfortunate accidents: (1) a misspelled word in the title of Chapter 1 escaped both the
author and the publisher, providing material for dozens of cruel jokes circulating in the 1950s; (2) on p. 295there is a photograph of Gibbs, with the caption: ‘J. Willard Gibbs (1839–1903), whose ergodic hypothesis
is the forerunner of fundamental ideas in information theory.’ Since Gibbs never mentioned ergodicity,
this is a source of more jokes. However, the author is guilty only of trusting the veracity of Wiener
(1948).
Goldstein, H. (1980), Classical Mechanics , Addison-Wesley, Reading, MA.
Good, I. J. (1950), Probability and the Weighing of Evidence , C. Grifﬁn & Co., London.
A work whose importance is out of all proportion to its small size. Still required reading for every student
of scientiﬁc inference, and can be read in one evening.
Good, I. J. (1962), The Scientist Speculates , Heinemann Basic Books, New York.
Good, I. J. (1967), ‘The white shoe is a red herring’, Brit. J. Phil. Sci. 17, 322.
Reprinted in Good (1983). Points out the error in the Hempel paradox.
Good, I. J. (1980), ‘The contributions of Jeffreys to Bayesian statistics’, in A. Zellner, ed., Bayesian
Analysis in Econometrics and Statistics , North-Holland Pub. Co., Amsterdam.
Good, I. J. (1983), Good Thinking , University of Minnesota Press.
Reprints of 23 articles, scattered over many topics and many years, plus a long bibliography of other
works. There are about 2000 short articles like these by Good, found throughout the statistical andphilosophical literature starting in 1940. Workers in the ﬁeld generally granted that every idea in modern
statistics can be found expressed by him in one or more of these articles; but their sheer number made itimpossible to ﬁnd or cite them, and most are only one or two pages long, dashed off in an hour and neverdeveloped further. So, for many years, whatever one did in Bayesian statistics, one just conceded priority toJack Good by default, without attempting the literature search for the relevant article, which would haverequired days. Finally, this book provided a bibliography of most of the ﬁrst 1517 of these articles(presumably in the order of their writing, which is not the order of publication) with a long index, so it isnow possible to give proper acknowledgment of his works up to 1983. Be sure to read Chap. 15, where hepoints out speciﬁc, quantitative errors in Karl Popper’s work and demonstrates that Bayesian methods,which Popper rejects, actually correct those errors.
Gould, S. J. (1989), Wonderful Life: The Burgess Shale and the Nature of History , W. W. Norton &
Co., New York.
A tiny region in the Canadian Rockies had exactly the right geological history so that soft-bodied animals
were preserved almost perfectly. As a result, we now know that the variety of life existing in early
Cambrian time was vastly greater than had been supposed; this has profound implications for our view of
evolution. Gould seems fanatical in his insistence that ‘evolution’ is not synonomous with ‘progress’. Of
course, anyone familiar with the principles of physics and chemistry will agree at once that a process that
proceeded in one direction can also proceed in the opposite one. Nevertheless, it seems to us that at least99% of observed evolutionary change has in fact been in the direction of progress (more competent,
adaptable creatures). We also think that Darwinian theory, properly stated in terms conforming to presentbasic knowledge and present Bayesian principles of reasoning, predicts just this.
Graunt, J. (1662), Natural and Political Observations Made Upon the Bills of Mortality , Roycroft,
London.
Reprinted in Newman, J. R., ed. (1956), The World of Mathematics , V ol. 3, pp. 1420–1435, Simon &
Schuster, New York. First recognition of the useful facts that can be inferred from records of births and
deaths; the beginning of sociological inference, as distinguished from the mere collection of statistics. This
work is sometimes attributed instead to William Petty; for details, see Greenwood (1942).
Gray, C. G. & Gubbins, K. E. (1984), Theory of Molecular Fluids , Oxford University Press.

<<<PAGE 724>>>

692 References
Greenwood, Major (1942), ‘Medical statistics from Graunt to Farr’, Biometrika ,32, 203–225.
Part 2 of a three-part work. A lengthy but confusingly disorganized account of John Graunt (1620–74),
William Petty (1623–87), and Edmund Halley (1656–1742) in the matter of the ﬁrst mortality tables. Petty(a friend of Graunt and one of those restless but undisciplined minds, which dabbles for a short time inpractically everything but never really masters anything) attempted to make a survey of Ireland many yearsbefore Halley, but did not reason carefully enough to produce a meaningful result. Greenwood ends in utterconfusion over whether Petty is or is not the real author of Graunt’s book, apparently unaware that Petty’sconnection is that he edited the ﬁfth (posthumous) edition of Graunt’s work; and it was Petty’s edition thatHalley referred to and saw how to correct. All this had been explained long before, with amusing sarcasm,by Augustus de Morgan (1872, V ol. I, pp. 113–115).
Grosser, M. (1979), The Discovery of Neptune , Dover Publications, Inc., New York.
Haldane, J. B. S. (1932), Proc. Camb. Phil. Soc. 28, 58.
Improper priors advocated and used. Harold Jeffreys (1939) acknowledges this as the source of some of his
own ideas on them.
Halley, E. (1693), ‘An estimate of the degrees of mortality of mankind’, Phil. Trans. Roy. Soc. 17,
596–610, 654–656.
Reprinted in Newman, J. R., ed., The World of Mathematics , Simon & Schuster, New York (1956), V ol. 3,
pp. 1436–1447. First mortality table, based on records of births and deaths in Breslau, 1687–1691. See alsoGreenwood (1942).
Hamilton, A. G. (1988), Logic for Mathematicians , revised 2nd edn, Cambridge University Press.
Hansel, C. E. M. (1980), ESP and Parapsychology – A Critical Re-evaluation , Prometheus Books,
Buffalo, NY , Chap. 12.
Hardy, G. H. (1911), ‘Theorems connected with MacLearin’s test for the convergence of series’,
Proc. Lond. Math. Soc. 9, (2), 126–144.
Harr, A. (1933), ‘Der Massbegriff in der Theorie der Kontinuierlichen Gruppen’, Ann. Math. Stat.
34, 147–169.
Hartigan, J. (1964), ‘Invariant prior distributons’, Ann. Math. Stat. 35, 836–845.
Hedges, L. V . & Olkin, I. (1985), Statistical Methods for Meta-Analysis , Academic Press, Inc.,
Orlando, FL.
Helmholtz, H. von (1868), ‘Ueber discontinuirliche ﬂussigkeitsbewegungen’, Monatsberichte
d. Konigl. akademie der wissenschaften zu Berlin.
Hempel, C. G. (1967), Brit. J. Phil. Sci. 18, 239–240.
Reply to Good (1967).
Herschel, J. (1850), Edinburgh Rev. 92, 14.
A two-dimensional ‘Maxwellian velocity distribution’ before Maxwell (1860).
Hill, B. M. (1980), ‘On some statistical paradoxes and nonconglomerability’, in Bernardo, J. M.
et al. , eds., Bayesian Statistics , University Press, Valencia.
Holland, J. D. (1962), ‘The Reverend Thomas Bayes F.R.S. (1702–1761)’, J. Roy. Stat. Soc. (A) ,
125, 451–461.
Howson, C. & Urbach, P. (1989), Scientiﬁc Reasoning: The Bayesian Approach , Open Court
Publishing Co., La Salle, Illinois.
A curiously outdated work, which might have served a useful purpose 60 years earlier. Mostly a rehash of
all the false starts of philosophers in the past, while offering no new insight into them and ignoring the
modern developments by scientists, engineers, and economists which have made them obsolete. What little
positive Bayesian material there is represents a level of understanding that Harold Jeffreys had surpassed50 years earlier, minus the mathematics needed to apply it. They persist in the pre-Jeffreys notation, which
fails to indicate the prior information in a probability symbol, take no note of nuisance parameters, and
solve no problems.
Howson, C. & Urbach, P. (1991), ‘Bayesian reasoning in science’, Nature 350, 371–374.
An advertisement for Howson and Urbach (1989), with the same shortcomings. Since they expound
Bayesian principles as they existed 60 years earlier, it is appropriate that Anthony Edwards responded
(Nature 352, 386–387) with the standard counter-arguments given by his teacher, R. A. Fisher, 60 years
earlier. But to those actively engaged in actually using Bayesian methods in the real problems of science
today, this exchange seems like arguing over two different systems of epicycles.

<<<PAGE 725>>>

References 693
Hoyt, W. G. (1980), Planets X and Pluto , University of Arizona Press, Tucson.
Huber, P. J. (1981), Robust Statistics , J. Wiley & Sons, Inc., New York.
Huber, P. J. (1992), Galileo’s Revenge: Junk Science in the Courtroom , Basic Books, Inc., NY .
Documents the devastating effects now being produced by charlatans and crackpots posing as scientists.
They are paid to give ‘expert’ testimony that claims all sorts of weird causal relations that do not exist, in
support of lawsuits that waste billions of dollars for consumers and businesses. The phenomena ofpro-causal and anti-causal bias are discussed in Chapters 5, 16 and 17. At present we seem to have no
effective way to counteract this; as noted by Gardner (1981), the news media will always raise a great wind
of publicity, giving support and encouragement to the charlatans, while denying responsible scientists a
hearing to present the real facts. It appears that the issue of what is and what is not valid scientiﬁc inference
must soon move out of academia and become a matter of legislation – a prospect even more frightening
than the present abuses.
Hume, D. (1739), A Treatise of Human Nature , London; as revised by P. H. Nidditch, Clarendon
Press, Oxford (1978).
Hume, D. (1777), An Inquiry Concerning Human Understanding , Clarendon Press, Oxford.
Jaynes, E. T. (1956), ‘Probability theory in science and engineering’, no. 4 in Colloquium Lectures
in Pure and Applied Science , Socony-Mobil Oil Co., USA.
Jaynes, E. T. (1957a), ‘Information theory and statistical mechanics’, Phys. Rev. 106, 620–630; 108,
pp. 171–190.
Reprinted in Jaynes (1983).
Jaynes, E. T. (1957b), ‘How does the brain do plausible reasoning?’, Stanford University Microwave
Laboratory Report 421.
Reprinted in Erickson & Smith (1988), V ol. 1, pp. 1–23.
Jaynes, E. T. (1963a), ‘New engineering applications of information theory’, in Bogdanoff, J. L. &
Kozin, F., eds., Engineering Uses of Random Function Theory and Probability ,J .W i l e y&
Sons, Inc., NY , pp. 163–203.
Jaynes, E. T. (1963b), ‘Information theory and statistical mechanics’, in K. W. Ford, ed., Statistical
Physics , W. A. Benjamin, Inc., New York, pp. 181–218.
Reprinted in Jaynes (1983).
Jaynes, E. T. (1963c), ‘Comments on an article by Ulric Neisser’, Science 140, 216.
An exchange of views on the interaction of men and machines.
Jaynes, E. T. (1965), ‘Gibbs vs. Boltzmann entropies’, Am. J. Phys. 33, 391.
Reprinted in Jaynes (1983).
Jaynes, E. T. (1967), ‘Foundations of probability theory and statistical mechanics’, in Bunge, M.
(ed.), Delaware Seminar in Foundations of Physics , Springer-Verlag, Berlin.
Reprinted in Jaynes (1983).
Jaynes, E. T. (1968), ‘Prior probabilities’, IEEE Trans. Systems Science and Cybernetics ,SSC-4 ,
227–241.
Reprinted in Tummala, V . M. Rao and Henshaw, R. C., eds., Concepts and Applications of Modern
Decision Models , Michigan State University Business Studies Series (1976); and in Jaynes (1983).
Jaynes, E. T. (1976), ‘Conﬁdence intervals vs Bayesian intervals’, in W. L. Harper & C. A. Hooker,
eds., Foundations of Probability Theory, Statistical Inference, and Statistical Theories of
Science , vol. II, Reidel Publishing Co., Dordrecht, Holland, pp. 175–257.
Reprinted in Jaynes (1983).
Jaynes, E. T. (1978) ‘Where do we stand on maximum entropy?’, in Levine, R. D. and Tribus, M.,
eds., The Maximum Entropy Formalism , M.I.T. Press, Cambridge MA, pp. 15–118.
Reprinted in Jaynes (1983).
Jaynes, E. T. (1980), ‘Marginalization and prior probabilities’, in Zellner, A., ed., Bayesian Analysis
in Econometrics and Statistics , North-Holland Publishing Co., Amsterdam.
Reprinted in Jaynes (1983).
Jaynes, E. T. (1983), in Rosenkrantz, R. D., ed., Papers on Probability, Statistics, and Statistical
Physics , D. Reidel Publishing Co., Dordrecht, Holland; second paperbound edition, Kluwer
Academic Publishers (1989).
Reprints of 13 papers dated 1957–1980.

<<<PAGE 726>>>

694 References
Jaynes, E. T. (1984), ‘The intuitive inadequacy of classical statistics’, Epistemologia, Special Issue
on Probability, Statistics, and Inductive Logic VII, 43–73.
With discussion.
Jaynes, E. T. (1985), ‘Highly informative priors’, in Bernardo, et al. , eds., Bayesian Statistics 2 ,
Elsevier Science Publishers, North-Holland, pp. 329–360.
With discussion. An historical survey, followed by a worked-out example (seasonal adjustment in
econometrics) showing how much prior information can affect our ﬁnal conclusions in a way that cannot
even be stated in the language of orthodox statistical theory, because it does not admit the concept of
correlations in a posterior distribution function.
Jaynes, E. T. (1986a), ‘Bayesian methods: general background’, in Justice, J. H., ed., Maximum
Entropy and Bayesian Methods in Geophysical Inverse Problems , Cambridge University
Press.
A general, non-technical introductory tutorial for beginners, intended to explain the terminology and
viewpoint, and warn of common pitfalls of misunderstanding and communication difﬁculties.
Jaynes, E. T. (1986b), ‘Monkeys, kangaroos, and N’, in Justice, J. H., ed., Maximum Entropy and
Bayesian Methods in Geophysical Inverse Problems , Cambridge University Press.
Preliminary exploration of deeper hypothesis spaces in image reconstruction, with Dirichlet priors.
Jaynes, E. T. (1986c), ‘Predictive statistical mechanics’, in Moore, G. T. and Scully , M. O., eds.,
Frontiers of Nonequilibrium Statistical Physics , Plenum Press, NY , pp. 33–55.
Jaynes, E. T. (1987), ‘Bayesian spectrum and chirp analysis’, in Smith, R. C. & Erickson, G. J., eds.,
Maximum Entropy and Bayesian Spectral Analysis and Estimation Problems , D. Reidel,
Dordrecht-Holland, pp. 1–37.
A reply to Tukey (1984; see the bibliography), carried much further by Bretthorst (1988).
Jaynes, E. T. (1989), ‘Clearing up mysteries – the original goal’, in Skilling, J., ed., Maximum
Entropy and Bayesian Methods , Kluwer Publishing Co., Holland, pp. 1–27.
This contains what we think is the ﬁrst application of Bayes’ theorem to kinetic theory, the ﬁrst recognition
of hidden assumptions in Bell’s theorem, and the ﬁrst quantitative application of the second law ofthermodynamics to biology.
Jaynes, E. T. (1990a), ‘Probability in quantum theory’, in Zurek, W. H., ed. Complexity, Entropy and
the Physics of Information , Addison-Wesley Pub. Co., Redwood City, CA, pp. 381–404.
Use of probability theory as logic makes the meaning of quantum theory appear very different, and hints at
possible future resolution of its conceptual difﬁculties.
Jaynes, E. T. (1990b), ‘Probability theory as logic’, in Foug` ere, P., ed., Proceedings of the Ninth
Annual Workshop on Maximum Entropy and Bayesian Methods , Kluwer Publishers, Holland.
Shows by a nontrivial example that conditional probabilities need not express any causal inﬂuence of the
Popper type – a fact highly relevant to the hidden assumptions in the Bell theorem, discussed in Jaynes
(1989).
Jaynes, E. T. (1992), ‘Commentary on two articles by C. A. Los’, Computers & Math. Appl. 24,
267–273.
This astonishing economist condemns not only our Bayesian analysis, but virtually every useful thing ever
done in data analysis, going back to Gauss.
Jefferson, T. (1781), Notes on Virginia ; reprinted in Koch, A. & Peden, W. (eds.), The Life and
Selected Writings of Thomas Jefferson , The Modern Library, New York (1944).
Reprinted 1972 by Random House, Inc.
Jeffrey, R. C. (1983), The Logic of Decision , 2nd edn, University of Chicago Press.
Attempts to modify Bayes’ theorem in an ad hoc way; as discussed in Chapter 5, this necessarily violates
one of our desiderata.
Jeffreys, H. (1931), Scientiﬁc Inference , Cambridge University Press; later editions, 1937, 1957,
1973.
Be sure to read his introductory section with a Galilean dialogue showing how induction is actually used in
science.
Jeffreys, H. (1932), ‘On the theory of errors and least squares’, Proc. Roy. Soc. 138, 48–55.
A beautiful derivation of the d σ/σ prior expressing complete ignorance of a scale parameter, ﬁercely
attacked by Fisher (1933) and discussed in Chapters 7 and 16.

<<<PAGE 727>>>

References 695
Jeffreys, H. (1939), Theory of Probability , Clarendon Press, Oxford; later editions, 1948, 1961,
1967, 1988.
Appreciated in our Preface.
Jeffreys, H. & Jeffreys, Lady Bertha Swirles (1946), Methods of Mathematical Physics , Cambridge
University Press.
Jevons, W. S. (1874), The Principles of Science: A Treatise on Logic and Scientiﬁc Method , 2 vols.,
Macmillan, London.
Reprinted by Dover Publications, Inc., NY (1958). Jevons was a student of de Morgan, and also expounds
the Laplacean viewpoint; for this both Jevons and de Morgan came under attack from Venn and others inwhat Zabell (1989) calls ‘The Great Jevonian Controversy’.
Johnson, R. W. (1985), ‘Independence and Bayesian updating methods’, U. S. Naval Research
Laboratory Memorandum Report 5689, November 1985.
Johnson, W. E. (1924), Logic, Part III: The Logical Foundations of Science , Cambridge University
Press; reprinted by Dover Publications, Inc., NY (1964).
Johnson, W. E. (1932), ‘Probability, the deduction and induction problem’, Mind 44,
409–413.
Justice, J. H. (1986), ed., Maximum Entropy and Bayesian Methods in Geophysical Inverse
Problems , Cambridge University Press.
Proceedings of the fourth annual ‘Maximum Entropy Workshop’, held in Calgary in August 1984.
Kac, M. (1956), ‘Some stochastic problems in physics and mathematics’, Field Research Laboratory.
Magnolia Petroleum Co., Dallas, Colloquium Lectures in Pure and Applied Science no. 2.
Kadane, J. B., Schervish, M. J. & Seidenfeld, T. (1986), ‘Statistical implications of ﬁnitely additive
probability’, in Goel, P. K. & Zellner, A., eds., Bayesian Inference and Decision Techniques ,
Elsevier Science Publishers, Amsterdam.
The ‘KSS’ work discussed at length in Chapter 15.
Kahneman, D. & Tversky, A. (1972), ‘Subjective probability: a judgment of representativeness’,
Cog. Psychol. 3, 430–454.
See also Tversky & Kahneman (1981).
Kempthorne, O. & Folks, L. (1971), Probability, Statistics and Data Analysis , Iowa State University
Press.
Kendall, M. G. (1963), ‘Ronald Aylmer Fisher, 1890–1962’, Biometrika 50, 1–15.
Reprinted in Pearson and Kendall (1970). Like the previous reference, this tells us more about the author
than the subject.
Kendall, M. G. & Moran, P. A. P. (1963), Geometrical Probability , Grifﬁn, London.
Much useful mathematical material, all of which is readily adapted to Bayesian pursuits.
Kendall, M. G. & Plackett, R. L. (1977), Studies in the History of Statistics and Probability , 2 vols,
Grifﬁn, London.
Kendall, M. G. & Stuart, A. (1961), The Advanced Theory of Statistics :Volume 2, Inference and
Relationship , Hafner Publishing Co., New York.
This represents the beginning of the end for the conﬁdence interval; whereas the authors continued to
endorse it on grounds of ‘objectivity’, they noted so many resulting absurdities that readers of this workwere afraid to use conﬁdence intervals thereafter. In Jaynes (1976) we explained the source of thedifﬁculty and showed that these absurd results are corrected automatically by use of Bayesian
methods.
Kendall, M. G. & Stuart, A. (1977), The Advanced Theory of Statistics: Volume 1, Distribution
Theory , Macmillan, New York.
Kennard, E. H. (1938), Kinetic Theory of Gases , McGraw-Hill Book Co., NY .
Keynes, J. M. (1921), A Treatise on Probability , Macmillan, London; reprinted by Harper & Row,
New York (1962).
The ﬁrst clear explanation of the distinction between logical independence and causal independence.
Important today because it served historically as the inspiration for the work of R. T. Cox. For an
interesting review of Keynes, see Borel (1924).
Keynes, J. M. (1936), Allgemeine theorie der beschuftigung, des Zinses und des Geldes ,v o n
Duncker & Humblot, Munchen, Leipzig.

<<<PAGE 728>>>

696 References
Khinchin, A. I. (1957), Mathematical Foundations of Information Theory , Dover Publications, Inc.,
New York.
Attempts of a mathematician to ‘rigorize’ Shannon’s work. But we do not think it was in need of this. In
any event, when one tries to work directly on inﬁnite sets from the beginning, the resulting theorems just
do not refer to anything in the real world. Khinchin was probably careful enough to avoid actual error and
thus produced theorems valid in his imaginary world; but we note in Chapter 15 some of the horrors that
have been produced by others who tried to do mathematics this way.
Kline, M. (1980), Mathematics: The Loss of Certainty , Oxford University Press.
A fairly complete history, recalling hundreds of interesting anecdotes, but expressing views very different
from the Bourbakist ones of F´ elix (1960).
Kolmogorov, A. N. (1933), Grundbegriffe der Wahrscheinlichkeitsrechnung , Ergebnisse der Math.
(2), Berlin; English translation, Foundations of the Theory of Probability , Chelsea Publishing
Co., New York (1950).
Described in Appendix A.
Koopman, B. O. (1936), ‘On distributions admitting a sufﬁcient statistic’, Trans. Am. Math. Soc. 39,
399–509.
Proof that the NASC for existence of a sufﬁcient statistic is that the sampling distribution have the
exponential form, later recognized as identical with what maximum entropy generates automatically.Simultaneous with Pitman (1936).
Kronecker, L. (1901), Vorlesungen ¨uber Zahlentheorie , Teubner, Leipzig; republished by
Springer-Verlag, 1978.
Kullback, S. & Leibler, R. A. (1951), ‘On information and sufﬁciency’, Ann. Math. Stat .22, 79–86.
Kurtz, P. (1985), A Skeptic’s Handbook of Parapsychology , Prometheus Books, Buffalo, NY .
Several chapters have relevant material; see particularly Chap. 11 by Betty Markwick.
Kyburg, H. E. & Smokler, H. E. (1981) Studies in Subjective Probability , 2nd edn, J. Wiley & Sons,
Inc., New York.
Lancaster, H. O. (1969), The Chi-squared Distribution , J. Wiley & Sons, Inc., New York.
Lane, D. A. (1980), ‘Fisher, Jeffreys, and the nature of probability’, in Fienberg, S., et al., eds., R. A.
Fisher, an Appreciation , Springer-Verlag, New York, pp. 148–160.
Laplace, P. S. (1774), ‘M´ emoire sur la probabilit´ e des causes par les ´ ev`enemens’, Mem. Acad. Roy.
Sci.6, 621–656.
Reprinted in Laplace (1878–1912), vol. 8, pp. 27–65; English translation by Stigler (1986b).
Laplace, P. S. (1781), ‘Memoire sur les probabilit´ es’,Mem. Acad. Roy. Sci. (Paris) .
Reprinted in Laplace (1878–1912), vol. 9, pp. 384–485. An early exposition of the properties of the
‘Gaussian’ distribution. Suggests that it is so important that it should be tabulated.
Laplace, P. S. (1810), ‘M´ emoire sur les approximations des formules qui sont fonctions de tr` es
grands nombres et sur leur application aux probabilit´ es,’Mem. Acad. Sci. Paris , 1809,
pp. 353–415, 559–565.
Reprinted in Laplace (1878–1912), vol. 12, pp. 301–353. A massive compendium of the origin, properties,
and uses of the Gaussian distribution.
Laplace, P. S. (1812), Th´eorie Analytique des Probabilit ´es, 2 vols., Courcier Imprimeur, Paris; 3rd
edition with supplements, 1820.
Reprinted in Laplace (1878–1912), V ol. 7. Reprints of this rare but very important work and the following
one are available from: Editions Culture et Civilisation, 115 Ave. Gabriel Lebron, 1160 Brussels, Belgium.
Laplace, P. S. (1814, 1819), Essai Philosophique sur les Probabilit ´es, Courcier Imprimeur, Paris.
Reprinted in Oeuvres Compl `etes de Laplace , V ol. 7, Gauthier-Villars, Paris, 1886; available from Editions
Culture et Civilisation, 115 Ave. Gabriel Lebron, 1160 Brussels, Belgium. English translation byF. W. Truscott & F. L. Emory, Dover Publications, Inc., New York (1951). Be warned that this ‘translation’
is little more than a literal transcription , which distorts Laplace’s meaning on many points. It is essential
to check the original French version before accepting any interpretive statement in this work.
Laplace, P. S. (1878–1912), Oeuvres Compl `etes, 14 vols., Gauthier-Villars, Paris.
Lee, Y . W. (1960), Statistical Theory of Communication , J. Wiley & Sons, New York.
The usable but watered-down pedagogical work that grew out of Wiener (1949). Masses of well-explained
examples, but none of the mathematical techniques such as the Paley–Wiener factorization or functional

<<<PAGE 729>>>

References 697
integration over Wiener measure, that were used in the original. Greatly extends the folklore about Gibbs
that started in Wiener (1948). Reviewed by E. T. Jaynes, Am. J. Phys. 29, 276 (1961).
Lehmann, E. L. (1959), Testing Statistical Hypotheses , Wiley, New York; 2nd edn, 1986.
Lighthill, M. J. (1957), Introduction to Fourier Analysis and Generalised Functions , Cambridge
University Press.
Required reading for all who have been taught to mistrust delta-functions. See the review by Dyson (1958).
Lighthill and Dyson were classmates in G. H. Hardy’s famous course in ‘pure mathematics’ at Cambridge
University, at a time when Fourier analysis was mostly preoccupied with convergence theory, as in
Titchmarsh (1937). Now with a redeﬁnition of the term ‘function’ as explained in our Appendix B, all that
becomes nearly irrelevant. Dyson states that Lighthill ‘lays Hardy’s work in ruins, and Hardy would have
enjoyed it more than anybody’.
Lindley, D. V . (1957), ‘A statistical paradox’, Biometrika 44, 187–192.
Mentions the Soal & Bateman (1954) parapsychology experiments.
Little, J. F. & Rubin, D. B. (1987), Statistical Analysis with Missing Data , J. Wiley & Sons,
New York.
Missing data can wreak havoc with orthodox methods because this changes the sample space, and thus
changes not only the sampling distribution of the estimator, but even its analytical form; one must go backto the beginning for each such case. But however complicated the change in the sampling distribution, the
change in the likelihood function is very simple. Bayesian methods accommodate missing data effortlessly;in all cases we simply include in the likelihood function all the data we have, and Bayes’ theoremautomatically returns the new optimal estimator for that data set.
Luce, R. D. & Raiffa, H. (1989), Games and Decisions , Dover Publications, NY .
Lukasiewicz, J. (1957), Aristotle’s Syllogistic from the Standpoint of Modern Formal Logic , 2nd
edn, Clarendon Press, Oxford; reprinted 1972.
Lusted, L. (1968), Introduction to Medical Decision Making , C. C. Thomas, Springﬁeld, IL.
Many useful Bayesian solutions to important medical problems, with computer source codes. Lee Lusted
(1923–1994) was a classmate and fellow physics major of the writer, at Cornell College many years ago.Then we followed surprisingly common paths: Lusted went into microwave radar countermeasures at the
Harvard Radio Research Laboratory, the writer into radar target identiﬁcation at the Naval Research
Laboratory, Anacostia, DC. After World War II, Lusted enrolled in the Harvard Medical School for an MDdegree, the writer in the Princeton University Graduate school for a Ph.D. Degree in Theoretical Physics;
we were both interested primarily in the reasoning processes used in those ﬁelds. Then we both discovered,independently, Bayesian analysis, saw that it was the solution to our problems, and devoted the rest of ourlives to it. At essentially the same time, Arnold Zellner followed a similar course, moving from physics toeconomics. Thus the modern Bayesian inﬂuence in three quite different ﬁelds arose from physicists, all ofnearly the same age and tastes. A sociologist has complained that ‘God gave the easy problems to thephysicists’. While some of us would wish to qualify that, we shall add only: ‘ ...and He so arranged that
the solutions physicists found would help also in solving the problems of others’.
McClave, J. T. & Benson, P. G. (1988), Statistics for Business and Economics , 4th edn, Dellen Publ.
Co., San Francisco.
Machol, R. E., Ladany, S. P. & Morrison, D. G. (eds.) (1976), Management Science in Sports , V ol. 4,
TIMS Studies in the Management Sciences, North-Holland, Amsterdam.
Curious applications of probability theory, leading to even more curious conclusions. Similarly, Morris
(1977) analyzes the game of tennis. He deﬁnes the ‘importance’ of a point as the probability that the server
wins the game if the point is won, minus the probability that the server wins the game if the point is lost.Comparing players of about equal ability, he ﬁnds the most important point to be 30–40. Then he
concludes that by trying a little harder on the most important points, the player can greatly enhance his
prospects of victory . It is a good exercise for the reader to criticize the logic here.
Maxwell, J. C. (1860), ‘Illustration of the dynamical theory of gases. Part I. On the motion and
collision of perfectly elastic spheres’, Phil. Mag. 56.
Middleton, D. (1960), An Introduction to Statistical Communication Theory , McGraw-Hill Book
Co., New York.
A massive work (1140 pages) with an incredible amount of mathematical material. The title is misleading,
since the material really applies to statistical inference in general. Unfortunately, most of the work was

<<<PAGE 730>>>

698 References
done a little too early, so the outlook is that of sampling theory and Neyman–Pearson decision rules, now
made obsolete by the Wald decision theory and Bayesian advances. Nevertheless, the mathematicalproblems – such as methods for solving singular integral equations – are independent of one’s philosophyof inference, so it has much useful material applicable in our current problems. One should browse throughit, and take note of what is available here.
Middleton, D. & Van Meter, D. (1955), ‘Detection and extraction of signals in noise from the point
of view of statistical decision theory, J. Soc. Ind. Appl. Math. 3, (4), 192.
Middleton, D. & Van Meter, D. (1956), ‘Detection and extraction of signals in noise from the point
of view of statistical decision theory’, J. Soc. Ind. Appl. Math. 4, (2), 86.
Molina, E. C. (1963), Two Papers by Bayes with Commentaries , Hafner Publishing Co., New York.
Contains penetrating historical remarks about the relation of Laplace and Boole, noting that those who
have quoted Boole in support of their attacks on Laplace may have misread Boole’s intentions.
Monod, Jacques (1970), Le Hazard et la N ´ecessit ´e, Seuil, Paris.
Morris, C. (1977), ‘The most important points in tennis’, in Ladany, S. P. & Machol, R. E., eds.,
Studies in Management Science andSystems , vol. 5 (North-Holland, Amsterdam).
Mosteller, F. (1965), Fifty Challenging Problems in Probability with Solutions , Addison-Wesley,
Reading, MA.
Newcomb, S. (1881), ‘Note on the frequency of use of the different digits in natural numbers’, Am.
J. Math. 4, 39–40.
Neyman, J. (1950), First Course in Probability and Statistics , Henry Holt & Co., New York.
Neyman, J. (1952), Lectures and Conferences on Mathematical Statistics and Probability , Graduate
School, US Dept of Agriculture.
Contains an incredible comparison of Bayesian interval estimation vs. conﬁdence intervals. A good
homework problem is to locate the error in his reasoning.
Northrop, E. P. (1944), Riddles in Mathematics; a Book of Paradoxes , van Nostrand, New York,
pp. 181–183.
Pearson, E. S. (1967), ‘Some reﬂections on continuity in the development of mathematical statistics
1890–94, Biometrika 54, 341–355.
Pearson E. S. & Clopper C. J. (1934), ‘The use of conﬁdence in ﬁducial limits illustrated in the case
of the binomial’, Biometrika 26,404–413.
Pearson, E. S. & Kendall, M. G. (1970), Studies in the History of Statistics and Probability , Hafner
Publishing Co., Darien, Conn.
Pearson, K. (1914–1930), The Life, Letters and Labours of Francis Galton , 3 vols., Cambridge
University Press.
Francis Galton had inherited a modest fortune, and on his death in 1911 he endowed the Chair of Eugenics
at University College, London. Karl Pearson was its ﬁrst occupant; this enabled him to give up the teaching
of applied mathematics to engineers and physicists, and concentrate on biology and statistics.
Pearson, K. (1920), ‘Notes on the history of correlation’, Biometrika 13, 25–45.
Reprinted in Pearson & Kendall (1970).
Pearson, K. (1970), ‘Walter Frank Raphael Weldon 1860–1906’, in Pearson, E. S. & Kendall, M. G.,
Studies in the History of Statistics and Probability , London.
Penrose, O. (1979), ‘Foundations of statistical mechanics’, Rep. Prog. Phys. 42, 1937–2006.
Published in ‘Reports of progress’, although it reports no progress.
Pitman, E. J. G. (1936), ‘Sufﬁcient statistics and intrinsic accuracy’, Proc. Camb. Phil. Soc. 32,
567–579.
Proof, almost simultaneous with Koopman (1936), of the NASC for sufﬁciency, now known as the
Pitman–Koopman theorem.
Poincar´ e, H. (1899), ‘L’Oeuvre math´ ematique de Weierstraß’, Acta. Math. 22, 1–18.
Contains an authoritative account of the relationship between the works of Kronecker and Weierstrasz,
pointing out that the difference was more in taste than in substance; to be contrasted with that of Bell
(1937), who tries to make them mortal enemies. Discussed in Appendix B.
Poincar´ e, H. (1904), Science et Hypothesis ; English translation, Dover Publications, Inc., NY (1952).
Poincar´ e had the gift of being able to say more in a sentence than most writers can in a page. Full of
quotable remarks, as true and important today as when they were written.

<<<PAGE 731>>>

References 699
Poincar´ e, H. (1909), Science et M ´ethode ; English translation, Dover Publications, Inc., New York
(1952).
Like Kline (1980), a ringing indictment of the contemporary work in mathematics and logic, for which the
Bourbakists have never forgiven him. However, in knowledge and judgment, Poincar´ e was far ahead of his
modern critics, because he was better connected to the real world.
Poincar´ e, H. (1912), Calcul des Probabilit ´es, 2nd edn, Gauthier-Villars, Paris.
Contains the ﬁrst example of the assignment of a probability distribution by the principle of group
invariance.
P´olya, G. (1920), ‘ ¨Uber den zentralen Grenzwertsatz der Wahrscheinlichkeitsrechnung und das
Momentenproblem’, Math. Zeit. 8, 171–181.
Reprinted in P´ olya (1984), V ol. IV . First appearance of the term ‘central limit theorem’ in print. He does
not actually prove the theorem (which he attributes to Laplace), but points out a theorem on uniform
convergence of a sequence of monotonic functions which can be used to shorten various proofs of it. But
our proof in Chapter 7 is even simpler.
P´olya, G. (1945), How to Solve It , Princeton University Press. Second paperbound edition by
Doubleday Anchor Books (1957).
P´olya, G. (1954), Mathematics and Plausible Reasoning , 2 vols, Princeton University Press.
P´olya, G. (1984), Collected Papers , 4 vols., ed. G-C. Rota, MIT Press, Cambridge, MA.
V olume IV contains papers on probability theory and combinatorics, several short articles on plausible
reasoning, and a bibliography of 248 papers by P´ olya. George P´ olya always claimed that his main interest
was in the mental processes for solving particular problems rather than in generalizations. Nevertheless,
some of his results launched new branches of mathematics through their generalizations by others. The
present work was inﬂuenced by P´ olya in more ways than noted in our Preface: most of our exposition is
aimed, not at expounding generalities for their own sake, but in learning how to solve speciﬁc problems –albeit by general methods.
P´olya, G. (1987), The P ´olya Picture Album: Encounters of a Mathematician , G. L. Alexanderson,
ed., Birkh¨ auser, Boston.
Over his lifetime, George P´ olya collected a large picture album with photographs of famous
mathematicians he had known, which he took delight in showing to visitors. After his death, the collection
was published in this charming book, which contains about 130 photographs with commentary by P´ olya,
plus a biography of P´ olya by the editor.
Popper, K. (1957), ‘The propensity interpretation of the calculus of probability, and the quantum
theory’, in Observation and Interpretation ,S .K ¨ orner, ed., Butterworth’s Scientiﬁc
Publications, London, pp. 65–70.
Here, Popper, who had criticized quantum theory, summarizes his views to an audience of scientists
concerned with foundations of quantum theory.
Popper, K. (1959), ‘The propensity interpretation of probability’, Brit. J. Phil. Sci. 10,
pp. 25–42.
Popper, K. (1974), ‘Replies to my critics’, in P. A. Schilpp, ed., The Philosophy of Karl Popper ,
Open Court Publishers, La Salle.
Presumably an authoritative statement of Popper’s position, since it is some years later than his best known
works, and seeks to address points of criticism directly.
Popper, K. & Miller, D. W. (1983), ‘A proof of the impossibility of inductive probability’, Nature ,
302, 687–688.
They arrive at this conclusion by a process that we examined in Chapter 5; asserting an intuitive ad hoc
principle not contained in probability theory. Written for scientists, this is like trying to prove theimpossibility of heavier-than-air ﬂight to an assembly of professional airline pilots.
Pratt, F. (1942), Secret and Urgent; The Story of Codes and Ciphers , 2nd edn, Blue Ribbon Books,
Garden City, NY .
Pratt, J. W. (1961), ‘Review of Testing Statistical Hypotheses ’ [Lehmann, 1959], J. Am. Stat. Assoc.
56, pp. 163–166.
A devastating criticism of orthodox hypothesis testing theory.
Press, W. H., Teukolsky, S. A., Vetterling, W. T., and Flannery, B. P. (1986), Numerical Recipes, The
Art of Scientiﬁc Computing , Cambridge University Press; 2nd edn, 1992.

<<<PAGE 732>>>

700 References
Quetelet, L. A. (1835), Sur L’homme et le D ´eveloppement de ses Facult ´es, ou Essai de Physique
Sociale (Bachelier, Paris).
Republished in 1869 under the title Physique Sociale .
Quetelet, L. A. (1869), Physique Sociale, ou Essai sur le D ´eveloppement des Facult ´es, de L’homme ,
C. Muquardt, Brussels.
Raiffa, H. A. & Schlaifer, R. S. (1961), Applied Statistical Decision Theory , Graduate School of
Business Administration, Harvard University.
Raimi, R. A. (1976), ‘The ﬁrst digit problem’, Am. Math. Monthly 83, 521–538.
Review article on ‘Benford’s law’ with many references.
Rao, M. M. (1993), Conditional Measures and Applications , Marcel Dekker, Inc., New York.
Noted in Appendix A as indicating how foreign the notion of conditional probability is in the Kolmogorov
system.
Reid, C. (1982), Neyman – From Life , Springer-Verlag, New York.
Rempe, G., Walter, H. & Klein, N. (1987), Phys. Rev. Lett. 58, 353–356.
Rosenkrantz, R. D. (1977), Inference, Method, and Decision: Towards a Bayesian Philosophy of
Science , D. Reidel Publishing Co., Boston.
Reviewed by E. T. Jaynes in J. Am. Stat. Assoc. , Sept. 1979, pp. 740–741.
Rothman, T. (1989), Science `a la Mode , Princeton University Press.
Accounts of what happens when scientists lose their objectivity and jump on bandwagons. We would stress
that they not only make themselves ridiculous, they do a disservice to science by promoting sensational butnonproductive ideas. For example, we think it will be realized eventually that the ‘chaos’ bandwagon hasput a stop to the orderly development of a half-dozen different ﬁelds without enabling any new predictiveability. Because, whenever chaos exists, it is surely predicted by the Hamiltonian equations of motion – just
what we have been using in statistical mechanics for a century. The chaos enthusiasts cannot make any
better predictions than does present statistical mechanics, because we never have the accurate knowledgeof initial conditions that would require. It has always been recognized, since the time of Maxwell and
Gibbs, that if we had exact knowledge of a microstate, that would enable us in principle to predict details of
future ‘thermal ﬂuctuations’ at present impossible; given such information, if chaos is present, its detailswould be predicted just as well. But in present statistical mechanics, lacking this information, we can
predict only an average over all possible chaotic behaviors consistent with the information we have; andthat is just the traditional thermodynamics.
Routh, E. J. (1905), The Elementary Part of A Treatise on the Dynamics of a System of Rigid Bodies ,
Macmillan, New York.
Parts 1 and 2 of a treatise on the whole subject.
Rowe, D. E. & McCleary, J., eds. (1989), The History of Modern Mathematics , 2 vols., Academic
Press, Inc., Boston.
Royall, R. M. & Cumberland, W. G. (1981), ‘The ﬁnite-population linear regression estimator and
estimators of its variance – an empirical study’, J. Am. Stat. Assoc. 76, 924–930.
Another demonstration of the folly of randomization.
Ruelle, D. (1991), Chance and Chaos , Princeton University Press.
How not to use probability theory in science; see the Comments section at the end of Chapter 4.
Savage, I. R. (1961), ‘Probability inequalities of the Tchebyscheff type’, J. Res. Nat. Bureau Stand.
65B, 211–222.
A useful collection of results, which ought to be made more accessible.
Savage, L. J. (1954), Foundations of Statistics , J. Wiley & Sons, NY; 2nd edn (rev.), Dover
Publications, Inc., NY (1972).
This work was attacked savagely by van Dantzig (1957).
Savage, L. J. (1961), ‘The foundations of statistics reconsidered’, Proceedings of the 4th Berkeley
Symposium on Mathematical Statistics and Probability , Berkeley University Press.
Savage, L. J. (1962), The Foundations of Statistical Inference, a Discussion , Methuen, London.
Savage, L. J. (1981), The Writings of Leonard Jimmie Savage – A Memorial Selection , American
Association of Statistics and the Institute of Mathematical Statistics.
Jimmie Savage died suddenly and unexpectedly in 1971, and his colleagues performed an important
service by putting together this collection of his writings that were scattered in many obscure places andhard to locate. Some personal reminiscences about him are in Jaynes (1984) and Jaynes (1985).

<<<PAGE 733>>>

References 701
Schr¨odinger, E. (1948), Statistical Thermodynamics , Cambridge University Press.
Schuster, A. (1897), ‘On lunar and solar periodicities of earthquakes’, Proc. Roy. Soc. 61, 455–465.
This marks the invention of the periodogram and could almost be called the origin of orthodox signiﬁcance
tests. Schuster undertakes to refute some claims of periodicities in earthquakes by considering only the
sampling distribution for the periodogram under the hypothesis that no periodicity exists !H en e v e r
considers what the probability is of getting the observed data if a periodicity of a certain frequency does
exist? Orthodoxy has been following this nonsensical procedure ever since.
Schwartz, L. (1950) Th´eorie des Distributions , 2 vols., Hermann et Cie, Paris.
Seal, H. (1967), ‘The historical development of the Gauss linear model’, Biometrika 54, 1–24.
Reprinted in Pearson & Kendall (1970).
Shannon, C. E. (1948), ‘A mathematical theory of communication’, Bell Syst. Tech. J. ,27, 379,
623.
Reprinted in C. E. Shannon & W. Weaver, The Mathematical Theory of Communication , University of
Illinois Press, Urbana, 1949. See also Sloane & Wyner (1993).
Shewhart, W. A. (1931), Economic Control of Quality of Manufactured Products , van Nostrand,
New York.
Shore, J. E. & Johnson, R. W. (1980), ‘Axiomatic derivation of the principle of maximum entropy
and the principle of minimum cross-entropy’, IEEE Trans. Information Theory IT-26 ,
26–37.
Many different choices of axioms all lead to the same actual algorithm for solution of problems. The authors
present a different basis from the one ﬁrst proposed (Jaynes, 1957a). But we stress that maximum entropy
and minimum cross-entropy are not different principles; a change of variables converts one into the other.
Simon, H. A. & Rescher, N. (1966), ‘Cause and Counterfactual’, Phil. Sci. 33, 323–340.
Simon, H. A. (1977), Models of Discovery , D. Reidel Publ. Co., Dordrecht, Holland.
Sims, C. A. (1988), ‘Bayesian skepticism on unit root econometrics’, J. Econ. Dyn. & Control 12,
463–474.
Unit root hypotheses (see Chapters 7 and 17) are not well connected to economic theory, but Bayesian
analysis of such models succeeds where orthodox signiﬁcance tests mislead.
Sivia, D. S. & Carlile, C. J. (1992), ‘Molecular spectroscopy and Bayesian spectral analysis – how
many lines are there?’, J. Chem. Phys. 96, 170–178.
Successful resolution of noisy data into as many as nine gaussian components by a Bayesian computer
program.
Sivia, D. S. (1996), Data Analysis – A Bayesian Tutorial , Clarendon Press, Oxford.
This small (less than 200 pages) but much-needed book contains a wealth of worked-out numerical
examples of Bayesian treatments of data, expounded from a theoretical standpoint identical to ours. It
should be considered an adjunct to the present work, supplying a great deal of practical advice for the
beginner, at an elementary level that will be grasped readily by every science or engineering student.
Sloane, N. J. A. & Wyner, A. D. (1993), Claude Elwood Shannon: Collected Papers , IEEE Press,
Piscataway, NJ.
Smart, W. M. (1947), John Couch Adams and the Discovery of Neptune , Royal Astronomical
Society, Occasional Notes No. 11.
Soal, S. G. & Bateman, F. (1954), Modern Experiments in Telepathy , Yale University Press, New
Haven.
Stigler, S. M. (1980), ‘Stigler’s law of eponymy’, Trans. NY Acad. Sci. 39, 147–159.
Stigler, S. M. (1983), ‘Who discovered Bayes’s Theorem?’, Am. Stat. 37, 290–296.
Stigler, S. M. (1986a), ‘John Craig and the probability of history’, JASA 81, 879–887.
Stigler, S. M. (1986b), ‘Translation of Laplace’s 1774 memoir on ‘Probability of causes’, Stat. Sci.
1, 359.
Stigler, S. M. (1986c), The History of Statistics , Harvard University Press.
A massive work of careful scholarship, required reading for all students of the subject. Gives full
discussions of many topics that we touch on only brieﬂy.
Stone, M. (1965), ‘Right Harr measure for convergence in probability to quasi-posterior
distributions’, Ann. Math. Stat. 30, 449–453.
Stone, M. (1976), ‘Strong inconsistency from uniform priors’, J. Am. Stat. Assoc. 71, 114–116.
A random walk in Flatland.

<<<PAGE 734>>>

702 References
Stone, M. (1979), ‘Review and analysis of some inconsistencies related to improper priors and ﬁnite
additivity’, in Proceedings of the 6th International Congress of Logic, Methodology, and
Philosophy of Science , Hanover, 1979, North Holland Press.
The tumbling tetrahedra of Chapter 15.
Stove, D. (1982), Popper and After: Four Modern Irrationalists , Pergamon Press, New York.
Sz´ekely, G. J. (1986), Paradoxes in Probability Theory and Mathematical Statistics , D. Reidel
Publishing Co., Dordrecht, Holland.
Gives, on p. 64, an erroneous solution for a biased coin; no comprehension of the physics. Compare with
our Chapter 10.
Takacs, L. (1958), ‘On a probability problem in the theory of counters’, Ann. Math. Stat. 29,
1257–1263.
There are many earlier papers by Takacs on this topic.
Tax, S., ed., (1960), Evolution After Darwin , 3 vols., University of Chicago Press.
V olume 1: The Evolution of Life ; V olume 2: The Evolution of Man ; V olume 3: Issues in Evolution .A
collection of articles and panel discussions by many workers in the ﬁeld, summarizing the state of
knowledge and current research directions 100 years after Darwin’s original publication.
Temple, G. (1955), ‘Theory of generalized functions’, Proc. Roy. Soc. Lond. Ser. A 228, 175–190.
Titchmarsh, E. C. (1937), Introduction to the Theory of Fourier Integrals , Clarendon Press, Oxford.
The ‘state of the art’ in Fourier analysis just before the appearance of Lighthill (1957), which made all the
lengthy convergence theory nearly irrelevant. However, only a part of this classic work is thereby madeobsolete; the material on Hilbert transforms, Hermite and Bessel functions, and Wiener–Hopf integralequations, remains essential for applied mathematics.
Titchmarsh, E. C. (1939), The Theory of Functions , 2nd edn, Oxford University Press.
In Chapter XI the reader may see – possibly for the ﬁrst time – some actual examples of nondifferentiable
functions. We discuss this brieﬂy in Appendix B.
Titterington, D. M., Smith, A. F. M. & Makov, U. E. (1985), Statistical Analysis of Finite Mixture
Distributions , Wiley, NY .
Tribus, M. (1961), Thermostatics and Thermodynamics; An Introduction to Energy, Information and
States of Matter, with Engineering Applications , Van Nostrand, Princeton, NJ.
Tribus, M. (1969), Rational Descriptions, Decisions and Designs , Pergamon Press, New York.
Tribus, M. & Fitts, G. (1968), ‘The widget problem revisited’, IEEE Trans. SSC-4 , (3), 241–248.
Tukey, J. W. (1977), Exploratory Data Analysis , Addison-Wesley, Reading, MA.
Introduces the word ‘resistant’ as a data-oriented version of ‘robust’.
Tversky, A. & Kahneman, D. (1981), ‘The framing of decisions and the psychology of choice’,
Science 211, 453–458.
Ulam, S. (1957), ‘Marian Smoluchowski and the theory of probabilities in physics’, Am. J. Phys. 25,
475–481.
Uspensky, J. V . (1937), Introduction to Mathematical Probability, McGraw-Hill, New York, p. 251.
Valavanis, S. (1959), Econometrics , McGraw-Hill, New York.
Modern students will ﬁnd this useful as a documented record of what econometrics was like under
orthodox statistical teaching. The demand for unbiased estimators at all costs can lead the author to throwaway practically all the information in the data; he just does not think in terms of information content.
van Dantzig, D. (1957), ‘Statistical priesthood (Savage on personal probabilities)’, Statistica
Neerlandica 2, 1–16.
Younger readers who ﬁnd it difﬁcult to understand today how Bayesians could have had to ﬁght for their
viewpoint, should read this attack on the work of Jimmie Savage. But one should realize that van Dantzig
was hardly alone here; his views were the ones most commonly expressed by statisticians in the 1950s and
1960s.
Venn, John (1866), The Logic of Chance , MacMillan & Co., London; later edns, 1876, 1888.
Picks up where Cournot and Ellis left off in the anti-Laplace cause. Some details are given in Jaynes
(1986b).
Ventris, M. (1988), ‘Work notes on Minoan language research and other unedited papers’, Sacconi,
A., ed., Edizioni dell’Ateneo, Rome.
Ventris, M. & Chadwick, J. (1956), Documents in Mycenaean Greek , Cambridge University Press.

<<<PAGE 735>>>

References 703
Vignaux, G. A. & Robertson, B. (1996), ‘Lessons from the New Evidence Scholarship’, in
G. R. Heidbreder, ed., Maximum Entropy and Bayesian Methods , Proceedings of the 13th
International Workshop, Santa Barbara, California, August 1–5, 1993, pp. 391–401, KluwerAcademic Publishers, Dordrecht, Holland.
A survey of the ﬁeld of Bayesian jurisprudence, with many references.
von Mises, R. (1957), Probability, Statistics and Truth , G. Allen & Unwin, Ltd, London.
von Mises, R. (1964), in Geiringer, H., ed., Mathematical Theory of Probability and Statistics ,
Academic Press, New York, pp. 160–166.
von Neumann, J. & Morgenstern, O. (1953), Theory of Games and Economic Behavior , 2nd edn,
Princeton University Press.
Wald, A. (1947), Sequential Analysis , Wiley, New York.
Reviewed by G. A. Barnard, J. Am. Stat. Assoc. 42, 668 (1947).
Wald, A. (1950), Statistical Decision Functions , Wiley, New York.
Wald’s ﬁnal work, in which he recognized the fundamental role of Bayesian methods and called his
optimal methods ‘Bayes strategies’.
Wason, P. C. & Johnson-Laird, P. N. (1972), Psychology of Reasoning , Batsford, London.
Weaver, W. (1963), Lady Luck, the Theory of Probability , Doubleday Anchor Books, Inc., Garden
City, NY .
Weber, B. H., Depew, D. J. & Smith, J. D., eds. (1988), Entropy, Information, and Evolution ,M I T
Press, Cambridge, MA.
A collection of 16 papers given at a symposium held in 1985. An appalling display of the state into which
evolution theory has degenerated, due to attempts to explain it in terms of the second law of
thermodynamics – by biologists and philosophers in total disagreement and confusion over what thesecond law is. Discussed brieﬂy in Chapter 7.
Weyl, H. (1946), The Classical Groups, Princeton University Press, NJ.
Weyl, H. (1949), Philosophy of Mathematics and Natural Science , Helmer, O., trans., Princeton
University Press.
Weyl, H. (1961), The Classical Groups; Their Invariants and Representations , Princeton University
Press.
Whittaker, E. T. & Robinson, G. (1924), The Calculus of Observations , Blackie & Son, London.
Notable because the fake ‘variable star’ data on p. 349 were used by Bloomﬁeld (1976), who proceeded
to make the authors’ analysis, with absurd conclusions, the centerpiece of his textbook on spectrum
analysis.
Whittaker, E. T. & Watson, G. N. (1927), A Course of Modern Analysis , 4th edn, Cambridge
University Press.
Whyte, A. J. (1980), The Planet Pluto , Pergamon Press, NY .
Widder, D. V . (1941), The Laplace Transform , Princeton University Press, Princeton, NJ.
Wiener, N. (1948), Cybernetics , J. Wiley & Sons, Inc., New York.
On p. 109, Norbert Wiener reveals himself as a closet Bayesian, although we know of no work of his that
actually uses Bayesian methods. But his conceptual understanding of the real world was in any event too
na¨ıve to have succeeded. On p. 46 he gets the effect of tidal forces in the Earth–Moon system backwards
(speeding up the Earth, slowing down the Moon). The statements about the work of Gibbs on pp. 61–62 arepure inventions; far from introducing or assuming ergodicity, Gibbs did not mention it at all. Today it isclear, from the discovery of strange attractors, chaos, etc., that almost no real system is ergodic, and in anyevent ergodicity is irrelevant to statistical mechanics because it makes no functional difference in the actualcalculations. In perceiving this, Gibbs was here a century ahead of the understanding of others.
Unfortunately, Wiener’s statements about Gibbs were quoted faithfully by other authors such as
S. Goldman (1953) and Y . W. Lee (1960), who were in turn quoted by others, thus creating a large and still
growing folklore. Wiener did not bother to proofread this work, and many equations are only vague hints as
to the appearance of the correct equation.
Wiener, N. (1949), Extrapolation, Interpolation, and Smoothing of Stationary time Series ,
J. Wiley & Sons, Inc., New York.
Another masterpiece of careless and obscure writing, partially deciphered by N. Levinson in the Appendix,
and more fully in the books of S. Goldman and Y . W. Lee.

<<<PAGE 736>>>

704 References
Wigner, E. P. (1931), Gruppentheorie und ihre Anwendung auf die Quantenmechanik der
Atomspektren, Fr. Vieweg, Braunschweig.
Wigner, E. P. (1959), Group Theory , Academic Press, Inc., New York.
Wing, G. M. (1962), An Introduction To Transport Theory, John Wiley and Sons, Inc., New York.
Woodward, P. M. (1953), Probability and Information Theory, with Applications to Radar ,
McGraw-Hill, NY .
An interesting historical document, which shows prophetic insight into what was about to happen, but
unfortunately just misses the small technical details needed to make it work.
Wrinch, D. M. & Jeffreys, H. (1919), Phil. Mag. 38, 715–734.
This was Harold Jeffreys’ ﬁrst publication on probability theory, concerned with modiﬁcations of the Rule
of Succession. He must have liked either the result or the association, because for the rest of his life he
made reference back to this paper on every possible occasion. Dorothy Wrinch was a mathematician born
in Argentina, who studied at Cambridge University and later taught at Smith College in the United States,
and, in the words of Jeffreys, ‘became a biologist’. Her photograph may be seen in P´ olya (1987), p. 85.
Two later papers by Wrinch and Jeffreys on the same topic are in Phil. Mag. 42, 369–390 (1921); 45,
368–374 (1923).
Zabell, S. L. (1989), ‘The Rule of Succession’, Erkenntnis ,31, 283–321.
A survey of the long and tangled history of the subject, with a wealth of unexpected detail and an
astonishing number of references, highly recommended. His attempt to assess the past criticisms and
present status of induction represents a notable advance over Popper but still fails, in our view, to recognizehow induction is used in actual scientiﬁc practice. Discussed in Chapter 9.
Zellner, A. (1971), An Introduction to Bayesian Inference in Econometrics , J. Wiley & Sons, Inc.,
New York; 2nd edn, 1987, R. E. Krieger Pub. Co., Malabar, Florida.
In spite of the word ‘econometrics” in the title, this work concerns universal principles and will be highly
valuable to all scientists and engineers. It may be regarded as a sequel to Jeffreys (1939, 3rd edn), carryingon multivariate problems beyond the stage reached by him. But the notation and style are the same,concentrating on the useful analytical material instead of mathematical irrelevancies. Contains a higherlevel of understanding of priors for linear regression than could be found in any textbook for more than20 years thereafter.
Zellner, A. (1988), ‘Optimal information processing and Bayes’ theorem’, Am. Stat. 42, 278–284.
With discussion. Points to the possibility of a general variational principle that includes both maximum
entropy and Bayesian algorithms as solutions. Discussed in Chapter 11.

<<<PAGE 737>>>

Bibliography
Akhiezer, N. I. (1965), The Classical Moment Problem , Hafner, New York.
Archimedes ( c220 bc), in Works, T. L. Heath, ed., Cambridge University Press (1897, 1912).
Paperback reprint by Dover Publications, Inc., New York, undated ( c1960).
Aristotle (4th century bc), Organon.
Deﬁnition of syllogisms.
Aristotle (4th century bc)Physics ; translation with commentary by Apostle, H. G., Indiana
University Press, Bloomington (1969).
Ash, B. B. (1966), Information Theory , John Wiley, New York.
Bacon, F. (1620), ‘Novum Organum’, in Spedding. J., Ellis, R. L. & Heath, D. D., eds., The
Works of Francis Bacon , vol. 4, Longman & Co., London (1857–1858).
Barber, N. F. & Ursell, F. (1948), ‘The generation and propagation of ocean waves and swell’, Phil.
Trans. Roy. Soc. Lond. ,A240 , 527–560.
Detection of chirped signals in noise.
Barlow, E. R. and Proschan, F. (1975), Statistical Theory of Reliability and Life Testing , Holt,
Rinehart & Winston, New York.
Barndorf-Nielsen, O. (1978), Information and Exponential Families in Statistical Theory ,J .W i l e y
& Sons, New York.
Barr, A. & Feigenbaum, E., eds. (1981), The Handbook of Artiﬁcial Intelligence , 3 vols., Wm.
Kaufman, Inc., Los Altos, CA.
Contributions from over 100 authors. V olume 1 surveys search routines, one of the few aspects of AI that
could be useful in scientiﬁc inference.
Barron, A. R. (1986), ‘Entropy and the central limit theorem’, Ann. Prob. 14, 336–342.
Bartholomew, D. J. (1965), ‘A comparison of some Bayesian and frequentist inference’, Biometrika ,
52, 19–35.
Benford, F. (1938), ‘The law of anomalous numbers’, Proc. Am. Phil. Soc. 78, 551–572.
Benford is probably the one referred to mysteriously by Warren Weaver (1963), p. 270. But, unknown to
them, Simon Newcomb (1881) had noticed this phenomenon long before. See Raimi (1976) for many moredetails and references.
Berkson, J. (1977), ‘My encounter with neo-Bayesianism’, Int. Stat. Rev. 45, 1–9.
Berkson, J. (1980), ‘Minimum chi-squared, not maximum likelihood!’, Ann. Stat. 8,
457–487.
Bernardo, J. M. (1977) ‘Inferences about the ratio of normal means: a Bayesian approach to the
Fieller-Creasy problem’, in Barra, J. D., et al. , eds., Recent Developments in Statistics , North
Holland Press, Amsterdam, pp. 345–350.
Bernado, J. M. (1979a), ‘Reference posterior distributions for Bayesian inference’, J. Roy. Stat. Soc.
B41, 113–147.
With discussion.
Bernado, J. M. (1979b), ‘Expected information as expected utility’, Ann. Stat. 7,
686–690.
705

<<<PAGE 738>>>

706 Bibliography
Bernado, J. M., de Groot, M. H., Lindley, D. V . & Smith, A. F. M., eds. (1980), Bayesian Statistics ,
Proceedings of the First Valencia International Meeting on Bayesian Statistics, Valencia,May 28–June 2, 1979, University Press, Valencia, Spain.
Bernado, J. M., de Groot, M. H. & Lindley, D. V ., eds. (1985), Bayesian Statistics 2 , Proceedings of
the Second Valencia International Meeting on Bayesian Statistics, September 6–10, 1983,
Elsevier Science Publishers, New York.
Billingsley, P. (1979), Probability and Measure , Wiley, New York.
Contains more Borel–Kolmogorov stuff that we do not go into.
Bishop, Y ., Fienberg, S., & Holland, P. (1975), Discrete Multivariate Analysis , MIT Press,
Cambridge, MA.
Blanc-Lapierre, A. & Fortet, R. (1953), Theorie des Fonctions Aleatoires , Masson et Cie, Paris.
Boole, G. (1916), Collected Logical Works ,Vol. 1: Studies in Logic and Probability; Vol II: An
Investigation of the Laws of Thought ; Open Court, Chicago.
Borel, E. (1926), Trait ´e du Calcul des Probabilit ´es, Gauthier-Villars, Paris.
The Hausdorff paradox on congruent sets on a sphere is discussed in Tome II, Fasc. 1.
Born, M. (1964), Natural Philosophy of Cause and Chance , Dover, New York.
Boscovich, Roger J. (1770), Voyage Astronomique et Geographique , N. M. Tillard, Paris.
Adjustment of data by the criterion that the sum of the corrections is zero, the sum of their magnitudes is
made a minimum.
Box, G. E. P. (1982), ‘An apology for ecumenism in statistics’, NRC Technical Report #2408,
Mathematics Research Center, University of Wisconsin, Madison.
Box, G. E. P., Leonard, T. & Wu, C-F, eds. (1983), Scientiﬁc Inference, Data Analysis, and
Robustness , Academic Press, Inc., Orlando, FL.
Proceedings of a conference held in Madison, Wisconsin, November 1981.
Bracewell, R. N. (1986), ‘Simulating the sunspot cycle’, Nature ,323, 516.
Ronald Bracewell is perhaps the ﬁrst author with the courage to present a deﬁnite prediction of future
sunspot activity. We await the Sun’s verdict with interest.
Brewster, D. (1855), Memoirs of the Life, Writings, and Discoveries of Sir Isaac Newton , 2 vols.,
Thomas Constable, Edinburgh.
Brigham, E. & Morrow, R. E. (1967), ‘The fast Fourier transform’, Proc. IEEE Spectrum 4,
63–70.
Brillouin, L. (1956), Science and Information Theory , Academic Press, New York.
Bross, I. D. J. (1963), ‘Linguistic analysis of a statistical controversy’, Am. Stat. 17, 18.
One of the most violent polemical denunciations of Bayesian methods in print – without the slightest
attempt to examine the actual results they give! Should be read by all who want to understand why and bywhat means the progress of inference was held up for so long. Jaynes (1976) was written originally in 1963as a reply to Bross, in circumstances explained in Jaynes (1983), p. 149.
Brown, E. E. & Duren, B. (1986), ‘Information integration for decision support’, Decision Support
Syst.,4, (2), 321–329.
Brown, R. (1828),‘A brief account of microscopical observations’, Edinburgh New Phil. J. 5,
358–371.
First report of the Brownian motion.
Burg, J. P. (1967), ‘Maximum entropy spectral analysis’, Proceedings of the 37th Meeting of the
Society of Exploration Geophysicists.
Burg, J. P. (1975), ‘Maximum entropy spectral analysis’, Ph.D. Thesis, Stanford University.
Busnel, R. G. & Fish, J. F., eds. (1980), Animal Sonar Systems , NATO ASI Series, V ol. A28, Plenum
Publishing Corp., New York.
A very large (1082 pp.) report of a meeting held on the island of Jersey, UK, in 1979.
Cajori, F. (1928), in Sir Isaac Newton 1727–1927 , Waverley Press, Baltimore, pp. 127–188.
Cajori, F. (1934), Sir Isaac Newton’s Mathematical Principles of Natural Philosophy and his System
of the World , University of California Press, Berkeley.
Carnap, R. (1950), Logical Foundations of Probability , Routlege and Kegan Paul Ltd., London.
Chen, Wen-chen, & de Groot, M. H. (1986), ‘Optimal search for new types’, in Goel, P. & Zellner,
A., eds. (1986), Bayesian Inference and Decision Techniques: Essays in Honor of Bruno de
Finetti , Elsevier Science Publishers, Amsterdam, pp. 443–458.

<<<PAGE 739>>>

Bibliography 707
Childers, D., ed. (1978), Modern Spectrum Analysis , IEEE Press, New York.
A collection of reprints of early works on maximum entropy spectrum analysis.
Chow, Y ., Robbins, H. & Siegmund, D. (1971), Great Expectations: Theory of Optimal Stopping ,
Houghton Mifﬂin & Co., Boston.
Cobb, L. & Watson, B. (1980), ‘Statistical catastrophe theory: an overview’, Math. Modelling ,1,
311–317.
We have no quarrel with this work, but wish to add two historical footnotes. (1) Their ‘stochastic
differential equation’ is what physicists have called a ‘Fokker–Planck equation’ since about 1917.However, we are used to having our statistical work attributed to Kolmogorov by mathematicians.(2) Stability considerations of multiple-valued ‘folded’ functions of the kind associated today with the
name of Ren´ e Thom are equivalent to convexity properties of a single-valued entropy function, and these
were given by J. Willard Gibbs in 1873.
Cohen, T. J. & Lintz, P. R. (1974), ‘Long term periodicities in the sunspot cycle’, Nature ,250, 398.
Cooley, J. W. & Tukey, J. W. (1965), ‘An algorithm for the machine calculation of complex Fourier
series’, Math. Comp. ,19, 297–301.
Cooley, J. W., Lewis, P. A. & Welch, P. D. (1967), ‘Historical notes on the fast Fourier transform’,
Proc. IEEE 55, 1675–1677.
Cook, A. (1994), The Observational Foundations of Physics , Cambridge University Press.
Notes that physical quantities are deﬁned in terms of the experimental arrangement used to measure them.
Of course, this is just the platitude that Niels Bohr emphasized in 1927.
Cox, D. R. & Hinkley, D. V . (1974), Theoretical Statistics , Chapman & Hall, London; reprints 1979,
1982.
Mostly a repetition of old sampling theory methods, in a bizarre notation that can make the simplest
equation unreadable. However, it has many useful historical summaries and side remarks, notinglimitations or extensions of the theory, that cannot be found elsewhere. Bayesian methods are introducedonly in the penultimate Chapter 10; and then the authors proceed to repeat all the old, erroneous objectionsto them, showing no comprehension that these were ancient misunderstandings long since corrected byJeffreys (1939), Savage (1954), and Lindley (1956). One prominent statistician, noting this, opined thatCox and Hinkley had ‘set statistics back 25 years’.
Cox, D. R. (1970), The Analysis of Binary Data , Methuen, London.
Cox, R. T. (1978), ‘Of inference and inquiry’, in Levine, R. D. & Tribus, M., eds., The Maximum
Entropy Formalism , MIT Press, Cambridge, MA, pp. 119–167.
Notes that, corresponding to the logic of propositions, there is a dual logic of questions. This could become
very important with further development, as discussed further in Jaynes (1983), pp. 382–388.
Cozzolino, J. M. & Zahner, M. J. (1973), ‘The maximum-entropy distribution of the future market
price of a stock’, Operations Res. ,21, 1200–1211.
Creasy, M. A. (1954), ‘Limits for the ratio of means’, J. Roy. Stat. Soc .B1 6 , 175–185.
Csiszar, I. (1984), ‘Sanov property, generalized I-projection and a conditional limit theorem’, Ann.
Prob. ,12, 768–793.
Czuber, E. (1908), Wahrscheinlichkeitsrechnung und Ihre Anwendung auf Fehlerausgleichung ,2
vols., Teubner, Berlin.
Some of Wolf’s famous dice data may be found here. In the period roughly 1850–1890, Wolf, a Zurich
astronomer, conducted and reported a mass of ‘random’ experiments; an account of these is given here.
Daganzo, C. (1977), Multinomial Probit: The Theory and its Application to Demand Forecasting ,
Academic Press, New York.
Dale, A. I. (1982), ‘Bayes or Laplace? An examination of the origin and early applications of
Bayes’ theorem’, Arch. Hist. Exact Sci. 27, 23–47.
Daniel, C. & Wood, F. S. (1971), Fitting Equations to Data , John Wiley, New York.
Daniell, G. J. & Potton, J. A. (1989), ‘Liquid structure factor determination by neutron scattering –
some dangers of maximum entropy’, in Skilling, J., ed. (1989), Maximum Entropy and
Bayesian Methods , Proceedings of the Eighth Maximum Entropy Workshop, Cambridge, UK,
August 1988, Kluwer Academic Publishers, Dordrecht, pp. 151–162.
The ‘danger’ here is that a beginner’s ﬁrst attempt to use maximum entropy on a complex problem may be
unsatisfactory because it is answering a different question than what the user had in mind. So the ﬁrst effortis really a ‘training exercise’ which makes one aware of how to formulate the problem properly.

<<<PAGE 740>>>

708 Bibliography
Davenport, W. S. & Root, W. L. (1958), Random Signals and Noise , McGraw-Hill, New York.
David, F. N. (1962), Games, Gods and Gambling , Grifﬁn, London.
A history of the earliest beginnings of probability theory. Notes that in archaeology, ‘the farther back one
goes, the more fragmentary is the evidence’. Just the kind of deep insight that we could ﬁnd nowhere else.
de Finetti, B. (1958), ‘Foundations of probability’, in Philosophy in the Mid-century ,L aN u o v a
Italia Editrice, Florence, pp. 140 –147.
de Groot, M. H., Bayarri, M. J. & Kadane, J. B. (1988), ‘What is the likelihood function?’ (with
discussion), in Gupta, S. S. & Berger, J. O., eds., Statistical Decision Theory and Related
Topics IV , Springer-Verlag, New York.
de Groot, M. H. & Cyert, R. M. (1987), Bayesian Analysis and Uncertainty in Economic Theory ,
Chapman & Hall, London.
de Groot, M. H., Fienberg, S. E. & Kadane, J. B. (1986), Statistics and the Law , John Wiley,
New York.
Deming, W. E. (1943), Statistical Adjustment of Data , John Wiley, New York.
Dempster, A. P. (1963), ‘On a paradox concerning inference about a covariance matrix’, Ann. Math.
Stat. 34, 1414–1418.
Dubois, D. & Prade, H. (1988), Possibility Theory , Plenum Publ. Co., New York.
Dunnington, G. W. (1955), Carl Friedrich Gauss, Titan of Science , Hafner, New York.
Dutta, M. (1966), ‘On maximum entropy estimation’, Sankhya, ser. A, 28,(4), 319–328.
Dyson, F. J. (1979), Disturbing the Universe , Harper & Row, New York.
A collection of personal reminiscences and speculations extending over some 50 years: 90% of it is
irrelevant to our present purpose; but one must persist here, because Freeman Dyson played a very
important part in the development of theoretical physics in the mid-20th century. His reminiscences aboutthis are uniquely valuable, but are unfortunately scattered in small pieces over several chapters. Unlike
some of his less thoughtful colleagues, Dyson saw correctly many fundamental things about probability
theory and quantum theory (but in our view missed some others equally fundamental). Reading this work israther like reading Kepler and trying to extract the tiny nuggets of important truth.
Eddington, Sir A. (1935), The Nature of the Physical World , Dent, London.
Another distinguished scientist who thinks as we do about probability.
Edwards, A. W. F. (1972), Likelihood , Cambridge University Press.
Anthony Edwards was the last student of R. A. Fisher; although he understands all the technical facts
pertaining to Bayesian methods as well as anybody, some mental block prevents him, as it did Fisher, fromaccepting their obvious consequences. So we must, sadly, part company and proceed with the constructivedevelopment of inference without him.
Edwards, A. W. F. (1992), Nature 352, 386–387.
Commentary on Bayesian methods.
Edwards, H. M. (1987), ‘An appreciation of Kronecker’, Math. Intelligencer ,9, 28–35.
Edwards, H. M. (1988), ‘Kronecker’s place in history’, in Aspray, W. & Kitcher, P., eds., History
and Philosophy of Modern Mathematics , University of Minnesota Press.
Efron, B. (1975), ‘Biased versus unbiased estimation’, Adv. Math. 16, 259–277.
Efron, B. (1978), ‘Controversies in the foundations of statistics’, Am. Math. Monthly 85, 231–246.
Efron, B. (1979a), ‘Bootstrap methods: another look at the jackknife’, Ann. Stat. 6, 1–26.
Efron, B. (1979b), ‘Computers and the theory of statistics: thinking the unthinkable ’,SIAM Rev. 21,
460–480.
Efron, B. & Gong, G. (1983), ‘A leisurely look at the bootstrap, the jackknife, and cross-validation’,
Am. Stat. 37, 36–48.
Orthodox statisticians have continued trying to deal with problems of inference by inventing arbitrary ad hoc
procedures instead of applying probability theory. Three recent examples are explained and advocated here.Of course, they all violate our desiderata of rationality and consistency; the reader will ﬁnd it interestingand instructive to demonstrate this and compare their results with those of the Bayesian alternatives.
Evans, M. (1969), Macroeconomic Forecasting , Harper & Row, New York.
Fechner, G. J. (1860), Elemente der Psychophysik , 2 vols.; V ol. 1 translated as Elements of
Psychophysics , Boring, E. G. & Howes, D. H., eds., Holt, Rinehart & Winston, New York
(1966).

<<<PAGE 741>>>

Bibliography 709
Fechner, G. J. (1882), Revision der Hauptpuncte der Psychophysik , Breitkopf u. H¨ artel, Leipzig.
Feinstein, A. (1958), Foundations of Information Theory , McGraw-Hill, New York.
Like the work of Khinchin (1957), a mathematician’s view of things, which has almost nothing in common
with the physically oriented view of Goldman (1953).
Ferguson, T. S. (1982), ‘An inconsistent maximum likelihood estimate’, J. Am. Stat. Assoc. 77,
831–834.
Fieller, E. C. (1954), ‘Some problems in interval estimation’, J. Roy. Stat. Soc. B1 6 , 175–185.
This and the contiguous paper by Creasy (1954; this bibliography) became famous as ‘the Fieller–Creasy
problem’ of estimating the ratio µ1/µ2of means of two normal sampling distributions. It generated a vast
amount of discussion and controversy because orthodox methods had no principles for dealing with it –
and for decades nobody would deign to examine the Bayesian solution. It is a prime example of anestimation problem, easily stated, for which only Bayesian methods provide the technical apparatusrequired to solve it. It is ﬁnally considered from a Bayesian standpoint by Jos´ e Bernardo (1977).
Fisher, R. A. (1912), ‘On an absolute criterion for ﬁtting frequency curves’, Messeng. Math. 41,
155–160.
Fisher, R. A. (1915), ‘Frequency distribution of the values of the correlation coefﬁcient in samples
from an indeﬁnitely large population’, Biometrika 10, 507–521.
Fisher, R. A. (1930), ‘Inverse probabilities’, Proc. Camb. Phil. Soc. 26, 528–535.
Fisher, R. A. (1935), The Design of Experiments , Oliver & Boyd, Edinburgh; six later editions to
1966.
Fisher, R. A. (1938), Statistical Tables for Biological, Agricultural and Medical Research (with F.
Yates), Oliver & Boyd, Edinburgh; ﬁve later editions to 1963.
Fisher, R. A. & Tippett, L. H. C. (1928), ‘Limiting forms of the frequency distribution of the largest
or smallest member of a sample’, Proc. Camb. Phil. Soc. 24, 180–190.
Fouger´ e, P. F. (1977), ‘A solution to the problem of spontaneous line splitting in maximum entropy
power spectrum analysis’, J. Geophys. Res. 82, 1051–1054.
Galton, F. (1863), Meteorographica , MacMillan, London.
Here this remarkable man invents weather maps and, from studying them, discovers the ‘anticyclone’
circulation patterns in the northern hemisphere.
Galton, F. (1889), Natural Inheritance , MacMillan, London.
Gentleman, W. M. (1968), ‘Matrix multiplication and fast Fourier transformations’, Bell Syst. Tech.
J.,17, 1099–1103.
Gillispie, C. C., ed. (1981), Dictionary of Scientiﬁc Biography , 16 vols., C. Scribner’s Sons, New
York.
The ﬁrst place to look for information on any scientist.
Glymour, C. (1980), Theory and Evidence , Princeton University Press.
Gnedenko, B. V . & Kolmogorov, A. N. (1954), Limit Distributions for Sums of Independent Random
Variables , Addison-Wesley, Cambridge, MA.
On p. 1 we ﬁnd the curious statement: ‘In fact, all epistomologic value of the theory of probability is based
on this: that large-scale random phenomena in their collective action create strict, non-random regularity.’
This was thought by some to serve a political purpose in the old USSR; in any event, the most valuableapplications of probability theory today are concerned with incomplete information and have nothing to dowith those so-called ‘random phenomena’ which are still undeﬁned in theory and unidentiﬁed in Nature.
Goel, P. & Zellner, A. (1986), eds., Bayesian Inference and Decision Techniques: Essays in Honor
of Bruno de Finetti , Elsevier Science Publishers, Amsterdam.
Gokhale, D. and Kullback, S. (1978), The Information in Contingency Tables , Marcel Dekker,
New York.
Goldberg, S. (1983), Probability in Social Science , Birkhaeuser, Basel.
Good, I. J. (1965), The Estimation of Probabilities , Research Monographs #30, MIT Press,
Cambridge, MA.
Jack Good persisted in believing in the existence of ‘physical probabilities’ that have some kind of reality
independently of human information; hence the (to us) incongruous title.
Grandy, W. T. & Schick, L. H., eds. (1991), Maximum Entropy and Bayesian Methods , Proceedings
of the Tenth annual Maximum Entropy workshop, Kluwer Academic Publishers, Holland.

<<<PAGE 742>>>

710 Bibliography
Grenander, U. & Szeg¨ o, G. (1957), Toeplitz Forms and their Applications , University of California
Press, Berkeley.
Grifﬁn, D. R. (1958), Listening in the Dark , Yale University Press, New Haven.
See also Slaughter, R. H. & Walton, D. W., eds. (1970), About Bats , SMU Press, Dallas, Texas.
Gull, S. F. & Daniell, G. J. (1978), ‘Image reconstruction from incomplete and noisy data’, Nature
272, 686.
Gull, S. F. & Daniell, G. J. (1980), ‘The maximum entropy algorithm applied to image
enhancement’, Proc. IEEE (E) 5, 170.
Gull, S. F. & Skilling, J. (1984), ‘The maximum entropy method’, in Roberts, J. A., ed., Indirect
Imaging , Cambridge University Press.
Hacking, I. (1965), Logic of Statistical Inference , Cambridge University Press.
Hacking, I. (1973), The Emergence of Probability , Cambridge University Press.
Hacking, I. (1984), ‘Historical models for justice’, Epistemologia, Special Issue on Probability,
Statistics, and Inductive Logic ,VII, 191–212.
Haldane, J. B. S. (1957), ‘Karl Pearson, 1857–1957’, Biometrika 44, 303–313.
Haldane’s writings, whatever the ostensible topic, often turned into political indoctrination for socialism. In
this case it made some sense, since Karl Pearson was himself a political radical. Haldane suggests that hemay have changed the spelling of his name from ‘Carl’ to ‘Karl’ in honor of Karl Marx, and from this
Centenary oration we learn that V . I. Lenin quoted approvingly from Karl Pearson. Haldane was Professorof Genetics at University College, London in the 1930s, but he resigned and moved to India as a protest atthe failure of the authorities to provide the ﬁnancial support he felt his Department needed. It is easy toimagine that this was precisely what those authorities, exasperated at his preoccupation with left-wingpolitics instead of genetics, hoped to bring about. An interesting coincidence is that Haldane’s sister,Naomi Haldane Mitchison, married a Labour MP and carried on the left-wing cause. James D. Watson was
a guest at her home at Christmas 1951, about a year before discovering the DNA helix structure. He was socharmed by the experience that his 1968 book, The Double Helix , is inscribed: ‘For Naomi Mitchison.’
Hampel, F. R. (1973), ‘Robust estimation: a condensed partial survey’, Zeit. Wahrsch ,theorie vrw.
Beb. 27, 87–104
Hankins, T. L. (1970), Jean d’Alembert: Science and the Enlightenment , Oxford University Press.
Heath, D. & Sudderth, W. (1976), ‘de Finetti’s theorem on exchangeable variables’, Am. Stat. 30,
188.
An extremely simple derivation.
Helliwell, R. A. (1965), Whistlers and Related Ionospheric Phenomena , Stanford University Press,
Palo Alto, CA.
Hellman, M. E. (1979), ‘The mathematics of public-key cryptography’, Sci. Am. 241, 130–139.
Hewitt, E. & Savage, L. J. (1955), ‘Symmetric measures on Cartesian products’, Trans. Am. Math.
Soc. 80, 470–501.
A generalization of de Finetti’s representation theorem to arbitrary sets.
Hirst, F. W. (1926), Life and Letters of Thomas Jefferson , Macmillan, New York.
Hobson, A. & Cheung, B. K. (1973), ‘A comparison of the Shannon and Kullback information
measures’, J. Stat. Phys. 7, 301–310.
Hodges, J. L. & Lehmann, E. L. (1956), ‘The efﬁciency of some nonparametric competitors of the
t-test’, Ann. Math. Stat. 27, 324–335.
Hofstadter, D. R. (1983), ‘Computer tournaments of the Prisoner’s dilemma suggest how
cooperation evolves’, Sci. Am. 248, (5), 16–26.
Holbrook, J. A. R. (1981), ‘Stochastic independence and space-ﬁlling curves’, Am. Math. Monthly
88, 426–432.
Jagers, P. (1975), Branching Processes with Biological Applications , John Wiley, London.
James, W. & Stein, C. (1961), ‘Estimation with quadratic loss’, Proc. 4th Berkeley Symp., Univ.
Calif. Press, 1, 361–380.
Jansson, P. A., ed. (1984), Deconvolution, with Applications in Spectroscopy , Academic Press,
Orlando, FL.
Articles by nine authors, summarizing the state of the art (mostly linear processing) as it existed just before
the introduction of Bayesian and maximum entropy methods.

<<<PAGE 743>>>

Bibliography 711
Jaynes, E. T. (1963), ‘Review of Noise and Fluctuations , by D. K. C. MacDonald’, Am. J. Phys. 31,
946.
Cited in Jaynes (1976) in response to a charge by Oscar Kempthorne that physicists have paid little
attention to noise; notes that there is no area of physics in which the phenomenon of noise does not present
itself. As a result, physicists were actively studying noise and knew the proper way to deal with it, long
before there was any such thing as a statistician.
Jaynes, E. T. (1973a), ‘Survey of the present status of neoclassical radiation theory’, in Mandel, L.
& Wolf, E., eds., Proceedings of the 1972 Rochester Conference on Optical Coherence ,
Pergamon Press, New York.
Jaynes, E. T. (1973b), ‘The well-posed problem’, Found. Phys. 3, 477–493.
Reprinted in Jaynes (1983).
Jaynes, E. T. (1980a), ‘The minimum entropy production principle’, Ann. Rev. Phys. Chem. 31,
579–601.
Reprinted in Jaynes (1983).
Jaynes, E. T. (1980b), ‘What is the question?’, in Bernardo, J. M., de Groot, M. H., Lindley,
D. V . & Smith, A. F. M., eds., Bayesian Statistics , University Press, Valencia, Spain,
pp. 618–629.
Discussion of the logic of questions, as pointed out by R. T. Cox (1978), and applied to the relationship
between parameter estimation and hypothesis testing. Reprinted in Jaynes (1983), pp. 382–388.
Jaynes, E. T. (1981), ‘What is the problem?’, in Haykin, S., ed., Proceedings of the Second SSSP
Workshop on Spectrum Analysis , McMaster University.
The following article is an enlarged version.
Jaynes, E. T. (1982), ‘On the rationale of maximum-entropy methods’, Proc. IEEE 70, 939–
952.
Jaynes, E. T. (1984), ‘Prior information and ambiguity in inverse problems’, in SIAM-AMS
Proceedings , V ol. 14, American Mathematical Society, pp. 151–166.
Jaynes, E. T. (1985a) ‘Where do we go from here?’, in Smith, C. & Grandy, W. T., eds.
Maximum-Entropy and Bayesian Methods in Inverse Problems , D. Reidel Publishing Co.,
Dordrecht, pp. 21–58.
Jaynes, E. T. (1985b), ‘Entropy and search theory’, in Smith, C. & Grandy, W. T., eds.
Maximum-Entropy and Bayesian Methods in Inverse Problems , D. Reidel Publishing Co.,
Dordrecht, pp. 443–454.
Shows that the failure of previous efforts to ﬁnd a connection between information theory and search
theory were due to use of the wrong entropy expression. In fact, there is a very simple and generalconnection, as soon as we deﬁne entropy on the deepest hypothesis space.
Jaynes, E. T. (1985c) ‘Macroscopic prediction’, in Haken, H., ed., Complex Systems – Operational
Approaches , Springer-Verlag, Berlin.
Jaynes, E. T. (1985d), ‘Generalized scattering’, in Smith, C. & Grandy, W. T., eds.,
Maximum-Entropy and Bayesian Methods in Inverse Problems , D. Reidel Publishing Co.,
Dordrecht, pp. 377–398.
Some of the remarkable physical predictions contained in the comparison of two maximum entropy
distributions, before and after adding a new constraint.
Jaynes, E. T. (1986), ‘Some applications and extensions of the de Finetti representation theorem’, in
Goel, P. & Zellner, A., eds., Bayesian Inference and Decision Techniques: Essays in Honor of
Bruno de Finetti , Elsevier Science Publishers, Amsterdam, pp. 31–42.
The theorem, commonly held to apply only to inﬁnite exchangeable sequences, remains valid for ﬁnite
ones if one drops the non-negativity condition on the generating function. This makes it applicable to a
much wider class of problems.
Jaynes, E. T. (1988a), ‘The relation of Bayesian and maximum entropy methods’, in Erickson, G. J.
& Smith, C. R., eds. (1988), Maximum-Entropy and Bayesian Methods in Science and
Engineering , V ol. 1, pp. 25–29.
Jaynes, E. T. (1988b), ‘Detection of extra-solar system planets’, in Erickson, G. J. & Smith, C. R.,
eds. (1988), Maximum-Entropy and Bayesian Methods in Science and Engineering , V ol. 1,
pp. 147–160.

<<<PAGE 744>>>

712 Bibliography
Jaynes, E. T. (1991), ‘Notes on present status and future prospects’, in Grandy, W. T. & Schick,
L. H., eds. (1991), Maximum Entropy and Bayesian Methods, Proceedings of the Tenth annual
Maximum Entropy Workshop, Kluwer Academic Publishers, Holland.
A general summing-up of the situation as it appeared in the summer of 1990.
Jaynes, E. T. (1993), ‘A backward look to the future’, in Grandy, W. T. & Milonni, P. W., eds.,
Physics and Probability: Essays in Honor of Edwin T. Jaynes , Cambridge University Press,
pp. 261–275.
A response to the contributors to this Festschrift volume marking the writer’s 70th birthday, with 22 articles
by my former students and colleagues.
Jefferys, W. H. (1990), ‘Bayesian analysis of random event generator data’, J. Sci. Expl. 4, 153–169.
Shows that orthodox signiﬁcance tests can grossly overestimate the signiﬁcance of ESP data; Bayesian
tests yield defensible conclusions because they do not depend on the intentions of the investigator.
Jeffreys, H. (1963), ‘Review of Savage (1962)’, Technometrics 5, 407–410.
Jeffreys, Lady Bertha Swirles (1992), ‘Harold Jeffreys from 1891 to 1940’, Notes Rec. Roy. Soc.
Lond. 46, 301–308.
A short, and puzzlingly incomplete, account of the early life of Sir Harold Jeffreys, with a photograph of
him in his 30s. Detailed account of his interest in botany and early honors (he entered St John’s College,Cambridge as an undergraduate, in 1910; and that same year received the Adams memorial prize for an
essay on ‘Precession and nutation’). But, astonishingly, there is no mention at all of his work in probabilitytheory! In the period 1919–1939, this resulted in many published articles and two books (Jeffreys, 1931,1939) of very great importance to scientists today. It is, furthermore, of fundamental importance and will
remain so long after all his other work recedes into history. Bertha Swirles Jeffreys was also a physicist,who studied with Max Born in G¨ ottingen in the late 1920s and later became Mistress of Girton College,
Cambridge.
Jerri, A. J. (1977), ‘The Shannon sampling theorem – its various extensions and applications’, Proc.
IEEE 65, 1565–1596.
A massive tutorial collection of useful formulas, with 248 references.
Johnson, R. W. (1979), ‘Axiomatic characterization of the directed divergences and their linear
combinations’, IEEE Trans. IT-7, 641–650.
Kale, B. K. (1970), ‘Inadmissibility of the maximum likelihood estimation in the presence of prior
information’, Can. Math. Bull. 13, 391–393.
Kalman, R. E. (1982), ‘Identiﬁcation from real data’, in Hazewinkel, M. & Rinnooy Kan, A., eds.,
Current Developments in the Interface: Economics, Econometrics, Mathematics , D. Reidel
Publishing Co., Dordrecht-Holland, pp. 161–196.
Kalman, R. E. (1990), Nine Lectures on Identiﬁcation , Lecture Notes on Economics and
Mathematical Systems, Springer-Verlag.
Kandel, A. (1986), Fuzzy Mathematical Techniques with Applications , Addison-Wesley, Reading,
MA.
Kay, S. & Marple, S. L., Jr (1979), ‘Source of and remedies for spectral line splitting in
autoregressive spectrum analysis’, Proceedings of the 1979 IEEE International Conference on
Acoustics, Speech Signal Processing, October 1978, pp. 469–471.
Kemeny, J. G. & Snell, J. L. (1960), Finite Markov Chains , D. van Nostrand Co., Princeton, NJ.
Kendall, M. G. (1956), ‘The beginnings of a probability calculus’, Biometrika 43, 1–14; reprinted
in Pearson & Kendall (1970).
A fascinating psychological study. In the attempt to interpret the slow early development of probability
theory as caused by the unfounded prejudices of others, he reveals inadvertently his own unfounded
prejudices, which in our view are the major cause of retarded – even backward – progress in the 20th
century.
Khinchin, A. I. (1949) Mathematical Foundations of Statistical Mechanics , Dover Publications,
Inc., New York.
An attempt to base the calculational techniques on the central limit theorem, not general enough for
problems of current interest. But the treatment of the Laplace transform relation between structure
functions and partition functions is still valuable reading today, and forms the mathematical basis for ourown development in Part 2.

<<<PAGE 745>>>

Bibliography 713
Kiefer, J. & Wolfowitz, J. (1956), ‘Consistency of the maximum likelihood estimation in the
presence of inﬁnitely many incidental parameters’, Ann. Math. Stat. 27, 887–906.
Kindermann, R. & Snall, J. L. (1980), Markov Random Fields , Contemporary Mathematics V ol. 1,
AMS, Providence, RI.
Kuhn, T. S. (1962), The Structure of Scientiﬁc Revolutions , University of Chicago Press; 2nd edn,
1970.
Kullback, S. (1959), Information Theory and Statistics , John Wiley, New York.
A beautiful work, never properly appreciated because it was 20 years ahead of its time.
Landau, H. J. (1983), ‘The inverse problem for the vocal tract and the moment problem’, SIAM
J. Math. Anal. 14, 1019–1035.
Modeling speech production by a reﬂection coefﬁcient technique closely related to the Burg maximum
entropy spectrum analysis.
Landau, H. J. (1987), ‘Maximum entropy and the moment problem’, Bull. Am. Math. Soc. 16, 47–77.
Interprets the Burg solution in terms of more general problems in several ﬁelds. Highly recommended for a
deeper understanding of the mathematics.
Legendre, A. M. (1806), ‘Nouvelles m´ ethods pour la d´ etermination des orbits des com´ etes’, Didot,
Paris.
Leibniz, G. W. (1968), General Investigations Concerning the Analysis of Concepts and Truths ,
trans. W. H. O’Briant, University of Georgia Press.
Lessard, S., ed. (1989), Mathematical and Statistical Developments in Evolutionary Theory ,N A T O
ASI Series V ol. C299, Kluwer Academic Publishers, Holland.
Proceedings of a meeting held in Montreal, Canada in 1987.
Lewis, G. N. (1930) ‘The symmetry of time in physics’, Science 71, 569.
An early recognition of the connection between entropy and information, showing an understanding far
superior to what many others were publishing 50 years later.
Lindley, D. V . (1956), ‘On a measure of the information provided by an experiment’, Ann. Math.
27, 986–1005.
Lindley, D. V . (1958) ‘Fiducial distributions and Bayes’ theorem’, J. Roy. Stat. Soc. B20, 102–107.
Lindley, D. V . (1971) Bayesian Statistics: A Review , Society for Industrial and Applied
Mathemathics, Philadelphia.
Linnik, Yu. V . (1961), Die Methode der kleinsten Quadrate in Moderner Darstellung , Deutscher
Verl. der Wiss., Berlin.
Litterman, R. B. (1985), ‘Vector autoregression for macroeconomic forecasting’, in Zellner, A. &
Goel, P., eds., Bayesian Inference and Decision Techniques , North-Holland Publishers,
Amsterdam.
Lukacs, E. (1960), Characteristic Functions , Grifﬁn, London.
Macdonald, P. D. M. (1987), ‘Analysis of length-frequency distributions’, in Summerfelt, R. C. &
Hall, G. E., eds., Age and Growth of Fish , Iowa State University Press, pp. 371–384.
A computer program for deconvolving mixtures of normal and other distributions. The program, ‘MIX 3.0’
is available from: Ichthus Data Systems, 59 Arkell St, Hamilton, Ontario, Canada L8S 1N6. In Chapter 7
we note that the problem is not very well-posed; Icthus acknowledges that it is ‘inherently difﬁcult’ andmay not work satisfactorily on the user’s data. See also Titterington, Smith & Makov (1985).
Mandel, J. (1964), The Statistical Analysis of Experimental Data , Interscience, New York.
Straight orthodox ad hockeries , one of which is analyzed in Jaynes (1976).
Mandelbrot, B. (1977), Fractals, Chance and Dimension , W. H. Freeman & Co., San Francisco.
Marple, S. L. (1987), Digital Spectral Analysis with Applications , Prentice-Hall, New Jersey.
Martin, R. D. & Thompson, D. J. (1982), ‘Robust-resistant spectrum estimation’, Proc. IEEE 70,
1097–1115.
Evidently written under the watchful eye of their mentor John Tukey, this continues his practice of
inventing a succession of ad hoc devices based on intuition rather than probability theory. It does not even
acknowledge the existence of maximum entropy or Bayesian methods. To their credit, the authors do give
computer analyses of several data sets by their methods – with results that do not look very encouraging to
us. It would be interesting to acquire their raw data and analyze them by methods like those of Bretthorst(1988) that do make use of probability theory; we think that the results would be quite different.

<<<PAGE 746>>>

714 Bibliography
Masani, S. M. (1977), ‘A paradox in admissibility’, Ann. Stat. 5, 544–546.
Maxwell, J. C. (1850), Letter to Lewis Campbell; reproduced in L. Campbell & W. Garrett, The Life
of James Clerk Maxwell , Macmillan, 1881.
McColl, H. (1897) ‘The calculus of equivalent statements’, Proc. Lond. Math. Soc. 28, 556.
Criticism of Boole’s version of probability theory.
McFadden, D. (1973), ‘Conditional logit analysis of qualitative choice behavior’, in Zarembka, P.,
ed.,Frontiers in Econometrics , Academic Press, New York.
Mead, L. R. & Papanicolaou, N. (1984), ‘Maximum entropy in the problem of moments’, J. Math.
Phys. 25, 2404–2417.
Miller, R. G. (1974), ‘The jackknife – a review’, Biometrika 61, 1–15.
Mitler, K. S. (1974), Multivariate Distributions , John Wiley, New York.
Molina, E. C. (1931), ‘Bayes’ theorem, an expository presentation’, Bell Syst. Tech. Publ.
Monograph B-557.
Stands, with Keynes (1921), Jeffreys (1939) and Woodward (1953), as proof that there have always been
lonely voices crying in the wilderness for a sensible approach to inference.
Moore, G. T. & Scully, M. O., eds. (1986), Frontiers of Nonequilibrium Statistical Physics , Plenum
Press, New York.
Here several speakers afﬁrmed their belief, on the basis of the Bell inequality experiments, that ‘atoms are
not real’ while maintaining the belief that probabilities areobjectively real! We consider this a ﬂagrant
example of the mind projection fallacy, carried to absurdity.
Munk, W. H. & Snodgrass, F. E. (1957), ‘Measurements of Southern Swell at Guadalupe Island’,
Deep-Sea Res. 4, 272–286.
This is the work which Tukey (1984) held up as the greatest example of his kind of spectral analysis, which
could never have been accomplished by other methods; to which in turn Jaynes (1987) replied with chirp
analysis.
Newton, Sir Isaac (1687) Philosophia Naturalis Principia Mathematica , trans. Andrew Motte,
1729; revised and reprinted as Mathematical Principles of Natural Philosophy , Florian Cajori,
ed., University of California Press (1946).
See also Cajori (1928, 1934; both this bibliography).
Neyman, J. & Pearson, E. S. (1933), ‘On the problem of the most efﬁcient test of statistical
hypotheses’, Phil. Trans. Roy. Soc. 231, 289–337.
Neyman, J. & Pearson, E. S. (1967), Joint Statistical Papers , Cambridge University Press.
Reprints of the several Neyman–Pearson papers of the 1930s, originally scattered over several different
journals.
Neyman, J. (1959), ‘On the two different aspects of representative method: the method of stratiﬁed
sampling and the method of purposive selection’, Estadistica 17, 587–651.
Neyman, J. (1962) ‘Two breakthroughs in the theory of statistical decision making’, Int. Stat. Rev.
30, 11–27.
It is an excellent homework problem to locate and correct the errors in this.
Neyman, J. (1981), ‘Egon S. Pearson (August 11, 1895–June 12, 1980)’, Ann. Stat. 9, 1–2.
Nov´ak, V . (1988), Fuzzy Sets and their Applications , A. Hilger, Bristol.
Nyquist, H. (1924), ‘Certain factors affecting telegraph speed’, Bell Syst. Tech. J. 3, 324.
Nyquist, H. (1928), ‘Certain topics in telegraph transmission theory’, Trans. AIEE ,47, 617–644.
O’Hagan, A. (1977), ‘On outlier rejection phenomena in Bayes inference’, J. Roy. Stat. Soc. B4 1 ,
358–367.
Our position is that Bayesian inference has no pathological, exceptional cases and in particular no outliers.
To reject any observation as an ‘outlier’ is a violation of the principles of rational inference, and signiﬁes
only that the problem was improperly formulated. That is, if you are able to decide that anyobservation is
an outlier from the model that you speciﬁed, then that model does not properly capture your priorinformation about the mechanisms that are generating the data. In principle, the remedy is not to reject anyobservation, but to deﬁne a more realistic model (as we note in our discussion of Robustness). However, weconcede that if the strictly correct procedure assigns a very low weight to the suspicious datum, itsstraight-out surgical removal from the data set may be a reasonable approximation, very easy to do.
Ore, O. (1953), Cardano, the Gambling Scholar , Princeton University Press.

<<<PAGE 747>>>

Bibliography 715
Ore, O. (1960), ‘Pascal and the invention of probability theory’, Am. Math. Monthly 67, 409–419.
Pearson, K. (1892), The Grammar of Science , Walter Scott, London.
Reprinted 1900, 1911 by A. & C. Black, London, and in 1937 by Everyman Press. An exposition of the
principles of scientiﬁc reasoning; notably chieﬂy because Harold Jeffreys was much inﬂuenced by it and
thought highly of it. This did not prevent him from pointing out that Karl Pearson was far from applying
his own principles in his later scientiﬁc efforts. For biographical material on Karl Pearson (1857–1936) see
Haldane (1957; this bibliography).
Pearson, K. (1905), ‘The problem of the random walk’, Nature 72, 294, 342.
Pearson, K. (1921–33), The History of Statistics in the 17’th and 18’th Centuries , Pearson, E.S., ed.,
Lectures given at University College, London, Grifﬁn, London (1978).
Penﬁeld, W. (1958), Proc. Natl Acad. Sci. (USA) 44, 59.
Accounts of observations made during brain surgery, in which electrical stimulation of a speciﬁc spots on
the brain caused the conscious patient to recall various long-forgotten experiences. This undoubtedly true
phenomenon is closely related to the theory of the Apdistribution in Chapter 18. But now others have
moved into this ﬁeld, with charges that psychiatrists are causing their patients – particularly young
children – to recall things that never happened, with catastrophic legal consequences. The problem of
recognizing valid and invalid recollections seems headed for a period of controversy.
Pierce, J. R. (1980) Symbols, Signals, and Noise: An Introduction to Information Theory , Dover
Publications, Inc., New York.
An easy introduction for absolute beginners, but does not get to the currently important applications.
Poisson, S. D. (1837), Recherches sur la Probabilit ´e des Jugements , Bachelier imprimeur-Libraire,
Paris.
First appearance of the Poisson distribution.
P´olya, G. (1921), ‘ ¨Uber eine Aufgabe der Wahrscheinlichkeitsrechnung betreffend die Irrfahrt im
Strassennetz’, Math. Ann. 84, 149–160.
It is sometimes stated that this was the ﬁrst appearance of the term ‘random walk’. However, we may point
to Pearson (1905) and Rayleigh (1919); both in this bibliography.
P´olya, G. (1923), ‘Herleitung des Gauss’schen Fehlergesetzes aus einer Funktionalgleichung’,
Math. Zeit. 18, 96–108.
Pontryagin, L. S. (1946), Topological Groups, Princeton University Press, Princeton, NJ.
Popper, K. (1958), The Logic of Scientiﬁc Discovery , Hutchinson & Co., London.
Denies the possibility of induction, on the grounds that the prior probability of every scientiﬁc theory is
zero. Karl Popper is famous mostly through making a career out of the doctrine that theories may not beproved true, only false; hence the merit of a theory lies in its falsiﬁability. There is an evident grain of truthhere, expressed by the syllogisms of Chapter 1; and Albert Einstein also noted this in his famous remark:‘No amount of experiments can ever prove me right; a single experiment may at any time prove me wrong .’
Nevertheless, the doctrine is true only of theories which assert the existence of unobservable causes or
mechanisms; any theory which asserts observable facts is a counter-example to it.
Popper, K. (1963), Conjectures and Refutations , Routledge & Kegan Paul, London.
Popov, V . N. (1987), Functional Integrals and Collective Excitations , Cambridge University Press.
Sketches applications to superﬂuidity, superconductivity, plasma dynamics, superradiation, and phase
transitions. A useful start on understanding of these phenomena, but still lacking any coherent theoreticalbasis – which we think is supplied only by the principle of maximum entropy as a method of reasoning.
Prenzel, H. V . (1975), Dynamic Trendline Charting: How to Spot the Big Stock Moves and Avoid
False Signals , Prentice-Hall, Englewood Cliffs, NJ.
Contains not a trace of probability theory or any other mathematics: merely plot the monthly ranges of
stock prices, draw a few straight lines on the graph, and their intersections tell you what to do and when to
do it. At least this system does enable one to see the four-year presidential election cycle, very clearly.
Press, S. J. (1989), Bayesian Statistics: Principles, Models and Applications , J. Wiley & Sons, Inc.,
New York.
Contains a list of many Bayesian computer programs now available.
Preston, C. J. (1974), Gibbs States on Countable Sets , Cambridge University Press.
Here we have the damnable practice of using the word state to denote a probability distribution .O n e
cannot conceive of a more destructively false and misleading terminology.

<<<PAGE 748>>>

716 Bibliography
Priestley, M. B. (1981), Spectral Analysis and Time Series , 2 vols., Academic Press, Inc., Orlando,
FL; combined paperback edition with corrections (1983).
Puri, M. L., ed. (1975), Stochastic Processes and Related Topics , Academic Press, New York.
Quaster, H., ed. (1953), Information Theory in Biology , University Illinois Press, Urbana.
Ramsey, F. P. (1931), The Foundations of Mathematics and Other Logical Essays , Routledge and
Kegan Paul, London.
Frank Ramsey was First Wrangler in Mathematics at Cambridge University in 1925, then became a Fellow
of Kings College, where among other activities he collaborated with John Maynard Keynes on economic
theory. He would undoubtedly have become the most inﬂuential Bayesian of the 20th century, but for the
fact that he died in 1930 at the age of 26. In these essays one can see the beginnings of something very
much like our exposition of probability theory.
Rayleigh, Lord (1919), ‘On the problem of random vibrations, and of random ﬂights in one, two or
three dimensions’, Edin. & Dublin Phil. Mag. & J. Sci. 37, series 6, 321–347.
Reichardt, H. (1960), C. F . Gauss–Leben und Werk , Haude & Spener, Berlin.
Reid, C. (1970), Hilbert , Springer-Verlag, New York.
Reid, C. (1959), ‘On a new axiomatic theory of probability’, Acta. Math. Acad. Sci. Hung. 6,
285–335.
This work has several things in common with ours, but expounded very differently.
Rihaczek, A. W. (1981), ‘The maximum entropy of radar resolution’, IEEE Trans. Aerospace
Electron. Syst. AES-17 , 144.
Another attack on maximum entropy, still denying the possibility of so-called ‘super resolution’, although
it had been demonstrated conclusively in both theory and practice by John Parker Burg many years before,
and was by 1981 in routine use by many scientists and engineers, as illustrated by the reprint collection ofChilders (1978); see this bibliography.
Rissanen, J. (1983), ‘A universal prior for the integers and estimation by minimum description
length’, Ann. Stat. 11, 416–431.
One of the few fresh new ideas in recent decades. We think it has a bright future, but are not yet prepared to
predict just what it will be.
Robbins, H. (1950), ‘Asymptotically subminimax solutions of compound statistical decision
problems’, Proceedings of the 2nd Berkeley Symposium of Mathematics Statistics and
Probability , University of California Press, pp. 131–148.
An anticipation of Stein (1956); see this bibliography.
Robbins, H. (1956), ‘An empirical Bayes’ approach to statistics’, Proceedings of the 3rd Berkeley
Symposium on Mathematics, Statistics and Probability I , University of California Press,
pp. 157–164.
Robinson, A. (1966), Non-standard Analysis , North-Holland, Amsterdam.
How to do every calculation wrong.
Robinson, E. A. (1982), ‘A historical perspective of spectrum estimation’, Proc. IEEE 70, 855–906.
Robinson, G. K. (1975), ‘Some counterexamples to the theory of conﬁdence intervals’, Biometrika
62, 155–162.
Rowlinson, J. S. (1970), ‘Probability, information and entropy’, Nature 225, 1196–1198.
An attack on the principle of maximum entropy showing a common misconception of the nature of
inference. Answered in Jaynes (1978).
Sampson, A. R. & Smith, R. L. (1984), ‘An information theory model for the evaluation of
circumstantial evidence,’ IEEE Trans. Systems, Man, and Cybernetics 15, 916.
Sampson, A. R. & Smith, R. L. (1982), ‘Assessing risks through the determination of rare event
probabilities’, Op. Res. 30, 839–866.
Sanov, I. N. (1961), ‘On the probability of large deviations of random variables’, IMS and AMS
Translations of Probability and Statistics, from Mat. Sbornik 42, 1144.
Scheff´ e, H. (1959), The Analysis of Variance , John Wiley, New York.
Schendel, U. (1989) Sparse Matrices , J. Wiley & Sons, New York.
Schlaifer, R. (1959), Probability and Statistics for Business Decisions: An Introduction to
Managerial Economics Under Uncertainty , McGraw-Hill Book Company, New York.
An early recognition of the need for Bayesian methods in the real-world problems of decision; in striking
contrast to the simultaneous Chernoff and Moses work (1959) on decision theory.

<<<PAGE 749>>>

Bibliography 717
Schneider, T. D. (1991), ‘Theory of molecular machines’, J. Theor. Biol. 148, 83–137.
In two parts, concerned with channel capacity and energy dissipation.
Schnell, E. E. (1960), ‘Samuel Pepys, Isaac Newton and probability’, Am. Stat. 14, 27–30.
From this we learn that both Pascal and Newton had the experience of giving a correct solution and not
being believed; the problem is not unique to modern Bayesians.
Schr¨odinger, E. (1945), ‘Probability problems in nuclear chemistry’, Proc. Roy. Irish Acad .51.
Schr¨odinger, E. (1947), ‘The foundation of the theory of probability’, Proc. Roy. Irish Acad. (A) ,
51, pp. 51–66, 141–146.
Valuable today because it enables us to add one more illustrious name to the list of those who think as we
do. Here Schr¨ odinger declares the ‘frequentist’ view of probability inadequate for the needs of science and
seeks to justify the view of probability as applying to individual cases rather than ‘ensembles’ of cases, byefforts somewhat in the spirit of our Chapters 1 and 2. He gives some ingenious arguments but, unknown tohim, these ideas had already advanced far beyond the level of his work. He was unaware of Cox’s theorems
and, like most scientists of that time with continental training, he had apparently never heard of ThomasBayes or Harold Jeffreys. He gives no useful applications and obtains no theoretical results beyond what
had been published by Jeffreys eight years earlier. Nevertheless, his thinking was aimed in the rightdirection on this and other controversial issues.
Shafer, G. (1976), A Mathematical Theory of Evidence , Princeton University Press, Princeton, NJ.
An attempt to develop a theory of two-valued probability, by a fanatical anti-Bayesian.
Shafer, G. (1982), ‘Lindley’s paradox’, J. Am. Stat. Assoc. 77, 325–334.
Apparently, Shafer was unaware that this was all in Jeffreys (1939, p. 194) some 20 years before Lindley.
But Shafer’s other work had made it clear already that he had never read and understood Jeffreys.
Shamir, A (1982), ‘A polynomial time algorithm for breaking the basic Merkle–Hellman
cryptosystem’, in Chaum, D., Rivest, R. L. & Sherman, A. T., eds., Advances in Cryptology:
Proceedings of Crypto 82, 23–25 August 1982 , Plenum Press, New York, pp. 279–288.
Shaw, D. (1976), Fourier Transform NMR Spectroscopy , Elsevier, New York.
Sheynin, O. B. (1978), ‘S. D. Poisson’s work in probability’, Archiv. f. Hist. Exact Sci. 18, 245–300.
Sheynin, O. B. (1979), ‘C. F. Gauss and the theory of errors’, Archiv. f. Hist. Exact Sci. 19, 21–72.
Shiryayev, A. N. (1978), Optimal Stopping Rules , Springer-Verlag, New York.
Siegmann, D. (1985) Sequential Analysis , Springer-Verlag, Berlin.
No mention of Bayes’ theorem or optional stopping!
Simmons, G. J. (1979), ‘Cryptography, the mathematics of secure communication’, The Math.
Intelligencer 1, 233–246.
Sinai, J. G. (1982), Rigorous Results in the Theory of Phase Transitions , Akad´ emiai Kiado, Budapest.
Skilling, J., ed. (1989), Maximum Entropy and Bayesian Methods , Proceedings of the Eighth
Maximum Entropy Workshop, Cambridge, UK, August 1988, Kluwer Academic Publishers,Dordrecht, Holland.
Smith, C. R. & Grandy, W. T., eds. (1985), Maximum-Entropy and Bayesian Methods in Inverse
Problems , D. Reidel Publishing Co., Dordrecht, Holland.
Smith, C. R. & Erickson, G. J., eds. (1987), Maximum-Entropy and Bayesian Spectral Analysis and
Estimation Problems , D. Reidel Publishing Co., Dordrecht, Holland.
Smith, D. E. (1959), A Source Book in Mathematics , McGraw-Hill Book Co., New York.
Contains the Fermat–Pascal correspondence.
Smith, W. B. (1905), ‘Meaning of the Epithet Nazorean’, The Monist 15, 25–95.
Concludes that prior to the Council of Nicæa, ‘Nazareth’ was not the name of a geographical place; it had
some other meaning.
Sonett, C. P. (1982), ‘Sunspot time series: spectrum from square law modulation of the Hale cycle’,
Geophys. Res. Lett. 9, 1313–1316.
Spinoza, B. (1663), ‘Renati des Cartes Principiorum philosophiae pars I, & II, more geometrico
demonstratae,’ Ethics , part 2, Prop. XLIV: ‘De natura Rationis no est res, ut contingentes; sed,
ut necessarias, contemplari.’
Translated, this proposition reads: ‘It is not in the nature of reason to regard things as contingent; instead,
they should be regarded as necessary.’
Spitzer, F. (1964), Principles of Random Walk , van Nostrand, New York.
Background history and present status.

<<<PAGE 750>>>

718 Bibliography
Stein, C. (1945), ‘A two sample test for a linear hypothesis whose power is independent of the
variance’, Ann. Math. Stat. 16, 243–258.
Stein, C. (1956), ‘Inadmissibility of the usual estimator for the mean of a multivariate normal
distribution’, Proceedings of the 3rd Berkeley Symposium , vol. 1, pp. 197–206, University of
California Press.
First announcement of the ‘Stein shrinking’ phenomenon.
Stein, C. (1959), ‘An example of wide discrepancy between ﬁducial and conﬁdence intervals’, Ann.
Math. Stat. 30, 877–880.
Stein, C. (1964), ‘Inadmissibility of the usual estimate for the variance of a normal distribution with
unknown mean’, Ann. Inst. Stat. Math. 16, 155–160.
Stein’s inadmissibility discoveries, while shocking to statisticians with conventional training, are not in the
least surprising or disconcerting to Bayesians. They only illustrate what was already clear to us: that thecriterion of admissibility, which ignores all prior information, is potentially dangerous in real problems.Here that criterion can reject as ‘inadmissible’ what is in fact the optimal estimator, as noted brieﬂy inChapter 13.
Stigler, S. M. (1974a), ‘Cauchy and the Witch of Agnesi’, Biometrika 61, 375–380.
Stigler, S. M. (1974b), ‘Gergonne’s 1815 paper on the design and analysis of polynomial regression
experiments’, Historia Math. 1, 431–477.
Stigler, S. M. (1982a), ‘Poisson on the Poisson distribution’, Stat. & Prob. Lett. 1, 33–35.
Stigler, S. M. (1982b), ‘Thomas Bayes’s Bayesian inference’, J. Roy. Stat. Soc. A145 , 250–258.
Stone, M. & Springer-Verlag, B. G. F. (1965), ‘A paradox involving quasi prior distributions’,
Biometrika 52, 623–627.
Stromberg, K. (1979), ‘The Banach-Tarski paradox’, Am. Math. Monthly 86, 151–160.
Congruent sets stuff.
Student (1908), ‘The probable error of a mean’, Biometrika 6, 1–24.
Takeuchi, K., Yanai, H. & Mukherjee, B. N. (1982), The Foundations of Multivariate Analysis ,
J. Wiley & Sons, New York.
Taylor, R. L., Daffer, P. Z. & Patterson, R. F. (1985), Limit Theorems for Sums of Exchangeable
Random Variables , Rowman & Allanheld Publishers.
Presents the known versions of limit theorems for discrete-time exchangeable sequences in Euclidean and
Banach spaces.
Thomas, M. U. (1979), ‘A generalized maximum entropy principle’, Operations Res. 27, 1188–1195.
Tikhonov, A. N. & Arsenin, V . Y . (1977), Solutions of Ill-posed Problems , Halsted Press, New York.
A collection of ad hoc mathematical recipes, in which the authors try persistently to invert operators which
have no inverses. Never perceives that these are problems of inference , not inversion .
Todhunter, I. (1865), A History of the Mathematical Theory of Probability , Macmillan, London;
reprinted 1949, 1965, by Chelsea Press, New York.
Todhunter, I. (1873), A History of the Mathematical Theories of Attraction and the Figure of the
Earth , 2 vols., Macmillan, London; reprinted 1962 by Dover Press, New York.
Toraldo di Francia, G. (1955), ‘Resolving power and information’, J. Opt. Soc. Am. 45, 497–501.
One of the ﬁrst recognitions of the nature of a generalized inverse problem; he tries to use information
theory but fails to see that (Bayesian) probability theory is the appropriate tool for his problems.
Train, K. (1986), Qualitative Choice Analysis Theory, Econometrics, and an Application to
Automobile Demand , MIT Press, Cambridge, MA.
Truesdell, C. (1987), Great Scientists of Old as Heretics in ‘The Scientiﬁc Method’ , University Press
of Virginia.
The historical record shows that some of the greatest advances in mathematical physics were made with
little or no basis in experiment, in seeming deﬁance of the ‘scientiﬁc method’ as usually proclaimed. Thisjust shows the overwhelming importance of creative hypothesis formulation as primary to inference fromgiven hypotheses. Unfortunately, while today we have a well-developed and highly successful theory ofinference, we have no formal theory at all on optimal hypothesis formulation, and very few successfulrecent examples of it.
Tukey, J. W. (1960), ‘A survey of sampling from contaminated distributions’, in Olkin, I., ed.,
Contributions to Probability and Statistics: Essays in Honor of Harold Hotelling , Stanford
University Press, California, pp. 448–485.

<<<PAGE 751>>>

Bibliography 719
Tukey, J. W. (1962), ‘The future of data analysis’, Ann. Math. Stat. 33, 1–67.
A potent object lesson for all who try to foretell the future as the realization of their own prejudices.
Tukey, J. W. (1978), ‘Granger on seasonality’, in Zellner, A., ed., Seasonal Analysis of Time Series ,
US Dept of Commerce, Washington.
An amusing view of the nature of Bayesian inference as a sneaky way of committing indecent
methodological sins ‘while modestly concealed behind a formal apparatus’.
Tukey, J. W. (1984), ‘Styles of spectrum analysis’, Scripps Inst. Oceanography Ref. Series 84–85,
March, pp. 100–103.
A polemical attack on all theoretical principles, including autoregressive models, maximum entropy, and
Bayesian methods. The ‘protagonist of maximum entropy’ who appears on p. 103 is none other than
E. T. Jaynes.
Tukey, J. W., Bloomﬁeld, P. Brillinger, D. & Cleveland, W. S. (1980), The Practice of Spectrum
Analysis , University Associates, Princeton, New Jersey.
Notes for a course given in December 1980.
Tukey, J. W. & Brillinger, D. (1982), ‘Spectrum estimation and system identiﬁcation relying on a
Fourier transform’, unpublished.
This rare work was written as an invited paper for the IEEE Special Issue of September 1982 on Spectrum
Analysis, but its length (112 pages in an incomplete version) prevented its appearing there. We hope that itwill ﬁnd publication elsewhere, because it is an important historical document. Tukey (1984; thisbibliography) contains parts of it.
Valery-Radot, R. (1923), The Life of Pasteur , Doubleday, Page & Co., Garden City, New York.
Van Campenhout, J. M. & Cover, T. M. (1981), ‘Maximum entropy and conditional probability’,
IEEE Trans. Info. Theor. IT-27 , 483–489.
A rediscovery and generalization of what physicists have, since 1928, called ‘the Darwin–Fowler method
of statistical mechanics’.
van den Bos, A. (1971), ‘Alternative interpretation of maximum entropy spectral analysis’, IEEE
Trans. Info. Theor. IT-17 , 493–494.
Reprinted in Childers (1978; this bibliography). Expresses several misgivings about maximum entropy
spectrum analysis, answered in Jaynes (1982; this bibliography).
Varian, H. (1978), Microeconomic Analysis , Norton & Co., New York.
Vasicek, O. (1980), ‘A conditional law of large numbers’, Ann. Prob. 8, 142–147.
Wald, A. (1941), Notes on the Theory of Statistical Estimation and of Testing Hypotheses ,
Mimeographed, Columbia University.
At this time, Wald was assuring his students that Bayesian methods were entirely erroneous and incapable
of dealing with the problems of inference. Nine years later, his own research had led him to the opposite
opinion.
Wald, A. (1942), On the Principles of Statistical Inference , Notre Dame University Press.
Wald, A. (1943), ‘Sequential analysis of statistical data: theory’, Restricted report dated September
1943.
Waldmeier, M. (1961), The Sunspot Activity in the Years 1610-1960 , Schulthes, Z¨ urich.
Probably the most analyzed of all data sets.
Walley, P. (1991), Statistical Reasoning with Imprecise Probabilities , Chapman & Hall, London.
Worried about improper priors, he introduces the notion of a ‘near-ignorance class’ (NIC) of priors. Since
then, attempts to deﬁne precisely the NIC of usable priors have occupied many authors. We propose to cut
all this short by noting that any prior which leads to a proper posterior distribution is usable and potentiallyuseful. Obviously, whether a given improper prior does or does not accomplish this is determined not by
any property of the prior alone, but by the joint behavior of the prior and the likelihood function; that is, bythe prior, the model, and the data. Need any more be said?
Watson, J. D. (1968), The Double Helix , Signet Books, New York.
The famous account of the events leading to discovery of the DNA structure. It became a best seller
because it inspired hysterically favorable reviews by persons without any knowledge of science, who weredelighted by the suggestion that scientists in their ivory towers have motives just as disreputable as theirs.This was not the view of scientists on the scene with technical knowledge of the facts, one of whom saidprivately to the present writer: ‘The person who emerges looking worst of all is Watson himself.’ But that isancient history; for us today, the interesting question is: would the discovery have been accelerated

<<<PAGE 752>>>

720 Bibliography
appreciably if the principles of Bayesian inference, as applied to X-ray diffraction data, had been
developed and reduced to computer programs in 1950? We suspect that Rosalind Franklin’s ﬁrst‘A-structure’ photograph, which looks hopelessly confusing to the eye at ﬁrst glance, if analyzed by a
computer program (like those of Bretthorst (1988) but adapted to this problem), would have pointed at
once to a double helix as overwhelmingly the most probable structure (at least, the open spaces which say
‘helix ’ were present and could be recognized by the eye after the fact). The problem is, in broad aspects,
very much like that of radar target identiﬁcation. For another version of the DNA story, with some different
recollections of the course of events, see Crick (1988; this bibliography).
Wax, N., ed. (1954), Noise & Stochastic Processes , Dover Publications, Inc., New York.
Wehrl, A. (1978), ‘General properties of entropy’, Rev. Mod. Phys. 50, 220–260.
Whittle, P. (1954), Comments on periodograms, Appendix to H. Wold (1954; this bibliography),
pp. 200–227.
Whittle, P. (1957), ‘Curve and periodogram smoothing’, J. Roy. Stat. Soc. B1 9 , 38–47.
Whittle, P. (1958), ‘On the smoothing of probability density functions’, J. Roy. Stat. Soc. B2 0 ,
334–343.
Wigner, E. P. (1967), Symmetries and Reﬂections , Indiana University Press, Bloomington.
From the standpoint of probability theory, the most interesting essay reprinted here is #15, ‘The probability
of the existence of a self-reproducing unit’. Writing the quantum-mechanical transformation from an initial
state with (one living creature +environment) to a ﬁnal state with (two identical ones +compatible
environment), he concludes that the number of equations to be satisﬁed is greater than the number ofunknowns, so the probability of replication is zero. Since the fact is that replication exists, the argument ifcorrect would show only that quantum theory is invalid.
Wilbraham, H. (1854), ‘On the theory of chances developed in Professor Boole’s “Laws of
Thought” ’, Phil. Mag. Series 4 ,7, (48), 465–476.
Criticism of Boole’s version of probability theory.
Williams, P. M. (1980), ‘Bayesian conditionalisation and the principle of minimum information’,
Brit. J. Phil. Sci. 31, 131–144.
Wilson, A. G. (1970), Entropy and Urban Modeling , Pion Limited, London.
Wold, H. (1954), Stationary Time Series , Almquist and Wiksell, Stockholm.
Yockey, H. P. (1992), Information Theory in Molecular Biology , Cambridge University Press.
Zabell, S. L. (1982), ‘W. E. Johnson’s sufﬁcientness postulate’, Ann. Stat. 10, 1091–1099.
Discussed in Jaynes (1986b).
Zabell, S. L. (1988), ‘Buffon, Price, and Laplace: scientiﬁc attribution in the 18’th century’, Arch.
Hist. Exact Sci. 39, 173–181.
Zellner, A. (1984), Basic Issues in Econometrics , University of Chicago Press.
A collection of 17 reprints of recent articles discussing and illustrating important principles of scientiﬁc
inference. Like the previous reference, this is of value to a far wider audience than one would expect from
the title. The problems and examples are stated in the context of economics, but the principles themselves
are of universal validty and importance. In our view they are if anything even more important for physics,biology, medicine, and environmental policy than for economics. Be sure to read Chapter 1.4, entitled
‘Causality and econometrics’. The problem of deciding whether a causal inﬂuence exists is vital for
physics, and one might have expected physicists to have the best analyses of it. Yet Zellner here gives a farmore sophisticated treatment than anything in the literature of physics or any other ‘hard’ science. He
makes the same points that we stress here with cogent examples showing why prior information isabsolutely essential in any judgment of this.
Zubarev, D. N. (1974) Nonequilibrium Statistical Thermodynamics , Plenum Publishing Corp.,
New York.
An amazing work; develops virtually all the maximum entropy partition functional algorithm as an ad hoc
device; but then rejects the maximum entropy principle which gives the rationale for it and explains why itworks! As a result, he is willing to use the formalism only for a tiny fraction of the problems which it iscapable of solving, and thus loses practically all the real value of the method. A striking demonstration ofhow useful applications can be paralyzed – even when all the requisite mathematics is at hand – byorthodox conceptualizing about probability.

<<<PAGE 753>>>

Author index
Abel, Niels Henrik, 27
Achilles, the heel, 126Acz´el, J´anos D., 27
Adams, John Couch, 134
Ames, Adelbert Jr, 132Arbuthnot, John, 136Aristotle, 4
Banach, Stefan, 6
Barnard, George A., 198Bateman, Frederick, 120Bayes, Rev. Thomas, 112, 377, 425, 499Beethoven, Ludwig van, 9Bell, Eric Temple, 665Berger, James O., 251, 407, 415, 420Berlioz, Hector, 9Bernardo, Jos´ e M., 120
Bernoulli, Daniel, 137, 203, 315, 321, 398Bernoulli, James, 43, 82, 112, 119, 163, 204, 284,
315, 493
Bertrand, Joseph L., 195, 386, 486Bierce, Ambrose, 397Biot, Jean-Baptiste, 124Birnbaum, Alan, 251Blackwell, David, 247Bloomﬁeld, Peter, 521Bohr, Niels Henrik David, 328Boltzmann, von Ludwig, 315, 440
Boole, George, 9, 49, 315
Borel, Emil, 386Boring, Edwin Garrigues, 120Box, George E. P., 314Brahe, Tycho, 203Bredin, Jean-Denis, 127Bretthorst, G. Larry, 125, 207, 473, 497, 505Broad, Charlie Dunbar, 155
Brouwer, Luitzen Egbertus Jan, 673
Burns, Arthur, 505
Caesar, Julius, 126
Cantrell, Hadley, 132Cardano, Gerolamo, 315
Carnap, Rudolf, 279, 383, 574
Carroll, Lewis, 671Charles II, 306
Chernoff, Herman, 374, 400, 419, 420, 514
Copi, Irving M., 16
Cornﬁeld, Jerome, 479Cournot, August Antoin, 137, 315Cox, Richard T., 27, 37, 325, 425, 492, 655Craig, John, 87, 116Cram´ er, Harald, 317, 329, 511, 562, 669, 673
Crick, Francis, 139
Cromwell, Oliver, 306Crow, Edwin L., 526
Darwin, Charles, 312
Davis, Frances A., 526Dawid, Philip A., 470de Finetti, Bruno, 37, 279, 317, 372, 425, 453, 464,
653
de Groot, Morrie, 248, 420de Morgan, Augustus, 198, 214, 316
de Moivre, Abraham, 112
Dirac, Paul Adrien Maurice, 667Dyson, Freeman J., 668
Edwards, Anthony W. F., 251, 335
Edwards, Harold M., 665
Einstein, Albert, 132, 135, 139, 229
Elias, Peter, 439Ellis, Robert Leslie, 315Euclid, 656Euler, Leonhard, 203, 589
Fechner, Gustav Theodor, 92
Feller, William, 69, 88, 94, 211, 268, 321, 329, 404,
464, 466, 492, 505, 525, 663
Fermat, Pierre de, 315
Fine, Terrence L., 657Fisher, Sir Ronald Aylmer, 45, 150, 175, 197, 211,
243, 251, 253, 279, 315, 405, 492, 493
Fitts, Gary, 440, 442Folks, Leroy, 251
Fraser, D. A. S., 251, 378, 470, 478
Galileo Galilei, 672
Galton, Sir Francis, 227, 239
721

<<<PAGE 754>>>

722 Author index
Gardner, Martin, 197
Gauss, Carl Friedrich, 84, 204, 230, 315, 451, 485Geisser, Seymour, 479, 496Gell-Mann, Murray, 673Gibbs, J. Willard, 315, 332, 674Glymour, Clark N., 97Gnedenko, Boris Vladimirovich, 386G¨odel, Kurt, 45, 422, 423
Goldstein, Herbert, 318Good, Irving John, 93, 116, 119, 125, 144, 317Gossett, William Sealey (aka Student), 495Gould, Stephen J., 196, 232Graunt, John, 306Grosser, Morton, 134
Haldane, John Burdon Sanderson, 166, 575
Halley, Edmund, 307Hamilton, John Barkley, 16Hansel, Charles Edward Mark, 126Hansen, William W., 193, 439Hardy, Godfrey Harold, 668, 671Harr, Alfr´ ed, 377
Hartigan, John A., 378Hausdorff, Felix, 672Hedges, Larry V ., 257Helmholtz, Hermann von, 490, 503Hempel, Carl Gustav, 143Hermite, Charles, 668Herschel, Sir John Frederick William, 134, 200Hill, Bruce, 456
Hipparchus, 203
Hirsch, Warren M., 404
Holmes, Sherlock, 62Howson, Cowlin, 126Hoyt, William G., 139Hume, David, 279, 310, 499Hurwicz, Leonid, 407
Huzurbazar, Vasant Shankar, 494
Jaynes, Edwin Thompson, 374
Jeans, Sir James, 494Jefferson, Thomas, 372Jeffrey, Richard C., 139Jeffreys, Sir Harold, 37, 135, 155, 166, 206, 243, 251,
279, 316, 326, 377, 383, 472, 478, 479, 492, 493,496, 524, 566
Jevons, William S., 316Johnson, Rodney W., 97Johnson, William Ernes, 155, 279Johnson-Laird, Philip N., 132
Kac, Mark, 664
Kadane, Joseph B., 453Kahneman, Daniel, 128, 132Kempthorne, Oscar, 251Kendall, Sir Maurice, 88, 386, 387, 404, 492Kepler, Johannes, 503Keynes, John Maynard, 10, 17, 37, 40, 118, 206, 211,
233, 493
Kline, Morris, 451, 665, 673, 674Kolmogorov, Andrei Nikolaevich, 49, 466, 651
Kronecker, Leopold, 665Kurtz, Paul, 126
Landon, Vernon D., 204
Lane, David, 496
Laplace, Pierre Simon, 9, 24, 42, 44, 84, 112, 124,
136, 155, 204, 230, 243, 279, 314, 315, 321, 336,377, 399, 492, 589
Lebesgue, Henri L´ eon, 668
Legendre, Adrien Marie, 315Lehmann, Erich Leo, 510Leverrier, Urbain Jean Joseph, 134, 138Lighthill, Sir Michael James, 668Lincoln, Abraham, 659Lindley, Dennis Victor, 120, 479, 561Lovecraft, Howard Phillips, 196Lowell, Percival, 139
McTaggart, John McTaggart Ellis, 671
Maxﬁeld, Margaret W., 526Maxwell, James Clerk, 4, 201, 315, 655
Mendel, Gregor, 139
Middleton, David, 404, 426, 510, 670Misner, Charles, 146
Moran, Patrick Alfred Pierce, 386, 387
Morgenstern, Oskar, 407Moses, Lincoln E., 374, 400, 419, 420, 514Mosteller, Frederick, 386
Newton, Sir Isaac, 139, 306
Neyman, Jerzy, 204, 404, 492, 495, 496, 673
Northrop, Eugene P., 386Nostradamus, Michael, 478Nyquist, Harry, 207, 521
Olkin, Ingram, 257
Orwell, George, 328
Pascal, de Blaise, 315
Pasteur, Louis, 503Peano, Giuseppe, 116, 560
Pearson, Egon Sharpe, 404
Pearson, Karl, 230, 495Penrose, Oliver, 60
Poincar` e, Henri, 116, 316, 333, 337, 378, 386, 387,
560, 670, 672
Poisson, Simeon Denis, 315P´olya, George, 6, 37, 134, 138, 242, 268
Pontryagin, Lev Semenovich, 377Popper, Karl, 61, 276, 310, 326, 499
Pratt, John W., 117Press, William H., 57
Quetelet, Adolphe, 235, 239Ramanujan, Srinivasa Ramanujan Aiyangar, 422
Reid, Constance, 496Rescher, Nichola, 5Rosenkrantz, Roger D., 37

<<<PAGE 755>>>

Author index 723
Routh, Edward John, 318
Ruelle, David, 118Russell, Bertrand, 116, 560, 672
Savage, Leonard J., 186, 335, 400, 407, 420, 492, 552,
657, 672, 674
Schaefer, Brad, 139Schervish, Mark J., 453Schwartz, Laurent, 667Seidenfeld, Teddy, 453Shannon, Claude Elwood, 521
Shewhart, Walter Andrew, 114Siegert, Arnold, 431
Simon, Herbert A., 5, 404, 438, 510Smart, William Marshall, 134Smith, Adam, 233Soal, Samuel George, 120, 126Sommerfeld, Arnold, 667Stewart, Gloria, 120Stigler, Stephen M., 92, 116, 490, 499Stone, Mervyn, 378, 455, 470Stove, David Charles, 310Stuart, Alan, 88Sz´ekely, G´ ebor J., 451
Tax, Sol, 232
Tell, William, 416Temple, George, 668
Titchmarsh, Edward Charles, 669, 671
Titterington, Donald Michael, 238Tombaugh, Clyde, 139Tribus, Myron, 25, 37, 116, 440, 442Tukey, John W., 505Turing, Alan, 116Tutankhamen, 659
Tversky, Amos, 128, 132
Ulam, Stanslaw, 6
Urbach, Peter, 126
Uspensky, James Victor, 386
Valavanis, Stefan, 514
Venn, John, 204, 279, 315, 495
von Mises, Richard, 386, 492von Neumann, John, 7, 22, 407
Wald, Abraham, 404, 425, 438
Wason, Peter Cathcart, 132Watson, George Neville, 452Watson, James D., 659Wegener, Alfred, 139Weierstraz, Karl, 665Weldon, Walter Frank Raphael, 230, 335Weyl, Hermann, 378, 389, 672, 673Whitehead, North Whitehead, 116, 132Whittaker, Edmund Taylor, 452Whyte, Anthony J., 139Wiener, Norbert, 509Wigner, Eugene Paul, 332, 377, 378, 389Wilks, Samuel Stanley, 673William of Ockham, 613Wolf, Rudolf, 334Wolpert, Robert, 251Wrinch, Dorothy, 155
Zabel, Sandy L., 155, 316, 499
Zellner, Arnold, 423, 497Zidek, James, V ., 470

<<<PAGE 756>>>

Subject index
a-priori probabilities, 87
accuracy of computations, 224adequate sets, 13, 34, 35, 652admissibility, 408alternative hypotheses, 135ambiguity of probabilistic notation, 472Ames room, 132ancillary information, 253angular momentum, 318archaeologist, 62Aristotelian logic, 9, 23Aristotelian proposition, 9, 146arrogance of the uninformed, 338aurora borealis, 524automobile seat belts, 126autoregressive model, 80
backward inference, 80
barber paradox, 672basic desiderata, 17Bayesian intervals, 673Bayesian jurisprudence, 144Bayesian periodicity analysis, 526Bernoulli trials, 163Bernoulli urn, 52betting, 655bias, 412bills of mortality, 305binary experiment, 164binary hypothesis testing, 90binomial identities, 69binomial monkey prior, 160biology, 327Biometrika , 230
black crows, 143Boolean algebra, 9, 166, 464Borel–Kolmogorov paradox, 110, 467,
654
Bourbakist, 452bridge hands, 321business transactions, 421
caloric theory, 146
Canadian rat, 608canonical inverse, 594
Cauchy distribution, 502causal dependence, 92
causative factor, 327
chain consistency, 259
change-point problem, 474cheating, 317chi-squared test, 135clever tricks, 73, 267coherence, 373, 425, 655coin, biased, 318, 320common language, 21common sense, 29comparative probability, 656comparative theories, 20complete class theorem, 408, 415complete ignorance, 113, 376composite hypotheses, 114conditionality principle, 251
conﬁdence intervals, 673
conjugate prior, 481conjunction, 10consistency, 65, 101, 108continuous hypotheses, 107convergence of opinions, 127convolutions, 677Copenhagen interpretation, 328correlations, 75countable additivity, 466Cox’s theorems, 117, 143, 486, 657Cramer–Rao inequality, 412
criminal behavior, 422
cumulants, 677
Darwin–Fowler method, 440
Darwinian evolution, 229de Finetti system, 655
de Finetti theorem, 337
deception, 123, 128
decibel, 91
decision theory, 96, 405, 427, 591delta-functions, 111denial, 10desiderata, 26
724

<<<PAGE 757>>>

Subject index 725
direct probabilities, 84
disaster mongers, 504disjunction, 10disjunctive normal form, 15, 34divergence of opinions, 127, 131divine providence, 136Dreyfus affair, 127drug, unsafe, 130
education, 658
efﬁciency, 520efﬁcient estimator, 377, 412eigenvector, 78electrical noise, 205elves and pixies, 196Emperor of China fallacy, 258,
337
entropy, 121enzymes, 327epistemological, 22equally likely outcome, 322equations of condition, 664Establishment, 330, 405evidence, 91evolution, 316exchangeable distribution, 62exchangable sequences, 663exchangeability, 81
exchangeable, 620
expectation, 66expert witnesses, 197
exploratorium, 132
extrasensory perception, 119, 301
false correlations, 535
feasible set, 595
ﬁne-grained propositions, 261
ﬁnite additivity, 464ﬁnite-sets policy, 43Fisher information matrix, 257ﬂuctuation-dissipation theorems, 232Fredholm integral equation, 482frequency interpretation, 315fundamental domain, 332future theories, 423
gamesmanship, 267
Gauss hypergeometric function, 56
Gaussian distribution, 494, 501
G¨odel’s theorem, 83
grass, 205group invariance, 40
Hanbury Brown–Twiss interferometer, 206
Hausdorff sphere paradox, 672, 674
Hermite polynomials, 237Hilbert space, 483
Huygens principle, 428hypergeometric binomial limit, 70hypergeometric distribution, 56, 59, 67, 68, 95, 150ideology, 332
ignorance priors, 372implication, 12improper prior, 487independence of tosses, 335indeterminacy, 328induction, 310, 326industrial quality control, 326inequality of Jupiter and Saturn, 203, 234inﬁnite population, 82inﬁnite regress, 324inﬂation, 126insurance, 400intuition, 40irrationalists, 310irreversible process, 80
jackknife, 174
Jeffreys’ prior, 422
Kelvin temperatures, 43
Kolmogorov system, 651
labor mediator, 421
Lagrangian, 334lattice theory, 657, 658law of large numbers, 337Lebesgue–Stieltjes notation, 111likelihood, 89
without credence, 196
likelihood principle, 250, 505
likelihood ratio, 90limb sawing, 659Lindemann’s theorem, 143Liouville’s theorem, 332location parameter, 491logic function, 13logical dependence, 92logistic, 116, 560loss function, 415, 421, 430
magniﬁcation, 659
marginal posterior pdf, 481
marginalization paradox, 166, 244, 470Markov chain, 77
Markovian approximation, 80matched ﬁlter, 439
maximum entropy, 373
maximum likelihood, 175
estimate, 414
Maxwellian velocity distribution, 494
Maxwell’s demon, 206
measure zero, 469mechanics under the clouds, 329medical malpractice, 146medical testing, 325
medicine, 327
Mengenlehre, 672meta-analysis, 257meteorites, 124

<<<PAGE 758>>>

726 Subject index
midparent, 227
mind projection fallacy, 22, 23, 74, 83, 92, 108, 131,
212, 315, 411
mind projection mythology, 608minimax criterion, 431, 435
minimax strategies, 407miracles, 124moments of binomial distribution, 295morality, 424mottled soap, 671moving average, 521multidimensional theories, 20
multiple hypothesis testing, 98, 103
multiple-valued logic, 23
multiplicity, 55Murphy’s law, 203
NAND, 16
National Bureau of Standards, 573natural selection, 133Neptune, discovery of, 134news reports and the media, 128, 156,
504
newspeak, 328Newtonian theory, 147
Neyman–Pearson criterion, 436
Neyman–Pearson theory, 431noble-sounding names, 409non-Aristotelian proposition, 146nonconglomerability, 453, 659nonsense, 423
NOR, 16
normal approximations, 122notation, 55nuisance parameter, 527null hypothesis, 524numerical values, 37Nyquist noise, 207, 609
objective, 45
objectivity, 86ontological, 22optical illusions, 133optional stopping, 96, 166ordinary least squares estimate, 609original sin, 673orthodox statistics, 316
paradox, 451
barber, 672Borel–Kolmogorov, 110, 467, 654
Emperor of China, 258, 337Hausdorff sphere, 672, 674of intuition, 144marginalization, 244mass production of, 485
parameter estimation, 409
parlor game, 452
partition function, 659pathological, exceptional cases, 192penguins, 48
periodicity, 520photoelectric effect, 327
physical probabilities, 319, 324, 327, 330physical reality, 328Pitman–Koopman theorem, 247Pluto, 139Poisson distribution, 170polhodes, 318pooled data, 260population dynamics, 229post-data question, 502
posterior odds, 90
posterior probability, 89pre-data question, 500, 501pre-ﬁltered data, 521predicate calculus, 23predictive probability, 463Principia Mathematica , 560
principle of indifference, 40, 386, 387, 395,
573
principle of maximum entropy, 207prior information, 88, 267, 484prior odds, 90prior probability, 87, 420
probability, 41
and frequency, 67
product rule, 26, 29, 34propensity vs. logic, 60propositional calculus, 23pseudoproblem, 485psychokinesis, 92, 167psychological tests, 132psychology
of concealing sin, 466of easy success, 487
of perpetuated errors, 451
public health education, 326purpose in Nature, 231
quantum theory, 327
quarantine, 673
random drawing, 74
random experiments, 324
random variables, 500
random walk, 459randomization, 73redescending psi function, 174redundant information, 166resurrection of dead hypotheses, 104,
134
risk, 408robot, 9, 86, 87, 92, 94, 96, 99, 406,
409
robustness, 174
rock classiﬁcation, 658
Rothamsted, 494Royal Society, 306
rule of succession, 155, 279, 339

<<<PAGE 759>>>

Subject index 727
sample re-use, 264
sampling distribution, 84sampling theory, 51sampling with replacement, 72Sam’s broken thermometer, 654scientiﬁc inference, 84semiliterate, 339set of all integers, 672shortest conﬁdence interval, 377sigma-ﬁeld, 651signiﬁcance test, 84, 137, 521, 523
sociology of science, 147Solvay Congress, 329soteriology, 147
sound propagation, 62spilled milk, 195spooks, 325St Malo, 195St Petersburg game, 399
state of Nature, 405, 409, 423statistical inference, 409statistician, 316strategy, 408strong domination, 407strong inconsistency, 455subjective, 44
Bayesian, 372
sufﬁciency, 245
and information, 428
sufﬁcient statistic, 245sum rule, 30, 34syllogism, 4, 133symmetry, 323, 331
arguments, 331equations, 40
systematic error, 258taxicab problem, 190
Tchebycheff inequality, 186temperature scales, 42tetrahedra, 459transformation equations, 39transformation group, 372, 380transitivity, 407, 656truth table, 13truth value, 10Turing machines, 16two-valued logic, 23types, theory of, 560
unbiased estimator, 377, 511
pathology, 516
unbiased minimum variance,
412
undecidability, 47uninformative priors, 485universal comparability, 656urn, contents of, 155utility of money, 399, 424
value judgment, 146
Venn diagram, 47, 261, 651
Venus, 329vested interest, 327viruses, 327visual perception, 132vitamins, 327
warfare between science and theology,
324
weather forecaser, 142, 402Weber–Fechner law, 95widget problem, 440