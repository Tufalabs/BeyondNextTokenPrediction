
<<<PAGE 1>>>



<<<PAGE 2>>>



<<<PAGE 3>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Quantum Computing for Computer Scientists
The multidisciplinary ﬁeld of quantum computing strives to exploit some
of the uncanny aspects of quantum mechanics to expand our computa-tional horizons. Quantum Computing for Computer Scientists takes read-
ers on a tour of this fascinating area of cutting-edge research. Writtenin an accessible yet rigorous fashion, this book employs ideas and tech-niques familiar to every student of computer science. The reader is not
expected to have any advanced mathematics or physics background. Af-
ter presenting the necessary prerequisites, the material is organized tolook at different aspects of quantum computing from the speciﬁc stand-
point of computer science. There are chapters on computer architecture,
algorithms, programming languages, theoretical computer science, cryp-tography, information theory, and hardware. The text has step-by-step
examples, more than two hundred exercises with solutions, and program-
ming drills that bring the ideas of quantum computing alive for today’scomputer science students and researchers.
Noson S. Yanofsky, PhD, is an Associate Professor in the Department
of Computer and Information Science at Brooklyn College, City Univer-
sity of New York and at the PhD Program in Computer Science at TheGraduate Center of CUNY.
Mirco A. Mannucci, PhD, is the founder and CEO of HoloMathics, LLC,
a research and development company with a focus on innovative mathe-
matical modeling. He also serves as Adjunct Professor of Computer Sci-
ence at George Mason University and the University of Maryland.
i

<<<PAGE 4>>>



<<<PAGE 5>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
QUANTUM COMPUTING FOR
COMPUTER SCIENTISTS
Noson S. Yanofsky
Brooklyn College, City University of New York
and
Mirco A. Mannucci
HoloMathics, LLC
iii

<<<PAGE 6>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
cambridge university press
Cambridge, New York, Melbourne, Madrid, Cape Town, Singapore, S ˜ao Paulo, Delhi
Cambridge University Press
32 Avenue of the Americas, New York, NY 10013-2473, USA
www.cambridge.org
Information on this title: www.cambridge.org/9780521879965
C/circlecopyrtNoson S. Yanofsky and Mirco A. Mannucci 2008
This publication is in copyright. Subject to statutory exceptionand to the provisions of relevant collective licensing agreements,no reproduction of any part may take place withoutthe written permission of Cambridge University Press.
First published 2008Printed in the United States of AmericaA catalog record for this publication is available from the British Library.Library of Congress Cataloging in Publication dataYanofsky, Noson S., 1967–
Quantum computing for computer scientists / Noson S. Yanofsky andMirco A. Mannucci.
p. cm.
Includes bibliographical references and index.ISBN 978-0-521-87996-5 (hardback)1. Quantum computers. I. Mannucci, Mirco A., 1960– II. Title.
QA76.889.Y35 2008
004.1–dc22 2008020507
ISBN 978-0-521-879965 hardbackCambridge University Press has no responsibility for
the persistence or accuracy of URLs for external orthird-party Internet Web sites referred to in this publicationand does not guarantee that any content on suchWeb sites is, or will remain, accurate or appropriate.
iv

<<<PAGE 7>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Dedicated to
Moishe and Sharon Yanofsky
and
to the memory of
Luigi and Antonietta Mannucci
v

<<<PAGE 8>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Wisdom is one thing: to know the thought by which
all things are directed through all things.
˜
Heraclitus of Ephesus (535–475 BCE)
as quoted in Diogenes Laertius’s
Lives and Opinions of Eminent Philosophers
Book IX, 1.
vi

<<<PAGE 9>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Contents
Preface xi
1 Complex Numbers 7
1.1 Basic Deﬁnitions 8
1.2 The Algebra of Complex Numbers 10
1.3 The Geometry of Complex Numbers 15
2 Complex Vector Spaces 29
2.1Cnas the Primary Example 30
2.2 Deﬁnitions, Properties, and Examples 34
2.3 Basis and Dimension 45
2.4 Inner Products and Hilbert Spaces 53
2.5 Eigenvalues and Eigenvectors 60
2.6 Hermitian and Unitary Matrices 62
2.7 Tensor Product of Vector Spaces 66
3 The Leap from Classical to Quantum 74
3.1 Classical Deterministic Systems 74
3.2 Probabilistic Systems 79
3.3 Quantum Systems 88
3.4 Assembling Systems 97
4 Basic Quantum Theory 103
4.1 Quantum States 103
4.2 Observables 115
4.3 Measuring 126
4.4 Dynamics 129
4.5 Assembling Quantum Systems 132
5 Architecture 138
5.1 Bits and Qubits 138
vii

<<<PAGE 10>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
viii Contents
5.2 Classical Gates 144
5.3 Reversible Gates 151
5.4 Quantum Gates 158
6 Algorithms 170
6.1 Deutsch’s Algorithm 171
6.2 The Deutsch–Jozsa Algorithm 179
6.3 Simon’s Periodicity Algorithm 187
6.4 Grover’s Search Algorithm 195
6.5 Shor’s Factoring Algorithm 204
7 Programming Languages 220
7.1 Programming in a Quantum World 220
7.2 Quantum Assembly Programming 221
7.3 Toward Higher-Level Quantum Programming 230
7.4 Quantum Computation Before Quantum Computers 237
8 Theoretical Computer Science 239
8.1 Deterministic and Nondeterministic Computations 239
8.2 Probabilistic Computations 246
8.3 Quantum Computations 251
9 Cryptography 262
9.1 Classical Cryptography 262
9.2 Quantum Key Exchange I: The BB84 Protocol 268
9.3 Quantum Key Exchange II: The B92 Protocol 273
9.4 Quantum Key Exchange III: The EPR Protocol 275
9.5 Quantum Teleportation 277
10 Information Theory 284
10.1 Classical Information and Shannon Entropy 284
10.2 Quantum Information and von Neumann Entropy 288
10.3 Classical and Quantum Data Compression 295
10.4 Error-Correcting Codes 302
11 Hardware 305
11.1 Quantum Hardware: Goals and Challenges 306
11.2 Implementing a Quantum Computer I: Ion Traps 31111.3 Implementing a Quantum Computer II: Linear Optics 313
11.4 Implementing a Quantum Computer III: NMR
and Superconductors 315
11.5 Future of Quantum Ware 316
Appendix A Historical Bibliography of Quantum Computing 319
by Jill Cirasella
A.1 Reading Scientiﬁc Articles 319
A.2 Models of Computation 320

<<<PAGE 11>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Contents ix
A.3 Quantum Gates 321
A.4 Quantum Algorithms and Implementations 321
A.5 Quantum Cryptography 323
A.6 Quantum Information 323
A.7 More Milestones? 324
Appendix B Answers to Selected Exercises 325
Appendix C Quantum Computing Experiments with MATLAB 351
C.1 Playing with Matlab 351
C.2 Complex Numbers and Matrices 351
C.3 Quantum Computations 354
Appendix D Keeping Abreast of Quantum News: Quantum
Computing on the Web and in the Literature 357
by Jill Cirasella
D.1 Keeping Abreast of Popular News 357
D.2 Keeping Abreast of Scientiﬁc Literature 358
D.3 The Best Way to Stay Abreast? 359
Appendix E Selected Topics for Student Presentations 360
E.1 Complex Numbers 361
E.2 Complex Vector Spaces 362
E.3 The Leap from Classical to Quantum 363
E.4 Basic Quantum Theory 364
E.5 Architecture 365
E.6 Algorithms 366
E.7 Programming Languages 368
E.8 Theoretical Computer Science 369
E.9 Cryptography 370
E.10 Information Theory 370
E.11 Hardware 371
Bibliography 373
Index 381

<<<PAGE 12>>>



<<<PAGE 13>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Preface
Quantum computing is a fascinating new ﬁeld at the intersection of computer sci-
ence, mathematics, and physics, which strives to harness some of the uncanny as-pects of quantum mechanics to broaden our computational horizons. This book
presents some of the most exciting and interesting topics in quantum computing.
Along the way, there will be some amazing facts about the universe in which we liveand about the very notions of information and computation.
The text you hold in your hands has a distinct ﬂavor from most of the other cur-
rently available books on quantum computing. First and foremost, we do not assumethat our reader has much of a mathematics or physics background. This book shouldbe readable by anyone who is in or beyond their second year in a computer science
program. We have written this book speciﬁcally with computer scientists in mind,
and tailored it accordingly: we assume a bare minimum of mathematical sophistica-tion, a ﬁrst course in discrete structures, and a healthy level of curiosity. Because this
text was written speciﬁcally for computer people, in addition to the many exercises
throughout the text, we added many programming drills. These are a hands-on, funway of learning the material presented and getting a real feel for the subject.
The calculus-phobic reader will be happy to learn that derivatives and integrals
are virtually absent from our text. Quite simply, we avoid differentiation, integra-tion, and all higher mathematics by carefully selecting only those topics that arecritical to a basic introduction to quantum computing. Because we are focusing on
the fundamentals of quantum computing, we can restrict ourselves to the ﬁnite-
dimensional mathematics that is required. This turns out to be not much more thanmanipulating vectors and matrices with complex entries. Surprisingly enough, the
lion’s share of quantum computing can be done without the intricacies of advanced
mathematics.
Nevertheless, we hasten to stress that this is a technical textbook. We are not
writing a popular science book, nor do we substitute hand waving for rigor or math-ematical precision.
Most other texts in the ﬁeld present a primer on quantum mechanics in all its
glory. Many assume some knowledge of classical mechanics. We do not make these
assumptions. We only discuss what is needed for a basic understanding of quantum
xi

<<<PAGE 14>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
xii Preface
computing as a ﬁeld of research in its own right, although we cite sources for learning
more about advanced topics.
There are some who consider quantum computing to be solely within the do-
main of physics. Others think of the subject as purely mathematical. We stress the
computer science aspect of quantum computing.
It is not our intention for this book to be the deﬁnitive treatment of quantum
computing. There are a few topics that we do not even touch, and there are severalothers that we approach brieﬂy, not exhaustively. As of this writing, the bible ofquantum computing is Nielsen and Chuang’s magniﬁcent Quantum Computing and
Quantum Information (2000). Their book contains almost everything known about
quantum computing at the time of its publication. We would like to think of ourbook as a useful ﬁrst step that can prepare the reader for that text.
FEATURES
This book is almost entirely self-contained. We do not demand that the reader come
armed with a large toolbox of skills. Even the subject of complex numbers, which is
taught in high school, is given a fairly comprehensive review.
The book contains many solved problems and easy-to-understand descriptions.
We do not merely present the theory; rather, we explain it and go through severalexamples. The book also contains many exercises, which we strongly recommendthe serious reader should attempt to solve. There is no substitute for rolling up one’s
sleeves and doing some work!
We have also incorporated plenty of programming drills throughout our text.
These are hands-on exercises that can be carried out on your laptop to gain a better
understanding of the concepts presented here (they are also a great way of hav-
ing fun). We hasten to point out that we are entirely language-agnostic. The stu-
dent should write the programs in the language that feels most comfortable. Weare also paradigm-agnostic. If declarative programming is your favorite method, go
for it. If object-oriented programming is your game, use that. The programming
drills build on one another. Functions created in one programming drill will be usedand modiﬁed in later drills. Furthermore, in Appendix C, we show how to make
little quantum computing emulators with MATLAB or how to use a ready-made
one. (Our choice of MATLAB was dictated by the fact that it makes very easy-to-build, quick-and-dirty prototypes, thanks to its vast amount of built-in mathematicaltools.)
This text appears to be the ﬁrst to handle quantum programming languages in a
signiﬁcant way. Until now, there have been only research papers and a few surveyson the topic. Chapter 7 describes the basics of this expanding ﬁeld: perhaps some of
our readers will be inspired to contribute to quantum programming!
This book also contains several appendices that are important for further study:/D2Appendix A takes readers on a tour of major papers in quantum computing.
This bibliographical essay was written by Jill Cirasella, Computational SciencesSpecialist at the Brooklyn College Library. In addition to having a master’s de-
gree in library and information science, Jill has a master’s degree in logic, for
which she wrote a thesis on classical and quantum graph algorithms. This dualbackground uniquely qualiﬁes her to suggest and describe further readings.

<<<PAGE 15>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Preface xiii/D2Appendix B contains the answers to some of the exercises in the text. Other
solutions will also be found on the book’s Web page. We strongly urge students
to do the exercises on their own and then check their answers against ours./D2Appendix C uses MATLAB, the popular mathematical environment and an es-
tablished industry standard, to show how to carry out most of the mathematicaloperations described in this book. MATLAB has scores of routines for manip-
ulating complex matrices: we brieﬂy review the most useful ones and show how
the reader can quickly perform a few quantum computing experiments with al-most no effort, using the freely available MATLAB quantum emulator Quack./D2Appendix D, also by Jill Cirasella, describes how to use online resources to keepup with developments in quantum computing. Quantum computing is a fast-moving ﬁeld, and this appendix offers guidelines and tips for ﬁnding relevant
articles and announcements./D2Appendix E is a list of possible topics for student presentations. We give brief
descriptions of different topics that a student might present before a class of hispeers. We also provide some hints about where to start looking for materials to
present.
ORGANIZATION
The book begins with two chapters of mathematical preliminaries. Chapter 1 con-
tains the basics of complex numbers, and Chapter 2 deals with complex vectorspaces. Although much of Chapter 1 is currently taught in high school, we feel thata review is in order. Much of Chapter 2 will be known by students who have had a
course in linear algebra. We deliberately did not relegate these chapters to an ap-
pendix at the end of the book because the mathematics is necessary to understandwhat is really going on. A reader who knows the material can safely skip the ﬁrst
two chapters. She might want to skim over these chapters and then return to them
as a reference, using the index and the table of contents to ﬁnd speciﬁc topics.
Chapter 3 is a gentle introduction to some of the ideas that will be encountered
throughout the rest of the text. Using simple models and simple matrix multipli-cation, we demonstrate some of the fundamental concepts of quantum mechanics,which are then formally developed in Chapter 4. From there, Chapter 5 presentssome of the basic architecture of quantum computing. Here one will ﬁnd the notions
of a qubit (a quantum generalization of a bit) and the quantum analog of logic gates.
Once Chapter 5 is understood, readers can safely proceed to their choice of
Chapters 6 through 11. Each chapter takes its title from a typical course offered in acomputer science department. The chapters look at that subﬁeld of quantum com-
puting from the perspective of the given course. These chapters are almost totallyindependent of one another. We urge the readers to study the particular chapter
that corresponds to their favorite course. Learn topics that you like ﬁrst. From there
proceed to other chapters.
Figure 0.1 summarizes the dependencies of the chapters.One of the hardest topics tackled in this text is that of considering two quan-
tum systems and combining them, or “entangled” quantum systems. This is donemathematically in Section 2.7. It is further motivated in Section 3.4 and formallypresented in Section 4.5. The reader might want to look at these sections together.

<<<PAGE 16>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
xiv Preface
Figure 0.1. Chapter dependencies.
There are many ways this book can be used as a text for a course. We urge
instructors to ﬁnd their own way. May we humbly suggest the following three plans
of action:
(1) A class that provides some depth might involve the following: Go through
Chapters 1, 2, 3, 4, and 5. Armed with that background, study the entirety of Chapter6 (“Algorithms”) in depth. One can spend at least a third of a semester on that
chapter. After wrestling a bit with quantum algorithms, the student will get a goodfeel for the entire enterprise.
(2) If breadth is preferred, pick and choose one or two sections from each of
the advanced chapters. Such a course might look like this: (1), 2, 3, 4.1, 4.4, 5, 6.1,7.1, 9.1, 10.1, 10.2, and 11. This will permit the student to see the broad outline ofquantum computing and then pursue his or her own path.
(3) For a more advanced class (a class in which linear algebra and some mathe-
matical sophistication is assumed), we recommend that students be told to readChapters 1, 2, and 3 on their own. A nice course can then commence with Chapter 4
and plow through most of the remainder of the book.
If this is being used as a text in a classroom setting, we strongly recommend that
the students make presentations. There are selected topics mentioned in AppendixE. There is no substitute for student participation!
Although we have tried to include many topics in this text, inevitably some oth-
ers had to be left out. Here are a few that we omitted because of space considera-
tions:/D2many of the more complicated proofs in Chapter 8,/D2results about oracle computation,/D2the details of the (quantum) Fourier transforms, and/D2the latest hardware implementations.
We give references for further study on these, as well as other subjects, throughout
the text.

<<<PAGE 17>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Preface xv
ANCILLARIES
We are going to maintain a Web page for the text at
www. sci.br ookl yn .cuny.edu/∼noson/ qctext .html/
The Web page will contain/D2periodic updates to the book,/D2links to interesting books and articles on quantum computing,/D2some answers to certain exercises not solved in Appendix B, and/D2errata.
The reader is encouraged to send any and all corrections to
noson@sci .br ookl yn .cuny.edu
Help us make this textbook better!
ACKNOLWEDGMENTS
Both of us had the great privilege of writing our doctoral theses under the gentle
guidance of the recently deceased Alex Heller. Professor Heller wrote the follow-
ing1about his teacher Samuel “Sammy” Eilenberg and Sammy’s mathematics:
As I perceived it, then, Sammy considered that the highest value in mathematics
was to be found, not in specious depth nor in the overcoming of overwhelming
difﬁculty, but rather in providing the deﬁnitive clarity that would illuminate itsunderlying order.
This never-ending struggle to bring out the underlying order of mathematical
structures was always Professor Heller’s everlasting goal, and he did his best to pass
it on to his students. We have gained greatly from his clarity of vision and his viewof mathematics, but we also saw, embodied in a man, the classical and sober ideal of
contemplative life at its very best. We both remain eternally grateful to him.
While at the City University of New York, we also had the privilege of inter-
acting with one of the world’s foremost logicians, Professor Rohit Parikh, a man
whose seminal contributions to the ﬁeld are only matched by his enduring com-
mitment to promote younger researchers’ work. Besides opening fascinating vis-
tas to us, Professor Parikh encouraged us more than once to follow new directionsof thought. His continued professional and personal guidance are greatly appre-
ciated.
We both received our Ph.D.’s from the Department of Mathematics in The
Graduate Center of the City University of New York. We thank them for providingus with a warm and friendly environment in which to study and learn real mathemat-
ics. The ﬁrst author also thanks the entire Brooklyn College family and, in partic-ular, the Computer and Information Science Department for being supportive andvery helpful in this endeavor.
1See page 1349 of Bass et al. (1998).

<<<PAGE 18>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
xvi Preface
Several faculty members of Brooklyn College and The Graduate Center were
kind enough to read and comment on parts of this book: Michael Anshel, David
Arnow, Jill Cirasella, Dayton Clark, Eva Cogan, Jim Cox, Scott Dexter, Edgar
Feldman, Fred Gardiner, Murray Gross, Chaya Gurwitz, Keith Harrow, JunHu, Yedidyah Langsam, Peter Lesser, Philipp Rothmaler, Chris Steinsvold, AlexSverdlov, Aaron Tenenbaum, Micha Tomkiewicz, Al Vasquez, Gerald Weiss, and
Paula Whitlock. Their comments have made this a better text. Thank you all!
We were fortunate to have had many students of Brooklyn College and The
Graduate Center read and comment on earlier drafts: Shira Abraham, RachelAdler, Ali Assarpour, Aleksander Barkan, Sayeef Bazli, Cheuk Man Chan, Wei
Chen, Evgenia Dandurova, Phillip Dreizen, C. S. Fahie, Miriam Gutherc, RaveHarpaz, David Herzog, Alex Hoffnung, Matthew P. Johnson, Joel Kammet, Serdar
Kara, Karen Kletter, Janusz Kusyk, Tiziana Ligorio, Matt Meyer, James Ng, Severin
Ngnosse, Eric Pacuit, Jason Schanker, Roman Shenderovsky, Aleksandr Shnayder-man, Rose B. Sigler, Shai Silver, Justin Stallard, Justin Tojeira, John Ma Sang Tsang,Sadia Zahoor, Mark Zelcer, and Xiaowen Zhang. We are indebted to them.
Many other people looked over parts or all of the text: Scott Aaronson, Ste-
fano Bettelli, Adam Brandenburger, Juan B. Climent, Anita Colvard, Leon Ehren-preis, Michael Greenebaum, Miriam Klein, Eli Kravits, Raphael Magarik, John
Maiorana, Domenico Napoletani, Vaughan Pratt, Suri Raber, Peter Selinger, Evan
Siegel, Thomas Tradler, and Jennifer Whitehead. Their criticism and helpful ideasare deeply appreciated.
Thanks to Peter Rohde for creating and making available to everyone his MAT-
LAB q-emulator Quack and also for letting us use it in our appendix. We had a gooddeal of fun playing with it, and we hope our readers will too.
Besides writing two wonderful appendices, our friendly neighborhood librar-
ian, Jill Cirasella, was always just an e-mail away with helpful advice and support.Thanks, Jill!
A very special thanks goes to our editor at Cambridge University Press, Heather
Bergman, for believing in our project right from the start, for guiding us through thisbook, and for providing endless support in all matters. This book would not existwithout her. Thanks, Heather!
We had the good fortune to have a truly stellar editor check much of the text
many times. Karen Kletter is a great friend and did a magniﬁcent job. We also ap-preciate that she refrained from killing us every time we handed her altered draftsthat she had previously edited.
But, of course, all errors are our own!
This book could not have been written without the help of my daughter, Hadas-
sah. She added meaning, purpose, and joy.
N.S.Y.
My dear wife, Rose, and our two wondrous and tireless cats, Ursula and Buster,
contributed in no small measure to melting my stress away during the long and
painful hours of writing and editing: to them my gratitude and love. (Ursula is a
scientist cat and will read this book. Buster will just shred it with his powerful claws.)
M.A.M.

<<<PAGE 19>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Introduction
THE FEATURES OF THE QUANTUM WORLD
In order to learn quantum computing, it is ﬁrst necessary to become familiar with
some basic facts about the quantum world. In this introduction, some unique fea-
tures of quantum mechanics are introduced, as well as the way they inﬂuence the
tale we are about to tell.2
From Real Numbers to Complex Numbers
Quantum mechanics is different from most other branches of science in that it uses
complex numbers in a fundamental way. Complex numbers were originally created
as a mathematical curiosity: i=√
−1 was the asserted “imaginary” solution to the
polynomial equation x2=−1. As time went on, an entire mathematical ediﬁce was
constructed with these “imaginary” numbers. Complex numbers have kept lonely
mathematicians busy for centuries, while physicists successfully ignored these ab-
stract creations. However, things changed with the systematic study of wave me-chanics. After the introduction of Fourier analysis, researchers learned that a com-
pact way to represent a wave was by using functions of complex numbers. As it turns
out, this was an important step on the road to using complex numbers in quantumtheory. Early quantum mechanics was largely based on wave mechanics.
At ﬁrst glance, we do not seem to experience complex numbers in the “real
world.” The length of a rod is a real number, not a complex number. The temper-ature outside today is 73
◦, not (32 −14i)◦. The amount of time a chemical process
takes is 32 .543 seconds, not −14.65 iseconds. One might wonder what possible role
complex numbers can have in any discussion of the physical world. It will soon be-come apparent that they play an important, indeed an essential, role in quantummechanics. We shall explore complex numbers in Chapters 1 and 2 of the text.
2This Introduction is not the proper place for technical details. Some of the concepts are covered in thetext and some of them can be found only in quantum mechanics textbooks. See the end of Chapter 4for some recommendations of easy, yet detailed, introductions to quantum physics.
1

<<<PAGE 20>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2 Introduction
From Single States to Superpositions of States
In order to survive in this world, human beings, as infants, must learn that every
object exists in a unique place and in a well-deﬁned state, even when we are not
looking at it. Although this is true for large objects, quantum mechanics tells us that
it is false for objects that are very small. A microscopic object can “hazily” be inmore than one place at one time. Rather than an object’s being in one position oranother, we say that it is in a “superposition,” i.e., in some sense, it is simultaneously
in more than one location at the same time. Not only is spatial position subject to
such “haziness” but so are other familiar physical properties, like energy, momen-tum, and certain properties that are unique to the quantum world, such as “spin.”
We do not actually see superposition of states. Every time we look, or more
properly, “measure,” a superposition of states, it “collapses” to a single well-deﬁnedstate. Nevertheless, before we measure it, it is in many states at the same time.
One is justiﬁed in greeting these claims with skepticism. After all, how can one
believe something different from what every infant knows? However, we will de-scribe certain experiments that show that this is exactly what happens.
From Locality to Nonlocality
Central to modern science is the notion that objects are directly affected only bynearby objects or forces. In order to determine why a phenomenon occurs at a cer-
tain place, one must examine all the phenomena and forces near
3that place. This
is called “locality,” i.e., the laws of physics work in a local way. One of the most
remarkable aspects of quantum mechanics is that its laws predict certain effects
that work in a nonlocal manner. Two particles can be connected or “entangled”
in such a way that an action performed on one of them can have an immediate ef-fect on the other particle light-years away. This “spooky action at a distance,” to use
Einstein’s colorful expression, was one of the most shocking discoveries of quantum
mechanics.
From Deterministic Laws to Probabilistic Laws
To which speciﬁc state will a superposition of states collapse when it is measured?Whereas in other branches of physics the laws are deterministic,
4i.e., there is a
unique outcome to every experiment, the laws of quantum mechanics state that wecan only know the probability of the outcome. This, again, might seem dubious. Itwas doubted by the leading researchers of the time. Einstein himself was skepticaland coined the colorful expression “God does not play dice with the Universe” to
express this. However, because of repeated experimental conﬁrmations, the proba-
bilistic nature of quantum mechanics is no longer in question.
3By “near” we mean anything close enough to affect the object. In physics jargon, anything in the pastlight cone of the object.
4Statistical mechanics being one major exception.

<<<PAGE 21>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
The Implications of the Quantum World on Computer Science 3
From Certainty to Uncertainty
The laws of quantum mechanics also inform us that there are inherent limitations
to the amount of knowledge that one can ascertain about a physical system. The
primary example of such a limitation is the famous “Heisenberg’s uncertainty prin-
ciple.”
There are other important features of the quantum world that we shall not ex-
plore here. These different features were all motivating forces behind the advent of
quantum computing. Rather than an historical review of how these features affected
quantum computing, let us look at several areas in computer science and see howthe aforementioned features affected each of those areas.
5
THE IMPLICATIONS OF THE QUANTUM WORLD
ON COMPUTER SCIENCE
Architecture
The concept of superposition will be used to generalize the notion of bit to its quan-
tum analog, the qubit. Whereas a bit can be in either one of two states, superposi-
tion will allow a qubit to be both states simultaneously. Putting many qubits togethergives us quantum registers. It is this superposition that is the basis for quantum com-puting’s real power. Rather than being in one state at a time, a quantum computer
can be in many states simultaneously.
After generalizing the notion of bit, the notion of a gate that manipulates bits will
be extended to the quantum setting. We shall have quantum gates that manipulatequbits. Quantum gates will have to follow the dynamics of quantum operations. In
particular, certain quantum operations are reversible, and hence certain quantumgates will have to be reversible.
6
Algorithms
The ﬁeld of quantum algorithms uses superposition in a fundamental way. Rather
than having a computer in one state at a time, one employs that aspect of the quan-
tum world to place a quantum computer in many states simultaneously. One mightthink of this as massive parallelism. This needs special care: we cannot measure the
computer while it is in this superposition because measuring it would collapse it to
a single position. Our algorithms will start with the quantum computer in a singleposition. We shall then delicately place it in a superposition of many states. From
there, we manipulate the qubits in a speciﬁed way. Finally, (some of) the qubits are
measured. The measurement will collapse the qubits to the desired bits, which willbe our output.
5For an historical view of quantum computing as seen through the major papers that launched the
subject, see Appendix A.
6It so happens that reversible computation has a long history predating quantum computing. This history
will be reviewed in due course.

<<<PAGE 22>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
4 Introduction
Entanglement will also play a role in quantum computing, as the qubits can
be entangled. By measuring some of them, others automatically reach the desired
position.
Consider searching for a particular object in an unordered array. A classical al-
gorithm examines the ﬁrst entry in the array, then the second entry, and so on. The
algorithm stops when either the object is found or the end of the array is reached.
S of o ra na r r a yw i t h nelements, in the worst-case scenario, an algorithm would have
to look at nentries of the array.
Now imagine a computer that uses superposition. Rather than having the ma-
chine look at this entry or that entry, let it look at allentries simultaneously. This
will result in a fantastic speedup. It turns out that such a quantum computer will be
able to ﬁnd the object in√nqueries to the array. This is one of the ﬁrst quantum
algorithms and is called “Grover’s algorithm.”
Another algorithm that demonstrates the power and usefulness of quantum
computing is Shor’s algorithm for factoring numbers. The usual algorithm to fac-tor a number involves looking at many possible factors of the number until a true
factor is found. Shor’s algorithm uses superposition (and a touch of number theory)
to look at many possible factors simultaneously.
Shor’s algorithm is partially based on earlier quantum algorithms that were
created to solve slightly contrived problems. Although these earlier algorithms(Deutch, Deutch-Joza, and Simon’s periodicity algorithm) solve artiﬁcial problems,we shall study them so that we can learn different techniques of quantum software
design.
Programming Languages
Algorithms must eventually develop into concrete software if they are to be useful
in real-life applications. The bridge that makes this step possible is programming.Quantum computing is no exception: researchers in the ﬁeld have started designing
quantum programming languages that will enable future generations of program-
mers to take control of quantum hardware and implement new quantum algorithms.We shall introduce a brief survey of programming languages (for the ﬁrst time, to
our knowledge, in a quantum computing textbook), starting with quantum assem-
bler and progressing to high-level quantum programming, in particular quantumfunctional programming.
Theoretical Computer Science
The goal of theoretical computer science is to formalize what engineers have done,
and more important, to formalize what the engineers cannot do. Such an analysis
is carried out by describing and classifying theoretical models of computation. The
superposition of quantum mechanics has a vague feel of nondeterminism that theo-
retical computer scientists have used (of course, nondeterminism is a purely ﬁctional
concept and superposition is an established fact of the physical world). The indeter-minacy of which state the superposition will collapse to is related to a probabilisticcomputation. We will be led to generalize the deﬁnition of a Turing machine to that

<<<PAGE 23>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
The Implications of the Quantum World on Computer Science 5
of a quantum Turing machine. With a clear deﬁnition in place, we will be able to
classify and relate all these different ideas.
We shall not only be interested in what a quantum Turing machine can do. We
are also interested in the question of efﬁciency. This brings us to quantum com-plexity theory. Deﬁnitions of quantum complexity classes will be given and will berelated to other well-known complexity classes.
Cryptography
Indeterminacy and superposition will be used in quantum versions of public key dis-tribution protocols. The fact that a measurement disturbs a quantum state shall beused to detect the presence of an eavesdropper listening in on (measuring) a com-
munication channel. Such detection is not easily achievable in classical cryptogra-
phy. Whereas classical public key distribution protocols rely on the fact that certaininverse functions are computationally hard to calculate, quantum key distribution
protocols are based on the fact that certain laws of quantum physics are true. It is
this strength that makes quantum cryptography so interesting and powerful.
There is also a public key protocol that uses entanglement in a fundamental
way. Related to cryptography is teleportation. In teleportation, a state of a systemis transported as opposed to a message. The teleportation protocol uses entangledparticles that can be separated across the universe.
The most amazing part of quantum cryptography is that it is not only a theoret-
ical curiosity. There are, in fact, actual commercially available quantum cryptogra-phy devices currently in use.
Information Theory
It is impossible to discuss topics such as compression, transmission, and storage,
without mentioning information. Information theory, now an established ﬁeld, was
introduced by Claude Shannon in the forties, and has developed a vast array oftechniques and ideas that ﬁnd their use in computer science and engineering. As
this book deals with quantum computation, it is imperative that we ask: is there a
satisfactory notion of quantum information? What is the information content en-coded by a stream of qubits? It turns out that such notions exist. Just as classical
information is related to measures of order (the so-called entropy of a source of sig-
nals), quantum information is paired with the notion of quantum entropy. We shallexplore, chieﬂy through examples, how order and information in the quantum realmdiffer from familiar notions, and how these differences can be exploited to achieve
new results in data storage, transmission, and compression.
Hardware
There is no future for quantum computing without quantum computers. We are go-
ing to spell out the challenges behind the implementation of quantum machines, es-
pecially one that is embedded in the very nature of the quantum world: decoherence.

<<<PAGE 24>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6 Introduction
We shall also describe the desirable features that a prospective quantum machine
must exhibit in order to be useful.
A few proposals for quantum hardware will be showcased. The emphasis here
is not on technical details (this is a book for computer scientists, not a quantumengineering handbook!). Instead, our goal is to convey the gist of these proposalsand their chances of success as they are currently assessed.

<<<PAGE 25>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
1
Complex Numbers
You, have you really understood all that stuff?
What?
The story of imaginary numbers?
Robert Musil, The Confusions of Young
T¨orless (1907)1
Complex numbers lie at the very core of quantum mechanics and are therefore ab-
solutely essential to a basic understanding of quantum computation. In this chapterwe present this important system of numbers from both the algebraic and the geo-metric standpoints. Section 1.1 presents some motivation and the basic deﬁnitions.
The algebraic structure and operations on complex numbers are given in Section 1.2.
The chapter concludes with Section 1.3, where complex numbers are presented froma geometric point of view and advanced topics are discussed. Our hope is that this
chapter will help you get a little closer to what Sir Roger Penrose has very aptly
called the “magic of complex numbers” (Penrose, 2005).
.................................................................................
Reader Tip. Many readers will ﬁnd that they are already familiar with some of the
material presented in this chapter. The reader who feels conﬁdent in her compre-hension of the fundamental knowledge of complex numbers, the basic operations,and their properties can safely move on to later chapters. We suggest, though, that
you at least skim through the following pages to see what topics are covered. Return
to Chapter 1 as a reference when needed (using the index to ﬁnd speciﬁc topics). ♥.................................................................................
1For the German-speaking reader, here is the original text (the translation at the beginning is ours):
Du, hast du das vorhin ganz verstanden?
Was?Die Geschichte mit den imagin ¨aren Zahlen?
Musil’s T¨orless is a remarkable book. A substantial part is dedicated to the struggle of young
T¨orless to come to grips with mathematics, as well as with his own life. Deﬁnitely recommended!
7

<<<PAGE 26>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
8 Complex Numbers
1.1 BASIC DEFINITIONS
The original motivation for the introduction of complex numbers was the theory of
algebraic equations, the part of algebra that seeks solutions of polynomial equations.
It became readily apparent that there are plenty of cases in which no solution amongfamiliar numbers can be found. Here is the simplest example:
x
2+1=0. (1.1)
Indeed, any possible x2would be positive or zero. Adding 1 ends up with some
quantity to the left that is strictly positive; hence, no solution exists.
Exercise 1.1.1 Verify that the equation x4+2x2+1=0 has no solution among
the real numbers. (Hint: Factor the polynomial.) /squaresolid
The aforementioned argument seems to dash any hope of solving Equation (1.1).
But does it?
Before building any new number system, it pays to remind ourselves of other
sets of numbers that we usually work with/D2positive numbers, P={1,2,3,...};/D2natural numbers, N={0,1,2,3,...};/D2integers (or whole numbers), Z={...,−3,−2,−1,0,1,2,3,...};/D2rational numbers, Q=/braceleftbigm
n|m∈Z,n∈P/bracerightbig
;/D2real numbers, R=Q/uniontext{...,√
2,..., e,...,π,...,e
π...};
In none of these familiar number systems can a valid solution to Equation (1.1) be
found. Mathematics often works around difﬁculties by simply postulating that such
a solution, albeit unknown, is available somewhere. Let us thus boldly assume thatthis enigmatic solution does indeed exist and determine what it looks like: Equa-
tion (1.1) is equivalent to
x
2=−1. (1.2)
What does this state? That the solution of Equation (1.1) is a number such that its
square is −1, i.e., a number isuch that
i2=−1o r i=/radicalbig
−1. (1.3)
Of course we know that no such number exists among known (i.e., real) numbers,but we have already stated that this is not going to deter us. We will simply allow thisnew creature into the realm of well-established numbers and use it as it pleases us.
Because it is imaginary, it is denoted i. We will impose on ourselves an important
restriction: aside from its weird behavior when squared, iwill behave just like an
ordinary number.
Example 1.1.1 What is the value of i
3? We shall treat ias a legitimate number, so
i3=i×i×i=(i2)×i=−1×i=−i. (1.4)
/square

<<<PAGE 27>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
1.1 Basic Deﬁnitions 9
Exercise 1.1.2 Find the value of i15. (Hint: Calculate i,i2,i3,i4, and i5. Find a pat-
tern.) /squaresolid
In opening the door to our new friend i, we are now ﬂooded with an entire
universe of new numbers: to begin with, all the multiples of iby a real number, like
2×i. These fellows, being akin to i, are known as imaginary numbers . But there is
more: add a real number and an imaginary number, for instance, 3 +5×i, and you
get a number that is neither a real nor an imaginary. Such a number, being a hybrid
entity, is rightfully called a complex number .
Deﬁnition 1.1.1 Acomplex number is an expression
c=a+b×i=a+bi, (1.5)
where a ,b are two real numbers; a is called the real part of c, whereas b is its imaginary
part. The set of all complex numbers will be denoted as C. When the ×is understood,
we shall omit it.
Complex numbers can be added and multiplied, as shown next.
Example 1.1.2 Let c1=3−iand c2=1+4i. We want to compute c1+c2and
c1×c2.
c1+c2=3−i+1+4i=(3+1)+(−1+4)i=4+3i. (1.6)
Multiplying is not as easy. We must remember to multiply each term of the ﬁrstcomplex number with each term of the second complex number. Also, remember
that i
2=−1.
c1×c2=(3−i)×(1+4i)=(3×1)+(3×4i)+(−i×1)+(−i×4i)
=(3+4)+(−1+12)i=7+11i. (1.7)
/square
Exercise 1.1.3 Letc1=−3+iandc2=2−4i. Calculate c1+c2andc1×c2./squaresolid
With addition and multiplication we can get all polynomials. We set out to ﬁnd a
solution for Equation (1.1); it turns out that complex numbers are enough to provide
solutions for allpolynomial equations.
Proposition 1.1.1 (Fundamental Theorem of Algebra). Every polynomial equa-
tion of one variable with complex coefﬁcients has a complex solution.
Exercise 1.1.4 Verify that the complex number −1+iis a solution for the polyno-
mial equation x2+2x+2=0. /squaresolid
This nontrivial result shows that complex numbers are well worth our attention.
In the next two sections, we explore the complex kingdom a little further.Programming Drill 1.1.1 Write a program that accepts two complex numbers and
outputs their sum and their product.

<<<PAGE 28>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
10 Complex Numbers
1.2 THE ALGEBRA OF COMPLEX NUMBERS
Admittedly, the fact that we know how to handle them does not explain away the
oddity of complex numbers. What arethey? What does it mean that isquared is
equal to −1?
In the next section, we see that the geometrical viewpoint greatly aids our in-
tuition. Meanwhile, we would like to convert complex numbers into more familiarobjects by carefully looking at how they are built.
Deﬁnition 1.1.1 tells us tworeal numbers correspond to each complex number:
its real and imaginary parts. A complex number is thus a two-pronged entity, carry-ing its two components along. How about deﬁning a complex number as an ordered
pair of reals?
c/mapsto−→ (a,b). (1.8)
Ordinary real numbers can be identiﬁed with pairs ( a,0)
a/mapsto−→ (a,0), (1.9)
whereas imaginary numbers will be pairs (0 ,b). In particular,
i/mapsto−→ (0,1). (1.10)
Addition is rather obvious – it adds pairs componentwise:
(a
1,b1)+(a2,b2)=(a1+a2,b1+b2). (1.11)
Multiplication is a little trickier:
(a1,b1)×(a2,b2)=(a1,b1)(a2,b2)=(a1a2−b1b2,a1b2+a2b1). (1.12)
Does this work? Multiplying iby itself gives
i×i=(0,1)×(0,1)=(0−1,0+0)=(−1, 0), (1.13)
which is what we wanted.
Using addition and multiplication, we can write any complex number in the usual
form:
c=(a,b)=(a,0)+(0,b)=(a,0)+(b,0)×(0,1)=a+bi. (1.14)
We have traded one oddity for another: iwas previously quite mysterious,
whereas now it is just (0 ,1). A complex number is nothing more than an ordered
pair of ordinary real numbers. Multiplication, though, is rather strange: perhaps thereader would have expected a componentwise multiplication, just like addition. We
shall see later that by viewing complex numbers through yet another looking glass
the strangeness linked to their multiplication rule will fade away.
Example 1.2.1 Let c
1=(3,−2) and c2=(1,2). Let us multiply them using the
aforementioned rule:
c1×c2=(3×1−(−2)×2,−2×1+2×3)
=(3+4,−2+6)=(7,4)=7+4i. (1.15)
/square

<<<PAGE 29>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
1.2 The Algebra of Complex Numbers 11
Exercise 1.2.1 Letc1=(−3,−1) and c2=(1,−2). Calculate their product. /squaresolid
So far, we have a set of numbers and two operations: addition and multiplication.
Both operations are commutative, meaning that for arbitrary complex numbers c1
andc2,
c1+c2=c2+c1 (1.16)
and
c1×c2=c2×c1. (1.17)
Both operations are also associative:
(c1+c2)+c3=c1+(c2+c3) (1.18)
and
(c1×c2)×c3=c1×(c2×c3). (1.19)
Exercise 1.2.2 Verify that multiplication of complex numbers is associative. /squaresolid
Moreover, multiplication distributes over addition: for all c1,c2,c3,we have
c1×(c2+c3)=(c1×c2)+(c1×c3). (1.20)
Let us verify this property: ﬁrst we write the complex numbers as pairs c1=(a1,b1),
c2=(a2,b2),andc3=(a3,b3). Now, let us expand the left side
c1×(c2+c3)=(a1,b1)×((a2,b2)+(a3,b3))
=(a1,b1)×(a2+a3,b2+b3)
=(a1×(a2+a3)−b1×(b2+b3),
a1×(b2+b3)+b1×(a2+a3))
=(a1×a2+a1×a3−b1×b2−b1×b3,
a1×b2+a1×b3+b1×a2+b1×a3). (1.21)
Turning to the right side of Equation (1.20) one piece at a time gives
c1×c2=(a1×a2−b1×b2,a1×b2+a2×b1) (1.22)
c1×c3=(a1×a3−b1×b3,a1×b3+a3×b1); (1.23)
summing them up we obtain
c1×c2+c1×c3=(a1×a2−b1×b2+a1×a3−b1×b3,
a1×b2+a2×b1+a1×b3+a3×b1), (1.24)
which is precisely what we got in Equation (1.21).
Having addition and multiplication, we need their complementary operations:
subtraction and division.

<<<PAGE 30>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
12 Complex Numbers
Subtraction is straightforward:
c1−c2=(a1,b1)−(a2,b2)=(a1−a2,b1−b2); (1.25)
in other words, subtraction is deﬁned componentwise, as expected.
As for division, we have to work a little: If
(x,y)=(a1,b1)
(a2,b2), (1.26)
then by deﬁnition of division as the inverse of multiplication
(a1,b1)=(x,y)×(a2,b2) (1.27)
or
(a1,b1)=(a2x−b2y,a2y+b2x). (1.28)
So we end up with
(1) a1=a2x−b2y, (1.29)
(2) b1=a2y+b2x. (1.30)
To determine the answer, we must solve this pair of equations for xand y. Multiply
both sides of (1) by a2and both sides of (2) by b2. We end up with
(1/prime) a1a2=a2
2x−b2a2y, (1.31)
(2/prime) b1b2=a2b2y+b2
2x. (1.32)
Now, let us add (1/prime) and (2/prime) to get
a1a2+b1b2=(a2
2+b2
2)x. (1.33)
Solving for xgives us
x=a1a2+b1b2
a2
2+b2
2. (1.34)
We can perform the same trick for yby multiplying (1) and (2) by b2and−a2,
respectively, and then summing. We obtain
y=a2b1−a1b2
a2
2+b2
2. (1.35)
In more compact notation, we can express this equation as
a1+b1i
a2+b2i=a1a2+b1b2
a2
2+b2
2+a2b1−a1b2
a2
2+b2
2i. (1.36)
Notice that both xand yare calculated using the same denominator, namely,
a2
2+b2
2. We are going to see what this quantity means presently. In the meantime,
here is a concrete example.
Example 1.2.2 Letc1=−2+iand c2=1+2i. We will computec1
c2. In this case,
a1=−2,b1=1,a2=1,andb2=2. Therefore,
a2
2+b2
2=12+22=5, (1.37)

<<<PAGE 31>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
1.2 The Algebra of Complex Numbers 13
a1a2+b1b2=−2×1+1×2=0, (1.38)
a2b1−a1b2=1×1−(−2)×2=1+4=5. (1.39)
The answer is thus/parenleftbig0
5,5
5/parenrightbig
=(0,1)=i. /square
Exercise 1.2.3 Letc1=3iandc2=−1−i. Calculatec1
c2. /squaresolid
Now, let us go back to the mysterious denominator in the quotient formula in
Equation (1.36). Real numbers have a unary operation, the absolute value, given by
|a|=+/radicalbig
a2. (1.40)
We can deﬁne a generalization of this operation2to the complex domain by letting
|c|=| a+bi|=+/radicalbig
a2+b2. (1.41)
This quantity is known as the modulus of a complex number.
Example 1.2.3 What is the modulus of c=1−i?
|c|=| 1−i|=+/radicalBig
12+(−1)2=√
2. (1.42)
/square
The geometric meaning of the modulus is discussed in the next section. For now,
we remark that the quantity in the denominator of the quotient of two complex
numbers is nothing more than the modulus squared of the divisor:
|c|2=a2+b2. (1.43)
This modulus must be different from zero, which always happens unless the divisor
is itself zero.
Exercise 1.2.4 Calculate the modulus of c=4−3i. /squaresolid
Exercise 1.2.5 Verify that given two arbitrary complex numbers c1andc2,t h ef o l -
lowing equality always holds:
|c1||c2|=| c1c2|. (1.44)
/squaresolid
Exercise 1.2.6 Prove that
|c1+c2|≤| c1|+|c2|. (1.45)
When are they, in fact, equal? (Hint: Square both sides.) /squaresolid
Exercise 1.2.7 Show that for all c∈C, we have c+(0,0)=(0,0)+c=c. That is,
(0,0) is an additive identity. /squaresolid
2The deﬁnition given in Equation (1.40) is entirely equivalent to the more familiar one: |a|=aifa≥0,
and|a|=− aifa<0.

<<<PAGE 32>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
14 Complex Numbers
Exercise 1.2.8 Show that for all c∈Cwe have c×(1,0)=(1,0)×c=c. That is,
(1,0) is a multiplicative identity. /squaresolid
In summation, we have deﬁned a new set of numbers, C, endowed with four
operations, verifying the following properties:
(i) Addition is commutative and associative.
(ii) Multiplication is commutative and associative.
(iii) Addition has an identity: (0 ,0).
(iv) Multiplication has an identity: (1 ,0).
(v) Multiplication distributes with respect to addition.
(vi) Subtraction (i.e., the inverse of addition) is deﬁned everywhere.
(vii) Division (i.e., the inverse of multiplication) is deﬁned everywhere except
when the divisor is zero.
A set with operations satisfying all these properties is called a ﬁeld. Cis a ﬁeld,
just like R, the ﬁeld of real numbers. In fact, via the identiﬁcation that associates
a real number to a complex number with 0 as the imaginary component, we can
think of Ras a subset3ofC.Rsits inside C; but Cis a vast ﬁeld, so vast, indeed,
that all polynomial equations with coefﬁcients in Chave a solution in Citself. R
is also a roomy ﬁeld, but not enough to enjoy this last property (remember Equa-tion (1.1)). A ﬁeld that contains all solutions for any of its polynomial equations issaid to be algebraically complete .Cis an algebraically complete ﬁeld, whereas R
is not.
There is a unary operation that plays a crucial role in the complex domain. The
reader is familiar with “changing signs” of real numbers. Here, however, there aretwo real numbers attached to a complex number. Therefore, there are three ways
of changing sign: either change the sign of the real part or change the sign of theimaginary part, or both. Let us analyze them one by one.
Changing both signs of the complex number is done by multiplying by the num-
ber−1=(−1, 0).
Exercise 1.2.9 Verify that multiplication by (−1, 0) changes the sign of the real and
imaginary components of a complex number. /squaresolid
Changing the sign of the imaginary part only is known as conjugation .
4Ifc=
a+biis an arbitrary complex number, then the conjugate of cisc=a−bi.T w o
numbers related by conjugation are said to be complex conjugates of each other.
Changing the sign of the real part (c /mapsto−→ − c) has no particular name, at least in
the algebraic context.5
The following exercises will guide you through conjugation’s most important
properties.
3A subset of a ﬁeld that is a ﬁeld in its own right is called a subﬁeld: Ris a subﬁeld of C.
4Its “geometric” name is real-axis reﬂection . The name becomes obvious in the next section.
5In the geometric viewpoint, it is known as imaginary-axis reﬂection. After reading Section 1.3, we invite
you to investigate this operation a bit further.

<<<PAGE 33>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
1.3 The Geometry of Complex Numbers 15
Exercise 1.2.10 Show that conjugation respects addition, i.e.,
c1+c2=c1+c2. (1.46)
/squaresolid
Exercise 1.2.11 Show that conjugation respects multiplication, i.e.,
c1×c2=c1×c2. (1.47)
/squaresolid
Notice that the function
c/mapsto−→ c (1.48)
given by conjugation is bijective, i.e., is one-to-one and onto. Indeed, two different
complex numbers are never sent to the same number by conjugation. Moreover,
every number is the complex conjugate of some number. A function from a ﬁeld to
a ﬁeld that is bijective and that respects addition and multiplication is known as a
ﬁeld isomorphism . Conjugation is thus a ﬁeld isomorphism of CtoC.
Exercise 1.2.12 Consider the operation given by ﬂipping the sign of the real part.
Is this a ﬁeld isomorphism of C? If yes, prove it. Otherwise, show where it fails. /squaresolid
We cannot continue without mentioning another property of conjugation:
c×c=|c|2. (1.49)
In words, the modulus squared of a complex number is obtained by multiplying
the number with its conjugate. For example,
(3+2i)×(3−2i)=32+22=13=|3+2i|2. (1.50)
We have covered what we need from the algebraic perspective. We see in the
next section that the geometric approach sheds some light on virtually all topics
touched on here.
Programming Drill 1.2.1 Take the program that you wrote in the last programming
drill and make it also perform subtraction and division of complex numbers. In ad-
dition, let the user enter a complex number and have the computer return its modulus
and conjugate.
1.3 THE GEOMETRY OF COMPLEX NUMBERS
As far as algebra is concerned, complex numbers are an algebraically complete ﬁeld,as we have described them in Section 1.2. That alone would render them invaluable
as a mathematical tool. It turns out that their signiﬁcance extends far beyond the
algebraic domain and makes them equally useful in geometry and hence in physics.To see why this is so, we need to look at a complex number in yet another way.At the beginning of Section 1.2, we learned that a complex number is a pair of real

<<<PAGE 34>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
16 Complex Numbers
Figure 1.1. Complex plane.
numbers. This suggests a natural means of representation: real numbers are placed
on the line, so pairs of reals correspond to points on the plane, or, equivalently,correspond to vectors starting from the origin and pointing to that point (as shown
inFigure 1.1).
In this representation, real numbers (i.e., complex numbers with no imaginary
part) sit on the horizontal axis and imaginary numbers sit on the vertical axis. This
plane is known as the complex plane or the Argand plane .
Through this representation, the algebraic properties of the complex numbers
can be seen in a new light. Let us start with the modulus: it is nothing more than the
length of the vector. Indeed, the length of a vector, via Pythagoras’ theorem, is the
square root of the sum of the squares of its edges, which is precisely the modulus, asdeﬁned in the previous section.
Example 1.3.1 Consider the complex numbers c=3+4idepicted in Figure 1.2.
The length of the vector is the hypotenuse of the right triangle whose edges have
length 3 and 4, respectively. Pythagoras’ theorem gives us the length as
length (c)=/radicalbig
42+32=/radicalbig
16+9=√
25=5. (1.51)
This is exactly the modulus of c. /square
Figure 1.2. Vector 3 +4i.

<<<PAGE 35>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
1.3 The Geometry of Complex Numbers 17
Figure 1.3. Parallelogram rule.
Next comes addition: vectors can be added using the so-called parallelogram rule
illustrated by Figure 1.3. In words, draw the parallelogram whose parallel edges are
the two vectors to be added; their sum is the diagonal.
Exercise 1.3.1 Draw the complex numbers c1=2−iand c2=1+iin the com-
plex plane, and add them using the parallelogram rule. Verify that you would get
the same result as adding them algebraically (the way we learned in Section 1.2). /squaresolid
Subtraction too has a clear geometric meaning: subtracting c2from c1is the same
as adding the negation of c2, i.e.,−c2,t oc1. But what is the negation of a vector?
It is just the vector of the same length pointed in the opposite direction (see Fig-
ure 1.4).
Exercise 1.3.2 Let c1=2−iand c2=1+i. Subtract c2from c1by ﬁrst draw-
ing−c2and then adding it to c1using the parallelogram rule. /squaresolid
To give a simple geometrical meaning to multiplication, we need to develop yet
another characterization of complex numbers. We saw a moment ago that for every
complex number we can draw a right triangle, whose edges’ lengths are the real and
imaginary parts of the number and whose hypotenuse’s length is the modulus. Now,
suppose someone tells us the modulus of the number what else do we need to knowto draw the triangle? The answer is the angle at the origin.
Figure 1.4. Subtraction.

<<<PAGE 36>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
18 Complex Numbers
The modulus ρandthe angle θ(notice: two real numbers, as before) are enough
to uniquely determine the complex number.
(a,b)/mapsto−→ (ρ,θ ). (1.52)
We know how to compute ρfrom a,b:
ρ=/radicalBig
(a2+b2). (1.53)
θis also easy, via trigonometry:
θ=tan−1/parenleftbiggb
a/parenrightbigg
. (1.54)
The ( a,b) representation is known as the Cartesian representation of a complex
number, whereas ( ρ,θ)i st h epolar representation .
We can go back from polar to Cartesian representation, again using trigono-
metry:
a=ρcos(θ ), b=ρsin(θ ). (1.55)
Example 1.3.2 Letc=1+i. What is its polar representation?
ρ=/radicalbig
12+12=√
2 (1.56)
θ=tan−1/parenleftbigg1
1/parenrightbigg
=tan−1(1)=π
4(1.57)
cis the vector of length√
2 from the origin at an angle ofπ
4radians, or 45◦. /square
Exercise 1.3.3 Draw the complex number given by the polar coordinates ρ=3
andθ=π
3. Compute its Cartesian coordinates. /squaresolid
Programming Drill 1.3.1 Write a program that converts a complex number from its
Cartesian representation to its polar representation and vice versa.
Before moving on, let us meditate a little: what kind of insight does the polar
representation give us? Instead of providing a ready-made answer, let us begin with
a question: how many complex numbers share exactly the same modulus? A mo-ment’s thought will tell us that for a ﬁxed modulus, say, ρ=1, there is an entire
circle centered at the origin (as shown in Figure 1.5).
θ
Figure 1.5. Phase θ.

<<<PAGE 37>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
1.3 The Geometry of Complex Numbers 19
θ
Figure 1.6. Points on a line with the same
phase.
So, here comes the angle: imagine the circle as your watch, and the complex
number as the needle. Angle θtells us the “time.” The “time” is known in physics
and engineering as the phase, whereas the length of the “needle” (i.e., the modulus)
is the magnitude of the number.
Deﬁnition 1.3.1 Acomplex number is a magnitude and a phase.
The ordinary positive reals are just complex numbers such that their phase is
zero. The negative reals have phase π. By the same token, imaginary numbers are
numbers with constant phase equal toπ
2(positive imaginary) or3π
2(negative imag-
inary).
Given a constant phase, there is an entire line of complex numbers having that
phase as depicted in Figure 1.6.
Observe that a complex number has a unique polar representation only if we
conﬁne the phase between 0 and 2π :
0≤θ< 2π (1.58)
(and the ρ≥0). If we restrict θin this fashion, though, we cannot in general add an-
gles (the sum may be bigger than 2 π). A better course is to let the angle be anything
andreduce it modulo 2 π:
θ1=θ2if and only if θ2=θ1+2πk,for some integer k. (1.59)
Two complex numbers in polar representations will be identical if their magni-
tude is the same and if the angles are the same modulo 2 π, as shown by the following
example.
Example 1.3.3 Are the numbers (3 ,−π) and (3,π ) the same? Indeed they are:
their magnitude is the same and their phases differ by ( −π)−π=−2π=(−1)2π.
/square

<<<PAGE 38>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
20 Complex Numbers
We are now ready for multiplication: given two complex numbers in polar co-
ordinates, (ρ 1,θ1) and ( ρ2,θ2), their product can be obtained by simply multiplying
their magnitude and adding their phase:
(ρ1,θ1)×(ρ2,θ2)=(ρ1ρ2,θ1+θ2). (1.60)
Example 1.3.4 Letc1=1+iand c2=−1+i. Their product, according to the al-
gebraic rule, is
c1c2=(1+i)(−1+i)=−2+0i=−2. (1.61)
Now, let us take their polar representation
c1=/parenleftBig√
2,π
4/parenrightBig
, c2=/parenleftbigg√
2,3π
4/parenrightbigg
. (1.62)
(Carry out the calculations!) Therefore, their product using the rule described ear-
lier is
c1c2=/parenleftbigg√
2×√
2,π
4+3π
4/parenrightbigg
=(2,π). (1.63)
If we revert to its Cartesian coordinates, we get
(2×cos(π ),2×sin(π ))=(−2, 0), (1.64)
which is precisely the answer we arrived at with the algebraic calculation in Equa-tion (1.61).
Figure 1.7 is the graphical representation of the two numbers and their product.As you can see, we simply rotated the ﬁrst vector by an angle equal to the phase
of the second vector and multiplied its length by the length of the second vector. /square
Exercise 1.3.4 Multiply c
1=−2−iandc2=−1−2iusing both the algebraic and
the geometric method; verify that the results are identical. /squaresolid
.................................................................................
Reader Tip. Most of the rest of this chapter are basic ideas in complex numbers;
however, they will not really be used in the text. The part on roots of unity will arisein our discussion of Shor’s algorithm (Section 6.5). The rest is included for the sake
Figure 1.7. Two complex numbers
and their product.

<<<PAGE 39>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
1.3 The Geometry of Complex Numbers 21
Figure 1.8. Multiplication by i.
of completeness. The restless reader can safely skim the rest of this chapter on the
ﬁrst reading. ♥.................................................................................
We have implicitly learned an important fact: multiplication in the complex do-
main has something to do with rotations of the complex plane. Indeed, observe just
what happens by left or right multiplication by i:
c/mapsto−→ c×i. (1.65)
ihas modulus 1, so the magnitude of the result is exactly equal to that of the starting
point. The phase of iisπ
2, so multiplying by ihas the net result of rotating the
original complex number by 90◦, a right angle. The same happens when we multiply
any complex number; so we can safely conclude that multiplication by iis a right-
angle counterclockwise rotation of the complex plane, as shown in Figure 1.8.
Exercise 1.3.5 Describe the geometric effect on the plane obtained by multiplying
by a real number, i.e., the function
c/mapsto−→ c×r0, (1.66)
where r0is a ﬁxed real number. /squaresolid
Exercise 1.3.6 Describe the geometric effect on the plane obtained by multiplying
by a generic complex number, i.e., the function
c/mapsto−→ c×c0, (1.67)
where c0is a ﬁxed complex number. /squaresolid
Programming Drill 1.3.2 If you like graphics, write a program that accepts a small
drawing around the origin of the complex plane and a complex number. The programshould change the drawing by multiplying every point of the diagram by a complex
number.

<<<PAGE 40>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
22 Complex Numbers
Now that we are armed with a geometric way of looking at multiplication, we can
tackle division as well. After all, division is nothing more than the inverse operation
of multiplication. Assume that
c1=(ρ1,θ1) and c2=(ρ2,θ2), (1.68)
are two complex numbers in polar form; what is the polar form ofc1
c2? A moment’s
thought tells us that it is the number
c1
c2=/parenleftbiggρ1
ρ2,θ1−θ2/parenrightbigg
. (1.69)
In words, we divide the magnitudes and subtract the angles.
Example 1.3.5 Letc1=−1+3iand c2=−1−4i. Let us calculate their polar co-
ordinates ﬁrst:
c1=/parenleftbigg/radicalBig
(−1)2+32,tan−1/parenleftbigg3
−1/parenrightbigg/parenrightbigg
=(√
10,tan−1(−3))=(3.1623, 1.8925) ,
(1.70)
c2=/parenleftbigg/radicalBig
(−1)2+(−4)2,tan−1/parenleftbigg−4
−1/parenrightbigg/parenrightbigg
=(√
17,tan−1(4))=(4.1231,−1.8158) ,
(1.71)
therefore, in polar coordinates the quotient is
c1
c2=/parenleftbigg3.1623
4.1231,1.8925−(−1.8158)/parenrightbigg
=(0.7670, 3.7083) . (1.72)
/square
Exercise 1.3.7 Divide 2 +2iby 1−iusing both the algebraic and the geometrical
method and verify that the results are the same. /squaresolid
You may have noticed that in Section 1.2, we have left out two important oper-
ations: powers and roots. The reason was that it is much easier to deal with them in
the present geometric setting than from the algebraic viewpoint.
Let us begin with powers. If c=(ρ,θ ) is a complex number in polar form and n
a positive integer, its nth power is just
cn=(ρn,nθ), (1.73)
because raising to the nth power is multiplying ntimes. Figure 1.9 shows a complex
number and its ﬁrst, second, and third powers.
Exercise 1.3.8 Let c=1−i. Convert it to polar coordinates, calculate its ﬁfth
power, and revert the answers to Cartesian coordinates. /squaresolid
What happens when the base is a number of magnitude 1? Its powers will also
have magnitude 1; thus, they will stay on the same unit circle. You can think of
the various powers 1, 2,... as time units, and a needle moving counterclockwise at

<<<PAGE 41>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
1.3 The Geometry of Complex Numbers 23
Figure 1.9. A complex number and its square and cube.
constant speed (it covers exactly θradians per time unit, where θis the phase of the
base).
Let us move on to roots. As you know already from high-school algebra, a root
is a fractional power. For instance, the square root means raising the base to the
power of one-half; the cube root is raising to the power of one-third; and so forth.The same holds true here, so we may take roots of complex numbers: if c=(ρ,θ )i s
a complex in polar form, its nth root is
c
1
n=/parenleftbigg
ρ1
n,1
nθ/parenrightbigg
. (1.74)
However, things get a bit more complicated. Remember, the phase is deﬁned only
up to multiples of 2 π. Therefore, we must rewrite Equation (1.74) as
c1
n=/parenleftbigg
n√ρ,1
n(θ+k2π)/parenrightbigg
. (1.75)
It appears that there are several roots of the same number. This fact should not
surprise us: in fact, even among real numbers, roots are not always unique. Take,for instance, the number 2 and notice that there are two square roots,√
2 and−√
2.
How many nth roots are there? There are precisely nnth roots for a complex
number. Why? Let us go back to Equation (1.75).
1
n(θ+2kπ)=1
nθ+k
n2π. (1.76)
How many different solutions can we generate by varying k? Here they are:
k=01nθ
k=11nθ+1n2π
......
k=n−11nθ+n−1n2π(1.77)
That is all: when k=n, we obtain the ﬁrst solution; when k=n+1, we obtain
the second solution; and so forth. (Verify this statement!)

<<<PAGE 42>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
24 Complex Numbers
Figure 1.10. The three cube roots of
unity.
To see what is happening, let us assume that ρ=1; in other words, let us ﬁnd
nth roots of a complex number c=(1,θ) on the unit circle. The nsolutions in Equa-
tion (1.77) can be interpreted in the following way: Draw the unit circle, and the
vectors whose phase is1
nθ,1
nθplus an angle equal tok
nof the entire circle, where
k=1,..., n. We get precisely the vertices of a regular polygon with nedges. Fig-
ure 1.10 is an example when n=3.
Exercise 1.3.9 Find all the cube roots of c=1+i. /squaresolid
By now we should feel pretty comfortable with the polar representation: we
know that any complex number, via the polar-to-Cartesian function, can be writ-ten as
c=ρ(cos(θ )+isin(θ)). (1.78)
Let us introduce yet another notation that will prove to be very handy in many
situations. The starting point is the following formula, known as Euler’s formula :
e
iθ=cos(θ )+isin(θ ). (1.79)
The full justiﬁcation of the remarkable formula of Euler lies outside the scope of
this book.6However, we can at least provide some evidence that substantiates its
6For the calculus-savvy reader: Use the well-known Taylor expansions.
ex=1+x+x2
2+···+xn
n!+··· , (1.80)
sin(x)=x−x3
3!+···+(−1)n
(2n+1)!x2n+1+··· , (1.81)
cos(x)=1−x2
2+···+(−1)n
(2n)!x2n+··· . (1.82)
Assume that they hold for complex values of x. Now, formally multiply sin( x)b y iand add compo-
nentwise cos( x) to obtain Euler’s formula.

<<<PAGE 43>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
1.3 The Geometry of Complex Numbers 25
validity. First of all, if θ=0, we get what we expected, namely, 1. Secondly,
ei(θ1+θ2)=cos(θ 1+θ2)+isin(θ 1+θ2)
=cos(θ 1) cos(θ 2)−sin(θ 1)s i n (θ2)
+i((sin(θ 1) cos(θ2)+sin(θ 2) cos(θ 1)) (1.83)
=(cos(θ 1)+isin(θ1))((cos(θ 2)+isin(θ 2))
=eiθ1×eiθ2.
In other words, the exponential function takes sums into products as it does in
the real case.
Exercise 1.3.10 Prove De Moivre’s formula :
(eθi)n=cos(nθ)+isin(nθ). (1.84)
(Hint: The trigonometric identities used earlier, with induction on n, will do the
work.) /squaresolid
Now that we know how to take the exponential of an imaginary number, there
is no problem in deﬁning the exponential of an arbitrary complex number:
ea+bi=ea×ebi=ea(cos(b )+isin(b )). (1.85)
Euler’s formula enables us to rewrite Equation (1.78) in a more compact form:
c=ρeiθ. (1.86)
We shall refer to Equation (1.86) as the exponential form of a complex number.
Exercise 1.3.11 Write the number c=3−4iin exponential form. /squaresolid
The exponential notation simpliﬁes matters when we perform multiplication:
c1c2=ρ1eiθ1ρ2eiθ2=ρ1ρ2ei(θ1+θ2). (1.87)
Exercise 1.3.12 Rewrite the law for dividing complex numbers in exponential
form.
/squaresolid
With this notation, we can look at the roots of the complex number 1 =(1,0)=
1+0i.L e t nbe a ﬁxed number. There are ndifferent roots of unity. Setting c=
(1,0) in Equation (1.75), we get
c1
n=(1,0)1
n=/parenleftbigg
n√
1,1
n(0+2kπ)=/parenleftbigg
1,2kπ
n/parenrightbigg/parenrightbigg
. (1.88)
By permitting k=0,1,2,...,n −1, we get ndifferent roots of unity. Notice that if
we set k=n, we get back to the ﬁrst one. The kth root of unity in exponential form
ise2πik/n. We denote these ndifferent roots of unity by
ω0
n=1,ω1
n,ω2
n,...,ωn−1
n. (1.89)

<<<PAGE 44>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
26 Complex Numbers
ω1
ω0
ω6
ω5ω4ω3ω2
Figure 1.11. The seventh root of unity and its
powers.
Geometrically these nroots of unity correspond to splitting up the unit circle into n
parts where the ﬁrst partition is (1 ,0).Figure 1.11 is a picture of the seventh root of
unity and all its powers.
If we multiply two roots of unity, we get
ωj
nωk
n=e2πij/ne2πik/n=e2πi(j+k)/n=ωj+k
n. (1.90)
Notice also that
ωj
nωn−j
n=ωn
n=1, (1.91)
and hence
ωj
n=ωn−j
n. (1.92)
Exercise 1.3.13 Draw all the ﬁfth roots of unity. /squaresolid
We are now in a position to characterize geometrically any function on complex
numbers. The simplest functions one can think of beyond the elementary operations
arepolynomials. An arbitrary polynomial with complex coefﬁcients looks like
P(x)=cnxn+cn−1xn−1+···+ c0, (1.93)
where c0,c1,..., cn−1are in C.P(x) can be seen as a function from CtoC
P(x):C−→C. (1.94)
To build some geometric intuition on polynomials, you can try your hand at thefollowing two exercises.
Exercise 1.3.14 Describe the geometric meaning of the function
c/mapsto−→ c
n(1.95)
from CtoC. /squaresolid

<<<PAGE 45>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
1.3 The Geometry of Complex Numbers 27
Exercise 1.3.15 Describe the geometric meaning of the function
c/mapsto−→ c+c0 (1.96)
from CtoC. /squaresolid
After polynomials, the next set of functions are rational functions , or quotients
of polynomials:
R(x)=P0(x)
P1(x)=cnxn+cn−1xn−1+···+ c0
dmxm+dm−1xm−1+···+ d0. (1.97)
In general, describing the action on the plane provided by a rational function is no
simple matter. The simplest case, though, is relatively easy and a very importantone:
R
a,b,c,d(x)=ax+b
cx+d, (1.98)
where a,b,c,dare in Cand ad−bc/negationslash=0 is known as the M¨obius transformation .
The following set of exercises introduce some of the basic properties of M ¨obius
transformations. (In particular, we show that the set of M ¨obius transformations form
a group.)7
Exercise 1.3.16 When a=d=0 and b=c=1, we get R(x)=1
x. Describe the ge-
ometrical effect of this transformation. (Hint: See what happens to the points insideand outside the circle of radius 1.) /squaresolid
Exercise 1.3.17 Prove that the composition of two M ¨obius transformations is a
M¨obius transformation. In other words, if R
a,b,c,dand Ra/prime,b/prime,c/prime,d/primeare two M ¨obius
transformations, the transformation Ra/prime,b/prime,c/prime,d/prime◦Ra,b,c,dgiven by
Ra/prime,b/prime,c/prime,d/prime◦Ra,b,c,d(x)=Ra/prime,b/prime,c/prime,d/prime(Ra,b,c,d(x)) (1.99)
is also a M ¨obius transformation. /squaresolid
Exercise 1.3.18 Show that the identity transformation, i.e., the transformation that
leaves every point ﬁxed, is a M ¨obius transformation. /squaresolid
Exercise 1.3.19 Show that each M ¨obius transformation has an inverse that is also
aM¨obius transformation, i.e., for each Ra,b,c,dyou can ﬁnd Ra/prime,b/prime,c/prime,d/primesuch that
Ra/prime,b/prime,c/prime,d/prime◦Ra,b,c,d(x)=x. (1.100)
/squaresolid
There are many more functions in the complex domain, but to introduce them
one needs tools from complex analysis , i.e., calculus over the complex numbers. The
main idea is quite simple: replace polynomials with a power series, i.e., polynomials
7M¨obius transformations are a truly fascinating topic, and perhaps the best entrance door to the geom-
etry of complex numbers. We invite you to ﬁnd out more about them in Schwerdtfeger (1980).

<<<PAGE 46>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
28 Complex Numbers
with an inﬁnite number of terms. The functions one studies are the so-called analytic
functions , which are functions that can be coherently pieced together from small
parts, each of which is represented by a series.
Programming Drill 1.3.3 Expand your program. Add functions for multiplication,
division, and returning the polar coordinates of a number.
We have covered the basic language of complex numbers. Before we embark on
our quantum journey, we need another tool: vector spaces over the complex ﬁeld.
.................................................................................
References: Most of the material found in this chapter can be found in any calcu-
lus or linear algebra textbook. References for some of the more advanced material
presented at the end of the chapter can be found in, e.g., Bak and Newman (1996),
Needham (1999), Schwerdtfeger (1980), andSilverman (1984).
The history of complex numbers goes back to the mid-sixteenth century during
the Italian Renaissance. The story of Tartaglia, Cardano, Bombelli and their effortto solve algebraic equations is well worth reading. Some of this fascinating tale is in
Nahin (1998), Mazur (2002), and several wonderful sections in Penrose (1994).

<<<PAGE 47>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2
Complex Vector Spaces
Philosophy is written in that great book which continually
lies open before us (I mean the Universe). But one cannot
understand this book until one has learned to understandthe language and to know the letters in which it is written. It
is written in the language of mathematics, and the letters are
triangles, circles and other geometric ﬁgures. Without thesemeans it is impossible for mankind to understand a single
word; without these means there is only vain stumbling in a
dark labyrinth.
1
Galileo Galilei
Quantum theory is cast in the language of complex vector spaces. These are mathe-
matical structures that are based on complex numbers. We learned all that we need
about such numbers in Chapter 1. Armed with this knowledge, we can now tackle
complex vector spaces themselves.
Section 2.1 goes through the main example of a (ﬁnite-dimensional) complex
vector space at tutorial pace. Section 2.2 provides formal deﬁnitions, basic prop-erties, and more examples. Each of Section 2.3 through Section 2.7 discusses anadvanced topic.
.................................................................................
Reader Tip. The reader might ﬁnd some of this chapter to be “just boring math.”
If you are eager to leap into the quantum world, we suggest reading the ﬁrst two orthree sections before moving on to Chapter 3. Return to Chapter 2 as a reference
when needed (using the index and the table of contents to ﬁnd speciﬁc topics). ♥.................................................................................
1...L a ﬁ l o s o ﬁ a ´e scritta in questo grandissimo libro che continuamente ci sta aperto innanzi a gli occhi
(io dico l’universo), ma non si puo intendere se prima non s’impara a intender la lingua, e conoscer i
caratteri, ne’ quali ´e scritto. Egli ´e scritto in lingua matematica, e i caratteri sono triangoli, cerchi, ed altre
ﬁgure geometriche, senza i quali mezi e impossibile a intenderne umanamente parola; senza questi e unaggirarsi vanamente per un’oscuro laberinto. . . (Opere Il Saggiatore p. 171) .
29

<<<PAGE 48>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
30 Complex Vector Spaces
A small disclaimer is in order. The theory of complex vector spaces is a vast and
beautiful subject. Lengthy textbooks have been written on this important area of
mathematics. It is impossible to provide anything more than a small glimpse into
the beauty and profundity of this topic in one chapter. Rather than “teaching” ourreader complex vector spaces, we aim to cover the bare minimum of concepts, termi-nology, and notation needed in order to start quantum computing. It is our sincere
hope that reading this chapter will inspire further investigation into this remarkable
subject.
2.1CnAS THE PRIMARY EXAMPLE
The primary example of a complex vector space is the set of vectors (one-dimensional arrays) of a ﬁxed length with complex entries. These vectors will de-
scribe the states of quantum systems and quantum computers. In order to ﬁx our
ideas and to see clearly what type of structure this set has, let us carefully exam-ine one concrete example: the set of vectors of length 4. We shall denote this set as
C
4=C×C×C×C, which reminds us that each vector is an ordered list of four
complex numbers.
A typical element of C4looks like this:
⎡
⎢⎢⎢⎢⎢⎢⎢⎣6−4i
7+3i
4.2−8.1i
−3i⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (2.1)
We might call this vector V. We denote the jth element of VasV[j]. The top row
is row number 0 (not 1);
2hence, V[1]=7+3i.
What types of operations can we carry out with such vectors? One operation
that seems obvious is to form the addition of two vectors. For example, given two
vectors of C4
V=⎡
⎢⎢⎢⎢⎢⎢⎢⎣6−4i
7+3i
4.2−8.1i
−3i⎤
⎥⎥⎥⎥⎥⎥⎥⎦and W=⎡
⎢⎢⎢⎢⎢⎢⎢⎣16+2.3i
−7i
6
−4i⎤
⎥⎥⎥⎥⎥⎥⎥⎦, (2.2)
2Computer scientists generally start indexing their rows and columns at 0. In contrast, mathematicians
and physicists tend to start indexing at 1. The difference is irrelevant. We shall generally follow thecomputer science convention (after all, this is a computer science text).

<<<PAGE 49>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.1Cnas the Primary Example 31
we can add them to form V+W∈C4by adding their respective entries:
⎡
⎢⎢⎢⎢⎢⎢⎢⎣6−4i
7+3i
4.2−8.1i
−3i⎤
⎥⎥⎥⎥⎥⎥⎥⎦+⎡
⎢⎢⎢⎢⎢⎢⎢⎣16+2.3i
−7i
6
−4i⎤
⎥⎥⎥⎥⎥⎥⎥⎦=⎡
⎢⎢⎢⎢⎢⎢⎢⎣(6−4i)+(16+2.3i)
(7+3i)+(−7i)
(4.2−8.1i)+(6)
(−3i)+(−4i)⎤
⎥⎥⎥⎥⎥⎥⎥⎦=⎡
⎢⎢⎢⎢⎢⎢⎢⎣22−1.7i
7−4i
10.2−8.1i
−7i⎤
⎥⎥⎥⎥⎥⎥⎥⎦.
(2.3)
Formally, this operation amounts to
(V+W)[j]=V[j]+W[j]. (2.4)
Exercise 2.1.1 Add the following two vectors:
⎡
⎢⎢⎢⎢⎢⎢⎢⎣5+13i
6+2i
0.53−6i
12⎤
⎥⎥⎥⎥⎥⎥⎥⎦+⎡
⎢⎢⎢⎢⎢⎢⎢⎣7−8i
4i
2
9.4+3i⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (2.5)
/squaresolid
The addition operation satisﬁes certain properties. For example, because the
addition of complex numbers is commutative, addition of complex vectors is also
commutative:
V+W=⎡
⎢⎢⎢⎢⎢⎢⎢⎣(6−4i)+(16+2.3i)
(7+3i)+(−7i)
(4.2−8.1i)+(6)
(−3i)+(−4i)⎤
⎥⎥⎥⎥⎥⎥⎥⎦=⎡
⎢⎢⎢⎢⎢⎢⎢⎣22−1.7i
7−4i
10.2−8.1i
−7i⎤
⎥⎥⎥⎥⎥⎥⎥⎦
=⎡
⎢⎢⎢⎢⎢⎢⎢⎣(16+2.3i)+(6−4i)
(−7i)+(7+3i)
(6)+(4.2−8.1i)
(−4i)+(−3i)⎤
⎥⎥⎥⎥⎥⎥⎥⎦=W+V. (2.6)
Similarly, addition of complex vectors is also associative, i.e., given three vectors
V,W, and X, we may add them as ( V+W)+Xor as V+(W+X). Associativity
states that the resulting sums are the same:
(V+W)+X=V+(W+X). (2.7)
Exercise 2.1.2 Formally prove the associativity property. /squaresolid

<<<PAGE 50>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
32 Complex Vector Spaces
There is also a distinguished vector called zero:
0=⎡
⎢⎢⎢⎢⎢⎢⎢⎣0
000⎤
⎥⎥⎥⎥⎥⎥⎥⎦, (2.8)
which satisﬁes the following property: for all vectors V∈C
4, we have
V+0=V=0+V. (2.9)
Formally, 0is deﬁned as 0[j]=0.
Every vector also has an (additive) inverse (ornegative). Consider
V=⎡
⎢⎢⎢⎢⎢⎢⎢⎣6−4i
7+3i
4.2−8.1i
−3i⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (2.10)
There exists in C
4another vector
−V=⎡
⎢⎢⎢⎢⎢⎢⎢⎣−6+4i
−7−3i
−4.2+8.1i
3i⎤
⎥⎥⎥⎥⎥⎥⎥⎦∈C
4(2.11)
such that
V+(−V)=⎡
⎢⎢⎢⎢⎢⎢⎢⎣6−4i
7+3i
4.2−8.1i
−3i⎤
⎥⎥⎥⎥⎥⎥⎥⎦+⎡
⎢⎢⎢⎢⎢⎢⎢⎣−6+4i
−7−3i
−4.2+8.1i
3i⎤
⎥⎥⎥⎥⎥⎥⎥⎦=⎡
⎢⎢⎢⎢⎢⎢⎢⎣0
0
0
0⎤
⎥⎥⎥⎥⎥⎥⎥⎦=0. (2.12)
In general, for every vector W∈C
4, there exists a vector −W∈C4such that
W+(−W)=(−W)+W=0.−Wis called the inverse ofW. Formally,
(−W)[j]=−(W[j]). (2.13)
The set C4with the addition, inverse operations, and zero such that the addition
is associative and commutative, form something called an Abelian group .

<<<PAGE 51>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.1Cnas the Primary Example 33
What other structure does our set C4have? Take an arbitrary complex number,
say, c=3+2i. Call this number a scalar . Take a vector
V=⎡
⎢⎢⎢⎢⎢⎢⎢⎣6+3i
0+0i
5+1i
4⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (2.14)
We can multiply an element by a scalar by multiplying the scalar with each entry of
the vector; i.e.,
(3+2i)·⎡
⎢⎢⎢⎢⎢⎢⎢⎣6+3i
0+0i
5+1i
4⎤
⎥⎥⎥⎥⎥⎥⎥⎦=⎡
⎢⎢⎢⎢⎢⎢⎢⎣12+21i
0+0i
13+13i
12+8i⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (2.15)
Formally, f or a complex number cand a vector V,w ef o r mc ·V, which is deﬁned as
(c·V)[j]=c×V[j], (2.16)
where the ×is complex multiplication. We shall omit the ·when the scalar multipli-
cation is understood.
Exercise 2.1.3 Scalar multiply 8 −2iwith⎡
⎣
16+2.3i
−7i
6
5−4i⎤⎦. /squaresolid
Scalar multiplication satisﬁes the following properties: for all c,c
1,c2∈Cand
for all V,W∈C4,/D21·V=V,/D2c1·(c2·V)=(c1×c2)·V,/D2c·(V+W)=c·V+c·W,/D2(c1+c2)·V=c1·V+c2·V.
Exercise 2.1.4 Formally prove that (c 1+c2)·V=c1·V+c2·V. /squaresolid
An Abelian group with a scalar multiplication that satisﬁes these properties is
called a complex vector space .
Notice that we have been working with vectors of size 4. However, everything
that we have stated about vectors of size 4 is also true for vectors of arbitrary size.
So the set Cnfor a ﬁxed but arbitrary nalso has the structure of a complex vector
space. In fact, these vector spaces will be the primary examples we will be working
with for the rest of the book.

<<<PAGE 52>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
34 Complex Vector Spaces
Programming Drill 2.1.1 Write three functions that perform the addition, inverse,
and scalar multiplication operations for Cn, i.e., write a function that accepts the ap-
propriate input for each of the operations and outputs the vector.
2.2 DEFINITIONS, PROPERTIES, AND EXAMPLES
There are many other examples of complex vector spaces. We shall need to broaden
our horizon and present a formal deﬁnition of a complex vector space.
Deﬁnition 2.2.1 Acomplex vector space is a nonempty set V, whose elements we
shall call vectors, with three operations/D2Addition: +:V×V−→V/D2Negation: −:V−→V/D2Scalar multiplication: ·:C×V−→V
and a distinguished element called the zero vector 0 ∈Vin the set. These opera-
tions and zero must satisfy the following properties: for all V ,W,X∈Vand for
all c,c1,c2∈C,
(i)Commutativity of addition: V +W=W+V,
(ii)Associativity of addition: (V+W)+X=V+(W+X),
(iii) Zero is an additive identity: V +0=V=0+V,
(iv) Every vector has an inverse: V +(−V)=0=(−V)+V,
(v)Scalar multiplication has a unit: 1·V=V,
(vi) Scalar multiplication respects complex multiplication:
c1·(c2·V)=(c1×c2)·V, (2.17)
(vii) Scalar multiplication distributes over addition:
c·(V+W)=c·V+c·W, (2.18)
(viii) Scalar multiplication distributes over complex addition:
(c1+c2)·V=c1·V+c2·V. (2.19)
To recap, any set that has an addition operation, an inverse operation, and a zero
element that satisﬁes Properties (i), (ii), (iii), and (iv) is called an Abelian group. If,
furthermore, there is a scalar multiplication operation that satisﬁes all the proper-
ties, then the set with the operations is called a complex vector space .
Although our main concern is complex vector spaces, we can gain much intuition
from real vector spaces.
Deﬁnition 2.2.2 Areal vector space is a nonempty set V(whose elements we shall
call vectors), along with an addition operation and a negation operation. Most impor-
tant, there is a scalar multiplication that uses Rand not C, i.e.,
·:R×V−→V. (2.20)
This set and these operations must satisfy the analogous properties of a complex vectorspace.

<<<PAGE 53>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.2 Deﬁnitions, Properties, and Examples 35
In plain words, a real vector space is like a complex vector space except that we
only require the scalar multiplication to be deﬁned for scalars in R⊂C.F r o mt h e
fact that R⊂C, it is easy to see that for every Vwe have R×V⊂C×V. If we have
a given
·:C×V−→V, (2.21)
then we can write
R×V/arrowhookleft→C×V−→V. (2.22)
We conclude that every complex vector space can automatically be given a real
vector space structure.
Let us descend from the abstract highlands and look at some concrete examples.
Example 2.2.1 Cn, the set of vectors of length nwith complex entries, is a com-
plex vector space that serves as our primary example for the rest of the book. InSection 2.1, we exhibited the operations and described the properties that are sati-
sﬁed. /square
Example 2.2.2 C
n, the set of vectors of length nwith complex entries, is also a real
vector space because every complex vector space is also a real vector space. Theoperations are the same as those in Example 2.2.1. /square
Example 2.2.3 R
n, the set of vectors of length nwith real number entries, is a real
vector space. Notice that there is no obvious way to make this into a complex vec-tor space. What would the scalar multiplication of a complex number with a realvector be? /square
In Chapter 1, we discussed the geometry of C=C
1. We showed how every com-
plex number can be thought of as a point in a two-dimensional plane. Things getmore complicated for C
2. Every element of C2involves two complex numbers or
four real numbers. One could visualize this as an element of four-dimensional space.
However, the human brain is not equipped to visualize four-dimensional space. The
most we can deal with is three dimensions. Many times throughout this text, weshall discuss C
nand then revert to R3in order to develop an intuition for what is
going on.
It pays to pause for a moment to take an in-depth look at the geometry of R3.
Every vector of R3can be thought of as a point in three-dimensional space or equiv-
alently, as an arrow from the origin of R3to that point. So the vector/bracketleftBigg
5
−7
6.3/bracketrightBigg
shown
inFigure 2.1 is 5 units in the xdirection, −7 units in the ydirection, and 6.3 units in
thezdirection.
Given two vectors V=/bracketleftBigg
r0
r1
r2/bracketrightBigg
and V/prime=⎡
⎣r/prime
0
r/prime
1
r/prime
2⎤⎦ofR
3, we may add them to form
/bracketleftBigg
r0+r/prime
0
r1+r/prime
1
r2+r/prime
2/bracketrightBigg
. Addition can be seen as making a parallelogram in R3where you attach
the beginning of one arrow to the end of the other one. The result of the addition is

<<<PAGE 54>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
36 Complex Vector Spaces
Figure 2.1. A vector in three
dimensional space.
the composition of the arrows (see Figure 2.2). The reason that we can be ambiguous
about which arrow comes ﬁrst demonstrates the commutativity property of addition.
Given a vector V=/bracketleftBigg
r0
r1
r2/bracketrightBigg
inR3, we form the inverse −V=/bracketleftBigg
−r0
−r1
−r2/bracketrightBigg
by looking at
the arrow in the opposite direction with respect to all dimensions (as in Figure 2.3).
And ﬁnally, the scalar multiplication of a real number rand a vector V=/bracketleftBigg
r0
r1
r2/bracketrightBigg
isr·V=/bracketleftBigg
rr0
rr1
rr2/bracketrightBigg
, which is simply the vector Vstretched or shrunk by r(as in Fig-
ure 2.4).
It is useful to look at some of the properties of a vector space from the geometric
point of view. For example, consider the property r·(V+W)=r·V+r·W.This
corresponds to Figure 2.5.
Exercise 2.2.1 Letr1=2,r2=3, and V=/bracketleftBigg
2
−4
1/bracketrightBigg
. Verify Property (vi), i.e., calcu-
later1·(r2·V) and ( r1×r2)·Vand show that they coincide. /squaresolid
Exercise 2.2.2 Draw pictures in R3that explain Properties (vi) and (viii) of the
deﬁnition of a real vector space. /squaresolid
Let us continue our list of examples.
Example 2.2.4 Cm×n,t h es e to fa l l m-by-nmatrices (two-dimensional arrays) with
complex entries, is a complex vector space. /square
′
′
′
Figure 2.2. Vector addition.

<<<PAGE 55>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.2 Deﬁnitions, Properties, and Examples 37
Figure 2.3. Inverse of a vector.
For a given A∈Cm×n, we denote the complex entry in the jth row and the kth
column as A[j,k]o rcj,k. We shall denote the jth row as A[j,−] and the kth col-
umn as A[−,k]. Several times throughout the text we shall show the row and column
numbers explicitly to the left and top of the square brackets:
A=⎡
⎢⎢⎢⎢⎣01 ··· n−1
0 c
0,0 c0,1··· c0,n−1
1 c1,0 c1,1··· c1,n−1
...............
m−1 cm−1,0cm−1,1··· cm−1,n−1⎤
⎥⎥⎥⎥⎦. (2.23)
The operations for C
m×nare given as follows: Addition is
⎡
⎢⎢⎢⎢⎢⎢⎢⎣c
0,0 c0,1··· c0,n−1
c1,0 c1,1··· c1,n−1
............
c
m−1,0cm−1,1··· cm−1,n−1⎤
⎥⎥⎥⎥⎥⎥⎥⎦+⎡
⎢⎢⎢⎢⎢⎢⎢⎣d
0,0 d0,1··· d0,n−1
d1,0 d1,1··· d1,n−1
............
d
m−1,0dm−1,1··· dm−1,n−1⎤
⎥⎥⎥⎥⎥⎥⎥⎦
=⎡
⎢⎢⎢⎢⎢⎢⎢⎣c
0,0+d0,0 c0,1+d0,1··· c0,n−1+d0,n−1
c1,0+d1,0 c1,1+d1,1··· c1,n−1+d1,n−1
............
c
m−1,0+dm−1,0cm−1,1+dm−1,1··· cm−1,n−1+dm−1,n−1⎤
⎥⎥⎥⎥⎥⎥⎥⎦.(2.24)
Figure 2.4. A real multiple of a
vector.

<<<PAGE 56>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
38 Complex Vector Spaces
Figure 2.5. Scalar multiplication distributes over addition.
The inverse operation is given as
−⎡
⎢⎢⎢⎢⎢⎢⎢⎣c
0,0 c0,1··· c0,n−1
c1,0 c1,1··· c1,n−1
............
c
m−1,0cm−1,1··· cm−1,n−1⎤
⎥⎥⎥⎥⎥⎥⎥⎦=⎡
⎢⎢⎢⎢⎢⎢⎢⎣−c
0,0−c0,1··· − c0,n−1
−c1,0−c1,1··· − c1,n−1
............
−c
m−1,0−cm−1,1··· − cm−1,n−1⎤
⎥⎥⎥⎥⎥⎥⎥⎦.
(2.25)
Scalar multiplication is given as
c·⎡
⎢⎢⎢⎢⎢⎢⎢⎣c
0,0 c0,1··· c0,n−1
c1,0 c1,1··· c1,n−1
............
c
m−1,0cm−1,1··· cm−1,n−1⎤
⎥⎥⎥⎥⎥⎥⎥⎦
=⎡
⎢⎢⎢⎢⎢⎢⎢⎣c×c
0,0 c×c0,1··· c×c0,n−1
c×c1,0 c×c1,1··· c×c1,n−1
............
c×c
m−1,0c×cm−1,1··· c×cm−1,n−1⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (2.26)
Formally, these operations can be described by the following formulas:
For two matrices, A,B∈C
m×n, we add them as
(A+B)[j,k]=A[j,k]+B[j,k]. (2.27)
The inverse of Ais
(−A)[j,k]=−(A[j,k]). (2.28)

<<<PAGE 57>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.2 Deﬁnitions, Properties, and Examples 39
The scalar multiplication of Awith a complex number c∈Cis
(c·A)[j,k]=c×A[j,k]. (2.29)
Exercise 2.2.3 Let c1=2i,c2=1+2i, and A=/bracketleftbigg
1−i 3
2+2i4+i/bracketrightbigg
. Verify Properties
(vi) and (viii) in showing C2×2is a complex vector space. /squaresolid
Exercise 2.2.4 Show that these operations on Cm×nsatisfy Properties (v), (vi), and
(viii) of being a complex vector space. /squaresolid
Programming Drill 2.2.1 Convert your functions from the last programming drill so
that instead of accepting elements of Cn, they accept elements of Cm×n.
When n=1, the matrices Cm×n=Cm×1=Cm, which we dealt with in Sec-
tion 2.1. Thus, we can think of vectors as special types of matrices.
When m=n, the vector space Cn×nhas more operations and more structure
than just a complex vector space. Here are three operations that one can perform
on an A∈Cn×n:/D2The transpose ofA, denoted AT, is deﬁned as
AT[j,k]=A[k,j]. (2.30)/D2The conjugate ofA, denoted A, is the matrix in which each element is the
complex conjugate of the corresponding element of the original matrix,3i.e.,
A[j,k]=A[j,k]./D2The transpose operation and the conjugate operation are combined to form theadjoint ordagger operation. The adjoint of A, denoted as A
†, is deﬁned as A†=
(A)T=(AT)o r A†[j,k]=A[k,j].
Exercise 2.2.5 Find the transpose, conjugate, and adjoint of
⎡
⎢⎢⎢⎢⎣6−3i2+12i−19i
05+2.1i 17
12 +5i3−4.5i⎤
⎥⎥⎥⎥⎦. (2.31)
/squaresolid
These three operations are deﬁned even when m/negationslash=n. The transpose and adjoint
are both functions from C
m×ntoCn×m.
These operations satisfy the following properties for all c∈Cand for all A,
B∈Cm×n:
(i) Transpose is idempotent: ( AT)T=A.
(ii) Transpose respects addition: ( A+B)T=AT+BT.
(iii) Transpose respects scalar multiplication: ( c·A)T=c·AT.
3This notation is overloaded. It is an operation on complex numbers and complex matrices.

<<<PAGE 58>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
40 Complex Vector Spaces
(iv) Conjugate is idempotent: A=A.
(v) Conjugate respects addition: A+B=A+B.
(vi) Conjugate respects scalar multiplication: c·A=c·A.
(vii) Adjoint is idempotent: ( A†)†=A.
(viii) Adjoint respects addition: ( A+B)†=A†+B†.
(ix) Adjoint relates to scalar multiplication: ( c·A)†=c·A†.
Exercise 2.2.6 Prove that conjugation respects scalar multiplication, i.e., c·A=
c·A. /squaresolid
Exercise 2.2.7 Prove Properties (vii), (viii), and (ix) using Properties (i) – (vi). /squaresolid
The transpose shall be used often in the text to save space. Rather than writing
⎡
⎢⎢⎢⎢⎢⎢⎢⎣c
0
c1
...
cn−1⎤
⎥⎥⎥⎥⎥⎥⎥⎦(2.32)
which requires more space, we write [c
0,c1,···,cn−1]T.
When m=n, there is another binary operation that is used: matrix multiplica-
tion. Consider the following two 3-by-3 matrices:
A=⎡
⎢⎢⎢⎢⎣3+2i 05−6i
14+2ii
4−i 04⎤
⎥⎥⎥⎥⎦,B=⎡
⎢⎢⎢⎢⎣52 −i6−4i
04+5i 2
7−4i2+7i 0⎤
⎥⎥⎥⎥⎦.(2.33)
We form the matrix product of Aand B, denoted A⋆B.A⋆Bwill also be a 3-by-3
matrix. ( A⋆B)[0,0] will be found by multiplying each element of the 0th row of A
with the corresponding element of the 0th column of B. We then sum the results:
(A⋆B)[0,0]=((3+2i)×5)+(0×0)+((5−6i)×(7−4i))
=(15+10i)+(0)+(11−62i)=26−52i. (2.34)
The (A⋆B)[j,k]entry canbefound by
multiplying each element of A[j,−]w i t h
the appropriate element of B[−,k] and summing the results. So,
(A⋆B)=⎡
⎢⎢⎢⎢⎣26−52i60+24i 26
9+7i 1+29i 14
48−21i15+22i20−22i⎤
⎥⎥⎥⎥⎦. (2.35)
Exercise 2.2.8 Find B⋆A. Does it equal A⋆B? /squaresolid
Matrix multiplication is
deﬁned in a more general setting. The matrices do not
have to be square. Rather, the number of columns in the ﬁrst matrix must be the

<<<PAGE 59>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.2 Deﬁnitions, Properties, and Examples 41
same as the number of rows in the second one. Matrix multiplication is a binary
operation
⋆:Cm×n×Cn×p−→Cm×p. (2.36)
Formally, given AinCm×nand BinCn×p, we construct A⋆BinCm×pas
(A⋆B)[j,k]=n−1/summationdisplay
h=0(A[j,h]×B[h,k]). (2.37)
When the multiplication is understood, we shall omit the ⋆.
For every n, there is a special n-by-nmatrix called the identity matrix ,
In=⎡
⎢⎢⎢⎢⎢⎢⎢⎣10··· 0
01··· 0
............
00··· 1⎤
⎥⎥⎥⎥⎥⎥⎥⎦, (2.38)
that plays the role of a unit of matrix multiplication. When nis understood, we shall
omit it.
Matrix multiplication satisﬁes the following properties: For all A,B,and Cin
C
n×n,
(i) Matrix multiplication is associative: ( A⋆B)⋆C=A⋆(B⋆C).
(ii) Matrix multiplication has Inas a unit: In⋆A=A=A⋆In.
(iii) Matrix multiplication distributes over addition:
A⋆(B+C)=(A⋆B)+(A⋆C), (2.39)
(B+C)⋆A=(B⋆A)+(C⋆A). (2.40)
(iv) Matrix multiplication respects scalar multiplication:
c·(A⋆B)=(c·A)⋆B=A⋆(c·B). (2.41)
(v) Matrix multiplication relates to the transpose:
(A⋆B)T=BT⋆AT. (2.42)
(vi) Matrix multiplication respects the conjugate:
A⋆B=A⋆B. (2.43)
(vii) Matrix multiplication relates to the adjoint:
(A⋆B)†=B†⋆A†. (2.44)
Notice that commutativity is nota basic property of matrix multiplication. This
fact will be very important in quantum mechanics.
Exercise 2.2.9 Prove Property (v) in the above list. /squaresolid

<<<PAGE 60>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
42 Complex Vector Spaces
Exercise 2.2.10 Use Aand Bfrom Equation (2.33) and show that ( A⋆B)†=B†
⋆A†. /squaresolid
Exercise 2.2.11 Prove Property (vii) from Properties (v) and (vi). /squaresolid
Deﬁnition 2.2.3 A complex vector space Vwith a multiplication ⋆that satisﬁes the
ﬁrst four properties is called a complex algebra .
Programming Drill 2.2.2 Write a function that accepts two complex matrices of the
appropriate size. The function should do matrix multiplication and return the result.
LetAbe any element in Cn×n. Then for any element B∈Cn, we have that A⋆B
is inCn. In other words, multiplication by Agives one a function from CntoCn.
From Equations (2.39) and (2.41), we see that this function preserves addition and
scalar multiplication. We will write this map as A:Cn−→Cn.
Let us look ahead for a moment and see what relevance this abstract mathe-
matics has for quantum computing. Just as Cnhas a major role, the complex al-
gebra Cn×nshall also be in our cast of characters. The elements of Cnare the
ways of describing the states of a quantum system. Some suitable elements ofC
n×nwill correspond to the changes that occur to the states of a quantum sys-
tem. Given a state X∈Cnand a matrix A∈Cn×n, we shall form another state of
the system A⋆Xwhich is an element of Cn.4Formally, ⋆in this case is a function
⋆:Cn×n×Cn−→Cn. We say that the algebra of matrices “ acts” on the vectors to
yield new vectors. We shall see this action again and again in the following chapters.
Programming Drill 2.2.3 Write a function that accepts a vector and a matrix and
outputs the vector resulting from the “action.”
We return to our list of examples.
Example 2.2.5 Cm×n,t h es e to fa l l m-by-nmatrices (two-dimensional arrays) with
complex entries, is a real vector space. (Remember: Every complex vector space isalso a real vector space.) /square
Example 2.2.6 R
m×n,t h es e to fa l l m-by-nmatrices (two-dimensional arrays) with
real entries, is a real vector space. /square
Deﬁnition 2.2.4 Given two complex vector spaces VandV/prime, we say that Vis acom-
plex subspace ofV/primeifVis a subset of V/primeand the operations of Vare restrictions of
operations of V/prime.
Equivalently, Vis a complex subspace of V/primeifVis a subset of the set V/primeand
(i)Vis closed under addition: For all V1and V2inV,V1+V2∈V.
(ii)Vis closed under scalar multiplication: For all c∈Cand V∈V,c·V∈V.
4This might seem reminiscent of computer graphics. In fact, there is a vague relationship that we shallsee when we discuss the Bloch sphere (in Chapter 5) and unitary matrices.

<<<PAGE 61>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.2 Deﬁnitions, Properties, and Examples 43
It turns out that being closed under addition and multiplication implies that Vis also
closed under inverse and that 0∈V.
Example 2.2.7 Consider the set of all vectors of C9with the second, ﬁfth, and
eighth position elements being 0:
[c0,c1,0,c3,c4,0,c6,c7,0]T. (2.45)
It is not hard to see that this is a complex subspace of C9. We shall see in a few
moments that this subspace is the “same” as C6. /square
Example 2.2.8 Consider the set Poly nof polynomials of degree nor less in one
variable with coefﬁcients in C.
P(x)=c0+c1x+c2x2+···+ cnxn. (2.46)
Poly nforms a complex vector space. /square
For completeness, let us go through the operations. Addition is given as
P(x)+Q(x)=(c0+c1x+c2x2+···+ cnxn)+(d0+d1x+d2x2+···+ dnxn)
=(c0+d0)+(c1+d1)x+(c2+d2)x2+···+ (cn+dn)xn.(2.47)
Negation is given as
−P(x)=−c0−c1x−c2x2−···− cnxn. (2.48)
Scalar multiplication by c∈Cis given as
c·P(x)=c×c0+c×c1x+c×c2x2+···+ c×cnxn. (2.49)
Exercise 2.2.12 Show that Polynwith these operations satisﬁes the properties of
being a complex vector space. /squaresolid
Exercise 2.2.13 Show that Poly5is a complex subspace of Poly7. /squaresolid
Example 2.2.9 Polynomials in one variable of degree nor less with coefﬁcients in
Calso form a real vector space. /square
Example 2.2.10 Polynomials in one variable of degree nor less with coefﬁcients
inR
P(x)=r0+r1x+r2x2+···+ rnxn(2.50)
form a real vector space. /square
Deﬁnition 2.2.5 LetVandV/primebe two complex vector spaces. A linear map from Vto
V/primeis a function f :V−→V/primesuch that for all V ,V1,V2∈V, and c ∈C,
(i)f respects the addition: f (V1+V2)=f(V1)+f(V2),
(ii) f respects the scalar multiplication: f (c·V)=c·f(V).

<<<PAGE 62>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
44 Complex Vector Spaces
Almost all the maps that we shall deal with in this text are linear maps. We have
already seen that when a matrix acts on a vector space, it is a linear map. We shall
call any linear map from a complex vector space to itself an operator.I f F:Cn−→
Cnis an operator on Cnand Ais an n-by-nmatrix such that for all Vwe have
F(V)=A⋆V, then we say that Fisrepresented byA. Several different matrices
might represent the same operator.
Computer scientists usually store a polynomial as the array of its coefﬁcients,
i.e., a polynomial with n+1 complex coefﬁcients is stored as an n+1 vector. So it
is not surprising that Poly nis the “same” as Cn+1. We will now formulate what it
means for two vector spaces to be the “same.”
Deﬁnition 2.2.6 Two complex vector spaces VandV/primeareisomorphic if there is
a one-to-one onto linear map f :V−→V/prime. Such a map is called an isomorphism .
When two vector spaces are isomorphic, it means that the names of the elements of
the vector spaces are renamed but the structure of the two vector spaces are the same.Two such vector spaces are “essentially the same” or “the same up to isomorphism.”
Exercise 2.2.14 Show that all real matrices of the form
⎡
⎢⎣xy
−yx⎤
⎥⎦ (2.51)
comprise a real subspace of R
2×2. Then show that this subspace is isomorphic to C
via the map f:C−→R2×2that is deﬁned as
f(x+iy)=⎡
⎢⎣xy
−yx⎤
⎥⎦. (2.52)
/squaresolid
Example 2.2.11 Consider the set Func (N,C) of functions from the natural num-
bersNto the complex numbers C. Given two functions f:N−→Candg:N−→C,
we may add them to form
(f+g)(n)=f(n)+g(n). (2.53)
The additive inverse of fis
(−f)(n)=−(f(n)). (2.54)
The scalar multiple of c∈Cand fis the function
(c·f)(n)=c×f(n). (2.55)
Because the operations are determined by
their values at each of their “points” in
the input, the constructed functions are said to be constructed pointwise . /square

<<<PAGE 63>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.3 Basis and Dimension 45
Exercise 2.2.15 Show that Func (N,C) with these operations forms a complex vec-
tor space. /squaresolid
Example 2.2.12 We can generalize Func (N,C) to other sets of functions. For
any a<binR, the set of functions from the interval [ a,b]⊆RtoCdenoted
Func ([a,b],C) is a complex vector space. /square
Exercise 2.2.16 Show that Func (N,R) and Func ([a,b],R) are real vector spaces.
/squaresolid
Example 2.2.13 There are several ways of constructing new vector spaces from
existing ones. Here we see one method and Section 2.7 describes another. Let
(V,+,−,0,·) and ( V/prime,+/prime,−/prime,0/prime,·/prime) be two complex vector spaces. We construct a
new complex vector space (V ×V/prime,+/prime/prime,−/prime/prime,0/prime/prime,·/prime/prime) called the Cartesian product5or
thedirect sum ofVandV/prime. The vectors are ordered pairs of vectors ( V,V/prime)∈V×V/prime.
Operations are performed pointwise:
(V1,V/prime
1)+/prime/prime(V2,V/prime
2)=(V1+V2,V/prime
1+/primeV/prime
2), (2.56)
−/prime/prime(V,V/prime)=(−V,−/primeV/prime), (2.57)
0/prime/prime=(0,0/prime), (2.58)
c·/prime/prime(V,V/prime)=(c·V,c·/primeV/prime). (2.59)
/square
Exercise 2.2.17 Show that Cm×Cnis isomorphic to Cm+n. /squaresolid
Exercise 2.2.18 Show that CmandCnare each a complex subspace of Cm×Cn./squaresolid
2.3 BASIS AND DIMENSION
A basis of a vector space is a set of vectors of that vector space that is specialin the sense that all other vectors can be uniquely written in terms of these basis
vectors.
Deﬁnition 2.3.1 LetVbe a complex (real) vector space. V ∈Vis alinear combina-
tion of the vectors V
0,V1,..., Vn−1inVif V can be written as
V=c0·V0+c1·V1+···+ cn−1·Vn−1 (2.60)
for some c 0,c1,..., cn−1inC(R).
L e tu sr e t u r nt oR3for examples.
5A note to the meticulous reader: Although we used ×for the product of two complex numbers, here
we use it for the Cartesian product of sets and the Cartesian product of vector spaces. We feel it is
better to overload known symbols than to introduce a plethora of new ones.

<<<PAGE 64>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
46 Complex Vector Spaces
Example 2.3.1 As
3⎡
⎢⎢⎢⎢⎣5
−2
3⎤
⎥⎥⎥⎥⎦+5⎡
⎢⎢⎢⎢⎣0
14⎤
⎥⎥⎥⎥⎦−4⎡
⎢⎢⎢⎢⎣−6
1
0⎤
⎥⎥⎥⎥⎦+2.1⎡
⎢⎢⎢⎢⎣3
11⎤
⎥⎥⎥⎥⎦=⎡
⎢⎢⎢⎢⎣45.3
−2.9
31.1⎤
⎥⎥⎥⎥⎦, (2.61)
we say that
[45.3,−2.9, 31.1]
T(2.62)
is a linear combination of
⎡
⎢⎢⎢⎢⎣5
−2
3⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣0
14⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣−6
1
0⎤
⎥⎥⎥⎥⎦,and⎡
⎢⎢⎢⎢⎣3
11⎤
⎥⎥⎥⎥⎦. (2.63)
/square
Deﬁnition 2.3.2 As e t{V
0,V1,..., Vn−1}of vectors in Vis called linearly indepen-
dent if
0=c0·V0+c1·V1+···+ cn−1·Vn−1 (2.64)
implies that c 0=c1=···= cn−1=0. This means that the only way that a linear com-
bination of the vectors can be the zero vector is if all the c jare zero.
It can be shown that this deﬁnition is equivalent to saying that for any nonzero
V∈V, there are unique coefﬁcients c0,c1,..., cn−1inCsuch that
V=c0·V0+c1·V1+···+ cn−1·Vn−1. (2.65)
The set of vectors are called linearly independent because each of the vectors in
the set{V0,V1,..., Vn−1}cannot be written as a combination of the others in the set.
Example 2.3.2 The set of vectors
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩⎡
⎢⎢⎢⎢⎣1
11⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣0
11⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣0
01⎤
⎥⎥⎥⎥⎦⎫
⎪⎪⎪⎪⎬
⎪⎪⎪⎪⎭(2.66)
is linearly independent because the only way that
0=⎡
⎢⎢⎢⎢⎣0
00⎤
⎥⎥⎥⎥⎦=x⎡
⎢⎢⎢⎢⎣1
11⎤
⎥⎥⎥⎥⎦+y⎡
⎢⎢⎢⎢⎣0
11⎤
⎥⎥⎥⎥⎦+z⎡
⎢⎢⎢⎢⎣0
01⎤
⎥⎥⎥⎥⎦(2.67)
can occur is if 0 =x,0=x+y, and 0 =x+y+z.
By substitution, we see that
x=y=z=0. /square

<<<PAGE 65>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.3 Basis and Dimension 47
Example 2.3.3 The set of vectors
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩⎡
⎢⎢⎢⎢⎣1
11⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣0
11⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣2
−1
−1⎤
⎥⎥⎥⎥⎦⎫
⎪⎪⎪⎪⎬
⎪⎪⎪⎪⎭(2.68)
is not linearly independent (called linearly dependent) because
0=⎡
⎢⎢⎢⎢⎣0
00⎤
⎥⎥⎥⎥⎦=x⎡
⎢⎢⎢⎢⎣1
11⎤
⎥⎥⎥⎥⎦+y⎡
⎢⎢⎢⎢⎣0
11⎤
⎥⎥⎥⎥⎦+z⎡
⎢⎢⎢⎢⎣2
−1
−1⎤
⎥⎥⎥⎥⎦(2.69)
can happen when x=2,y=−3, and z=−1. /square
Exercise 2.3.1 Show that the set of vectors
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩⎡
⎢⎢⎢⎢⎣1
23⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣3
02⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣1
−4
−4⎤
⎥⎥⎥⎥⎦⎫
⎪⎪⎪⎪⎬
⎪⎪⎪⎪⎭(2.70)
is not linearly independent. /squaresolid
Deﬁnition 2.3.3 As e tB ={V
0,V1,..., Vn−1}⊆Vof vectors is called a basis of a
(complex) vector space Vif both
(i)every, V ∈Vcan be written as a linear combination of vectors from Band
(ii)Bis linearly independent.
Example 2.3.4 R3has a basis
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩⎡
⎢⎢⎢⎢⎣1
11⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣0
11⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣0
01⎤
⎥⎥⎥⎥⎦⎫
⎪⎪⎪⎪⎬
⎪⎪⎪⎪⎭. (2.71)
/square
Exercise 2.3.2 Verify that the preceding three vectors are in fact a basis of R
3./squaresolid
There may be many sets that each form a basis of a particular vector space but
there is also a basis that is easier to work with called the canonical basis or the
standard basis. Many of the examples that we will deal with have canonical basis.
Let us look at some examples of canonical basis.

<<<PAGE 66>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
48 Complex Vector Spaces/D2R3:
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩⎡
⎢⎢⎢⎢⎣1
00⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣0
10⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣0
01⎤
⎥⎥⎥⎥⎦⎫
⎪⎪⎪⎪⎬
⎪⎪⎪⎪⎭. (2.72)/D2Cn(and Rn):
E0=⎡
⎢⎢⎢⎢⎢⎢⎢⎣1
0
...
0⎤
⎥⎥⎥⎥⎥⎥⎥⎦,E
1=⎡
⎢⎢⎢⎢⎢⎢⎢⎣0
1
...
0⎤
⎥⎥⎥⎥⎥⎥⎥⎦, ..., E
i=⎡
⎢⎢⎢⎢⎢⎢⎢⎣0
...
1
0⎤
⎥⎥⎥⎥⎥⎥⎥⎦,. . ., E
n−1=⎡
⎢⎢⎢⎢⎢⎢⎢⎣0
0
...
1⎤
⎥⎥⎥⎥⎥⎥⎥⎦.(2.73)
Every vector [ c
0,c1,..., cn−1]Tcan be written as
n−1/summationdisplay
j=0(cj·Ej). (2.74)/D2Cm×n: The canonical basis for this vector space consists of matrices of the form
Ej,k=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣01··· k··· n−1
0 00··· 0··· 0
1 00··· 0··· 0
.........··· ···...
j 00··· 1··· 0
.........··· ···...
m−1 00··· 0··· 0⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦, (2.75)
where E
j,kh a sa1i nr o w j, column k, and 0’s everywhere else. There is an Ej,k
forj=0,1,..., m−1 and k=0,1,...,n −1. It is not hard to see that for every
m-by-nmatrix, Acan be written as the sum:
A=m−1/summationdisplay
j=0n−1/summationdisplay
k=0A[j,k]·Ej,k. (2.76)/D2Polyn: The canonical basis is formed by the following set of monomials:
1,x,x2,..., xn. (2.77)

<<<PAGE 67>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.3 Basis and Dimension 49/D2Func (N,C): The canonical basis is composed of a countably inﬁnite6number of
functions fj(j=0,1,2,... ), where fjis deﬁned as
fj(n)=⎧
⎪⎨
⎪⎩1, ifj=n,
0, otherwise.(2.78)
The deﬁnition previously given of a ﬁnite linear combination can easily be gen-
eralized to an inﬁnite linear combination. It is not hard to see that any function
f∈Func (N,C) can be written as the inﬁnite sum
f=∞/summationdisplay
j=0cj·fj, (2.79)
where cj=f(j). It is also not hard to see that these functions are linearly inde-
pendent. Hence they form a basis for Func (N,C)./D2(For the calculus-savvy reader.) Func ([a,b],C): The canonical basis is com-
posed of an uncountably inﬁnite number of functions frforr∈[a,b]⊆R, which
is deﬁned as
fr(x)=⎧
⎪⎨
⎪⎩1, ifr=x,
0, otherwise.(2.80)
These functions are linearly independent. Analogous to the last countable dis-
crete summation given in Equation (2.79), we may write any function f∈
Func ([a,b],C) as an integral:
f=/integraldisplayb
acr·fr, (2.81)
where cr=f(r). Hence the frform a basis for Func ([a,b],C).
It is easy to construct a basis for a Cartesian product of two vector spaces. If
B={V0,V1,..., Vm−1}is a basis for VandB/prime={V/prime
0,V/prime
1,..., V/prime
m−1}is a basis for V/prime,
thenB/uniontextB/prime={V0,V1,..., Vm−1,V/prime
0,V/prime
1,..., V/prime
m−1}is a basis of V×V/prime.
Let us look at R3carefully. There is the canonical basis:
B=⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩⎡
⎢⎢⎢⎢⎣1
00⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣0
10⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣0
01⎤
⎥⎥⎥⎥⎦⎫
⎪⎪⎪⎪⎬
⎪⎪⎪⎪⎭. (2.82)
6If the reader does not know the difference between “countably” and “uncountably” inﬁnite, fear not.
These notions do not play a major role in the tale we are telling. We shall mostly stay within theﬁnite world. Sufﬁce it to state that an inﬁnite set is countable if the set can be put in a one-to-onecorrespondence with the set of natural numbers N. A set is uncountably inﬁnite if it is inﬁnite and
cannot be put into such a correspondence.

<<<PAGE 68>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
50 Complex Vector Spaces
There are, however, many other bases of R3, e.g.,
B1=⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩⎡
⎢⎢⎢⎢⎣1
11⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣0
11⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣0
01⎤
⎥⎥⎥⎥⎦⎫
⎪⎪⎪⎪⎬
⎪⎪⎪⎪⎭, (2.83)
B
2=⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩⎡
⎢⎢⎢⎢⎣1
0
−1⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣2
12⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣3
−2
0⎤
⎥⎥⎥⎥⎦⎫
⎪⎪⎪⎪⎬
⎪⎪⎪⎪⎭. (2.84)
It is no coincidence that all these bases have the same number of vectors.
Proposition 2.3.1 For every vector space, every basis has the same number of vec-
tors.
Deﬁnition 2.3.4 The dimension of a (complex) vector space is the number of ele-
ments in a basis of the vector space.This coincides with the usual use of the word “dimension.” Let us run through some
of our examples:/D2R3, as a real vector space, is of dimension 3./D2In general, Rnhas dimension nas a real vector space./D2Cnhas dimension nas a complex vector space./D2Cnis of dimension 2n as a real vector space because every complex number is
described by two real numbers./D2Poly nis isomorphic to Cn+1; it is not hard to see that the dimension of Poly nis
also n+1./D2Cm×n: the dimension is mnas a complex vector space./D2Func (N,C) has countably inﬁnite dimension./D2Func ([a,b],C) has uncountably inﬁnite dimension./D2The dimension of V×V/primeis the dimension of Vplus the dimension of V/prime.
The following proposition will make our lives easier:
Proposition 2.3.2 Any two complex vector spaces that have the same dimension are
isomorphic. In particular, for each n, there is essentially only one complex vector
space that is of dimension n:Cn.
(It is easy to see why this is true. Let VandV/primebe any two vector spaces with
the same dimension. Every V∈Vcan be written in a unique way as a linear com-
bination of basis vectors in V. Taking those unique coefﬁcients and using them as
coefﬁcients for the linear combination of the basis elements of any basis of V/primegives
us a nice isomorphism from VtoV/prime.)
Because we will be concentrating on ﬁnite-dimensional vector spaces, we only
concern ourselves with Cn.

<<<PAGE 69>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.3 Basis and Dimension 51
Sometimes we shall use more than one basis for a single vector space.
Example 2.3.5 Consider the basis
B=⎧
⎪⎨
⎪⎩⎡
⎢⎣1
−3⎤
⎥⎦,⎡
⎢⎣−2
4⎤
⎥⎦⎫
⎪⎬
⎪⎭(2.85)
ofR2. The vector V=/bracketleftbigg
7
−17/bracketrightbigg
can be written as
⎡
⎢⎣7
−17⎤
⎥⎦=3⎡
⎢⎣1
−3⎤
⎥⎦−2⎡
⎢⎣−2
4⎤
⎥⎦. (2.86)
The coefﬁcients for Vwith respect to the basis Bare 3 and −2. We write this as
VB=/bracketleftbigg
3
−2/bracketrightbigg
.I fCis the canonical basis of R2, then
⎡
⎢⎣7
−17⎤
⎥⎦=7⎡
⎢⎣1
0⎤
⎥⎦−17⎡
⎢⎣0
1⎤
⎥⎦, (2.87)
i.e.,VC=V=/bracketleftbigg
7
−17/bracketrightbigg
.
Let us consider another basis of R2:
D=⎧
⎪⎨
⎪⎩⎡
⎢⎣−7
9⎤
⎥⎦,⎡
⎢⎣−5
7⎤
⎥⎦⎫
⎪⎬
⎪⎭. (2.88)
What are the coefﬁcients of Vwith respect to D? What is VD?A change of basis
matrix or a transition matrix from basis Bto basis Dis a matrix MD←Bsuch that for
any matrix V, we have
VD=MD←B⋆VB. (2.89)
In other words, MD←Bis a way of getting the coefﬁcients with respect to one basis
from the coefﬁcients with respect to another basis. For the above bases BandD,t h e
transition matrix is
MD←B=⎡
⎢⎣2−3
2
−35
2⎤
⎥⎦. (2.90)
So
VD=MD←BVB=⎡
⎢⎣2−3
2
−35
2⎤
⎥⎦⎡
⎢⎣3
−2⎤
⎥⎦=⎡
⎢⎣9
−14⎤
⎥⎦. (2.91)

<<<PAGE 70>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
52 Complex Vector Spaces
Figure 2.6. The Hadamard matrix as
a transition between two bases.
Checking, we see that
⎡
⎢⎣7
−17⎤
⎥⎦=9⎡
⎢⎣−7
9⎤
⎥⎦−14⎡
⎢⎣−5
7⎤
⎥⎦. (2.92)
/square
Given two bases of a ﬁnite-dimensional vector space, there are standard algo-
rithms to ﬁnd a transition matrix from one to the other. (We will not need to know
how to ﬁnd these matrices.)
InR2, the transition matrix from the canonical basis
⎧
⎪⎨
⎪⎩⎡
⎢⎣1
0⎤
⎥⎦,⎡
⎢⎣0
1⎤
⎥⎦⎫
⎪⎬
⎪⎭(2.93)
to this other basis⎧
⎪⎨
⎪⎩⎡
⎢⎣1√
2
1√
2⎤
⎥⎦,⎡
⎢⎣1√
2
−1√
2⎤
⎥⎦⎫
⎪⎬
⎪⎭(2.94)
is the Hadamard matrix :
H=1√
2⎡
⎢⎣11
1−1⎤
⎥⎦=⎡
⎢⎣1√
21√
2
1√
2−1√
2⎤
⎥⎦. (2.95)
Exercise 2.3.3 Show that Htimes itself gives you the identity matrix. /squaresolid
Because Hmultiplied by itself gives the identity matrix, we observe that the tran-
sition back to the canonical basis is also the Hadamard matrix. We might envision
these transitions as in Figure 2.6.
It turns out that the Hadamard matrix plays a major role in quantum computing.
In physics, we are often faced with a problem in which it is easier to calculate
something in a noncanonical basis. For example, consider a ball rolling down a ramp
as depicted in Figure 2.7.
The ball will not be moving in the direction of the canonical basis. Rather it
will be rolling downward in the direction of +45◦,−45◦basis. Suppose we wish to
calculate when this ball will reach the bottom of the ramp or what is the speed ofthe ball. To do this, we change the problem from one in the canonical basis to one in
the other basis. In this other basis, the motion is easier to deal with. Once we have

<<<PAGE 71>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.4 Inner Products and Hilbert Spaces 53
Figure 2.7. A ball rolling down a ramp and the two relevant
bases.
completed the calculations, we change our results into the more understandable
canonical basis and produce the desired answer. We might envision this as the ﬂow-
chart shown in Figure 2.8.
Throughout this text, we shall go from one basis to another basis, perform some
calculations, and ﬁnally revert to the original basis. The Hadamard matrix will fre-
quently be the means by which we change the basis.
2.4 INNER PRODUCTS AND HILBERT SPACES
We will be interested in complex vector spaces with additional structure. Recall that
a state of a quantum system corresponds to a vector in a complex vector space. A
need will arise to compare different states of the system; hence, there is a need to
compare corresponding vectors or measure one vector against another in a vectorspace.
Consider the following operation that we can perform with two vectors in R
3:
/angbracketleftBigg⎡
⎢⎢⎢⎢⎣5
3
−7⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣6
20⎤
⎥⎥⎥⎥⎦/angbracketrightBigg
=[5,3,−7]⋆⎡
⎢⎢⎢⎢⎣6
20⎤
⎥⎥⎥⎥⎦=(5×6)+(3×2)+(−7×0)=36.
(2.96)
Figure 2.8. Problem-solving ﬂowchart.

<<<PAGE 72>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
54 Complex Vector Spaces
In general, for any two vectors V1=[r0,r1,r2]Tand V2=[r/prime
0,r/prime
1,r/prime
2]TinR3,w e
can form a real number by performing the following operation:
/angbracketleftV1,V2/angbracketright=VT
1⋆V2=2/summationdisplay
j=0rjr/prime
j. (2.97)
This is an example of an inner product of two vectors. An inner product in a complex
(real) vector space is a binary operation that accepts two vectors as inputs and out-puts a complex (real) number. This operation must satisfy certain properties spelledout in the following:
Deﬁnition 2.4.1 Aninner product (also called a dot product orscalar product )o na
complex vector space Vis a function
/angbracketleft−,−/angbracketright:V×V−→C (2.98)
that satisﬁes the following conditions for all V ,V
1,V2,and V 3inVand for a c ∈C:
(i)Nondegenerate:
/angbracketleftV,V/angbracketright≥0, (2.99)
/angbracketleftV,V/angbracketright=0 if and only if V =0 (2.100)
(i.e., the only time it “degenerates” is when it is 0).
(ii)Respects addition:
/angbracketleftV1+V2,V3/angbracketright=/angbracketleft V1,V3/angbracketright+/angbracketleft V2,V3/angbracketright, (2.101)
/angbracketleftV1,V2+V3/angbracketright=/angbracketleft V1,V2/angbracketright+/angbracketleft V1,V3/angbracketright. (2.102)
(iii) Respects scalar multiplication:
/angbracketleftc·V1,V2/angbracketright=c×/angbracketleftV1,V2/angbracketright, (2.103)
/angbracketleftV1,c·V2/angbracketright=c×/angbracketleftV1,V2/angbracketright. (2.104)
(iv) Skew symmetric:
/angbracketleftV1,V2/angbracketright=/angbracketleftV2,V1/angbracketright. (2.105)
An inner product on real vector space /angbracketleft,/angbracketright:V×V−→Rmust satisfy the same
properties. Because any r∈Rsatisﬁes r=r, Properties (iii) and (iv) are simpler for
a real vector space.Deﬁnition 2.4.2 A(complex) inner product space is a (complex) vector space along
with an inner product.
Let us list some examples of inner product spaces./D2Rn: The inner product is given as
/angbracketleftV1,V2/angbracketright=VT
1⋆V2. (2.106)

<<<PAGE 73>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.4 Inner Products and Hilbert Spaces 55/D2Cn: The inner product is given as
/angbracketleftV1,V2/angbracketright=V†
1⋆V2. (2.107)/D2Rn×nhas an inner product given for matrices A,B∈Rn×nas
/angbracketleftA,B/angbracketright=Trace( AT⋆B), (2.108)
where the trace of a square matrix Cis given as the sum of the diagonal elements.
That is,
Trace(C) =n−1/summationdisplay
i=0C[i,i]. (2.109)/D2Cn×nhas an inner product given for matrices A,B∈Cn×nas
/angbracketleftA,B/angbracketright=Trace (A†⋆B). (2.110)/D2Func (N,C):
/angbracketleftf,g/angbracketright=∞/summationdisplay
j=0f(j)g(j). (2.111)/D2Func ([a,b],C):
/angbracketleftf,g/angbracketright=/integraldisplayb
af(t)g(t)dt. (2.112)
Exercise 2.4.1 LetV1=[2,1,3]T,V2=[6,2,4]T, and V3=[0,−1,2]T. Show that
the inner product in R3respects the addition, i.e., Equations (2.101) and (2.102). /squaresolid
Exercise 2.4.2 Show that the function /angbracketleft,/angbracketright:Rn×Rn−→Rgiven in Equa-
tion (2.106) satisﬁes all the properties of being an inner product on Rn. /squaresolid
Exercise 2.4.3 Let A=/bracketleftbigg
12
01/bracketrightbigg
,B=/bracketleftbigg
0−1
−10/bracketrightbigg
, and C=/bracketleftbigg
2113/bracketrightbigg
. Show that the in-
ner product in R2×2respects addition (Equations (2.101) and (2.102)) with these
matrices. /squaresolid
Exercise 2.4.4 Show that the function given for pairs of real matrices satisﬁes the
inner product properties and converts the real vector space Rn×nto a real inner
product space. /squaresolid
Programming Drill 2.4.1 Write a function that accepts two complex vectors of length
n and calculates their inner product.
The inner product of a complex vector with itself is a real number. We can ob-
serve this from the property that for all V1,V2, an inner product must satisfy
/angbracketleftV1,V2/angbracketright=/angbracketleftV2,V1/angbracketright. (2.113)

<<<PAGE 74>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
56 Complex Vector Spaces
It follows that if V2=V1, then we have
/angbracketleftV1,V1/angbracketright=/angbracketleftV1,V1/angbracketright; (2.114)
hence it is real.
Deﬁnition 2.4.3 For every complex inner product space V,/angbracketleft−,−/angbracketright, we can deﬁne a
norm orlength which is a function
||:V−→R (2.115)
deﬁned as |V|=√/angbracketleftV,V/angbracketright.
Example 2.4.1 InR3, the norm of vector [3, −6,2]Tis
/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle⎡
⎢⎢⎢⎢⎣3
−6
2⎤
⎥⎥⎥⎥⎦/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle=/radicaltp/radicalvertex/radicalvertex/radicalvertex/radicalvertex/radicalvertex/radicalvertex/radicalvertex/radicalbt
/angbracketleftBigg⎡
⎢⎢⎢⎢⎣3
−6
2⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣3
−6
2⎤
⎥⎥⎥⎥⎦/angbracketrightBigg
=/radicalBig
32+(−6)2+22=√
49=7. (2.116)
/square
Exercise 2.4.5 Calculate the norm of [4 +3i,6−4i,12−7i,13i]T. /squaresolid
Exercise 2.4.6 LetA=/bracketleftbigg
35
23/bracketrightbigg
∈R2×2. Calculate the norm |A|=√/angbracketleftA,A/angbracketright./squaresolid
In general, the norm of the vector [ x,y,z]Tis
/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle⎡
⎢⎢⎢⎢⎣x
y
z⎤
⎥⎥⎥⎥⎦/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle=/radicaltp/radicalvertex/radicalvertex/radicalvertex/radicalvertex/radicalvertex/radicalvertex/radicalvertex/radicalbt
/angbracketleftBigg⎡
⎢⎢⎢⎢⎣x
y
z⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣x
y
z⎤
⎥⎥⎥⎥⎦/angbracketrightBigg
=/radicalbig
x2+y2+z2. (2.117)
This is the Pythagorean formula for the length of a vector. The intuition one
should have is that the norm of a vector in any vector space is the length of thevector.
From the properties of an inner product space, it follows that a norm has the
following properties for all V,W∈Vandc∈C:
(i) Norm is nondegenerate: |V|>0i fV/negationslash=0and|0|= 0.
(ii) Norm satisﬁes the triangle inequality: |V+W|≤| V|+|W|.
(iii) Norm respects scalar multiplication: |c·V|=| c|×|V|.

<<<PAGE 75>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.4 Inner Products and Hilbert Spaces 57
Programming Drill 2.4.2 Write a function that calculates the norm of a given complex
vector.
Given a norm, we can proceed and deﬁne a distance function.
Deﬁnition 2.4.4 For every complex inner product space (V,/angbracketleft,/angbracketright), we can deﬁne a
distance function
d(,):V×V−→R, (2.118)
where
d(V1,V2)=|V1−V2|=/radicalbig
/angbracketleftV1−V2,V1−V2/angbracketright. (2.119)
Exercise 2.4.7 Let V1=⎡
⎣3
12⎤
⎦and V2=⎡⎣2
2
−1⎤
⎦. Calculate the distance between
these two vectors. /squaresolid
The intuition is that d(V1,V2) is the distance from the end of vector V1to the end
of vector V2. From the properties of an inner product space, it is not hard to show
that a distance function has the following properties for all U,V,W∈V:
(i) Distance is nondegenerate: d(V,W)>0i fV/negationslash=Wandd(V,V)=0.
(ii) Distance satisﬁes the triangle inequality: d(U,V)≤d(U,W)+d(W,V).
(iii) Distance is symmetric: d(V,W)=d(W,V).
Programming Drill 2.4.3 Write a function that calculates the distance of two given
complex vectors.
Deﬁnition 2.4.5 Two vectors V 1and V 2in an inner product space Vareorthogonal
if/angbracketleftV1,V2/angbracketright=0.
The picture to keep in mind is that two vectors are orthogonal if they are per-
pendicular to each other.
Deﬁnition 2.4.6 A basis B={V0,V1,..., Vn−1}for an inner product space Vis called
anorthogonal basis if the vectors are pairwise orthogonal to each other, i.e., j /negationslash=ki m -
plies/angbracketleftVj,Vk/angbracketright=0. An orthogonal basis is called an orthonormal basis if every vector
in the basis is of norm 1, i.e.,
/angbracketleftVj,Vk/angbracketright=δ j,k=⎧
⎪⎨
⎪⎩1, if j=k,
0, if j/negationslash=k.(2.120)
δj,kis called the Kronecker delta function.

<<<PAGE 76>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
58 Complex Vector Spaces
Figure 2.9. Three bases for R2.
Example 2.4.2 Consider the three bases for R2shown in Figure 2.9.
Formally, these bases are
(i)⎡
⎢⎢⎢⎣1
1⎤
⎥⎥⎥⎦,⎡
⎢⎢⎢⎣1
0⎤
⎥⎥⎥⎦,
(ii)⎡
⎢⎢⎢⎣1
1⎤
⎥⎥⎥⎦,⎡
⎢⎢⎢⎣1
−1⎤
⎥⎥⎥⎦,
(iii)1√
2⎡
⎢⎢⎢⎣1
1⎤
⎥⎥⎥⎦,1√
2⎡
⎢⎢⎢⎣1
−1⎤
⎥⎥⎥⎦.
/square
InR3, the standard inner product /angbracketleftV,V/prime/angbracketright=VTV/primecan be shown to be equivalent
to
/angbracketleftV,V/prime/angbracketright=| V||V/prime|cosθ, (2.121)
where θis the angle between Vand V/prime. When |V/prime|=1, this equation reduces to
/angbracketleftV,V/prime/angbracketright=| V|cosθ. (2.122)
Exercise 2.4.8 LetV=[3,−1,0]Tand V/prime=[2,−2,1]T. Calculate the angle θbe-
tween these two vectors. /squaresolid
Elementary trigonometry teaches us that when |V/prime|=1, the number /angbracketleftV,V/prime/angbracketrightis
the length of the projection of Vonto the direction of V/prime(Figure 2.10).
Figure 2.10. The projection of VontoV/prime.

<<<PAGE 77>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.4 Inner Products and Hilbert Spaces 59
/angbracketleftV,V/prime/angbracketright·V/primeis the vector V/primeextended (or reduced) to meet the projection of V
onto V/prime.
What does this mean in terms of R3?L e t V=[r0,r1,r2]Tbe any vector in R3.
LetE0,E1, and E2be the canonical basis of R3. Then
V=⎡
⎢⎢⎢⎢⎣r
0
r1
r2⎤
⎥⎥⎥⎥⎦=/angbracketleftE
0,V/angbracketright⎡
⎢⎢⎢⎢⎣1
00⎤
⎥⎥⎥⎥⎦+/angbracketleftE
1,V/angbracketright⎡
⎢⎢⎢⎢⎣0
10⎤
⎥⎥⎥⎥⎦+/angbracketleftE
2,V/angbracketright⎡
⎢⎢⎢⎢⎣0
01⎤
⎥⎥⎥⎥⎦. (2.123)
In general, for any V∈R
n,
V=n−1/summationdisplay
j=0/angbracketleftEj,V/angbracketrightEj. (2.124)
We shall use the intuition afforded by R3andRnto understand this type of de-
composition of vectors into sums of canonical vectors for other vector spaces.
Proposition 2.4.1 InCn, we also have that any Vcan be written as
V=/angbracketleftE0,V/angbracketrightE0+/angbracketleftE1,V/angbracketrightE1+···+/angbracketleft En−1,V/angbracketrightEn−1. (2.125)
It must be stressed that this is true for any orthonormal basis, not just the canonical
one.
InFunc (N,C) for an arbitrary function g:N−→Cand for a canonical basis
function fj:N−→C, we have
/angbracketleftfj,g/angbracketright=∞/summationdisplay
k=0fj(k)g(k)=1×g(j)=g(j). (2.126)
And so any g:N−→Ccan be written as
g=∞/summationdisplay
k=0(/angbracketleftfk,g/angbracketrightfk). (2.127)
.................................................................................
Reader Tip. The following deﬁnitions will not be essential for us, but we include
them so that the reader will be able to understand other texts. In our text, there isno reason to worry about them because we are restricting ourselves to ﬁnite-dimen-sional inner product spaces and they automatically satisfy these properties. ♥.................................................................................
Deﬁnition 2.4.7 Within an inner product space V,/angbracketleft,/angbracketright(with the derived norm and
a distance function), a sequence of vectors V
0,V1,V2,... is called a Cauchy sequence
if for every /epsilon1>0, there exists an N 0∈Nsuch that
for all m ,n≥N0,d(Vm,Vn)≤/epsilon1. (2.128)

<<<PAGE 78>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
60 Complex Vector Spaces
Figure 2.11. Completeness for a complex inner product space.
Deﬁnition 2.4.8 A complex inner product space is called complete if for any Cauchy
sequence of vectors V 0,V1,V2,..., there exists a vector ¯V∈Vsuch that
lim
n→∞|Vn−¯V|=0. (2.129)
The intuition behind this is that a vector space with an inner product is complete
if any sequence accumulating somewhere converges to a point (Figure 2.11).
Deﬁnition 2.4.9 AHilbert space is a complex inner product space that is complete.
If completeness seems like an overly complicated notion, fear not. We do not
have to worry about completeness because of the following proposition (which we
shall not prove).
Proposition 2.4.2 Every inner product on a ﬁnite -dimensional complex vector space
is automatically complete; hence, every ﬁnite-dimensional complex vector space
with an inner product is automatically a Hilbert space.
Quantum computing in our text will only deal with ﬁnite-dimensional vector
spaces and so we do not have to concern ourselves with the notion of completeness.However, in the culture of quantum mechanics and quantum computing, you will
encounter the words “Hilbert space,” which should no longer cause any anxiety.
2.5 EIGENVALUES AND EIGENVECTORS
Example 2.5.1 Consider the simple 2-by-2 real matrix
⎡
⎢⎣4−1
21⎤
⎥⎦. (2.130)
Notice that
⎡
⎢⎣4−1
21⎤
⎥⎦⎡
⎢⎣1
1⎤
⎥⎦=⎡
⎢⎣3
3⎤
⎥⎦=3⎡
⎢⎣1
1⎤
⎥⎦. (2.131)

<<<PAGE 79>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.5 Eigenvalues and Eigenvectors 61
Figure 2.12. A vector before and
after a matrix action.
Multiplying our matrix by this vector is nothing more than multiplying the vector
by a scalar. We can see this in Figure 2.12.
In other words, when the matrix acts on this vector, it does not change the direc-
tion of the vector, but only its length. /square
Example 2.5.2 Consider the following matrix and vector:
⎡
⎢⎣4−1
21⎤
⎥⎦⎡
⎢⎣1
2⎤
⎥⎦=⎡
⎢⎣2
4⎤
⎥⎦=2⎡
⎢⎣1
2⎤
⎥⎦. (2.132)
Again, the matrix acting on this vector does not change the vector’s direction, rather
its length as in Figure 2.13. /square
This is not always true for every vector, nor is it true for every matrix. However,
when it is true, we assign such scalars and vectors special names.
Deﬁnition 2.5.1 For a matrix A in Cn×n, if there is a number c in Cand a vector
V/negationslash=0withCnsuch that
AV=c·V, (2.133)
then c is called an eigenvalue of A and V is called an eigenvector of A associated
with c. (“eigen-” is a German preﬁx that indicates possession.)
Figure 2.13. Another
vector before and after
a matrix action.

<<<PAGE 80>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
62 Complex Vector Spaces
Exercise 2.5.1 The following vectors
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩⎡
⎢⎢⎢⎢⎣1
10⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣1
0
−1⎤
⎥⎥⎥⎥⎦,⎡
⎢⎢⎢⎢⎣1
12⎤
⎥⎥⎥⎥⎦⎫
⎪⎪⎪⎪⎬
⎪⎪⎪⎪⎭(2.134)
are eigenvectors of the matrix
⎡
⎢⎢⎢⎢⎣1−33
3−53
6−64⎤
⎥⎥⎥⎥⎦. (2.135)
Find the eigenvalues. /squaresolid
If a matrix Ahas eigenvalue c
0with eigenvector V0, then for any c∈Cwe have
A(cV 0)=cAV 0=cc0V0=c0(cV 0), (2.136)
which shows that cV0is also an eigenvector of Awith eigenvalue c0.I fcV 0andc/primeV0
are two such eigenvectors, then because
A(cV 0+c/primeV0)=AcV 0+Ac/primeV0=cAV 0+c/primeAV 0
=c(c0V0)+c/prime(c0V0)=(c+c/prime)(c0V0)=c0(c+c/prime)V0,(2.137)
we see that the addition of two such eigenvectors is also an eigenvector. We con-
clude the following:
Proposition 2.5.1 Every eigenvector determines a complex subvector space of the
vector space. This space is known as the eigenspace associated with the given eigen-
vector.
Some matrices have many eigenvalues and eigenvectors and some matrices have
none.
2.6 HERMITIAN AND UNITARY MATRICES
We shall need certain types of important square matrices and their properties.
Am a t r i x A∈Rn×nis called symmetric ifAT=A. In other words, A[j,k]=
A[k,j]. Let us generalize this notion from the real numbers to the complex
numbers.
Deﬁnition 2.6.1 An n-by-n matrix A is called hermitian if A†=A. In other words,
A[j,k]=A[k,j].
Deﬁnition 2.6.2 If A is a hermitian matrix then the operator that it represents is called
self-adjoint .

<<<PAGE 81>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.6 Hermitian and Unitary Matrices 63
Example 2.6.1 The matrix
⎡
⎢⎢⎢⎢⎣54 +5i6−16i
4−5i 13 7
6+16i 7−2.1⎤
⎥⎥⎥⎥⎦(2.138)
is hermitian. /square
Exercise 2.6.1 Show that the matrix
⎡
⎢⎣76+5i
6−5i−3⎤
⎥⎦ (2.139)
is hermitian. /squaresolid
Exercise 2.6.2 Show that Ais hermitian if and only if A
T=A. /squaresolid
Notice from the deﬁnition that the elements along the diagonal of a hermitian
matrix must be real. The old notion of a symmetric matrix is a special case of hermi-
tian that is limited to matrices with only real entries.
Proposition 2.6.1 IfAis a hermitian n-by-nmatrix, then for all V,V/prime∈Cnwe
have
/angbracketleftAV,V/prime/angbracketright=/angbracketleft V,AV/prime/angbracketright. (2.140)
The proof is easy to see:
/angbracketleftAV,V/prime/angbracketright=( AV)†⋆V/prime=V†A†V/prime=V†⋆AV/prime=/angbracketleftV,AV/prime/angbracketright (2.141)
where the ﬁrst and the fourth equalities are from the deﬁnition of an inner product,
the second equality is from the property of †, and the third equality is from the
deﬁnition of a hermitian matrix.
Exercise 2.6.3 Prove the same proposition for symmetric real matrices. /squaresolid
Proposition 2.6.2 IfAis a hermitian, then all eigenvalues are real.
To prove this, let Abe a hermitian matrix with an eigenvalue c∈Cand an eigen-
vector V. Consider the following sequence of equalities:
c/angbracketleftV,V/angbracketright=/angbracketleft cV,V/angbracketright=/angbracketleft AV,V/angbracketright=/angbracketleft V,AV/angbracketright=/angbracketleft V,cV/angbracketright=c/angbracketleftV,V/angbracketright. (2.142)
The ﬁrst and ﬁfth equalities are properties of the inner product. The second and
fourth equalities are from the deﬁnition of eigenvalue. The third equality is fromProposition 2.6.1. Because cand Vare nonzero, c=
cand hence must be real.
Exercise 2.6.4 Prove that the eigenvalues of a symmetric matrix are real. /squaresolid

<<<PAGE 82>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
64 Complex Vector Spaces
Proposition 2.6.3 For a given hermitian matrix, distinct eigenvectors that have dis-
tinct eigenvalues are orthogonal.
We prove this by looking at V1and V2that are distinct eigenvectors of a hermi-
tian matrix A.
AV 1=c1V1and AV 2=c2V2. (2.143)
Then we have the following sequence of equalities:
c1/angbracketleftV1,V2/angbracketright=/angbracketleft c1V1,V2/angbracketright=/angbracketleft AV 1,V2/angbracketright=/angbracketleft V1,AV 2/angbracketright
=/angbracketleftV1,c2V2/angbracketright=c2/angbracketleftV1,V2/angbracketright=c 2/angbracketleftV1,V2/angbracketright (2.144)
where the ﬁrst and ﬁfth equalities are from properties of inner products, the second
and fourth equalities are by deﬁnition of eigenvector, the third equality follows from
the fact that His hermitian, and the last equality is from the fact that eigenvalues
of hermitian matrices are real. As the left side is equal to the right side, we may
subtract one from the other to get 0:
c1/angbracketleftV1,V2/angbracketright−c2/angbracketleftV1,V2/angbracketright=(c1−c2)/angbracketleftV1,V2/angbracketright=0. (2.145)
Because c1and c2are distinct, c1−c2/negationslash=0. Hence, it follows that /angbracketleftV1,V2/angbracketright=0 and
they are orthogonal.
We shall need one more important proposition about self-adjoint operators.
Deﬁnition 2.6.3 Adiagonal matrix is a square matrix whose only nonzero entries
are on the diagonal. All entries off the diagonal are zero.
Proposition 2.6.4 (The Spectral Theorem for Finite-Dimensional Self-Adjoint
Operators.) Every self-adjoint operator Aon a ﬁnite-dimensional complex vec-
tor space Vcan be represented by a diagonal matrix whose diagonal entries are the
eigenvalues of A, and whose eigenvectors form an orthonormal basis for V(we shall
call this basis an eigenbasis).
Hermitian matrices and their eigenbases will play a major role in our story. We
shall see in Chapter 4 that associated with every physical observable of a quantumsystem there is a corresponding hermitian matrix. Measurements of that observablealways lead to a state that is represented by one of the eigenvectors of the associated
hermitian matrix.
Programming Drill 2.6.1 Write a function that accepts a square matrix and tells if it
is hermitian.
Another fundamental type of matrix is unitary. A matrix Aisinvertible if there
exists a matrix A
−1such that
A⋆A−1=A−1⋆A=In. (2.146)
Unitary matrices are a type of invertible matrix. They are invertible and their in-
verse is their adjoint. This fact ensures that unitary matrices “preserve the geome-
try” of the space on which it is acting.

<<<PAGE 83>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.6 Hermitian and Unitary Matrices 65
Deﬁnition 2.6.4 An n-by-n matrix U is unitary if
U⋆U†=U†⋆U=In. (2.147)
It is important to realize that not all invertible matrices are unitary.
Example 2.6.2 For any θ,t h em a t r i x
⎡
⎢⎢⎢⎢⎣cosθ−sinθ0
sinθ cosθ 0
00 1⎤
⎥⎥⎥⎥⎦(2.148)
is a unitary matrix. (You might have seen such a matrix when studying computer
graphics. We shall see why in a few moments.) /square
Exercise 2.6.5 Show that the matrix given in Equation (2.148) is unitary. /squaresolid
Example 2.6.3 The matrix
⎡
⎢⎢⎢⎢⎣1+i
2i√
33+i
2√
15
−1
21√
34+3i
2√
15
1
2−i√
35i
2√
15⎤
⎥⎥⎥⎥⎦(2.149)
is a unitary matrix. /square
Exercise 2.6.6 Show that the matrix given in Equation (2.149) is unitary. /squaresolid
Exercise 2.6.7 Show that if UandU/primeare unitary matrices, then so is U⋆U/prime.( H i n t :
Use Equation (2.44)). /squaresolid
Proposition 2.6.5 Unitary matrices preserve inner products, i.e., if Uis unitary, then
for any V,V/prime∈Cn, we have /angbracketleftUV,UV/prime/angbracketright=/angbracketleft V,V/prime/angbracketright.
This proposition is actually very easy to demonstrate:
/angbracketleftUV,UV/prime/angbracketright=(UV)†⋆UV/prime=V†U†⋆UV/prime=V†⋆I⋆V/prime=V†⋆V/prime=/angbracketleftV,V/prime/angbracketright
(2.150)
where the ﬁrst and ﬁfth equalities are from the deﬁnition of the inner product, the
second equality is from the properties of the adjoint, the third equality is from
the deﬁnition of a unitary matrix, and the fourth equality is due to the face that
Iis the identity.
Because unitary matrices preserve inner products, they also preserve norms
|UV|=/radicalbig
/angbracketleftUV,UV/angbracketright=/radicalbig
/angbracketleftV,V/angbracketright=| V|. (2.151)
In particular, if |V|=1, then |UV|=1. Consider the set of all vectors that have
length 1. They form a ball around the origin (the zero of the vector space). We callthis ball the unit sphere and imagine it as Figure 2.14.

<<<PAGE 84>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
66 Complex Vector Spaces
Figure 2.14. The unit sphere
a n dt h ea c t i o no fU onV.
IfVis a vector on the unit sphere (in any dimension), then UV is also on the
unit sphere. We shall see that a unitary matrix is a way of rotating the unit sphere.7
Exercise 2.6.8 Show that if Uis a unitary matrix and V1and V2are in Cn, then
d(UV 1,UV 2)=d(V1,V2), (2.152)
i.e., U preserves distances. (An operator that preserves distances is called an
isometry .) /squaresolid
What does unitary really mean? As we saw, it means that it preserves the geom-
etry. But it also means something else: If Uis unitary and UV=V/prime, then we can
easily form U†and multiply both sides of the equation by U†to get U†UV=U†V/prime
orV=U†V/prime. In other words, because Uis unitary, there is a related matrix that can
“undo” the action that Uperforms. U†takes the result of U’s action and gets back
the original vector. In the quantum world, all actions (that are not measurements)are “undoable” or “reversible” in such a manner.
Hermitian matrices and unitary matrices will be very important in our text. The
Venn diagram shown in Figure 2.15 is helpful.
Exercise 2.6.9 Show that I
nand−1·Inare both hermitian and unitary. /squaresolid
Programming Drill 2.6.2 Write a function that accepts a square matrix and tells if it
is unitary.
2.7 TENSOR PRODUCT OF VECTOR SPACES
At the conclusion of Section 2.2 we were introduced to the Cartesian product, which
is one method of combining vector spaces. In this section, we study the tensor prod-uct, which is another, more important, method of combining vector spaces. If V
describes one quantum system and V
/primedescribes another, then their tensor prod-
uct describes both quantum systems as one. The tensor product is the fundamentalbuilding operation of quantum systems.
7These movements of the unit sphere are important in computer graphics.

<<<PAGE 85>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.7 Tensor Product of Vector Spaces 67
Figure 2.15. Types of matrices.
.................................................................................
Reader Tip. A brief warning is in order. The tensor product of two vector spaces is
perhaps one of the most difﬁcult subjects in this chapter, as well as one of the most
essential. Do not be intimidated if you do not understand it the ﬁrst time you read it.
Everyone has a hard time with tensor products. We also suggest that you read thissection in conjunction with Sections 3.4 and 4.5. All these three sections deal withthe tensor product from slightly different viewpoints. ♥.................................................................................
Given two vector spaces VandV
/prime, we shall form the tensor product of two vector
spaces, and denote it V⊗V/prime. The tensor product is generated by the set of “tensors”
of all vectors:
{V⊗V/prime|V∈Vand V/prime∈V/prime}, (2.153)
where⊗is just a symbol. A typical element of V⊗V/primelooks like this:
c0(V0⊗V/prime
0)+c1(V1⊗V/prime
1)+···+ cp−1(Vp−1⊗V/prime
p−1), (2.154)
where V0,V1,..., Vp−1are elements of Vand V/prime
0,V/prime
1,..., V/prime
p−1are elements of V/prime.
We might write this as
p−1/summationdisplay
i=0ci(Vi⊗V/prime
i). (2.155)
The operations on this vector space are straightforward. For a given/summationtextp−1
i=0ci(Vi⊗
V/prime
i) and/summationtextq−1
i=0c/prime
i(Wi⊗W/prime
i), addition is simply the addition of summations, i.e.,
p−1/summationdisplay
i=0ci(Vi⊗V/prime
i)+q−1/summationdisplay
i=0c/prime
i(Wi⊗W/prime
i). (2.156)
The scalar multiplication for a given c∈Cis
c·p−1/summationdisplay
i=0ci(Vi⊗V/prime
i)=p−1/summationdisplay
i=0(c×ci)(Vi⊗V/prime
i). (2.157)

<<<PAGE 86>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
68 Complex Vector Spaces
We impose the following important rewriting rules for this vector space:
(i) The tensor must respect addition in both VandV/prime:
(Vi+Vj)⊗V/prime
k=Vi⊗V/prime
k+Vj⊗V/prime
k, (2.158)
Vi⊗(V/prime
j+V/prime
k)=Vi⊗V/prime
j+Vi⊗V/prime
k. (2.159)
(ii) The tensor must respect the scalar multiplication in both VandV/prime:
c·(Vj⊗V/prime
k)=(c·Vj)⊗V/prime
k=Vj⊗(c·V/prime
k). (2.160)
By following these rewriting rules and setting elements equal to each other, we form
V⊗V/prime.
Let us ﬁnd a basis for V⊗V/prime. Say, Vhas a basis B={B0,B1,..., Bm−1}and
V/primehas a basis B/prime={B/prime
0,B/prime
1,..., B/prime
n−1}. Given that every Vi∈Vand V/prime
i∈V/primecan be
written in a unique way for these bases, we can use the rewrite rules to “decompose”every element/summationtext
p−1
i=0ci(Vi⊗V/prime
i) in the tensor product. This will give us a basis for
V⊗V/prime. In detail, the basis for V⊗V/primewill be the set of vectors
{Bj⊗B/prime
k|j=0,1,...,m −1 and k=0,1,...,n −1}. (2.161)
Every/summationtextp−1
i=0ci(Vi⊗V/prime
i)∈V⊗V/primecan be written as
c0,0(B0⊗B/prime
0)+c1,0(B1⊗B/prime
0)+···+ cm−1,n−1(Bm−1⊗B/prime
n−1). (2.162)
The dimension of V⊗V/primeis the dimension of Vtimes the dimension of V/prime.( R e -
member that the dimension of V×V/primeis the dimension of Vplus the dimension of
V/prime. So the tensor product of two vector spaces is usually a larger space than their
Cartesian product.8) One should think of V×V/primeas the vector space whose states
are the states of a system Vora system V/primeor both. V⊗V/primeis to be thought of as the
vector space whose basic states are pairs of states, one from system Vandone from
the system V/prime.
Given an element of V
c0B0+c1B1+···+ cm−1Bm−1, (2.163)
and an element of V/prime
c/prime
0B/prime
0+c/prime
1B/prime
1+···+ c/prime
n−1B/prime
n−1, (2.164)
we can associate9the following element of V⊗V/prime:
(c0×c/prime
0)(B0⊗B/prime
0)+(c0×c/prime
1)(B0⊗B/prime
1)+···+ (cm−1×c/prime
n−1)(Bm−1⊗B/prime
n−1).
(2.165)
Let us step down from the abstract highland and see what Cm⊗Cnactually looks
like.Cm⊗Cnis of dimension mnand hence is isomorphic to Cm×n. What is impor-
tant is how Cm⊗Cnis isomorphic to Cm×n.I fEjis an element of the canonical basis
of each vector space, then we might identify Ej⊗Ekwith Ej×k. It is not hard to see
8But not always! Remember that 1 ×1<1+1a n d1 ×2<1+2, etc.
9It is important to notice that this “association” is not a linear map; it is something called a bilinear map .

<<<PAGE 87>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.7 Tensor Product of Vector Spaces 69
from the association given in Equation (2.165) that the tensor product of vectors is
deﬁned as follows:
⎡
⎢⎢⎢⎢⎢⎢⎢⎣a
0
a1
a2
a3⎤
⎥⎥⎥⎥⎥⎥⎥⎦⊗⎡
⎢⎢⎢⎢⎣b
0
b1
b2⎤
⎥⎥⎥⎥⎦=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣a
0·⎡
⎢⎢⎢⎢⎣b
0
b1
b2⎤
⎥⎥⎥⎥⎦
a
1·⎡
⎢⎢⎢⎢⎣b
0
b1
b2⎤
⎥⎥⎥⎥⎦
a
2·⎡
⎢⎢⎢⎢⎣b
0
b1
b2⎤
⎥⎥⎥⎥⎦
a
3·⎡
⎢⎢⎢⎢⎣b0
b1
b2⎤
⎥⎥⎥⎥⎦⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣a
0b0
a0b1
a0b2
a1b0
a1b1
a1b2
a2b0
a2b1
a2b2
a3b0
a3b1
a3b2⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (2.166)
In general, C
m×Cnis much smaller than Cm⊗Cn.
Example 2.7.1 For example, consider C2×C3andC2⊗C3=C6. Consider the
vector
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣8
12
6
12
18
9⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦∈C
6=C2⊗C3. (2.167)
It is not hard to see that this is simply
⎡
⎢⎣2
3⎤
⎥⎦⊗⎡
⎢⎢⎢⎢⎣4
63⎤
⎥⎥⎥⎥⎦. (2.168)
/square

<<<PAGE 88>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
70 Complex Vector Spaces
Example 2.7.2 In contrast to the above example,
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣8
0000
18⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦∈C
6=C2⊗C3(2.169)
cannot be written as the tensor product of a vector from C2andC3. In order to see
this, consider the variables
⎡
⎢⎣x
y⎤
⎥⎦⊗⎡
⎢⎢⎢⎢⎣a
b
c⎤
⎥⎥⎥⎥⎦=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣xa
xb
xc
ya
yb
yc⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (2.170)
There are no solutions for the variable that will give you the required results. How-
ever, we can write the vector in Equation (2.169) as
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣8
0000
18⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦=⎡
⎢⎣1
0⎤
⎥⎦⊗⎡
⎢⎢⎢⎢⎣8
00⎤
⎥⎥⎥⎥⎦+⎡
⎢⎣0
6⎤
⎥⎦⊗⎡
⎢⎢⎢⎢⎣0
03⎤
⎥⎥⎥⎥⎦. (2.171)
This is a summation of two vectors. /square

<<<PAGE 89>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.7 Tensor Product of Vector Spaces 71
For reasons that are made clear in Sections 3.4 and 4.5, we shall call a vector
that can be written as the tensor of two vectors separable . In contrast, a vector that
cannot be written as the tensor of two vectors (but can be written as the nontrivial
sum of such tensors) shall be called entangled.
Exercise 2.7.1 Calculate the tensor product⎡
⎣3
4
7⎤
⎦⊗/bracketleftbigg
−1
2/bracketrightbigg
. /squaresolid
Exercise 2.7.2 State whether [5 ,6,3,2,0,1]Tis a tensor product of smaller vectors
from C3andC2. /squaresolid
We will need to know not only how to take the tensor product of two vectors, but
also how to determine the tensor product of two matrices.10Consider two matrices
A=⎡
⎢⎣a0,0a0,1
a1,0a1,1⎤
⎥⎦ and B=⎡
⎢⎢⎢⎢⎣b
0,0b0,1b0,2
b1,0b1,1b1,2
b2,0b2,1b2,2⎤
⎥⎥⎥⎥⎦. (2.172)
From the association given in Equation (2.165), it can be seen that the tensor prod-
uctA⊗Bis the matrix that has every element of A, scalar multiplied with the entire
matrix B. That is,
A⊗B=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣a
0,0·⎡
⎢⎢⎢⎢⎣b
0,0b0,1b0,2
b1,0b1,1b1,2
b2,0b2,1b2,2⎤
⎥⎥⎥⎥⎦a
0,1·⎡
⎢⎢⎢⎢⎣b
0,0b0,1b0,2
b1,0b1,1b1,2
b2,0b2,1b2,2⎤
⎥⎥⎥⎥⎦
a
1,0·⎡
⎢⎢⎢⎢⎣b
0,0b0,1b0,2
b1,0b1,1b1,2
b2,0b2,1b2,2⎤
⎥⎥⎥⎥⎦a
1,1·⎡
⎢⎢⎢⎢⎣b
0,0b0,1b0,2
b1,0b1,1b1,2
b2,0b2,1b2,2⎤
⎥⎥⎥⎥⎦⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣a
0,0×b0,0a0,0×b0,1a0,0×b0,2a0,1×b0,0a0,1×b0,1a0,1×b0,2
a0,0×b1,0a0,0×b1,1a0,0×b1,2a0,1×b1,0a0,1×b1,1a0,1×b1,2
a0,0×b2,0a0,0×b2,1a0,0×b2,2a0,1×b2,0a0,1×b2,1a0,1×b2,2
a1,0×b0,0a1,0×b0,1a1,0×b0,2a1,1×b0,0a1,1×b0,1a1,1×b0,2
a1,0×b1,0a1,0×b1,1a1,0×b1,2a1,1×b1,0a1,1×b1,1a1,1×b1,2
a1,0×b2,0a1,0×b2,1a1,0×b2,2a1,1×b2,0a1,1×b2,1a1,1×b2,2⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦.
(2.173)
10It should be clear that the tensor product of two vectors is simply a special case of the tensor product
of two matrices.

<<<PAGE 90>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
72 Complex Vector Spaces
Formally, the tensor product of matrices is a function
⊗:Cm×m/prime×Cn×n/prime−→Cmn× m/primen/prime(2.174)
and it is deﬁned as
(A⊗B)[j,k]=A[j/n,k/m]×B[jMod n,kMod m]. (2.175)
Exercise 2.7.3 Calculate
⎡
⎢⎢⎢⎢⎣3+2i5−i 2i
01 2 6 −3i
24+4i9+3i⎤
⎥⎥⎥⎥⎦⊗⎡
⎢⎢⎢⎢⎣13 +4i5−7i
10+2i 62+5i
01 2 +9i⎤
⎥⎥⎥⎥⎦. (2.176)
/squaresolid
Exercise 2.7.4 Prove that the tensor product
is “almost” commutative. Take two
2-by-2 matrices Aand B. Calculate A⊗Band B⊗A.In general, although they are
not equal, they do have the same entries, and one can be transformed to the other
with a “nice” change of rows and columns. /squaresolid
Exercise 2.7.5 LetA=/bracketleftbigg
12
01/bracketrightbigg
,B=/bracketleftbigg
32
−10/bracketrightbigg
, and C=/bracketleftbigg
6532/bracketrightbigg
. Calculate A⊗(B⊗
C) and ( A⊗B)⊗Cand show that they are equal. /squaresolid
Exercise 2.7.6 Prove that the tensor product is associative, i.e., for arbitrary matri-
cesA,B, and C,
A⊗(B⊗C)=(A⊗B)⊗C. (2.177)
/squaresolid
Exercise 2.7.7 LetA=/bracketleftbigg
23/bracketrightbigg
and B=/bracketleftbigg
12
34/bracketrightbigg
. Calculate ( A⊗B)†and A†⊗B†
and show that they are equal. /squaresolid
Exercise 2.7.8 Prove that ( A⊗B)†=A†⊗B†. /squaresolid
Exercise 2.7.9 LetA,A/prime,B, and B/primebe matrices of the appropriate sizes. Prove that
(A⋆A/prime)⊗(B⋆B/prime)=(A⊗B)⋆(A/prime⊗B/prime). (2.178)
/squaresolid
IfAacts on Vand Bacts on V/prime, then we deﬁne the action on their tensor product
as
(A⊗B)⋆(V⊗V/prime)=A⋆V⊗B⋆V/prime. (2.179)
Such “parallel” actions will arise over and over again.

<<<PAGE 91>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
2.7 Tensor Product of Vector Spaces 73
Programming Drill 2.7.1 Write a function that accepts two matrices and constructs
their tensor product.
.................................................................................
References: There are plenty of good references for basic linear algebra. Many of
the more elementary ones, like Gilbert and Gilbert (2004), Lang (1986), and Penney
(1998), contain many examples and intuitive drawings. Complex vector spaces are
discussed in, e.g., Nicholson (1994) and O’Nan (1976). The tensor product is found
only in more advanced texts, such as Lang (1993).
A history of the development of the subject can be found in Crowe (1994).

<<<PAGE 92>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
3
The Leap from Classical to Quantum
Everyone has lost their marbles!
Anonymous
Before we formally present quantum mechanics in all its wonders, we shall spend
time providing some basic intuitions behind its core methods and ideas. Realizing
that computer scientists feel comfortable with graphs and matrices, we shall cast
quantum mechanical ideas in graph-theoretic and matrix-theoretic terms. Everyonewho has taken a class in discrete structures knows how to represent a (weighted)graph as an adjacency matrix. We shall take this basic idea and generalize it in sev-
eral straightforward ways. While doing this, we shall present a few concepts that
are at the very core of quantum mechanics. In Section 3.1, the graphs are withoutweights. This will model classical deterministic systems. In Section 3.2, the graphs
are weighted with real numbers. This will model classical probabilistic systems. In
Section 3.3, the graphs are weighted with complex numbers and will model quantumsystems. We conclude Section 3.3 with a computer science/graph-theoretic version
of the double-slit experiment. This is perhaps the most important experiment in
quantum mechanics. Section 3.4 discusses ways of combining systems to yield largersystems.
Throughout this chapter, we ﬁrst present an idea in terms of a toy model, then
generalize it to an abstract point, and ﬁnally discuss its connection with quantummechanics, before moving on to the next idea.
3.1 CLASSICAL DETERMINISTIC SYSTEMS
We begin with a simple system described by a graph together with some toy marbles.
Imagine the identical marbles as being placed on the vertices of a graph. The state
of a system is described by how many marbles are on each vertex.
Example 3.1.1 Let there be 6 vertices in a graph and a total of 27 marbles. We
might place 6 marbles on vertex 0, 2 marbles on vertex 1, and the rest as described
by this picture.
74

<<<PAGE 93>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
3.1 Classical Deterministic Systems 75
0•6 1•2 2•1
3•5 4•3 5•10(3.1)
We shall denote this state as X=[6,2,1,5,3,10]T. /square
Example 3.1.2 The state [5 ,5,0,2,0,15]T(in the same 6 vertex, 27 marble system)
will correspond to
0•5 1•5 2•0
3•2 4•0 5•15(3.2)
/square
We are concerned not only with the states of the system, but also with the way
the states change. How they change – or the dynamics of the system – can be repre-
sented by a graph with directed edges. We do not permit an arbitrary graph. Rather,
we insist that every vertex in the graph has exactly one outgoing edge. This require-
ment will coincide with our demand that the system be deterministic. In other words,each marble must move to exactly one place.
Example 3.1.3 An example of the dynamics might be described by the following
directed graph:
0•
6
/d40/d40/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d811•2/d47/d472•1
/d124/d124/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122
3•5/d2/d2
4•3/d47/d475•10/d79/d79
(3.3)
The idea is that if an arrow exists from vertex ito vertex j, then in one time click,
all the marbles on vertex iwill shift to vertex j.

<<<PAGE 94>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
76 The Leap from Classical to Quantum
This graph is easy to store in a computer as a Boolean adjacency matrix, M(for
“marbles”):
M=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣012345
0000000
1000000
2010001
3000100
4001000
5100010⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦, (3.4)
where M[i,j]=1 if and only if there is an arrow from vertex jto vertex i.
1The
requirement that every vertex has exactly one outgoing edge corresponds to the
fact that every column of the Boolean adjacency matrix contains exactly one 1. /square
Let’s say that we multiply Mby a state of the system X=[6,2,1,5,3,10]T. Then
we have
MX=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣000000
000000
010001000100001000100010⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣6
2
153
10⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣0
0
12
5
19⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦=Y. (3.5)
To what does this correspond? If Xdescribes the state of the system at time t,
then Yis the state of the system at time t+1 , i.e., after one time click. We can see
this clearly by looking at the formula for matrix multiplication:
Y[i]=(MX)[i]=
5/summationdisplay
k=0M[i,k]X[k]. (3.6)
In plain English, this states that the number of marbles that will reach vertex iafter
one time step is the sum of all the marbles that are on vertices with edges connecting
to vertex i.
Notice that the top two entries of Yare 0. This corresponds to the fact that there
are no arrows going to vertex 0 or vertex 1.
Exercise 3.1.1 Using the dynamics given in Equation (3.4), determine what the
state of the system would be if you start with the state [5 ,5,0,2,0,15]T. /squaresolid
1Although most texts have M[i,j]=1 if and only if there is an arrow from vertex ito vertex j,w es h a l l
need it to be the other way for reasons which will become apparent later.

<<<PAGE 95>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
3.1 Classical Deterministic Systems 77
In general, any simple directed graph with nvertices can be represented by an
n-by-nmatrix Mhaving entries as
M[i,j]=1 if and only if there is an edge from vertex jto vertex i.
=1 if and only if there is a path of length 1 from vertex jto vertex i.
(3.7)
IfX=[x0,x1,..., xn−1]Tis a column vector that corresponds to placing ximar-
bles on vertex i, and if MX=Ywhere Y=[y0,y1,..., yn−1]T, then there are yj
marbles on vertex jafter one time click. Mis thus a way of describing how the state
of the marbles can change from time tto time t+1.
As we shall soon see, (ﬁnite-dimensional) quantum mechanics works the same
way. States of a system are represented by column vectors, and the way in which the
system changes in one time click is represented by matrices. Multiplying a matrix
with a column vector yields a subsequent state of the system.
Looking at the formula for Boolean matrix multiplication
M2[i,j]=n−1/logicalordisplay
k=0M[i,k]∧M[k,j], (3.8)
we observe that it really shows us how to go from vertex jto vertex iintwotime
clicks. The following picture is helpful:
•0
•1
/d41/d41/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83
j•/d58/d58/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d53/d53/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107
/d41/d41/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83...•i
•n−1(3.9)
There will be a path of length 2 from vertex jto vertex iif there exists (/logicalortext)s o m e
vertex ksuch that there is an arrow from vertex jto vertex kand (∧) an arrow from
vertex kto vertex i.
Thus, we have that
M2[i,j]=1 if and only if there is a path of length 2 from vertex jto vertex i.
(3.10)

<<<PAGE 96>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
78 The Leap from Classical to Quantum
For an arbitrary kwe have
Mk[i,j]=1 if and only if there is a path of length kfrom vertex jto vertex i.
(3.11)
Exercise 3.1.2 For the matrix Mgiven in Equation (3.4), calculate M2,M3, and
M6. If all the marbles start at vertex 2, where will all the marbles end up after 6 time
steps? /squaresolid
In general, multiplying an n-by-nmatrix by itself several times will produce an-
other matrix whose i,jth entry will indicate whether there is a path after several
time clicks. Consider X=[x0,x1,..., xn−1]Tto be the state where one places x0
marbles on vertex 0, x1marbles on vertex 1, ..., xn−1marbles on vertex n−1. Then,
after ksteps, the state of the marbles is Y, where Y=[y0,y1,..., yn−1]T=MkX.I n
other words, yjis the number of marbles on vertex jafter ksteps.
In quantum mechanics, if there are two or more matrices that manipulate states,
the action of one followed by another is described by their product. We shall take
different states of systems and multiply the states by various matrices (of the appro-priate type) to obtain other ones. These new states will again be multiplied by other
matrices until we attain the desired end state. In quantum computing, we shall start
with an initial state, described by a vector of numbers. The initial state will essen-tially be the input to the system. Operations in a quantum computer will correspondto multiplying the vector with matrices. The output will be the state of the system
when we are ﬁnished carrying out all the operations.
Summing up, we have learned the following:/D2The states of a system correspond to column vectors (state vectors)./D2The dynamics of a system correspond to matrices./D2To progress from one state to another in one time step, one must multiply the
state vector by a matrix./D2Multiple step dynamics are obtained via matrix multiplication.
Exercise 3.1.3 What would happen if we relaxed the requirement that exactly one
edge leaves each vertex, i.e., what would happen if we permitted any graph? /squaresolid
Exercise 3.1.4 What would happen if we permitted not only 0’s and 1’s but also
−1 in the adjacency matrix? Give an interpretation of this scenario in terms ofmarbles. /squaresolid
Exercise 3.1.5 Consider the following graph representing city streets. Single-
headed arrows ( −→) correspond to one-way streets and double-headed arrows
(←→ ) correspond to two-way streets.

<<<PAGE 97>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
3.2 Probabilistic Systems 79
0/d111/d111 /d47/d471 2
/d15/d15
3/d12/d12
4
/d15/d155
/d15/d15
6/d47/d477/d47/d478/d12/d12(3.12)
Imagine that it takes one time click to traverse an arrow. You may assume that ev-
eryone must move at every time click. If every corner starts with exactly one person,
where will everyone be after one time click? After two time clicks? After four timeclicks? /squaresolid
Programming Drill 3.1.1 Write a program that performs our little marble experi-
ment. The program should allow the user to enter a Boolean matrix that describes theways that marbles move. Make sure that the matrix follows our requirement. The usershould also be permitted to enter a starting state of how many marbles are on each
vertex. Then the user enters how many time clicks she wants to proceed. The com-
puter should then calculate and output the state of the system after those time clicks.We will make changes to this program later in the chapter.
3.2 PROBABILISTIC SYSTEMS
In quantum mechanics, there is an inherent indeterminacy in our knowledge of a
physical state. Furthermore, states change with probabilistic laws. This simply means
that the laws governing a system’s evolution are given by describing how states tran-sition from one to another with a certain likelihood.
In order to capture these probabilistic scenarios, let us modify what we did in
the last section. Instead of dealing with a bunch of marbles moving about, we shallwork with a single marble. The state of the system will tell us the probabilities of the
marble being on each vertex. For a three-vertex graph, a typical state might look like
X=/bracketleftbig
1
5,3
10,1
2/bracketrightbigT. This will correspond to the fact that there is a one-ﬁfth2chance that
the marble is on vertex 0, a three-tenths chance that the marble is on vertex 1; and ahalf chance that the marble is on vertex 2. Because the marble must be somewhere
on the graph, the sum of the probabilities is 1.
We must modify the dynamics as well. Rather than exactly one arrow leaving
each vertex, we will have several arrows shooting out of each vertex with real num-bers between 0 and 1 as weights. These weights describe the probability of ourmarble moving from one vertex to another in one time click. We shall restrict our
2Although the theory works with any r∈[0,1], we shall deal only with fractions.

<<<PAGE 98>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
80 The Leap from Classical to Quantum
attention to weighted graphs that satisfy the following two conditions: a) the sum
of all the weights leaving a vertex is 1 and b) the sum of all the weights entering a
vertex is 1. This will correspond to the fact that the marble must both go and comefrom someplace (there might be loops).
Example 3.2.1 An example of such a graph is
0•1
3
/d45/d45
2
3
/d21/d21•1
1
3
/d3/d31
6/d109/d1091
2
/d12/d12
•25
6/d85/d85
1
6/d67/d67
(3.13)
The adjacency matrix for this graph is
M=⎡
⎢⎢⎢⎢⎣01
65
6
1
31
21
6
2
31
30⎤
⎥⎥⎥⎥⎦. (3.14)
/square
The adjacency matrices for our graphs will have real entries between 0 and 1
where the sums of the rows and the sums of the columns are all 1. Such matrices are
called doubly stochastic.
Let us see how the states interact with the dynamics. Suppose we have a state
X=/bracketleftbig1
6,1
6,2
3/bracketrightbigTthat expresses an indeterminacy about the position of a marble: the
probability is1
6that the marble is on vertex 0, the probability is1
6that the marble is
on vertex 1, and the probability is2
3that the marble is on vertex 2.
With this interpretation, we will calculate how a state changes:
MX=⎡
⎢⎢⎢⎢⎣0
1
65
6
1
31
21
6
2
31
30⎤
⎥⎥⎥⎥⎦⎡
⎢⎢⎢⎢⎣1
6
1
6
2
3⎤
⎥⎥⎥⎥⎦=⎡
⎢⎢⎢⎢⎣21
36
9
36
6
36⎤
⎥⎥⎥⎥⎦=Y. (3.15)

<<<PAGE 99>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
3.2 Probabilistic Systems 81
Notice that the sum of the entries of Yis 1. We might express this by saying
If the marble’s position is
1
6chance on vertex 0,
1
6chance on vertex 1, and
2
3chance on vertex 2,
then, after following the arrows, the probability of the marble’s position is
21
36chance on vertex 0,
9
36chance on vertex 1, and
6
36chance on vertex 2.
That is, if we have Xexpressing the probability of the position of a mar-
ble and Mexpressing the probability of the way the marble moves around, then
MX=Y=/bracketleftbig21
36,9
36,6
36/bracketrightbigTis expressing the probability of the marble’s location after
moving. If Xis the probability of the marble at time t, then MX is the probability of
the marble at time t+1.
Exercise 3.2.1 LetMbe as in Equation (3.14) and let X=/bracketleftbig1
2,0,1
2/bracketrightbigT. Show that the
entries of Y=MX sum to 1. /squaresolid
Exercise 3.2.2 LetMbe any n-by-ndoubly stochastic matrix. Let Xbe an n-by-1
column vector. Let the result of MX=Y.
a) If the sum of the entries of Xis 1, prove that the sum of the entries of Yis 1.
b) More generally, prove that if the sum of the entries of Xisx, then the sum of
the entries of Yis also x, i.e., Mpreserves the sum of the entries of a column vector
multiplied at the right of M. /squaresolid
We shall multiply vectors not only on the right of a matrix, but on the left as
well. We shall posit that a row vector will also correspond to a state of a system.
Take a row vector where the sum of the entries is 1. Multiply it on the left of M.
W=/bracketleftbig1
3,0,2
3/bracketrightbig
. Then we have
WM=/bracketleftbigg1
3,0,2
3/bracketrightbigg⎡
⎢⎢⎢⎢⎣0
1
65
6
1
31
21
6
2
31
30⎤
⎥⎥⎥⎥⎦=/bracketleftbigg4
9,5
18,5
18/bracketrightbigg
=Z. (3.16)
Notice that the sum of the entries of Zis 1.
Exercise 3.2.3 Let Mbe any n-by-ndoubly stochastic matrix. Let Wbe a 1-by- n
row vector. Then we have the resulting
WM=Z. (3.17)
a) If the sum of the entries of Wis 1, prove that the sum of the entries of Zis 1.
b) More generally, prove that if the sum of the entries of Wisw, then the sum
of the entries of Zis also w, i.e., Mpreserves the sum of the entries of a row vector
multiplied on the left of M. /squaresolid

<<<PAGE 100>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
82 The Leap from Classical to Quantum
What can this possibly mean? The transpose of M
MT=⎡
⎢⎢⎢⎢⎣0
1
32
3
1
61
21
3
5
61
60⎤
⎥⎥⎥⎥⎦(3.18)
corresponds to our directed graph with the arrows reversed:
0•1
6
/d45/d45
5
6
/d21/d21•1
1
6
/d3/d31
3/d109/d1091
2
/d12/d12
•22
3/d85/d85
1
3/d67/d67
(3.19)
Reversing the arrows is like traveling back in time or having the marble roll
backward. A simple calculation shows that
MTWT=⎡
⎢⎢⎢⎢⎣01
32
3
1
61
21
3
5
61
60⎤
⎥⎥⎥⎥⎦⎡
⎢⎢⎢⎢⎣1
3
0
2
3⎤
⎥⎥⎥⎥⎦=⎡
⎢⎢⎢⎢⎣4
9
5
18
5
18⎤
⎥⎥⎥⎥⎦=ZT, (3.20)
i.e.,
MTWT=(WM )T=ZT. (3.21)
So if multiplying on the right of Mtakes states from time tto time t+1, then
multiplying on the left of Mtakes states from time tto time t−1.
This time symmetry is one of the fundamental concepts of quantum mechanics
and quantum computation. Our description of system dynamics is entirely symmet-
ric: by replacing column vectors with row vectors, and forward evolution in timewith backward evolution, the laws of dynamics still hold. We shall encounter row
vectors in Chapter 4, and unravel their role. But let us now go back to M.

<<<PAGE 101>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
3.2 Probabilistic Systems 83
Let’s multiply Mby itself. MM=M2:
⎡
⎢⎢⎢⎢⎣0
1
65
6
1
31
21
6
2
31
30⎤
⎥⎥⎥⎥⎦⎡
⎢⎢⎢⎢⎣0
1
65
6
1
31
21
6
2
31
30⎤
⎥⎥⎥⎥⎦=⎡
⎢⎢⎢⎢⎣11
1813
361
36
5
1813
3613
36
1
95
1811
18⎤
⎥⎥⎥⎥⎦. (3.22)
The following picture can help us understand matrix multiplication with probability
entries:
•0
M[i,0]
/d35/d35/d72/d72/d72/d72/d72/d72/d72/d72/d72/d72/d72/d72/d72/d72/d72/d72/d72/d72/d72/d72/d72/d72/d72
•1
M[i,1]/d41/d41/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83
j•M[0,j]/d58/d58/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118/d118M[1,j]/d53/d53/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107
M[n−1,j] /d41/d41/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83...•i
•n−1M[i,n−1]/d53/d53/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107(3.23)
In order to go from vertex jto vertex iin two steps,
one can go from vertex jto vertex 0 and (multiply) go to vertex ior (add)
one can go from vertex jto vertex 1 and (multiply) go to vertex ior (add)
...
or (add)
one can go from vertex jto vertex n−1 and (multiply) go to vertex i.
This is exactly the formula for multiplying matrices in Equation (2.37) on page 41.And so we can state
M
2[i,j]=the probability of going from vertex jto vertex ii n2t i m ec l i c k s .
(3.24)
Exercise 3.2.4 Let
M=⎡
⎢⎣1
32
3
2
31
3⎤
⎥⎦ and N=⎡
⎢⎣1
21
2
1
21
2⎤
⎥⎦
be two doubly stochastic matrices. Calculate M⋆Nand show that this is again a
doubly stochastic matrix. /squaresolid

<<<PAGE 102>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
84 The Leap from Classical to Quantum
Exercise 3.2.5 Prove that the product of a doubly stochastic matrix with another
doubly stochastic matrix is also a doubly stochastic matrix. /squaresolid
In general, for an arbitrary positive integer k, we have
Mk[i,j]=the probability of going from vertex jto vertex iinktime clicks.
(3.25)
IfMis an n-by-ndoubly stochastic matrix and Xis an n-by-1 column vector
whose entries sum to 1, then MkX=Yis expressing the probability of the position
of a marble after ktime clicks. That is, if X=[x0,x1,..., xn−1]Tmeans that there
is an xichance that a marble is on vertex i, then MkX=Y=[y0,y1,..., yn−1]T
means that after ktime clicks, there is a yjchance that the marble is on
vertex j.
We are not constrained to multiply Mby itself. We may also multiply Mby
another doubly stochastic matrix. Let Mand Nbe two n-by-ndoubly stochastic
matrices corresponding to the weighted nvertex graphs GMand GN, respectively.
Then M⋆Ncorresponds to an n-vertex graph whose weight is given as
(M⋆N)[i,j]=n−1/summationdisplay
k=0M[i,k]N[k,j]. (3.26)
In terms of a marble, this n-vertex graph corresponds to the sum of the probabilities
of its shifting from vertex jto some vertex kinGNand then shifting from vertex k
to vertex iinGM.S oi f Mand Neach describe some probability transition for going
from one time click to the next, M⋆Nwill then describe a probability transition of
going from time ttot+1t o t+2.
Example 3.2.2 Let us tackle a real example: the stochastic billiard ball . Consider
the graph
1•
1
2
/d26/d261
2 /d121/d121
0•1
2/d57/d57
1
2 /d37/d37•31
2/d90/d90
1
2 /d121/d121
2•1
2/d57/d57
1
2/d101/d101 (3.27)

<<<PAGE 103>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
3.2 Probabilistic Systems 85
Corresponding to this graph is the matrix
A=⎡
⎢⎢⎢⎢⎢⎢⎢⎣0
1
21
20
1
2001
2
1
2001
2
01
21
20⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (3.28)
Notice that Ais a doubly stochastic matrix. Let us start with a single marble on
vertex 0; that is, we shall start in state [1 ,0,0,0]
T. After one time click, the system
will be in state
/bracketleftbigg
0,1
2,1
2,0/bracketrightbiggT
. (3.29)
A quick calculation shows that in another time click, the system will be in state
/bracketleftbigg1
2,0,0,1
2/bracketrightbiggT
. (3.30)
Continuing in this fashion, we ﬁnd that the marble acts like a billiard ball and contin-
ues to bounce back and forth between vertices 1,2 and 0,3. We shall meet a quantum
version of this example in the next section. /square
Exercise 3.2.6 Consider the following hypothetical situation at a hypothetical col-
lege. Thirty percent of all math majors become computer science majors after oneyear. Another 60% become physics majors after one year. After a year, 70% ofthe physics majors become math majors and 10% of the physics majors become
computer science majors. In contrast to the other departments, computer science
students are usually very happy: only 20% of them become math majors and 20%become physics majors after a year.
(a) Draw a graph that describes the situation.(b) Give the corresponding adjacency matrix. Notice that it is a doubly stochastic
matrix.
(c) If a student is majoring in one of these three areas, indicate her probable
major after 2, 4, and 8 years. /squaresolid
Before moving on to the next section, let us examine an interesting example.
This shall be known as the probabilistic double-slit experiment. Consider Figure 3.1
where there is a diagram of a gun shooting bullets.
There are two slits in the wall. The shooter is a good enough shot to always
get the bullets through one of the two slits. There is a 50% chance that the bullet
will travel through the top slit. Similarly, there is a 50% chance the bullet will travel
through the bottom slit. Once a bullet is through a slit, there are three targets tothe right of each slit that the bullet can hit with equal probability. The middle targetcan get hit in one of two ways: from the top slit going down or from the bottom
slit going up. It is assumed that it takes the bullet one time click to travel from the

<<<PAGE 104>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
86 The Leap from Classical to Quantum
Figure 3.1. Double-slit experiment with bullets.
gun to the wall and one time click to travel from the wall to the targets. The picture
corresponds to the following weighted graph:
•31
/d13/d13
1•1
3/d63/d63/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d1261
3/d47/d47
1
3
/d31/d31/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64•41
/d13/d13
0•1
2/d63/d63/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126
1
2
/d31/d31/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64•51
/d13/d13
2•1
3/d63/d63/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d1261
3/d47/d47
1
3
/d31/d31/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64•61
/d13/d13
•71
/d13/d13(3.31)

<<<PAGE 105>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
3.2 Probabilistic Systems 87
Notice that the vertex marked 5 can receive bullets from either of the two slits. Also
notice that once a bullet is in position 3, 4, 5, 6, or 7, it will, with probability 1, stay
there.
Corresponding to this graph is the matrix B(for “bullets”):
B=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣00000000
1
20000000
1
20000000
01
3010000
01
3001000
01
31
300100
001
300010
001
300001⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (3.32)
In words, Bdescribes the way a bullet will move after one time click. The matrix
Bis not a doubly stochastic matrix. The sum of the weights entering vertex 0 is not
1. The sum of weights leaving vertices 3, 4, 5, 6, and 7 are more than 1. In order to
convert this to a doubly stochastic matrix, our bullets would require the ability to go
from right to left. In other words, the targets and the slits would have to be madeof some type of elastic material that could cause the bullets to ricochet as in our
stochastic billiard ball example. Rather than consider such a complicated scenario,
we shall stick to this simpliﬁed version.
Let us calculate the probabilities for the bullet’s position after two time clicks.
B⋆B=B
2=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣00000000
00000000
00000000
1
61
3010000
1
61
3001000
1
31
31
300100
1
601
300010
1
601
300001⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (3.33)
SoB
2indicates the probabilities of the bullet’s position after two time clicks.
If we are sure that we start with the bullet in position 0, i.e.,
X=[1,0,0,0,0,0,0,0]T, (3.34)

<<<PAGE 106>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
88 The Leap from Classical to Quantum
then after two time clicks, the state of the bullets will be
B2X=/bracketleftbigg
0,0,0,1
6,1
6,1
3,1
6,1
6/bracketrightbiggT
. (3.35)
The key idea is to notice that B2[5,0]=1
6+1
6=1
3because the gun shoots the bullet
from position 0; hence, there are two possible ways for the bullets to get to position
5. The possibilities sum to1
3. This is what we would expect. We revisit this example
in the next section where strange things start happening!
Let us summarize what we should retain from this section:/D2The vectors that represent states of a probabilistic physical system express a typeof indeterminacy about the exact physical state of the system./D2The matrices that represent the dynamics express a type of indeterminacy aboutthe way the physical system will change over time. Their entries enable us tocompute the likelihood of transitioning from one state to the next./D2The way in which the indeterminacy progresses is simulated by matrix multipli-cation, just as in the deterministic scenario.
Programming Drill 3.2.1 Modify your program from Programming Drill 3.1.1 so
that the entries in the matrices can be fractions as opposed to Boolean values.
Programming Drill 3.2.2 What would happen if there were more than two slits?
Write a program that asks a user to design a multislit experiment. The user notes
the number of slits and the number of targets to measure the bullets. Then the user
enters probabilities of the bullets’ moving from each slit to each target. An appropriate
matrix is set up and then the matrix is multiplied by itself. Have the program print theappropriate resulting matrix and vector.
3.3 QUANTUM SYSTEMS
We are now ready to leave the world of classical probabilities and enter the world ofthe quantum. As mentioned earlier, quantum mechanics works with complex num-bers. A weight is not given as a real number pbetween 0 and 1. Rather, it is given
as a complex number csuch that |c|
2is a real number between 0 and 1.
What difference does it make how probabilities are given? What does it matter
if a probability is given directly as a real number between 0 and 1, or indirectly asa complex number whose modulus squared is a real number between 0 and 1? The
difference is – and this lies at the very core of quantum theory – that real number
probabilities can only increase when added. In contrast, complex numbers can can-cel each other and lower their probability. For example, if p
1and p2are two real
numbers between 0 and 1, then ( p1+p2)≥p1and ( p1+p2)≥p2. Now let us look
at the complex case. Let c1andc2be two complex numbers with associated squares
of modulus |c1|2and|c2|2.|c1+c2|2need not be bigger than |c1|2and it also does not
need to be bigger than |c2|2.

<<<PAGE 107>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
3.3 Quantum Systems 89
Example 3.3.1 For example,3ifc1=5+3iand c2=−3−2i, then|c1|2=34 and
|c2|2=13 but|c1+c2|2=|2+i|2=5. 5 is less than 34, and 5 is less than 13. /square
The fact that complex numbers may cancel each other out when added has a
well-deﬁned physical meaning in quantum mechanics (and in classical wave me-
chanics as well). It is referred to as interference4and it is one of the most important
concepts in quantum theory.
Let us generalize our states and graphs from the previous section. For our states,
rather than insisting that the sum of the entries in the column vector is 1, we shall
require that the sum of the modulus squared of the entries be 1. (This makes sense
because we are considering the probability as the modulus squared.) An example ofsuch a state is
X=/bracketleftBigg
1
√
3,2i√
15,/radicalbigg
2
5/bracketrightBiggT
. (3.36)
Rather than talking about graphs with real number weights, we shall talk about
graphs with complex number weights. Instead of insisting that the adjacency matrixof such a graph be a doubly stochastic matrix, we ask instead that the adjacencymatrix be unitary.
5
For example, consider the graph
0•1√
2
/d18/d18−i√
2
/d45/d45•1
1√
2/d109/d109i√
2
/d115/d115
•2i
/d12/d12(3.37)
The corresponding unitary adjacency matrix is
U=⎡
⎢⎢⎢⎢⎣1√
21√
20
−i√
2i√
20
00 i⎤
⎥⎥⎥⎥⎦. (3.38)
3The important point here is that the modulus squared is positive. For simplicity of calculation, we have
chosen easy complex numbers.
4The clever reader might have considered something like “negative probability” to perform the sametask as complex numbers. It turns out that much of quantum mechanics can, in fact, be done that way.However, it is not the standard way of introducing quantum theory, and we will not take that route.
5We deﬁned a “unitary matrix” in Section 2.6. Remember: A matrix Uis unitary if U⋆U†=I=
U†⋆U.

<<<PAGE 108>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
90 The Leap from Classical to Quantum
Unitary matrices are related to doubly stochastic matrices as follows: the modu-
lus squared of the all the complex entries in Uforms a doubly stochastic matrix.6
The i,jth element in Uis denoted U[i,j], and its modulus squared is denoted
|U[i,j]|2. By abuse of notation, we shall denote the entire matrix of modulus squares
as|U[i,j]|2:
|U[i,j]|2=⎡
⎢⎢⎢⎢⎣1
21
20
1
21
20
001⎤
⎥⎥⎥⎥⎦. (3.39)
It is easy to see that this is a doubly stochastic matrix.
Exercise 3.3.1 Find the |U[i,j]|
2for the unitary matrix
U=⎡
⎢⎢⎢⎢⎣cosθ−sinθ0
sinθ cosθ 0
00 1⎤
⎥⎥⎥⎥⎦
for any θ. Check that it is doubly stochastic. /squaresolid
Exercise 3.3.2 Given any unitary matrix, prove that the modulus squared of each
of the entries forms a doubly stochastic matrix. /squaresolid
Let us now see how unitary matrices act on states. Calculating UX=Y, we get
⎡
⎢⎢⎢⎢⎣1√
21√
20
−i√
2i√
20
00 i⎤
⎥⎥⎥⎥⎦⎡
⎢⎢⎢⎢⎣1√
3
2i√
15/radicalBig
2
5⎤
⎥⎥⎥⎥⎦=⎡
⎢⎢⎢⎢⎣5+2i√
30
−2−√
5i√
30/radicalBig
2
5i⎤
⎥⎥⎥⎥⎦. (3.40)
Notice that the sum of the modulus squares of Yis 1.
Exercise 3.3.3 Prove that a unitary matrix preserves the sum of the modulus
squares of a column vector multiplied on its right. /squaresolid
From the graph-theoretic point of view, it is easy to see what unitary means: the
conjugate transpose of the Umatrix is
U†=⎡
⎢⎢⎢⎢⎣1√
2i√
20
1√
2−i√
20
00 −i⎤
⎥⎥⎥⎥⎦. (3.41)
6In fact, it is a symmetric doubly stochastic matrix.

<<<PAGE 109>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
3.3 Quantum Systems 91
This matrix corresponds to the graph
0•1√
2
/d18/d181√
2
/d45/d45•1
i√
2/d109/d109−i√
2
/d12/d12
•2−i
/d12/d12(3.42)
IfUis the matrix that takes a state from time tto time t+1, then U†is the matrix
that takes a state from time tto time t−1. If we were to multiply U†and U,w e
would obtain the identity matrix I3. We can then have the following sequence of
vectors in times steps:
V/mapsto−→ UV/mapsto−→ U†UV=I3V=V. (3.43)
I3corresponds to the graph
0•1
/d12/d12
•11
/d12/d12
•21
/d12/d12(3.44)
This means that if you perform some operation and then “undo” the operation, you
will ﬁnd yourself (with probability 1) in the same state with which you began.
Example 3.3.2 Let us revisit the stochastic billiard ball example. This time we shall
make a quantum system out of it: the quantum billiard ball. Consider the graph
1•
−1√
2
/d26/d261√
2 /d121/d121
0•1√
2/d57/d57
1√
2 /d37/d37•3−1√
2/d90/d90
1√
2 /d121/d121
2•1√
2/d57/d571√
2/d101/d101 (3.45)

<<<PAGE 110>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
92 The Leap from Classical to Quantum
The matrix corresponding to this graph is
A=⎡
⎢⎢⎢⎢⎢⎢⎢⎣0
1√
21√
20
1√
200 −1√
2
1√
2001√
2
0−1√
21√
20⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (3.46)
Notice that this matrix is unitary. Let us start with a single marble on vertex 0, i.e.,
the state [1 ,0,0,0]
T. After one time click, the system will be in the state
/bracketleftBigg
0,/radicalbigg
1
2,/radicalbigg
1
2,0/bracketrightBiggT
(3.47)
reﬂecting the 50-50 chance as in the stochastic billiard ball example. But what hap-
pens if we multiply this vector by Ato determine the next state of the system? A
quick calculation will show that after the next time click, the system will be back in
state
[1,0,0,0]T. (3.48)
This is in stark contrast to what happened with the stochastic billiard ball. Here,
the other paths cancel each other out (interference). We could have seen this by
noticing that in order to ﬁnd the state after two time clicks, we would have had to
multiply our starting state with A⋆A. However, A⋆A=A2=I4. /square
Figure 3.2. Double-slit experiment with photons.

<<<PAGE 111>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
3.3 Quantum Systems 93
In order to see the interference phenomenon more clearly, we shall revisit the
double-slit experiment from Section 3.2. Rather than examine bullets, which are
relatively large objects and hence adhere to the laws of classical physics, we shall
study microscopic objects such as photons that follow the laws of quantum physics.Rather than a gun, we shall have a laser shoot photons. (Photons are elementaryparticles that are the basic ingredients of light.) We shall shoot photons through two
slits as in Figure 3.2.
Again, we shall make the assumption that a photon will pass through one of
the two slits. Each slit has a 50% chance of the photon’s passing through it. Tothe right of each slit, there are three measuring devices. It is assumed that it takes
one time click to go from the laser to the wall and one time click to go from thewall to the measuring devices. We are not interested in how large the slits are or
how far the measuring devices are from the slits. Physicists are very adept at cal-
culating many different aspects of this experiment. We are only interested in thesetup.
The following weighted graph describes the setup of the experiment:
•3
1
/d12/d12
1•−1+i√
6/d62/d62/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126−1−i√
6/d47/d47
1−i√
6 /d32/d32/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64•41
/d12/d12
0•1√
2/d62/d62/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126
1√
2 /d32/d32/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64•51
/d12/d12
2•−1+i√
6/d62/d62/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126/d126−1−i√
6/d47/d47
1−i√
6 /d32/d32/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64/d64 •61
/d12/d12
•71
/d12/d12(3.49)
The modulus squared of1√
2is1
2, which corresponds to the fact that there is a 50–50
chance of the photon’s passing through either slit./vextendsingle/vextendsingle/vextendsingle±1±i√
6/vextendsingle/vextendsingle/vextendsingle2
=1
3,which corresponds

<<<PAGE 112>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
94 The Leap from Classical to Quantum
to the fact that whichever slit the photon passes through, there is a1
3chance of its
hitting any of the three measuring devices to the right of that slit.7
The adjacency matrix, P(for “photons”), of this graph is
P=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣0 0 0 00000
1√
20 0 00000
1√
20 0 00000
0−1+i√
60 10000
0−1−i√
60 01000
01−i√
6−1+ i√
600100
00−1−i√
600010
001−i√
600001⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (3.50)
This matrix is not unitary. The reason this matrix fails to be unitary is that we have
not placed all the arrows in our graph. There are many more possible ways the pho-ton can travel in a real-life physical situation. In particular, the photon might travel
from right to left. The diagram and matrix would become too complicated if we
put in all the transitions. We are simply trying to demonstrate the phenomenon ofinterference and we can accomplish that even with a matrix that is not quite unitary.
The modulus squared of the Pmatrix is exactly the same as that of the bullet’s
matrix, i.e.,
|P[i,j]|
2=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣00000000
1
20000000
1
20000000
01
3010000
01
3001000
01
31
300100
001
300010
001
300001⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (3.51)
In fact, we chose our complex numbers so that |P[i,j]|
2would be equal to Bof
Section 3.2. This means that nothing strange happens after one time click.
7The actual complex number weights are not our concern here. If we wanted to calculate the actual
numbers, we would have to measure the width of the slits, the distance between them, the distance fromthe slits to the measuring devices, etc. However, our goal here is to clearly demonstrate the interferencephenomenon, and so we chose the above complex numbers simply because the modulus squared areexactly the same as in the bullet’s case.

<<<PAGE 113>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
3.3 Quantum Systems 95
So far, everything looks normal. Let us see what happens if we calculate the
transition matrix after twotime clicks.
P2=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣0 0 0 00000
0 0 0 000000 0 0 00000
−1+i√
12−1+ i√
60 10000
−1−i√
12−1− i√
60 01000
0−1+i√
61−i√
600100
−1−i√
120−1−i√
600010
−1+i√
1201−i√
600001⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (3.52)
How do we interpret this in terms of probability? Let us look at the modulus
squared of each of the entries.
|P
2[i,j]|2=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣00000000
0000000000000000
1
61
3010000
1
61
3001000
01
31
300100
1
601
300010
1
601
300001⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (3.53)
This matrix is almost exactly the same as B
2of Section 3.2, but with one glaring
difference. B2[5,0]=1
3because of the two ways of starting at position 0 and ending
at position 5. We added the nonnegative probabilities1
6+1
6=1
3. However, with a
photon that follows the laws of quantum mechanics, the complex numbers are added
as opposed to their probabilities.
1√
2/parenleftbigg−1+i√
6/parenrightbigg
+1√
2/parenleftbigg1−i√
6/parenrightbigg
=−1+i√
12+1−i√
12=0√
12=0, (3.54)
thus giving us |P2[5,0]|2=0. In other words, although there are two ways of a pho-
ton’s going from vertex 0 to vertex 5, there will be no photon at vertex 5.
How is one to understand this phenomenon? For hundreds of years, physicists
have had a simple explanation for interference: waves. A familiar observation such

<<<PAGE 114>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
96 The Leap from Classical to Quantum
as two pebbles thrown into a pool of water will easily convince us that waves in-
terfere, sometimes reinforcing each other, sometimes canceling each other. Thus,
the double-slit experiment points to the wave-like nature of light. At the same time,
another crucial experiment in quantum mechanics, namely the photoelectric effect,points toward a different direction: light is absorbed and emitted in discrete quanti-ties – photons. It is as if light (and matter) has a double nature: on some occasions it
acts as a beam of particles, and at other times it acts like a wave.
It is important to notice that the experiment can be done with a single photon
shot from vertex 0. Even in this scenario, interference will still occur. What is goingon here?
The naive probabilistic interpretation of the position of the photon following the
bullet metaphor of the previous section is thus not entirely adequate. Let the stateof the system be given by X=[c
0,c1,..., cn−1]T∈Cn. It is incorrect to say that the
probability of the photon’s being in position kis|ck|2. Rather, to be in state Xmeans
that the particle is in some sense in allpositions simultaneously. The photon passes
through the top slit and the bottom slit simultaneously, and when it exits both slits,
it can cancel itself out. A photon is not in asingle position, rather it is in many
positions, a superposition.
This might generate some justiﬁable disbelief. After all, we do not see things in
many different positions. Our everyday experience tells us that things are in one
position or (exclusive or!) another. How can this be? The reason we see particlesin one particular position is because we have performed a measurement. When we
measure something at the quantum level, the quantum object that we have mea-sured is no longer in a superposition of states, rather it collapses to a single classicalstate. So we have to redeﬁne what the state of a quantum system is: a system is instate Xmeans that after measuring it, it will be found in position iwith probability
|c
i|2.
What are we to make of these strange ideas? Are we really to believe them?
Richard Feynman, in discussing the double-slit experiment (Feynman, 1963, Vol.
III, page 1-1) waxes lyrical:
We choose to examine a phenomenon which is impossible, absolutely impossible,
to explain in any classical way, and which has in it the heart of quantum mechan-
ics. In reality, it contains the only mystery. We cannot make the mystery go away
by “explaining” how it works. We will just tell you how it works.
It is exactly this superposition of states that is the real power behind quantum
computing. Classical computers are in one state at every moment. Imagine putting a
computer in many different classical states simultaneously and then processing withallthe states at once. This is the ultimate in parallel processing! Such a computer
can only be conceived of in the quantum world.
Let us review what we have learned:/D2States in a quantum system are represented by column vectors of complex num-bers whose sum of moduli squared is 1./D2The dynamics of a quantum system is represented by unitary matrices and istherefore reversible. The “undoing” is obtained via the algebraic inverse, i.e.,
the adjoint of the unitary matrix representing forward evolution.

<<<PAGE 115>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
3.4 Assembling Systems 97/D2The probabilities of quantum mechanics are always given as the modulus square
of complex numbers./D2Quantum states can be superposed, i.e., a physical system can be in more thanone basic state simultaneously.
Programming Drill 3.3.1 Modify your program from Programming Drill 3.2.1 so
that you allow the entries to be complex numbers as opposed to fractions.
Programming Drill 3.3.2 Modify your program from Programming Drill 3.2.2 so
that you allow transitions from the many slits to the many measuring devices to be
complex numbers. Your program should identify where there are interference phe-
nomena.
3.4 ASSEMBLING SYSTEMS
Quantum mechanics also deals with composite systems, i.e., systems that have more
than one part. In this section, we learn how to combine several systems into one.
We shall talk about assembling classical probabilistic systems. However, whatever
is stated about probabilistic systems is also true for quantum systems.
Consider two different marbles. Imagine that a red marble follows the probabil-
ities of the graph GM:
GM=0•1
3
/d45/d45
2
3
/d21/d21•1
1
3
/d3/d31
6/d109/d1091
2
/d12/d12
•25
6/d85/d85
1
6/d67/d67
(3.55)
whose corresponding adjacency matrix is
M=⎡
⎢⎢⎢⎢⎣01
65
6
1
31
21
6
2
31
30⎤
⎥⎥⎥⎥⎦. (3.56)

<<<PAGE 116>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
98 The Leap from Classical to Quantum
Furthermore, there is also a blue marble that follows the transitions given by the
graph
GN= a•1
3
/d17/d172
3
/d44/d44•b1
3
/d12/d12
2
3/d108/d108 (3.57)
i.e., the matrix
N=⎡
⎢⎣1
32
3
2
31
3⎤
⎥⎦. (3.58)
How does a state for a two-marble system look? Because the red marble can be
on one of three vertices and the blue marble can be on one of two vertices, there
are 3×2=6 possible states of the combined system. This is the tensor product of a
3-by-1 vector with a 2-by-1 vector. A typical state might look like this:
X=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣0a
1
18
0b 0
1a2
18
1b1
3
2a 0
2b1
2⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦, (3.59)
which would correspond to the fact that there is a
1
18chance of the red marble being on vertex 0 and the blue marble being on
vertex a,
0 chance of the red marble being on vertex 0 and the blue marble being on
vertex b,
2
18chance of the red marble being on vertex 1 and the blue marble being on
vertex a,
1
3chance of the red marble being on vertex 1 and the blue marble being on
vertex b,
0 chance of the red marble being on vertex 2 and the blue marble being on
vertex a, and
1
2chance of the red marble being on vertex 2 and the blue marble being on
vertex b.
How does a system with these twomarbles change? What is its dynamics? Imag-
ine that the red marble is on vertex 1 and the blue marble is on vertex a.W em a y
write this state as “1 a.” What is the probability of going from state 1 ato state 2 b?
Obviously, the red marble must move from vertex 1 to vertex 2 and (multiply) the
blue marble must move from vertex ato vertex b. The probability is1
3×2
3=2
9.
In general, for a system to go from state ijto a state i/primej/primewe must multiply the

<<<PAGE 117>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
3.4 Assembling Systems 99
probability of going from state ito state i/primewith the probability of going from state j
to state j/prime.
ijM[i/prime,i]×N[j/prime,j]/d47/d47i/primej/prime. (3.60)
For the changes of all states, we have to do this for all entries. We are really giving
the tensor product of two matrices as deﬁned in Equation (2.175) of Section 2.7.
M⊗N=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣012
00⎡
⎢⎣
1
32
3
2
31
3⎤
⎥⎦1
6⎡
⎢⎣1
32
3
2
31
3⎤
⎥⎦5
6⎡
⎢⎣1
32
3
2
31
3⎤
⎥⎦
11
3⎡
⎢⎣1
32
3
2
31
3⎤
⎥⎦1
2⎡
⎢⎣1
32
3
2
31
3⎤
⎥⎦1
6⎡
⎢⎣1
32
3
2
31
3⎤
⎥⎦
22
3⎡
⎢⎣1
32
3
2
31
3⎤
⎥⎦1
3⎡
⎢⎣1
32
3
2
31
3⎤
⎥⎦0⎡
⎢⎣1
32
3
2
31
3⎤
⎥⎦⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣0a 0b 1a 1b 2a 2b
0a 00
1
182
185
1810
18
0b 002
181
1810
185
18
1a1
92
91
62
61
182
18
1b2
91
92
61
62
181
18
2a2
94
91
92
900
2b4
92
92
91
900⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (3.61)
The graph that corresponds to this matrix, G
M×GN– called the Cartesian product
of two weighted graphs – has 28 weighted arrows. We shall simply ﬁll in those arrows
that correspond to the third column of M⊗N:
0a•• 0b
1a•1
6
/d18/d181
18/d79/d79
2
18/d55/d55/d111/d111/d111/d111/d111/d111/d111/d111/d111/d111/d111/d111/d111/d111/d111/d111/d111/d111/d111/d111/d111/d111/d111/d111/d111/d1112
6/d47/d47
2
9
/d39/d39/d79/d79/d79/d79/d79/d79/d79/d79/d79/d79/d79/d79/d79/d79/d79/d79/d79/d79/d79/d79/d79/d79/d79/d79/d79/d79
1
9
/d15/d15•1b
2a•• 2b(3.62)
Exercise 3.4.1 Complete the graph in Equation (3.62) on a large piece of paper.
/squaresolid

<<<PAGE 118>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
100 The Leap from Classical to Quantum
Exercise 3.4.2 Find the matrix and the graph that correspond to N⊗N. /squaresolid
In quantum theory, the states of two separate systems can be combined using
the tensor product of two vectors and the changes of two systems are combined by
using the tensor product of two matrices. The tensor product of the matrices willthen act on the tensor product of the vectors. However, it must be stressed that inthe quantum world there are many more possible states than just states that can be
combined from smaller ones. In fact, the states that are not the tensor product of
the smaller states are the more interesting ones. They are called entangled states .
We shall see them again in Section 4.5. Similarly, there are many more actions on a
combined quantum system than simply that of the tensor product of the individual
system’s actions.
In general, the Cartesian product of an n-vertex graph with an n
/prime-vertex graph is
an (n×n/prime)-vertex graph. If we have an n-vertex graph Gand we are interested in m
different marbles moving within this system, we would need to look at the graph
Gm=G×G×···× G/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
mtimes, (3.63)
which will have nmvertices. If MGis the associated adjacency matrix, then we will
be interested in
M⊗m
G=MG⊗MG⊗···⊗ MG/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
mtimes, (3.64)
which will be a nm-by-nmmatrix.
One might think of a bit as a two-vertex graph with a marble on the 0 vertex
or a marble on the 1 vertex. If one wished to represent mbits with a single marble,
one would need a 2mvertex graph, or equivalently, a 2m-by-2mmatrix. So there is
exponential growth of the resources needed for the number of bits under discussion.
This exponential growth is actually one of the main reasons Richard Feynman
started talking (Feynman, 1982) about quantum computing in the ﬁrst place. Herealized that because of this exponential growth, it would be hard for a classical
computer to simulate such a system. He then asked whether a prospective quantum
computer, with its inherent ability to perform massive parallel processing, might beable to accomplish the task. After all, Nature can keep up with herself! We discuss
this exponential growth again in Section 5.1.
.................................................................................
Reader Tip. It might be a good idea to ﬂip through Section 2.7 again now that you
have developed some intuition about the tensor product. ♥.................................................................................
L e tu ss u m m a r i z e :/D2A composite system is represented by the Cartesian product of the transitiongraphs of its subsystems.

<<<PAGE 119>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
3.4 Assembling Systems 101/D2If two matrices act on the subsystems independently, then their tensor product
acts on the states of their combined system./D2There is an exponential growth in the amount of resources needed to describelarger and larger composite systems.
Exercise 3.4.3 Let
M=⎡
⎢⎣1
32
3
2
31
3⎤
⎥⎦ and N=⎡
⎢⎣1
21
2
1
21
2⎤
⎥⎦.
Calculate M⊗Nand ﬁnd its associated graph. Compare this graph to GM×GN./squaresolid
Exercise 3.4.4 Prove a general theorem: given two square matrices Mand Nwith
associated weighted graphs GMand GN, show that the two graphs
GM⊗N∼=GM×GN (3.65)
are essentially the same (isomorphism of weighted graphs). /squaresolid
Exercise 3.4.5 Prove a general theorem: given two weighted graphs Gand Hwith
associated adjacency matrices MGand MH, show the equality of matrices
MG×H=MG⊗MH. (3.66)
/squaresolid
Exercise 3.4.6 In Exercise 2.7.4, you proved the essential commutativity of the ten-
sor product of matrices, that is, for matrices Mand N, we have the following isomor-
phism:
M⊗N∼=N⊗M. (3.67)
What does this correspond to in terms of marbles moving on graphs? /squaresolid
Exercise 3.4.7 In Exercise 2.7.9, you proved that for matrices of the appropriate
sizes M,M/prime,N, and N/prime, we have the following equation:
(M⋆M/prime)⊗(N⋆N/prime)=(M⊗N)⋆(M/prime⊗N/prime). (3.68)
What does this correspond to in terms of marbles moving on graphs? /squaresolid
.................................................................................
References: The relationship between graphs and matrices can be found in any
book of discrete mathematics, e.g., Grimaldi (2003), Ross and Wright (2003), and
Rosen (2003). The connection between the number of paths in a graph and matrix
multiplication can be found in many books, e.g., Section 11.3 of Ross and Wright
(2003). The rest of this chapter consists of generalizations of this idea with a view
toward basic quantum mechanics.

<<<PAGE 120>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
102 The Leap from Classical to Quantum
To learn elementary quantum mechanics, see the references at the end of
Chapter 4.
The double-slit experiment is discussed in depth in Chapter 1 of Volume III of
Feynman (1963). Feynman derives many of the properties of quantum mechanics
from this simple experiment. Deﬁnitely worth the read!
To learn more about the tensor product of vector spaces, see the references at
the end of Chapter 2.

<<<PAGE 121>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
4
Basic Quantum Theory
Reality is that which, when you stop believing in it, does not
go away.
Philip K. Dick1
In Chapters 1 and 2 we developed the necessary mathematical apparatus and termi-
nology that will be used throughout this book. Chapter 3 has provided some heuris-
tics and gently led us to the threshold of quantum mechanics. It is now time to open
the door, introduce the basic concepts and tools of the trade, and continue our jour-ney to quantum computing.
2
In Section 4.1 we spend a few words on the motivations behind quantum me-
chanics. We then introduce quantum states and how they are distinguishable fromone another through observations. Section 4.2 describes observable physical quanti-ties within the quantum framework. How observable quantities are measured is the
topic of Section 4.3. The dynamics of quantum systems, i.e., their evolution in time,
is the focus of Section 4.4. Finally, in Section 4.5, we revisit the tensor product andshow how it describes the way in which larger quantum systems are assembled from
smaller ones. In the process, we meet the crucial notion of entanglement, a feature
of the quantum world that pops up again in the chapters ahead.
4.1 QUANTUM STATES
Why quantum mechanics? To answer this question, we have to hearken back in timeto the dawn of the twentieth century. Classical mechanics still dominated the scene,
with its double-pronged approach: particles andwaves . Matter was considered to be
1The quotation is taken from Dick’s 1978 lecture How to build a Universe that does not fall apart two
days later , freely available on the Web at http://deoxy.org/pkd how2build.htm.
2No attempt will be made to present the material in an exhaustive historical manner. The curious reader
can refer to the references at the end of this chapter for a plethora of good, comprehensive introduc-tions to quantum mechanics.
103

<<<PAGE 122>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
104 Basic Quantum Theory
Figure 4.1. Young’ s double-slit experiment.
ultimately composed of microscopic particles, and light was thought of as continuous
electromagnetic waves propagating in space.
The dichotomy – particles versus waves – was proven false by several ground-
breaking experiments. For instance, the diffraction experiment shows that a beam
of subatomic particles hitting a crystal diffract following a wave-like pattern, en-
tirely similar to the diffraction pattern of light itself. By the mid-twenties, physicists
started associating waves to all known particles, the so-called matter waves (the ﬁrst
proposal was made by French physicist Louis De Broglie in 1924 in his doctoral
dissertation).
The photoelectric effect (observed by Hertz in 1887) showed that an atom hit
by a beam of light may absorb it, causing some electrons to transition to a higher-
energy orbital (i.e., farther from the nucleus). Later on, the absorbed energy may
be released in the form of emitted light, causing the excited electrons to revert to a
lower orbital. What the photoelectric effect unraveled was that light-matter trans-actions always occur through discrete packets of energy, known as photons (the
concept was introduced by Einstein in his seminal 1905 paper, as a way to accountfor the photoelectric effect). Photons act as genuine particles that can get absorbedand emitted, one at a time.
Further experimental evidence from many quarters accumulated over time,
strongly suggesting that the old duality particle–wave theory must be replaced bya new theory of the microscopic world in which both matter and light manifest a
particle-like and a wave-like behavior . Time was ripe for the conceptual framework
of quantum mechanics.
In Chapter 3 we met a toy version of the double-slit experiment; as it turns out,
this was an actual experiment, indeed an entire series of related experiments, the
ﬁrst one being carried out with light by the English polymath Thomas Young around
1801. Before we move on, it is worth our while to revisit it brieﬂy, as it contains mostof the main ingredients that make up quantum’s magic.
One shines light at a boundary with two slits that are very close to each other.
The pattern of the light to the right of the boundary will have certain regions thatare dark and certain others that are bright, as depicted in Figure 4.1.
The reason why there are regions on the screen with no light is that light waves
are interfering with each other. Light is propagating as a single wave from its source;

<<<PAGE 123>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
4.1 Quantum States 105
Figure 4.2. Young’ s double-slit experiment with
one slit closed.
the two slits cause this wave to split into two independent ones, which can then
interfere with each other when reaching the screen. Some regions are going to be
darker, others are going to be brighter, depending on whether the two waves are inphase (positive interference) or out of phase (negative interference).
What would happen if we closed off one of the slits? In that case, there is no
splitting and therefore no interference pattern whatsoever (Figure 4.2).
Two remarks on this seminal experiment are in order:/D2As we have already pointed out in Chapter 3, the double-slit experiment can bedone with just one photon at a time. Rather than spotting patterns of lighter or
darker light on the screen, we are now looking for which region is more or less
likely for the single photon to land. The same pattern can then be viewed as de-scribing the probability for a certain region to get hit by the photon. The naturalquestion then is, if there is a single photon why would there be any interference
pattern? Yet, experiments have shown that such a pattern is there. Our photon
is a true chameleon: sometimes it behaves as a particle and sometimes as a wave,depending on how it is observed./D2The double-slit experiment is not only about light: one can perform it equallywell with electrons, protons, and even atomic nuclei, and they will all exhibitexactly the same interference behavior.
3Once again, this clearly indicates that
the rigid distinction between waves and particles as a paradigm of description ofthe physical world is untenable at the quantum level.
In the rest of this section, we are going to introduce the basic mathematical de-
scription of a quantum physical system. We shall restrict ourselves to two simpleexamples, to illustrate the basic machinery:/D2a particle conﬁned to a set of discrete positions on a line/D2a single-particle spin system
3Such experiments have indeed been performed, only much later than Young’s original version of thedouble-slit experiment. We invite you to read about this fascinating slice of experimental physics inRodgers (2002).

<<<PAGE 124>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
106 Basic Quantum Theory
Consider a subatomic particle on a line; moreover, let us suppose that it can
only be detected at one of the equally spaced points {x0,x1,..., xn−1}, where x1=
x0+δx,x2=x1+δx,...,w i t hδ xsome ﬁxed increment.
x0 x1 ··· xi··· xn−1
• • • •(4.1)
In real life, a particle can of course occupy any of the points of the line, not just
a ﬁnite subset thereof. However, if we followed this route, the state space of oursystem would be inﬁnite dimensional, requiring a considerably larger mathematical
apparatus than the one covered in the last chapters. Whereas such an apparatus is
vital for quantum mechanics, it is not needed for an exposition of quantum comput-ing.
4For our current exposition, we can thus assume that the set {x0,x1,..., xn−1}is
composed of a great many points ( nlarge) and that δxis tiny, thereby providing a
reasonably good approximation of a continuous system.
We are now going to associate to the current state of the particle an n-
dimensional complex column vector [ c0,c1,..., cn−1]T.
The particle being at the point xishall be denoted as |xi/angbracketright, using the Dirac ket
notation. (Do not worry about the funny symbol: it will be explained momentarily.)To each of these nbasic states, we shall associate a column vector:
|x
0/angbracketright /mapsto−→ [1,0,.... 0]T
|x1/angbracketright /mapsto−→ [0,1,.... 0]T(4.2)
...
|xn−1/angbracketright /mapsto−→ [0,0,.... 1]T.
Observe that these vectors form the canonical basis of Cn. From the standpoint
of classical mechanics, the basic states in Equation (4.2) are all we shall ever need.
Not so in quantum mechanics: experimental evidence testiﬁes to the fact that the
particle can be in a strange fuzzy blending of these states (think again of the double-slit!). To catch up with Nature, we shall make a bold leap by positing that allvectors
inC
nrepresent a legitimate physical state of the particle.
What can all this possibly mean?An arbitrary state, which we shall denote as |ψ/angbracketright, will be a linear combination of
|x
0/angbracketright,|x1/angbracketright,...,|xn−1/angbracketright, by suitable complex weights, c0,c1,..., cn−1, known as complex
amplitudes ,5
|ψ/angbracketright=c0|x0/angbracketright+c 1|x1/angbracketright+···+ cn−1|xn−1/angbracketright. (4.3)
4We mention in passing that in computer simulation one must always turn a continuous physical system(classical or quantum) into a discrete one: computers cannot deal with inﬁnities.
5This name comes from the fact that |ψ/angbracketrightis indeed a (complex) wave when we study its time evolution, as
we shall see at the end of Section 4.3. Waves are characterized by their amplitude (think of the intensityof a sound wave) – hence the name above – as well as by their frequency (in case of sound waves, theirpitch). As it turns out, the frequency of |ψ/angbracketrightplays a key role in the particle’s momentum. You can think
of Equation (4 .3) as describing |ψ/angbracketrightas the overlap of nwaves, the |x
i/angbracketright, each contributing with intensity
ci.

<<<PAGE 125>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
4.1 Quantum States 107
Thus, every state of our system can be represented by an element of Cnas
|ψ/angbracketright /mapsto−→ [c0,c1,..., cn−1]T. (4.4)
W es a yt h a tt h es t a t e |ψ/angbracketrightis asuperposition of the basic states. |ψ/angbracketrightrepresents the
particle as being simultaneously in all {x0,x1,..., xn−1}locations, or a blending of
all the|xi/angbracketright. There are, however, different possible blendings (much like in the recipe
for baking an apple pie you can vary the proportions of the ingredients and obtain
different ﬂavors). The complex numbers c0,c1,..., cn−1tell us precisely which su-
perposition our particle is currently in. The norm square of the complex number ci
divided by the norm squared of |ψ/angbracketrightwill tell us the probability that, after observing
the particle, we will detect it at the point xi:
p(xi)=|ci|2
||ψ/angbracketright|2=|ci|2
/summationdisplay
j|cj|2. (4.5)
Observe that p(xi) is always a positive real number and 0 ≤p(xi)≤1, as any
genuine probability should be.
When|ψ/angbracketrightis observed, we will ﬁnd it in one of the basic states. We might write
it as6
|ψ/angbracketright /d47/d47 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 |xi/angbracketright. (4.6)
Example 4.1.1 Let us assume that the particle can only be at the four points
{x0,x1,x2,x3}. Thus, we are concerned with the state space C4. Let us also assume
that now the state vector is
|ψ/angbracketright=⎡
⎢⎢⎢⎢⎢⎢⎢⎣−3−i
−2i
i
2⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (4.7)
We shall calculate the probability that our particle can be found at position x
2.T h e
norm of |ψ/angbracketrightis given by
||ψ/angbracketright| =/radicalbig
|−3−i|2+|− 2i|2+|i|2+|2|2=4.3589. (4.8)
The probability is therefore
|i|2
(4.3589)2=0.052624 . (4.9)
/square
6The wiggly line is used throughout this chapter to denote the state of a quantum system before and
after measurement.

<<<PAGE 126>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
108 Basic Quantum Theory
Exercise 4.1.1 Let us assume that the particle is conﬁned to {x0,x1,..., x5}and the
current state vector is
|ψ/angbracketright=[2−i,2i,1−i,1,−2i,2]T. (4.10)
What is the likelihood of ﬁnding the particle at position x3? /squaresolid
Kets can be added: if
|ψ/angbracketright=c0|x0/angbracketright+c 1|x1/angbracketright+···+ cn−1|xn−1/angbracketright=[c 0,c1,..., cn−1]T(4.11)
and
|ψ/prime/angbracketright=c/prime
0|x0/angbracketright+c/prime
1|x1/angbracketright+···+ c/prime
n−1|xn−1/angbracketright=[c/prime
0,c/prime
1,..., c/prime
n−1]T, (4.12)
then
|ψ/angbracketright+|ψ/prime/angbracketright=(c0+c/prime
0)|x0/angbracketright+(c 1+c/prime
1)|x1/angbracketright+···+ (cn−1+c/prime
n−1)|xn−1/angbracketright
=[c0+c/prime
0,c1+c/prime
1,..., cn−1+c/prime
n−1]T. (4.13)
Also, for a complex number c∈C, we can scalar multiply a ket by c:
c|ψ/angbracketright=cc0|x0/angbracketright+cc1|x1/angbracketright+···+ ccn−1|xn−1/angbracketright=[cc 0,cc1,..., ccn−1]T.(4.14)
What happens if we add a ket to itself?
|ψ/angbracketright+|ψ/angbracketright=2|ψ/angbracketright=[c 0+c0,c1+c1,..., cj+cj,..., cn−1+cn−1]T
=[2c0,2c1,..., 2cj,..., 2cn−1]T. (4.15)
The sum of the moduli squared is
S/prime=|2c0|2+|2c1|2+···+| 2cn−1|2=22|c0|2+22|c1|2+···+ 22|cn−1|2
=22(|c0|2+|c1|2+···+| cn−1|2). (4.16)
For the state 2|ψ /angbracketright, the chance that the particle will be found in position jis
p(xj)=|2c j|2
S/prime=22|cj|2
22(|c0|2+|c1|2+···+| cn−1|2)
=|cj|2
|c0|2+|c1|2+···+| cn−1|2. (4.17)
In other words, the ket 2 |ψ/angbracketrightdescribes the same physical system as|ψ/angbracketright.Notice that we
could replace 2 with an arbitrary c∈Cand get the same results. Geometrically, the
vector|ψ/angbracketrightand all its complex scalar multiples c|ψ/angbracketright, i.e., the entire subspace generated
by|ψ/angbracketright, describe the same physical state. The length of |ψ/angbracketrightdoes not matter as far as
physics goes.
Exercise 4.1.2 Let|ψ/angbracketrightbe [c 0,c1,..., cn−1]T. Check that multiplying |ψ/angbracketrightby any
complex number cwill not alter the calculation of probabilities. (Hint: Factor out c
in the ratio.) /squaresolid

<<<PAGE 127>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
4.1 Quantum States 109
Example 4.1.2 The vectors
|ψ1/angbracketright=⎡
⎢⎣1+i
i⎤
⎥⎦ and|ψ2/angbracketright=⎡
⎢⎣2+4i
3i−1⎤
⎥⎦ (4.18)
differ by the factor 3 +i(verify it!), and are thus representatives of the same quan-
tum state. /square
Exercise 4.1.3 Do the vectors [1 +i,2−i]Tand [2+2i,1−2i]Trepresent the
same state? /squaresolid
As we can multiply (or divide) a ket by any (complex) number and still have a
representation of the same physical state, we may as well work with a normalized
|ψ/angbracketright, i.e.,
|ψ/angbracketright
||ψ/angbracketright|(4.19)
which has length 1.7
Example 4.1.3 The vector [2 −3i,1+2i]Thas length given by
/radicalbig
|2−3i|2+|1+2i|2=4.2426. (4.20)
We can normalize it by simply dividing by its length:
1
4.2426[2−3i,1+2i]T=[0.41714−0.70711 i,0.23570 +0.47140 i]T.(4.21)
/square
Exercise 4.1.4 Normalize the ket
|ψ/angbracketright=[3−i,2+6i,7−8i,6.3+4.9i,13i,0,21.1]T. (4.22)
/squaresolid
Exercise 4.1.5 (a) Verify that the two state vectors [√
2
2,√
2
2]Tand [√
2
2,−√
2
2]Tare
each of length 1 in C2. (b) Find the vector on the unit ball of C2representing the
superposition (addition) of these two states. /squaresolid
Given a normalized ket |ψ/angbracketright, the denominator of Equation (4.5) is 1, and hence,
the equation reduces to
p(xi)=|ci|2. (4.23)
We are now done with our ﬁrst motivating example. Let us move on to the sec-
ond one. In order to talk about it, we need to introduce a property of subatomic
particles called spin. As it turns out, spin will play a major role in our story, because
it is the prototypical way to implement quantum bits of information, or qubits, which
we shall encounter in Section 5.1.
7In Section 3.3, we limited ourselves to normalized complex vectors. Now you see why!

<<<PAGE 128>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
110 Basic Quantum Theory
Figure 4.3. The Stern–Gerlach experiment.
What is spin? The Stern–Gerlach experiment (ﬁrst performed in 1922) showed
that an electron in the presence of a magnetic ﬁeld will behave as if it were a charged
spinning top: it will act as a small magnet and strive to align itself to the external
ﬁeld. The Stern–Gerlach experiment (as shown in Figure 4.3) consists of shooting a
beam of electrons through a nonhomogeneous magnetic ﬁeld oriented in a certain
direction, say, vertically ( zdirection). As it happens, the ﬁeld splits the beam into
two streams, with opposite spin. Certain electrons will be found spinning one way,
and certain others spinning the opposite way.
With respect to a classical spinning top, there are two striking differences:/D2First, the electron does not appear to have an internal structure, by itself it is just
a charged point. It acts as a spinning top but it is no top! Spin is therefore a new
property of the quantum world, with no classical analog./D2Secondly, and quite surprisingly, all our electrons can be found either at thetop of the screen or at the bottom, none in between. But, we had not prepared
the “spinning” electrons in any way before letting them interact with the mag-
netic ﬁeld. Classically, one would have expected them to have different magneticcomponents along the vertical axis, and therefore to be differently pulled by the
ﬁeld. There should be some in the middle of the screen. But there isn’t. Con-
clusion: when the spinning particle is measured in a given direction, it can onlybe found in two states: it spins either clockwise or anticlockwise (as shown in
Figure 4.4).
Figure 4.4. Particles with spin.

<<<PAGE 129>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
4.1 Quantum States 111
For each given direction in space, there are only two basic spin states. For the
vertical axis, these states have a name: spin up|↑ /angbracketrightand spin down|↓ /angbracketright. The generic
state will then be a superposition of up and down, or
|ψ/angbracketright=c0|↑ /angbracketright+ c1|↓ /angbracketright. (4.24)
Just like before, c0is the amplitude of ﬁnding the particle in the up state, and simi-
larly for c1.
Example 4.1.4 Consider a particle whose spin is described by the ket
|ψ/angbracketright=(3−4i)|↑ /angbracketright+ (7+2i)|↓ /angbracketright. (4.25)
The length of the ket is
/radicalbig
|3−4i|2+|7+2i|2=8.8318. (4.26)
Therefore, the probability of detecting the spin of the particle in the up direction is
p(↑)=|3−4i|2
8.83182=25
78. (4.27)
The probability of detecting the spin of the particle in state down is
p(↓)=|7+2i|2
8.83182=53
78. (4.28)
/square
Exercise 4.1.6 Let the spinning electron’s current state be |ψ/angbracketright=3i|↑ /angbracketright− 2|↓ /angbracketright .
Find the probability that it will be detected in the up state. /squaresolid
Exercise 4.1.7 Normalize the ket given in Equation (4.25). /squaresolid
In Chapter 2, the inner product was introduced as an abstract mathematical
idea. This product turned a vector space into a space with a geometry : angles, or-
thogonality, and distance were added to the canvas. Let us now investigate its
physical meaning. The inner product of the state space gives us a tool to com-
pute complex numbers known as transition amplitudes, which in turn will enable
us to determine how likely the state of the system before a speciﬁc measurement
(start state), will change to another (end state), after measurement has been carried
out. Let
|ψ/angbracketright=⎡
⎢⎢⎢⎢⎢⎢⎢⎣c
0
c1
...
cn−1⎤
⎥⎥⎥⎥⎥⎥⎥⎦and|ψ
/prime/angbracketright=⎡
⎢⎢⎢⎢⎢⎢⎢⎣c
/prime
0
c/prime
1
...
c/prime
n−1⎤
⎥⎥⎥⎥⎥⎥⎥⎦(4.29)
be two normalized states. We can extract the transition amplitude between state |ψ/angbracketright
and state |ψ
/prime/angbracketrightby the following recipe: |ψ/angbracketrightwill be our start state. The end state will be
a row vector whose coordinates will be the complex conjugate of |ψ/prime/angbracketrightcoordinates.

<<<PAGE 130>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
112 Basic Quantum Theory
Such a state is called a bra, and will be denoted /angbracketleftψ/prime|, or equivalently
/angbracketleftψ/prime|=|ψ/prime/angbracketright†=/bracketleftbig
c/prime
0,c/prime
1,..., c/prime
n−1/bracketrightbig
. (4.30)
To ﬁnd the transition amplitude we multiply them as matrices (notice that we put
them side by side, forming a bra–ket, or bra(c)ket, i.e., their inner product):
/angbracketleftψ/prime|ψ/angbracketright=/bracketleftbig
c/prime
0,c/prime
1,..., c/prime
n−1/bracketrightbig⎡
⎢⎢⎢⎢⎣c
0
c1
...
cn−1⎤
⎥⎥⎥⎥⎦=
c/prime
0×c0+c/prime
1×c1+···+ c/prime
n−1×cn−1.
(4.31)
We can represent the start state, the ending state, and the amplitude of going
from the ﬁrst to the second as the decorated arrow:
|ψ/angbracketright/angbracketleftψ|ψ/prime/angbracketright/d47/d47 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 /d47/d111 |ψ/prime/angbracketright. (4.32)
This recipe is, of course, none other than the inner product of Section 2.4. What
we have done is simply split the product into the bra–ket form. Although this is
mathematically equivalent to our previous deﬁnition, it is quite handy for doing
calculations, and moreover opens up an entirely new vista: it shifts the focus from
states tostate transitions .8
Note: The transition amplitude between two states may be zero. In fact, that hap-
pens precisely when the two states are orthogonal to one another. This simple facthints at the physical content of orthogonality: orthogonal states are as far apart asthey can possibly be. We can think of them as mutually exclusive alternatives:f o r
instance, an electron can be in an arbitrary superposition of spin up and down, but
after we measure it in the zdirection, it will always be either upordown, never
both up and down. If our electron was already in the up state before the zdi-
rection measurement, it will never transition to the down state as a result of themeasurement.
Assume that we are given a normalized start state |ψ/angbracketrightand an orthonormal basis
{|b
0/angbracketright,|b1/angbracketright,...,|bn−1/angbracketright}, representing a maximal list of mutually exclusive end states
associated with some speciﬁc measurement of the system. In other words, we know
beforehand that the result of our measurement will necessarily be one or the otherof the states in the basis, but never a superposition of any of them. We show inSection 4.3 that for every complete measurement of a quantum system there is an
associated orthonormal basis of all its possible outcomes.
8This line of thought has been pursued by some researchers, in the ambitious attempt to provide a
satisfactory interpretation of quantum mechanics. For instance, Yakhir Aharonov and his colleagueshave in recent years proposed a model called the two-vector formalism, in which the single vectordescription is replaced with the full bra-ket pair. The interested reader can consult Aharonov’s recentbook Quantum Paradoxes (Aharonov and Rohrlich, 2005).

<<<PAGE 131>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
4.1 Quantum States 113
We can express |ψ/angbracketrightin the basis {|b0/angbracketright,|b1/angbracketright,...,|bn−1/angbracketright}as
|ψ/angbracketright=b0|b0/angbracketright+b1|b1/angbracketright+···+ bn−1|bn−1/angbracketright. (4.33)
We invite you to check that bi=/angbracketleftbi|ψ/angbracketrightand that |b0|2+|b1|2+···+| bn−1|2=1.
It is thus natural to read Equation (4.33) in the following way: each |bi|2is the
probability of ending up in state |bi/angbracketrightafter a measurement has been made.
|b0/angbracketright
|b1/angbracketright
|ψ/angbracketright
/angbracketleftbi|ψ/angbracketright
/d41/d41 /d41/d105 /d41/d105 /d41/d105 /d41/d105 /d41/d105 /d41/d105 /d41/d105 /d41/d105 /d41/d105 /d41/d105 /d41/d105 /d41/d105 /d41/d105/angbracketleftb0|ψ/angbracketright/d59/d59/d59/d123/d59/d123/d59/d123/d59/d123/d59/d123/d59/d123/d59/d123/d59/d123/d59/d123/d59/d123/d59/d123/d59/d123/d59/d123/d59/d123/d59/d123/angbracketleftb1|ψ/angbracketright/d53/d53/d53/d117 /d53/d117 /d53/d117 /d53/d117 /d53/d117 /d53/d117 /d53/d117 /d53/d117 /d53/d117 /d53/d117 /d53/d117 /d53/d117
/angbracketleftbn−1|ψ/angbracketright
/d29/d29/d29/d93/d29/d93/d29/d93/d29/d93/d29/d93/d29/d93/d29/d93/d29/d93/d29/d93/d29/d93/d29/d93/d29/d93/d29/d93/d29/d93/d29/d93/d29/d93/d29/d93/d29/d93/d29/d93/d29/d93...
|bi/angbracketright
...
|b
n−1/angbracketright(4.34)
Exercise 4.1.8 Check that the set {|x0/angbracketright,|x1/angbracketright...,|xn−1/angbracketright}is an orthonormal basis for
the state space of the particle on the line. Similarly, verify that {| ↑/angbracketright,|↓ /angbracketright } is an or-
thonormal basis of the one-particle spin system. /squaresolid
From now on, we shall use the row–column and the bra–ket notation introduced
earlier interchangeably, as we deem ﬁt.9
Let us work through a couple of examples together.
Example 4.1.5 Let us compute the bra corresponding to the ket |ψ/angbracketright=[3,1−2i]T.
It is quite easy; we take the complex conjugate of all the entries, and list them:
/angbracketleftψ|=[3,1+2i]. /square
Example 4.1.6 Let us now compute the amplitude of the transition from
|ψ/angbracketright=√
2
2[1,i]Tto|φ/angbracketright=√
2
2[i,−1]T. We ﬁrst need to write down the bra correspond-
ing to the end state:
/angbracketleftφ|=√
2
2[−i,−1]. (4.35)
9An historical note is in order: the bra–ket notation, which is now ubiquitous in quantum mechanics,
was introduced by the great physicist Paul A.M. Dirac around 1930.

<<<PAGE 132>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
114 Basic Quantum Theory
Now we can take their inner product:
/angbracketleftφ,ψ/angbracketright=− i. (4.36)
/square
Exercise 4.1.9 Calculate the bra corresponding to the ket |ψ/angbracketright=[3+i,−2i]T./squaresolid
Exercise 4.1.10 Calculate the amplitude of the transition from√
2
2[i,−1]Tto√
2
2[1,−i]T. /squaresolid
Observe that in the calculation of transition amplitudes via the inner product, the
requirement that the representatives be normalized states can be easily removed by
simply dividing the hermitian product by the product of the length of the two vec-
tors (or equivalently, normalizing your states ﬁrst, and then computing their inner
product). Here is an example.
Example 4.1.7 Let us calculate the amplitude of the transition from |ψ/angbracketright=[1,−i]T
to|φ/angbracketright=[ i,1]T. Both vectors have norm√
2.
We can take their inner product ﬁrst:
/angbracketleftφ|ψ/angbracketright=[−i,1][1,−i]T=−2i. (4.37)
and then divide it by the product of their norm:
−2i√
2∗√
2=−i. (4.38)
Equivalently, we can ﬁrst normalize them, and then take their product:
/angbracketleftbigg1√
2φ|1√
2ψ/angbracketrightbigg
=/bracketleftbigg−i√
2,1√
2/bracketrightbigg/bracketleftbigg1√
2,−i√
2/bracketrightbiggT
=−i. (4.39)
The result is, of course, the same. We can concisely indicate it as
/angbracketleftφ|ψ/angbracketright
||φ/angbracketright| ||ψ/angbracketright|. (4.40)
/square
Let us pause one moment, and see where we are./D2We have learned to associate a vector space to a quantum system. The dimension
of this space reﬂects the amount of basic states of the system./D2States can be superposed, by adding their representing vectors./D2A state is left unchanged if its representing vector is multiplied by a complexscalar./D2The state space has a geometry, given by its inner product. This geometry has
a physical meaning: it tells us the likelihood for a given state to transition intoanother one after being measured. States that are orthogonal to one another are
mutually exclusive.

<<<PAGE 133>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
4.2 Observables 115
Before moving on to the next sections, we invite you to write a simple computer
simulation.
Programming Drill 4.1.1 Write a program that simulates the ﬁrst quantum system de-
scribed in this section. The user should be able to specify how many points the particle
can occupy (warning: keep the max number low, or you will fairly quickly run out ofmemory). The user will also specify a ket state vector by assigning its amplitudes.
The program, when asked the likelihood of ﬁnding the particle at a given point, will
perform the calculations described in Example 4.1.1. If the user enters two kets, the
system will calculate the probability of transitioning from the ﬁrst ket to the second,
after an observation has been made.
4.2 OBSERVABLES
Physics is, by and large, about observations: physical quantities like mass, momen-
tum, velocity, etc., make sense only insofar as they can be observed in a quantiﬁableway. We can think of a physical system as speciﬁed by a double list: on the one hand,
its state space, i.e., the collection of all the states it can possibly be found in (see the
previous section), and on the other hand, the set of its observables, i.e., the physical
quantities that can be observed in each state of the state space.
Each observable may be thought of as a speciﬁc question we pose to the system :
if the system is currently in some given state |ψ/angbracketright, which values can we possibly ob-
serve?
In our quantum dictionary, we need to introduce the mathematical analog of an
observable:
Postulate 4.2.1 To each physical observable there corresponds a hermitian operator.
Let us see what this postulate actually entails. First of all, an observable is a linear
operator, which means that it maps states to states. If we apply the observable /Omega1to
the state vector |ψ/angbracketright, the resulting state is now /Omega1|ψ/angbracketright.
Example 4.2.1 Let|ψ/angbracketright=[−1,−1−i]
Tbe the start state in the two-dimensional
spin state space. Now, let
/Omega1=⎡
⎢⎣−1−i
i 1⎤
⎥⎦. (4.41)
This matrix acts as an operator on C2. Therefore, we can apply it to |ψ/angbracketright. The result is
the vector /Omega1|ψ/angbracketright=[ i,−1−2i]T. Observe that |ψ/angbracketrightand/Omega1|ψ/angbracketrightarenotscalar multiples
of one another, and thus they do not represent the same state: /Omega1has modiﬁed the
state of the system. /square
Secondly, as we already know from Chapter 2, the eigenvalues of a hermitian
operator are all real. The physical meaning of this fact is established by the follow-
ing:

<<<PAGE 134>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
116 Basic Quantum Theory
Postulate 4.2.2 The eigenvalues of a hermitian operator /Omega1associated with a physical
observable are the only possible values observable can take as a result of measuring
it on any given state. Furthermore, the eigenvectors of /Omega1form a basis for the state
space.
As we have said before, observables can be thought of as legitimate questions we
can pose to quantum systems. Each question admits a set of answers: the eigenvalues
of the observable. We learn in the next section how to compute the likelihood that
one speciﬁc answer will come up out of the entire set.
Before delving into the subtler properties of observables, let us mention some
real-life ones. In the case of the ﬁrst quantum system of Section 4.1, namely, theparticle on the line, the most obvious observable is position . As we have stated
already, each observable represents a speciﬁc question we pose to the quantum
system. Position asks: “Where can the particle be found?” Which hermitian op-
erator corresponds to position? We are going to tell ﬁrst how it acts on the basicstates:
P(|ψ/angbracketright)=P(|x
i/angbracketright)=xi|xi/angbracketright. (4.42)
In plain words, Pacts as multiplication by position.
As the basic states form a basis, we can extend Equation 4.42 to arbitrary states:
P/parenleftBig/summationdisplay
ci|xi/angbracketright/parenrightBig
=/summationdisplay
xici|xi/angbracketright. (4.43)
Here is the matrix representation of the operator in the standard basis:
P=⎡
⎢⎢⎢⎢⎢⎢⎢⎣x
00··· 0
0x100
............
00 ··· xn−1⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (4.44)
Pis simply the diagonal matrix whose entries are the x
icoordinates. Observe that
Pis trivially hermitian, its eigenvalues are the xivalues, and its normalized eigen-
vectors are precisely the basic state vectors that we met at the beginning of Section
4.1:|x0/angbracketright,|x1/angbracketright,...,|xn−1/angbracketright.
Exercise 4.2.1 Verify the last statement. [Hint: Do it by brute force (start with
a generic vector, multiply it by the position operator, and assume that the resultvector is a scalar multiple of the original one. Conclude that it must be one of the
basis vectors).] /squaresolid
There is a second natural question one may ask of our particle: What is your
velocity? Actually, physicists ask a slightly different question: “What is your mo-
mentum?” where momentum is deﬁned classically as velocity times mass . There is a
quantum analog of this question, which is represented in our discrete model by the

<<<PAGE 135>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
4.2 Observables 117
following operator (recall that δxis the increment of distance on the line):
M(|ψ/angbracketright)=−i∗/planckover2pi∗|ψ(x+δx)/angbracketright−|ψ(x)/angbracketright
δx. (4.45)
In words, momentum is, up to the constant −i∗/planckover2pi, the rate of change of the state
vector from one point to the next.10
The constant /planckover2pi(pronounced h bar) that we have just met is a universal constant
in quantum mechanics, known as the reduced Planck constant . Although it plays a
fundamental role in modern physics (it is one of the universal constants of nature),
for the purpose of the present discussion it can be safely ignored.
As it turns out, position and momentum are the most elementary questions we
can ask of the particle: there are of course many more, such as energy, angular mo-mentum, etc., but these two are in a sense the basic building blocks (most observ-
ables can be expressed in terms of position and momentum). We shall meet againposition and momentum at the end of the next section.
Our second example of observables comes from the spin system. The typical
question we might pose to such a system is: given a speciﬁc direction in space, inwhich way is the particle spinning? We can, for instance, ask: is the particle spinningup or down in the zdirection? Left or right in the xdirection? In or out in the y
direction? The three spin operators corresponding to these questions are
S
z=/planckover2pi
2⎡
⎢⎣10
0−1⎤
⎥⎦, Sy=/planckover2pi
2⎡
⎢⎣0−i
i0⎤
⎥⎦, Sx=/planckover2pi
2⎡
⎢⎣01
10⎤
⎥⎦. (4.46)
Each of the three spin operators comes equipped with its orthonormal basis. We
have already met up and down, the eigenbasis of Sz.Sxhas eigenbasis {| ←/angbracketright,|→ /angbracketright } ,
or left and right, and Syhas{| /arrowsouthwest/angbracketright,|/arrownortheast /angbracketright } , or in and out.
Exercise 4.2.2 Consider a particle in initial spin up. Apply Sxto it and determine
the probability that the resulting state is still spin up. /squaresolid
.................................................................................
Reader Tip. The remainder of this section, although quite relevant for general
quantum theory, is tangential to quantum computation, and can thus be safely
skipped in a ﬁrst reading (just take a look at the summary at the end of this sec-tion and proceed to Section 4.3). ♥.................................................................................
We are going to make some calculations with the operators described before in
a little while; ﬁrst, though, we need a few additional facts on observables and their
associated hermitian matrices.
Up to this point, the collection of physical observables on a given quantum sys-
tem is just a set. However, even an informal acquaintance with elementary physics
10The calculus-enabled reader would have easily recognized a one-step discrete version of the derivative
in the momentum. Indeed, if δxgoes to zero, momentum is precisely the derivative with respect to
position of ψ/angbracketrighttimes the scalar −i∗/planckover2pi.

<<<PAGE 136>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
118 Basic Quantum Theory
teaches us that observable quantities can be added, multiplied, or multiplied by a
scalar number to form other meaningful physical quantities, i.e., other examples
of observables abound: think of momentum as mass times velocity, work as force
times displacement, total energy of a particle in motion as the sum of its kineticand potential energies, etc. We are thus naturally concerned with the following is-sue: to what extent can we manipulate quantum observables to obtain yet other
observables?
Let us start our investigation from the ﬁrst step, namely, multiplying an observ-
able by a number (i.e., a scalar). There is no problem with carrying out this op-eration: indeed, if we scalar multiply a hermitian matrix by a real scalar (i.e., we
multiply all its entries), the result is still hermitian.
Exercise 4.2.3 Verify the last statement. /squaresolid
Exercise 4.2.4 What about complex scalars? Try to ﬁnd a hermitian matrix and a
complex number such that their product fails to be hermitian. /squaresolid
Let us make the next move. What about the addition of two hermitian matrices?
Suppose we are looking at two physical observables, represented respectively by
the hermitians /Omega1
1and/Omega12. Again, no problem: their sum /Omega11+/Omega12is the observable
whose representative is the sum of the corresponding hermitian operators, /Omega11+/Omega12,
which happens to be hermitian.
Exercise 4.2.5 Check that the sum of two arbitrary hermitian matrices is hermitian.
/squaresolid
From these two facts it ensues that the set of hermitian matrices of ﬁxed dimen-
sion forms a real (but not a complex) vector space.
How about products? It is quite tempting to conclude that the product of two
physical quantities, represented respectively by the hermitians /Omega11and/Omega12, is an ob-
servable whose representative is the product (i.e., matrix composition) of /Omega11and
/Omega12. There are two substantial difﬁculties here. First, the order in which operators
are applied to state vectors matters. Why? Well, simply because matrix multipli-
cation, unlike multiplication of ordinary numbers or functions, is not, in general, a
commutative operation.
Example 4.2.2 Let
/Omega11=⎡
⎢⎣1−1−i
−1+i 1⎤
⎥⎦ and /Omega12=⎡
⎢⎣0−1
−12⎤
⎥⎦. (4.47)
Their product /Omega12⋆/Omega1 1is equal to
/Omega12⋆/Omega1 1=⎡
⎢⎣1−i−1
−3+2i3+i⎤
⎥⎦, (4.48)

<<<PAGE 137>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
4.2 Observables 119
whereas /Omega11⋆/Omega1 2is equal to
/Omega11⋆/Omega1 2=⎡
⎢⎣1+i−3−2i
−13 −i⎤
⎥⎦. (4.49)
/square
Exercise 4.2.6 Let/Omega11=/bracketleftbigg
1−i
i1/bracketrightbigg
and/Omega12=/bracketleftbigg
20
04/bracketrightbigg
. Verify that both are hermitian.
Do they commute with respect to multiplication? /squaresolid
The second difﬁculty is just as serious: in general, the product of hermitian op-
erators is not guaranteed to be hermitian. Let us now investigate in a more rigorous
way what it takes for the product of two hermitian operators to be hermitian. Notice
that we have
/angbracketleft/Omega11⋆/Omega1 2φ,ψ/angbracketright=/angbracketleft/Omega12φ,/Omega1 1ψ/angbracketright=/angbracketleftφ,/Omega1 2⋆/Omega1 1ψ/angbracketright, (4.50)
where the ﬁrst equality comes from the fact that /Omega11is hermitian and the second
equality comes from the fact that /Omega12is hermitian. For /Omega11⋆/Omega1 2to be hermitian, we
would need that
/angbracketleft/Omega11⋆/Omega1 2φ,ψ/angbracketright=/angbracketleftφ,/Omega1 1⋆/Omega1 2ψ/angbracketright. (4.51)
This in turn implies
/Omega11⋆/Omega1 2=/Omega12⋆/Omega1 1, (4.52)
or equivalently, the operator
[/Omega11,/Omega12]=/Omega11⋆/Omega1 2−/Omega12⋆/Omega1 1 (4.53)
must be the zero operator (i.e., the operator that sends every vector to the zero
vector).
The operator [ /Omega11,/Omega12] is so important that it deserves its own name; it is called
thecommutator of/Omega11and/Omega12. We have just learned that if the commutator is zero
then the product (in whichever order) is hermitian. We are going to meet the com-mutator again in a little while. Meanwhile, let us familiarize ourselves with the com-
mutator through a simple and very important example.
Example 4.2.3 Let us calculate the commutators of the three spin matrices (we
shall deliberately ignore the constant factor/planckover2pi
2):
[Sx,Sy]=⎡
⎢⎣01
10⎤
⎥⎦⎡
⎢⎣0−i
i0⎤
⎥⎦−⎡
⎢⎣0−i
i0⎤
⎥⎦⎡
⎢⎣01
10⎤
⎥⎦=2i⎡
⎢⎣10
0−1⎤
⎥⎦, (4.54)
[Sy,Sz]=⎡
⎢⎣0−i
i0⎤
⎥⎦⎡
⎢⎣10
0−1⎤
⎥⎦−⎡
⎢⎣10
0−1⎤
⎥⎦⎡
⎢⎣0−i
i0⎤
⎥⎦=2i⎡
⎢⎣01
10⎤
⎥⎦,(4.55)

<<<PAGE 138>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
120 Basic Quantum Theory
[Sz,Sx]=⎡
⎢⎣10
0−1⎤
⎥⎦⎡
⎢⎣01
10⎤
⎥⎦−⎡
⎢⎣01
10⎤
⎥⎦⎡
⎢⎣10
0−1⎤
⎥⎦=2i⎡
⎢⎣0−i
i0⎤
⎥⎦. (4.56)
A bit more concisely,
[Sx,Sy]=2iSz,[Sy,Sz]=2iSx,[Sz,Sx]=2iSy. (4.57)
As we have just seen, none of the commutators are zero. The spin operators do not
commute with each other. /square
Now it is your turn.
Exercise 4.2.7 Explicitly calculate the commutator of the operators of Exam-
ple 4.2.2. /squaresolid
Note: A moment’s thought shows that the product of a hermitian operator with itself
always commutes and so does the exponent operation. Therefore, given a single
hermitian /Omega1, we automatically get the entire algebra of polynomials over /Omega1, i.e., all
operators of the form
/Omega1/prime=α0+α1/Omega1+α2/Omega12+···+ αn−1/Omega1n−1. (4.58)
All such operators commute with one another.
Exercise 4.2.8 Show that the commutator of two hermitian matrices is a hermitian
matrix. /squaresolid
If the commutator of two hermitian operators is zero, or equivalently, the two
operators commute, there is no difﬁculty in assigning their product (in whatever
order) as the mathematical equivalent of the physical product of their associated
observables. But what about the other cases, when the two operators do notcom-
mute? The Heisenberg’s uncertainty principle, which we are going to meet at the
end of this section, will provide an answer.
There is yet another aspect of the association between observables and hermitian
operators that can provide substantial physical insight: we know from Chapter 2 thathermitian operators are precisely those operators that behave well with respect tothe inner product, i.e.,
/angbracketleft/Omega1φ,ψ/angbracketright=/angbracketleftφ,/Omega1ψ/angbracketright (4.59)
for each pair |ψ/angbracketright,|φ/angbracketright.
From this fact, it immediately derives that /angbracketleft/Omega1ψ,ψ/angbracketrightis a real number for each
|ψ/angbracketright, which we shall denote as /angbracketleft/Omega1/angbracketright
ψ(the subscript points to the fact that this quantity
depends on the state vector). We can attach a physical meaning to the number /angbracketleft/Omega1/angbracketrightψ.
Postulate 4.2.3 /angbracketleft/Omega1/angbracketrightψis the expected value of observing /Omega1repeatedly on the same
stateψ.

<<<PAGE 139>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
4.2 Observables 121
This postulate states the following: suppose that
λ0,λ1,...,λ n−1 (4.60)
is the list of eigenvalues of /Omega1. Let us prepare our quantum system so that it is in
state|ψ/angbracketrightand let us observe the value of /Omega1. We are going to obtain one or another
of the aforementioned eigenvalues. Now, let us start all over again many times, say,
ntimes, and let us keep track of what was observed each time. At the end of our
experiment, the eigenvalue λihas been seen pitimes, where 0 ≤pi≤n(in statistical
jargon, its frequency is pi/n). Now perform the calculation
λ0×p0
n+λ1×p1
n+···+ λn−1×pn−1
n. (4.61)
Ifnis sufﬁciently large, this number (known in statistics as the estimated expected
value of /Omega1) will be very close to /angbracketleft/Omega1ψ,ψ/angbracketright.
Example 4.2.4 Let us calculate the expected value of the position operator on an
arbitrary normalized state vector: let
|ψ/angbracketright=c0|x0/angbracketright+c1|x1/angbracketright+···+ cn−1|xn−1/angbracketright (4.62)
be our state vector and
/angbracketleftPψ,ψ/angbracketright=| c0|2×x0+|c1|2×x1+···+| cn−1|2×xn−1, (4.63)
where
|c0|2+|c1|2+···+| cn−1|2=1. (4.64)
In particular, if |ψ/angbracketrighthappens to be just |xi/angbracketright, we simply get xi(verify it!). In other
words, the expected value of position on any of its eigenvectors |xi/angbracketrightis the corre-
sponding position xion the line. /square
Example 4.2.5 Let|ψ/angbracketright=/bracketleftBig√
2
2,√
2
2i/bracketrightBigT
and/Omega1=/bracketleftbigg
1−i
i2/bracketrightbigg
.
Let us calculate /Omega1(|ψ/angbracketright):
/Omega1(|ψ/angbracketright)=⎡
⎢⎣1−i
i2⎤
⎥⎦⎡
⎢⎣√
2
2
√
2
2i⎤
⎥⎦=⎡
⎢⎣√
2
3
2√
2i⎤
⎥⎦. (4.65)
The bra associated with /Omega1|ψ/angbracketrightis/bracketleftBig√
2,−3
2√
2i/bracketrightBig
. The scalar product /angbracketleft/Omega1ψ|ψ/angbracketright, i.e.,
the average value of /Omega1on|ψ/angbracketright, is thus equal to
/bracketleftBig√
2,−3
2√
2i/bracketrightBig/bracketleftBig√
2
2,√
2
2i/bracketrightBigT
=2.5. (4.66)
/square
Exercise 4.2.9 Repeat the steps of the previous example where
|ψ/angbracketright=/vextendsingle/vextendsingle/vextendsingle√
2
2,−√
2
2/angbracketrightBig
(4.67)

<<<PAGE 140>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
122 Basic Quantum Theory
and
/Omega1=⎡
⎢⎣31+2i
1−2i−1⎤
⎥⎦. (4.68)
/squaresolid
We now know that the result of observing /Omega1repeatedly on a given state will be
a certain frequency distribution on the set of its eigenvalues. In plain words, sooner
or later we will encounter all its eigenvalues, some more frequently and some less.In the next section we compute the probability that a given eigenvalue of /Omega1will
actually be observed on a given state. For now, we may be interested in know-ing the spread of the distribution around its expected value, i.e., the variance of
the distribution. A small variance will tell us that most of the eigenvalues are veryclose to the mean, whereas a large variance means just the opposite. We can deﬁne
the variance in our framework in a few stages. First, we introduce the hermitian
operator
/Delta1
ψ(/Omega1)=/Omega1−/angbracketleft/Omega1/angbracketrightψI (4.69)
(Iis the identity operator). The operator /Delta1ψ(/Omega1) acts on a generic vector |φ/angbracketrightin the
following fashion:
/Delta1ψ(/Omega1)|φ/angbracketright=/Omega1(|φ/angbracketright)−(/angbracketleft/Omega1/angbracketright ψ)|φ/angbracketright. (4.70)
So/Delta1ψ(/Omega1) just subtracts the mean from the result of /Omega1. What then is the mean of
/Delta1ψ(/Omega1) itself on the normalized state |ψ/angbracketright? A simple calculation shows that it is pre-
cisely zero: /Delta1ψ(/Omega1)i st h edemeaned version of /Omega1.
Exercise 4.2.10 Verify the last statement. /squaresolid
We can now deﬁne the variance of /Omega1at|ψ/angbracketrightas the expectation value of /Delta1ψ(/Omega1)
squared (i.e., the operator /Delta1ψ(/Omega1) composed with itself):
Varψ(/Omega1)=/angbracketleft(/Delta1ψ(/Omega1))⋆(/Delta1ψ(/Omega1))/angbracketright ψ. (4.71)
Admittedly, the deﬁnition looks at ﬁrst sight rather obscure, although it is not sobad if we remember the usual deﬁnition of the variance of a random variable Xas
Var(X)=E((X−µ)
2)=E((X−µ)(X−µ)), (4.72)
where Eis the expected value function. The best course is to turn to a simple exam-
ple to get a concrete feel for it.

<<<PAGE 141>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
4.2 Observables 123
Example 4.2.6 Let/Omega1be a 2-by-2 diagonal matrix with real entries:
/Omega1=⎡
⎢⎣λ10
0λ2⎤
⎥⎦,
and let
/angbracketleft|ψ/angbracketright=⎡
⎢⎣c1
c2⎤
⎥⎦. (4.73)
Let us denote by µ(pronounced “mu”) the mean of /Omega1on|ψ/angbracketright.
/Delta1ψ(/Omega1)=/Omega1−/angbracketleft/Omega1/angbracketrightψ=⎡
⎢⎣λ10
0λ2⎤
⎥⎦−⎡
⎢⎣µ0
0µ⎤
⎥⎦=⎡
⎢⎣λ1−µ 0
0 λ2−µ⎤
⎥⎦.
(4.74)
Now we calculate /Delta1ψ(/Omega1)⋆/Delta1ψ(/Omega1):
/Delta1ψ(/Omega1)⋆/Delta1ψ(/Omega1)=⎡
⎢⎣λ1−µ 0
0 λ2−µ⎤
⎥⎦⎡
⎢⎣λ1−µ 0
0 λ2−µ⎤
⎥⎦
=⎡
⎢⎣(λ1−µ)20
0( λ2−µ)2⎤
⎥⎦. (4.75)
Finally, we can compute the variance:
/angbracketleft(/Delta1ψ(/Omega1))(/Delta1 ψ(/Omega1))/angbracketright ψ=/bracketleftbigg
c1c2/bracketrightbigg⎡
⎢⎣(λ1−µ)20
0( λ2−µ)2⎤
⎥⎦⎡
⎢⎣c1
c2⎤
⎥⎦
=|c1|2×(λ1−µ)2+|c2|2×(λ2−µ)2. (4.76)
We are now able to see that if both λ1andλ2are very close to µ, the term in the
equation will be close to zero. Conversely, if either of the two eigenvalues is far from
µ(it is immaterial whether above or below it, because we are taking squares), the
variance will be a big real number. Conclusion: the variance does indeed inform us
about the spread of the eigenvalues around their mean. /square
Our reader may still be a bit unsatisﬁed after this example: after all, what it
shows is that the deﬁnition of variance given above works as it should in the case ofdiagonal matrices. Actually, it is a known fact that all hermitian matrices can be di-agonalized by switching to a basis of eigenvectors, so the example is comprehensive
enough to legitimize our deﬁnition.

<<<PAGE 142>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
124 Basic Quantum Theory
Example 4.2.7 Let us calculate the variance of the operator described in Exam-
ple 4.2.5:
/Delta1ψ(/Omega1)=/Omega1−/angbracketleft/Omega1/angbracketrightψ=⎡
⎢⎣1−i
i2⎤
⎥⎦−⎡
⎢⎣2.50
02.5⎤
⎥⎦=⎡
⎢⎣−1.5 −i
i−0.5⎤
⎥⎦.(4.77)
We now compute /Delta1ψ(/Omega1)⋆/Delta1ψ(/Omega1):
/Delta1ψ(/Omega1)⋆/Delta1ψ(/Omega1)=⎡
⎢⎣−1.5 −i
i−0.5⎤
⎥⎦⎡
⎢⎣−1.5 −i
i−0.5⎤
⎥⎦=⎡
⎢⎣3.25 2 i
−2i1.25⎤
⎥⎦.
(4.78)
Hence the variance is
/angbracketleft(/Delta1ψ(/Omega1))(/Delta1 ψ(/Omega1))/angbracketright ψ=/bracketleftbigg√
2
2√
2
2i/bracketrightbigg⎡
⎢⎣3.25 2 i
−2i1.25⎤
⎥⎦⎡
⎢⎣√
2
2
√
2
2⎤
⎥⎦=0.25.
(4.79)
/square
Exercise 4.2.11 Calculate the variance of the position operator. Show that the vari-
ance of position on any of its eigenvectors is zero. /squaresolid
Exercise 4.2.12 Calculate the variance of Szon a generic spin state. Show that the
variance of Szreaches a maximum on the state√
2
2(|↓ /angbracketright+|↑ /angbracketright ). /squaresolid
Note: The variance of the same hermitian varies from state to state: In particular, on
an eigenvector of the operator the variance is zero, and the expected value is just the
corresponding eigenvalue: we can say that an observable is sharp on its eigenvectors
(no ambiguity on the outcome).
Exercise 4.2.13 Prove the preceding statement. (Hint: Work out some examples
ﬁrst.) /squaresolid
We have built all the machinery needed to introduce a fundamental theorem of
quantum mechanics, known as Heisenberg’s uncertainty principle. Let us begin with
two observables, represented by the two hermitians /Omega11and/Omega12, and a given state,
say,|ψ/angbracketright. We can compute the variance of /Omega11and/Omega12on|ψ/angbracketright, obtaining Varψ(/Omega11) and
Varψ(/Omega12). Do these two quantities relate in any way, and if so, how?
Let us see what the question actually means. We have two observables, and our
hope would be to simultaneously minimize their variances, thereby getting a sharpoutcome for both. If there were no correlation in the variances, we could expect avery sharp measure of both observables on some convenient state (such as a com-mon eigenvector, if any such existed). Alas, this is not the case, as shown by the
following.

<<<PAGE 143>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
4.2 Observables 125
Theorem 4.2.1 (Heisenberg’s Uncertainty Principle). The product of the variances
of two arbitrary hermitian operators on a given state is always greater than or equal
to one-fourth the square of the expected value of their commutator. In formulas:
Varψ(/Omega11)×Varψ(/Omega12)≥1
4|/angbracketleft[/Omega11,/Omega12]/angbracketrightψ|2. (4.80)
As promised, we have found our commutator once again. Heisenberg’s principle
tells us that the commutator measures how good a simultaneous measure of two
observables can possibly be . In particular, if the commutator happens to be zero (or
equivalently, if the observables commute), there is no limit (at least in principle) toour accuracy. In quantum mechanics, however, there are plenty of operators that do
not commute: in fact, we have seen that the directional spin operators provide one
such example.
Exercise 4.2.14 Use the calculation of the commutator in Example 4.2.3 and
Heisenberg’s principle to give an estimate of how accurate a simultaneous obser-
vation of spin in the zand xdirections can be. /squaresolid
Another typical example, related to our ﬁrst quantum system, is given by the
pair position–momentum, which we have also met in the last section. So far |ψ/angbracketrightfor
the particle on the line has been described in terms of its position eigenbasis, i.e., thecollection {|x
i/angbracketright}.|ψ/angbracketrightcan be written in many other orthonormal bases, corresponding
to different observables. One of those is the momentum eigenbasis. This basis comes
up when we think of |ψ/angbracketrightas a wave (a bit like a wave hovering over the line). We
can thus decompose it into its basic frequencies, just as we can resolve a sound into
its basic pure tones. These pure tones are precisely the elements of the momentum
eigenbasis.
The image of |ψ/angbracketrightin the position basis is as different as it can possibly be from
the one associated with the momentum eigenbasis. The position eigenbasis is madeof “peaks,” i.e., vectors that are zero everywhere except at a point ( Dirac’s deltas ,
in math jargon). Therefore, |ψ/angbracketrightis decomposed into a weighted sum of peaks. The
momentum eigenbasis, on the other hand, is made of sinusoids, whose position is
totally undetermined.
The commutator of the position–momentum pair captures well this inherent dis-
similarity: it is not zero, and therefore our hope to keep the comforting traditionalpicture of a particle as a tiny billiard ball moving around in space is dashed. If we
can pin down the particle position at a given point in time (i.e., if the variance of
its position operator is very small), we are at a loss as to its momentum (i.e., thevariance of its momentum operator is very big), and vice versa.
Let us sum up:/D2Observables are represented by hermitian operators. The result of an observa-
tion is always an eigenvalue of the hermitian./D2The expression /angbracketleftψ|/Omega1|ψ/angbracketrightrepresents the expected value of observing /Omega1on|ψ/angbracketright./D2Observables in general do not commute. This means that the order of observa-
tion matters. Moreover, if the commutator of two observables is not zero, there
is an intrinsic limit to our capability of measuring their values simultaneously.

<<<PAGE 144>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
126 Basic Quantum Theory
Programming Drill 4.2.1 Continue your simulation of a quantum system by adding
observables to the picture: the user will input a square matrix of the appropriate size,
and a ket vector. The program will verify that the matrix is hermitian, and if so, it will
calculate the mean value and the variance of the observable on the given state.
4.3 MEASURING
The act of carrying out an observation on a given physical system is called measur-
ing. Just as a single observable represents a speciﬁc question posed to the system,
measuring is the process consisting of asking a speciﬁc question and receiving a deﬁ-
nite answer.
In classical physics, we implicitly assumed that/D2the act of measuring would leave the system in whatever state it already was, atleast in principle; and/D2the result of a measurement on a well-deﬁned state is predictable, i.e., if we knowthe state with absolute certainty, we can anticipate the value of the observable
on that state.
Both these assumptions proved wrong, as research in the subatomic scale has
repeatedly shown: systems doget perturbed and modiﬁed as a result of measuring
them. Furthermore, only the probability of observing speciﬁc values can be calcu-lated: measurement is inherently a nondeterministic process.
Let us brieﬂy recapitulate what we know: an observable can only assume one of
its eigenvalues as the result of an observation. So far though, nothing tells us how
frequently we are going to see a speciﬁc eigenvalue, say, λ. Moreover, our frame-
work does not tell us yet what happens to the state vector if λis actually observed.
We need an additional postulate to handle concrete measures:
Postulate 4.3.1 Let/Omega1be an observable and |ψ/angbracketrightbe a state. If the result of measur-
ing/Omega1is the eigenvalue λ, the state after measurement will always be an eigenvector
corresponding to λ.
Example 4.3.1 Let us go back to Example 4.2.1: It is easy to check that the eigen-
values of /Omega1areλ
1=−√
2 and λ2=√
2 and the corresponding normalized eigenvec-
tors are |e1/angbracketright=[−0.923 i,−0.382]Tand|e2/angbracketright=[−0.382 i,0.923]T.
Now, let us suppose that after an observation of /Omega1on|ψ/angbracketright=1
2[1,1]T, the actual
value observed is λ1. The system has “collapsed” from |ψ/angbracketrightto|e1/angbracketright. /square
Exercise 4.3.1 Find all the possible states the system described in Exercise 4.2.2
can transition into after a measurement has been carried out. /squaresolid
What is the probability that a normalized start state |ψ/angbracketrightwill transition to a spe-
ciﬁc eigenvector, say, |e/angbracketright? We must go back to what we said in Section 4.1: the prob-
ability of the transition to the eigenvector is given by the square of the inner product
of the two states: |/angbracketlefte|ψ/angbracketright|2. This expression has a simple meaning: it is the projection
of|ψ/angbracketrightalong|e/angbracketright.

<<<PAGE 145>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
4.3 Measuring 127
We are ready for a new insight into the real meaning of /angbracketleft/Omega1/angbracketrightψof the last section:
ﬁrst, let us recall that the normalized eigenvectors of /Omega1constitute an orthogonal
basis of the state space. Therefore, we can express |ψ/angbracketrightas a linear combination in
this basis:
|ψ/angbracketright=c0|e0/angbracketright+c1|e1/angbracketright+···+ cn−1|en−1/angbracketright. (4.81)
Now, let us compute the mean:
/angbracketleft/Omega1/angbracketrightψ=/angbracketleft/Omega1ψ,ψ/angbracketright=| c0|2λ0+|c1|2λ1+···+| cn−1|2λn−1. (4.82)
(Verify this identity!)
As we can now see, /angbracketleft/Omega1/angbracketrightvis precisely the mean value of the probability distri-
bution
(λ0,p0),(λ1,p1),..., (λn−1,pn−1), (4.83)
where each piis the square of the amplitude of the collapse into the corresponding
eigenvector.
Example 4.3.2 Let us go back to Example 4.3.1 and calculate the probabilities that
our state vector will fall into one of the two eigenvectors:
p1=| /angbracketleftψ|e1/angbracketright|2=0.5 and p2=| /angbracketleftψ|e2/angbracketright|2=0.5. (4.84)
Now, let us compute the mean value of the distribution:
p1×λ1+p2×λ2=0.00, (4.85)
which is precisely the value we obtained by directly calculating /angbracketleftψ|/Omega1|ψ/angbracketright.
/square
Exercise 4.3.2 Perform the same calculations as in the last example, using Exer-
cise 4.3.1. Then draw the probability distribution of the eigenvalues as in the previ-
ous example. /squaresolid
Note: As a result of the foregoing discussion, an important fact emerges. Suppose
we ask a speciﬁc question (i.e., we choose an observable) and perform a measure-ment once. We get an answer, say, λ, and the system transitions to the corresponding
eigenvector. Now, let us ask the same question immediately thereafter. What is go-ing to happen? The system will give exactly the same answer, and stay where it is. All
right, you may say. But, what about changing the question? The following examplewill clarify matters.
Example 4.3.3 Until now we have dealt with measurements relative to only one
observable. What if there were more than one observable involved? With each ob-
servable there is a different set of eigenvectors the system can possibly collapse toafter a measurement has taken place. As it turns out, the answers we get will depend
on which order we pose our questions , i.e., which observable we measure ﬁrst.
There is an intriguing experiment that one can easily perform in order to see
some of these ideas in action (and have some fun in the process). Suppose you shoota beam of light. Light is also a wave, and like all waves it vibrates during its journey
(think of sea waves). There are two possibilities: either it vibrates along all possible

<<<PAGE 146>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
128 Basic Quantum Theory
Figure 4.5. Light par-
tially passing through
one polarization
sheet.
planes orthogonal to its line of propagation, or it does it only in a speciﬁc one. In
the second case we say that light is polarized.11What kind of questions we can ask
concerning polarization? We can set a speciﬁc plane, and ask: is light vibrating alongthis plane or is orthogonal?
For our experiment we need thin plastic semitransparent polarization sheets
(they are fairly easy to obtain). Polarization sheets do two things: once you orientthem in a speciﬁc direction, they measure the polarization of light in the orthogo-nal basis corresponding to that direction (let us call it the vertical–horizontal basis),and then ﬁlter out those photons that collapsed to one of the elements of the basis
(Figure 4.5).
What if we had two sheets? If the two sheets were oriented in the same direc-
tion, there would be no difference whatsoever (why? because we are asking thesame question; the photon will give once more the same exact answer). However,
if we rotated the second sheet by 90
◦, then no light would pass through both sheets
(Figure 4.6).
Placing the sheets orthogonal to each other ensures that the permitted half that
passes through the left sheet is ﬁltered out by the right sheet.
What happens if we add a third sheet? Placing a third sheet to the left or to
the right of the other two sheets does not have any effect whatsoever. No light was
permitted before and none will be allowed through the additional sheet. However,
placing the third sheet in-between the other two at an angle, say, 45◦, does have a
remarkable effect (Figure 4.7).
Light will pass through all the three sheets! How can this be? Let us see what is
going on here. The left sheet measures all the light relative to the up–down basis.The polarized light in the vertical polarization state that goes through is then con-
sidered to be a superposition with respect to the diagonal middle sheet measuring
basis. The middle sheet recollapses the permitted half, ﬁlters some, and passes somethrough. But what is passed through is now in a diagonal polarization state. Whenthis light passes through the right sheet, it is again in a superposition of the vertical–
horizontal basis, and so it must collapse once more. Notice that only one-eighth of
the original light passes through all three sheets. /square
11Polarization is a familiar phenomenon: fancy sun glasses are made on the basis of light polarization.

<<<PAGE 147>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
4.4 Dynamics 129
Figure 4.6. No light passing
through two polarization sheets
at orthogonal angels.
A brief summary is in order:/D2The end state of the measurement of an observable is always one of its eigen-
vectors./D2The probability for an initial state to collapse into an eigenvector of the observ-
able is given by the length squared of the projection./D2When we measure several observables, the order of measurements matters.
We have come a long way. We now have three main ingredients to cook up quantum
dishes. We need one more, dynamics.
Programming Drill 4.3.1 Next step in the simulation: when the user enters an observ-
able and a state vector, the program will return the list of eigenvalues of the observable,
the mean value of the observable on the state, and the probability that the state will
transition to each one of the eigenstates. Optional: plot the corresponding probability
distribution.
4.4 DYNAMICS
Thus far, we have been concerned with static quantum systems, i.e., systems that do
not evolve over time. To be sure, changes could still occur as a result of one or pos-
sibly many measurements, but the system itself was not time-dependent. In reality,of course, quantum systems do evolve over time, and we thus need to add a newhue to the canvas namely quantum dynamics . Just as hermitian operators represent
physical observables, unitary operators introduce dynamics in the quantum arena.
Figure 4.7. Light partially passing through
three polarization sheets.

<<<PAGE 148>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
130 Basic Quantum Theory
Postulate 4.4.1 The evolution of a quantum system (that is not a measurement) is
given by a unitary operator or transformation.
That is, if Uis a unitary matrix that represents a unitary operator and |ψ(t)/angbracketright
represents a state of the system at time t, then
|ψ(t+1)/angbracketright=U|ψ(t)/angbracketright (4.86)
will represent the system at time t+1.
An important feature of unitary transformations is that they are closed under
composition and inverse, i.e., the product of two arbitrary unitary matrices is uni-
tary, and the inverse of a unitary transformation is also unitary. Finally, there is a
multiplicative identity, namely, the identity operator itself (which is trivially uni-tary). In math jargon, one says that the set of unitary transformations constitutes agroup of transformations with respect to composition.
Exercise 4.4.1 Verify that
U
1=⎡
⎢⎣01
10⎤
⎥⎦ and U2=⎡
⎢⎣√
2
2√
2
2
√
2
2−√
2
2⎤
⎥⎦ (4.87)
are unitary matrices. Multiply them and verify that their product is also unitary. /squaresolid
We are now going to see how dynamics is determined by unitary transforma-
tions: assume we have a rule, U, that associates with each instant of time
t0,t1,t2,..., tn−1 (4.88)
a unitary matrix
U[t0],U[t1],..., U[tn−1]. (4.89)
Let us start with an initial state vector |ψ/angbracketright. We can apply U[t0]t o|ψ/angbracketright, then apply
U[t1] to the result, and so forth. We will obtain a sequence of state vectors
U[t0]|ψ/angbracketright, (4.90)
U[t1]U[t 0]|ψ/angbracketright, (4.91)
... (4.92)
U[tn−1]U[t n−2]···U[t0]|ψ/angbracketright. (4.93)

<<<PAGE 149>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
4.4 Dynamics 131
Such a sequence is called the orbit12of|ψ/angbracketrightunder the action of U[ti] at the time clicks
t0,t1,..., tn−1.
|ψ/angbracketrightU[t0]/d47/d47
U[t0]|ψ/angbracketrightU[t1]/d47/d47
U[t0]†/d111/d111U[t1]U[t 0]|ψ/angbracketrightU[t2]/d47/d47
U[t1]†/d111/d111U[t2]U[t 1]U[t 0]|ψ/angbracketright
U[t2]†/d111/d111
/d47/d47
···/d47/d47
/d111/d111U[tn−1]U[t n−2]···U[t0]|ψ/angbracketright./d111/d111(4.94)
Observe that one can always go back, just like running a movie backward, simply
by applying the inverses of U[t0],U[t1],..., U[tn−1] in reverse order: evolution of a
quantum system is symmetric with respect to time.
We can now preview how a quantum computation will look. A quantum com-
puter shall be placed into an initial state |ψ/angbracketright, and we shall then apply a sequence of
unitary operators to the state. When we are done, we will measure the output and
get a ﬁnal state. The next chapters are largely devoted to working out these ideas indetail.
Here is an exercise for you on dynamics:
Exercise 4.4.2 Go back to Example 3 .3.2 (quantum billiard ball), keep the same
initial state vector [1 ,0,0,0]
T, but change the unitary map to
⎡
⎢⎢⎢⎢⎢⎢⎢⎣0
1√
21√
20
i√
2001√
2
1√
200i√
2
01√
2−1√
20⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (4.95)
Determine the state of the system after three time steps. What is the chance of
the quantum ball to be found at point 3? /squaresolid
The reader may wonder how the sequence U[t
i] of unitary transformations is
actually selected in real-life quantum mechanics. In other words, given a concrete
quantum system, how is its dynamics determined? How does the system change?The answer lies in an equation known as the Schr ¨odinger equation:
13
|ψ(t+δt)/angbracketright−|ψ(t)/angbracketright
δt=−i2π
/planckover2piH|ψ(t)/angbracketright. (4.96)
12A small warning: one commonly thinks of an orbit as closed (a typical example is the orbit of the moonaround the earth). In dynamics, this is not always the case: an orbit can be open or closed.
13The version shown here is actually the discretized version of the original equation, which is a differen-tial equation obtained from the above by letting δtbecome inﬁnitesimal. It is this discretized version
(or variants thereof) that is usually employed in computer simulation of quantum systems.

<<<PAGE 150>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
132 Basic Quantum Theory
A complete discussion of this fundamental equation goes beyond the scope of
this introductory chapter. However, without going into technical details, we can at
least convey its spirit. Classical mechanics taught physicists that the global energy
of an isolated system is preserved throughout its evolution.14Energy is an observ-
able, and therefore for a concrete quantum system it is possible to write down ahermitian matrix representing it (this expression will of course vary from system to
system). This observable is called the hamiltonian of the system, indicated by Hin
Equation (4.96).
The Schr ¨odinger equation states that the rate of variation of the state vector
|ψ(t)/angbracketrightwith respect to time at the instant tis equal (up to the scalar factor
2π
h)t o
|ψ(t)/angbracketrightmultiplied by the operator −i∗H. By solving the equation with some initial
conditions one is able to determine the evolution of the system over time.
Time for a small recap:/D2Quantum dynamics is given by unitary transformations./D2Unitary transformations are invertible; thus, all closed system dynamics are re-
versible in time (as long as no measurement is involved)./D2The concrete dynamics is given by the Schr ¨odinger equation, which determines
the evolution of a quantum system whenever its hamiltonian is speciﬁed.
Programming Drill 4.4.1 Add dynamics to your computer simulation of the particle
on a grid: the user should input a number of time steps n, and a corresponding se-quence of unitary matrices U
nof the appropriate size. The program will then compute
the state vector after the entire sequence U nhas been applied.
4.5 ASSEMBLING QUANTUM SYSTEMS
The opening section of this chapter described a simple quantum system: a parti-cle moving in a conﬁned one-dimensional grid (the set of points {x
0,x1,..., xn−1}).
Now, let us suppose that we are dealing with two particles conﬁned to the grid. Weshall make the following assumption: the points on the grid that can be occupied bythe ﬁrst particle will be {x
0,x1,..., xn−1}. The second particle can be at the points
{y0,y1,..., ym−1}.
x0 x1 ... xn−1 y0 y1 ... ym−1
• • ··· •• • ··· •(4.97)
Can we lift the description we already have to this new setup? Yes. The details willkeep us busy in this section.
Our answer will not be conﬁned to the aforementioned system. Instead, it will
provide us with a quantum version of a building block game, i.e., a way of assem-bling more complex quantum systems starting from simpler ones. This procedure
14For instance, a stone dropped from a height falls down in such a way that its kinetic energy plus itspotential energy plus energy dissipated from attrition is constant.

<<<PAGE 151>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
4.5 Assembling Quantum Systems 133
lies at the very core of modern quantum physics: it enables physicists to model
multiparticle quantum systems.15
We need one last expansion of our quantum dictionary: assembling quantum
systems means tensoring the state space of their constituents .
Postulate 4.5.1 Assume we have two independent quantum systems Q and Q/prime, rep-
resented respectively by the vector spaces VandV/prime. The quantum system obtained by
merging Q and Q/primewill have the tensor product V⊗V/primeas a state space.
Notice that the postulate above enables us to assemble as many systems as we like.The tensor product of vector spaces is associative, so we can progressively build
larger and larger systems:
V
0⊗V1⊗···⊗ Vk. (4.98)
Let us go back to our example. To begin with, there are n×mpossible basic
states:
|x0/angbracketright⊗| y0/angbracketright, meaning the ﬁrst particle is at x0and the second particle at y0.
|x0/angbracketright⊗| y1/angbracketright, meaning the ﬁrst particle is at x0and second particle at y1.
...
|x0/angbracketright⊗| ym−1/angbracketright, meaning the ﬁrst particle is at x0and the second particle at ym−1.
|x1/angbracketright⊗| y0/angbracketright, meaning the ﬁrst particle is at x1and the second particle at y0.
...
|xi/angbracketright⊗| yj/angbracketright, meaning the ﬁrst particle is at xiand the second particle at yj.
...
|xn−1/angbracketright⊗| ym−1/angbracketright, meaning the ﬁrst particle is at xn−1and the second particle at
ym−1.
Now, let us write the generic state vector as a superposition of the basic states:
|ψ/angbracketright=c0,0|x0/angbracketright⊗| y0/angbracketright+···+ ci,j|xi/angbracketright⊗| yj/angbracketright+···+ cn−1,m−1|xn−1/angbracketright⊗| ym−1/angbracketright,
(4.99)
which is a vector in the ( n×m)-dimensional complex space Cn×m.
The quantum amplitude |ci,j|squared will give us the probability of ﬁnding the
two particles at positions xiand yj, respectively, as shown by the following example.
Example 4.5.1 Assume n=2 and m=2 in the above. We are thus dealing with
the state space C4whose standard basis is
{|x0/angbracketright⊗| y0/angbracketright,|x0/angbracketright⊗| y1/angbracketright,|x1/angbracketright⊗| y0/angbracketright,|x1/angbracketright⊗| y1/angbracketright}. (4.100)
15By thinking of ﬁelds such as the electromagnetic ﬁeld as systems composed of inﬁnitely many particles,this procedure makes ﬁeld theory amenable to the quantum approach.

<<<PAGE 152>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
134 Basic Quantum Theory
Now, let us consider the state vector for the two-particle system given by
|ψ/angbracketright=i|x0/angbracketright⊗| y0/angbracketright+(1−i)|x0/angbracketright⊗| y1/angbracketright+2|x1/angbracketright⊗| x0/angbracketright+(−1 −i)|x1/angbracketright⊗| x1/angbracketright.
(4.101)
What is the probability of ﬁnding the ﬁrst particle at location x1and the second one
aty1? We look at the last amplitude in the list given before, and use the same recipe
as in the one-particle system:
p(x1,y1)=|−1−i|2
|i|2+|1−i|2+|2|2+|−1−i|2=0.2222. (4.102)
/square
Exercise 4.5.1 Redo the steps of the last example when n=m=4 and c0,0=
c0,1=···= c3,3=1+i. /squaresolid
The same machinery can be applied to any other quantum system. For instance,
it is instructive to generalize our spin example of Section 4.1 to a system where many
particles are involved. You can try yourself.
Exercise 4.5.2 Write down the generic state vector for the system of two particles
with spin. Generalize it to a system with nparticles (this is important: it will be the
physical realization for quantum registers!). /squaresolid
Now that we are a bit familiar with quantum assemblage, we are ready for the ﬁ-
nal puzzling surprise of quantum mechanics: entanglement . Entanglement will force
us to abandon one last comforting faith, namely, that assembled complex systems
can be understood completely in terms of their constituents.
The basic states of the assembled system are just the tensor product of basic
states of its constituents. It would be nice if each generic state vector could be rewrit-
ten as the tensor product of two states, one coming from the ﬁrst quantum subsystem
and the other one from the second. It turns out that this is not true, as is easily shownby this example.
Example 4.5.2 Let us work on the simplest nontrivial two-particle system: each
particle is allowed only two points. Consider the state
|ψ/angbracketright=| x
0/angbracketright⊗| y0/angbracketright+| x1/angbracketright⊗| y1/angbracketright. (4.103)
In order to clarify what is left out, we might write this as
|ψ/angbracketright=1|x0/angbracketright⊗| y0/angbracketright+0| x0/angbracketright⊗| y1/angbracketright+0|x1/angbracketright⊗| y0/angbracketright+1|x1/angbracketright⊗| y1/angbracketright. (4.104)
Let us see if we can write |ψ/angbracketrightas the tensor product of two states coming from the
two subsystems. Any vector representing the ﬁrst particle on the line can be written
as
c0|x0/angbracketright+c 1|x1/angbracketright. (4.105)

<<<PAGE 153>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
4.5 Assembling Quantum Systems 135
Similarly, any vector representing the second particle on the line can be written as
c/prime
0|y0/angbracketright+c/prime
1|y1/angbracketright. (4.106)
Therefore, if |ψ/angbracketrightcame from the tensor product of the two subsystems, we would
have
(c0|x0/angbracketright+c1|x1/angbracketright)⊗(c/prime
0|y0/angbracketright+c/prime
1|y1/angbracketright)=c0c/prime
0|x0/angbracketright⊗| y0/angbracketright+c0c/prime
1|x0/angbracketright⊗| y1/angbracketright
+c1c/prime
0|x1/angbracketright⊗| y0/angbracketright+c1c/prime
1|x1/angbracketright⊗| y1/angbracketright.(4.107)
For our |ψ/angbracketrightin Equation (4.104) this would imply that c0c/prime
0=c1c/prime
1=1 and c0c/prime
1=
c1c/prime
0=0. However, these equations have no solution. We conclude that |ψ/angbracketrightcannot
be rewritten as a tensor product.
Let us go back to |ψ/angbracketrightand see what it physically means. What would happen if
we measured the ﬁrst particle? A quick calculation will show that the ﬁrst particle
has a 50–50 chance of being found at the position x0or at x1. So, what if it is, in fact,
found in position x0? Because the term |x0/angbracketright⊗| y1/angbracketrighthas a 0 coefﬁcient, we know that
there is no chance that the second particle will be found in position y1. We must then
conclude that the second particle can only be found in position y0. Similarly, if the
ﬁrst particle is found in position x1, then the second particle must be in position y1.
Notice that the situation is perfectly symmetrical with respect to the two particles,i.e., it would be the same if we measured the second one ﬁrst. The individual statesof the two particles are intimately related to one another, or entangled. The amazing
side of this story is that the x
i’s can be light years away from the yj’s. Regardless of
their actual distance in space, a measurement’s outcome for one particle will alwaysdetermine the measurement’s outcome for the other one.
The state |ψ/angbracketrightis in sharp contrast to other states like
|ψ
/prime/angbracketright=1| x0/angbracketright⊗| y0/angbracketright+1| x0/angbracketright⊗| y1/angbracketright+1|x1/angbracketright⊗| y0/angbracketright+1|x1/angbracketright⊗| y1/angbracketright. (4.108)
Here, ﬁnding the ﬁrst particle at a particular position does not provide any clue as
to where the second particle will be found (check it!). /square
States that can be broken into the tensor product of states from the constituent
subsystems (like |ψ/prime/angbracketright) are called separable states , whereas states that are unbreak-
able (like |ψ/angbracketright) are referred to as entangled states.
Exercise 4.5.3 Assume the same scenario as in Example 4.5.2 and let
|φ/angbracketright=| x0/angbracketright⊗| y1/angbracketright+| x1/angbracketright⊗| y1/angbracketright. (4.109)
Is this state separable? /squaresolid
A clear physical case of entanglement is in order. We must revert to spin. Just
as there are laws of conservation of momentum, angular momentum, energy-mass,
and other physical properties, so too there is a law of conservation of total spin ofa quantum system. This means that in an isolated system the total amount of spinmust stay the same. Let us ﬁx a speciﬁc direction, say, the vertical one ( zaxis), and
the corresponding spin basis, up and down. Consider the case of a quantum system,

<<<PAGE 154>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
136 Basic Quantum Theory
Figure 4.8. Two possible scenarios of a composite system where
the total spin is zero.
such as a composite particle, whose total spin is zero. This particle might split up at
some point in time into two other particles that do have spin (Figure 4.8).
The spin states of the two particles will now be entangled. The law of conserva-
tion of spin stipulates that because we began with a system of total spin zero, thesum of the spins of the two particles must cancel each other out. This amounts tothe fact that if we measure the spin of the left particle along the zaxis and we ﬁnd it
in state |↑
L/angbracketright(where the subscript is to describe which particle we are dealing with),
then it must be that the spin of the particle on the right will be |↓R/angbracketright. Similarly, if the
state of the left particle is |↓L/angbracketright, then the spin of the right particle must be |↑R/angbracketright.
We can describe this within our notation. In terms of vector spaces, the basis
that describes the left particle is BL={ ↑ L,↓L}and the basis that describes the right
particle is BR={ ↑ R,↓R}. The basis elements of the entire system are
{↑L⊗↑ R,↑L⊗↓ R,↓L⊗↑ R,↓L⊗↓ R}. (4.110)
In such a vector space, our entangled particles can be described by
|↑L⊗↓ R/angbracketright+|↓ L⊗↑ R/angbracketright√
2, (4.111)
similar to Equation (4.104). As we said before, the combinations |↑L⊗↑ R/angbracketrightand
|↓L⊗↓ R/angbracketrightcannot occur because of the law of conservation of spin. When one mea-
sures the left particle and it collapses to the state |↑L/angbracketrightthen instantaneously the right
particle will collapse to the state |↓R/angbracketright,even if the right particle is millions of light-
years away .
How will entanglement arise in the tale that we are telling? We ﬁnd in Chapter 6
that it plays a central role in algorithm design. It is also used extensively in Chapter 9while discussing cryptography (Section 9 .4) and teleportation (Section 9.5). Entan-
glement makes a ﬁnal appearance in Chapter 11, in connection with decoherence.

<<<PAGE 155>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
4.5 Assembling Quantum Systems 137
What have we learned?/D2We can use the tensor product to build complex quantum systems out of simpler
ones./D2The new system cannot be analyzed simply in terms of states belonging to its
subsystems. An entire set of new states has been created, which cannot be re-
solved into their constituents.
Programming Drill 4.5.1 Expand the simulation of the last sections by letting the
user choose the number of particles.
.................................................................................
References: There are many elementary introductions to quantum mechanics that
are very readable. Here is a list of some of them: Chen (2003), Gillespie (1974),
Martin (1982), Polkinghorne (2002), andWhite (1966).
Special mention must be made of the classic introduction by P.A.M. Dirac
(1982). Seventy years after its ﬁrst publication, it remains a classic that is worth
reading.
For a more advanced and modern presentation see, e.g., Volume III of Feynman
(1963), Hannabuss (1997), Sakurai (1994), orSudbery (1986).
For a short history of the early development of quantum mechanics, see Gamow
(1985).

<<<PAGE 156>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
5
Architecture
From the intrinsic evidence of his creation, the Great Archi-
tect of the Universe now begins to appear as a pure mathe-
matician.
Sir James Jeans, Mysterious Universe
Now that we have the mathematical and physical preliminaries under our belt, we
can move on to the nuts and bolts of quantum computing. At the heart of a clas-
sical computer is the notion of a bit and at the heart of quantum computer is ageneralization of the concept of a bit called a qubit, which shall be discussed inSection 5.1. In Section 5.2, classical (logical) gates, which manipulate bits, are pre-
sented from a new and different perspective. From this angle, it is easy to formulate
the notion of quantum gates, which manipulate qubits. As mentioned in Chapters3 and 4, the evolution of a quantum system is reversible, i.e., manipulations that
can be done must also be able to be undone. This “undoing” translates into re-
versible gates, which are discussed in Section 5.3. We move on to quantum gates inSection 5.4.
.................................................................................
Reader Tip. Discussion of the actual physical implementation of qubits and quan-
tum gates is dealt with in Chapter 11. ♥.................................................................................
5.1 BITS AND QUBITS
What is a bit?
Deﬁnition 5.1.1 Abitis a unit of information describing a two-dimensional classical
system.
138

<<<PAGE 157>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
5.1 Bits and Qubits 139
There are many examples of bits:/D2A bit is electricity traveling through a circuit or not (or high and low)./D2A bit is a way of denoting “true” or “false.”/D2A bit is a switch turned on or off.
All these examples are saying the same thing: a bit is a way of describing a system
whose set of states is of size 2. We usually write these two possible states as 0 and 1,
or F and T, etc.
As we have become adept at matrices, let us use them as a way of representing
a bit. We shall represent 0 – or, better, the state |0/angbracketright– as a 2-by-1 matrix with a 1 in
the 0’s row and a 0 in the 1’s row:
|0/angbracketright=/bracketleftBigg
01
10/bracketrightBigg
. (5.1)
We shall represent a 1, or state |1/angbracketright,a s
|1/angbracketright=/bracketleftBigg
00
11/bracketrightBigg
. (5.2)
Because these are two different representations (indeed orthogonal), we have an
honest-to-goodness bit. We explore how to manipulate these bits in Section 5.2.
A bit can be either in state |0/angbracketrightor in state |1/angbracketright, which was sufﬁcient for the classical
world. Either electricity is running through a circuit or it is not. Either a proposition
is true or it is false. Either a switch is on or it is off. But either/or is not sufﬁcient in
the quantum world. In that world, there are situations where we are in one state and
in the other simultaneously. In the realm of the quantum, there are systems where a
switch is both on and off at the same time. One quantum system can be in state |0/angbracketright
andin state |1/angbracketrightsimultaneously. Hence we are led to the deﬁnition of a qubit:
Deﬁnition 5.1.2 Aquantum bit or a qubit is a unit of information describing a two-
dimensional quantum system.
We shall represent a qubit as a 2-by-1 matrix with complex numbers
/bracketleftBigg
0c0
1c1/bracketrightBigg
, (5.3)
where|c0|2+|c1|2=1. Notice that a classical bit is a special type of qubit. |c0|2is to
be interpreted as the probability that after measuring the qubit, it will be found instate|0/angbracketright.|c
1|2is to be interpreted as the probability that after measuring the qubit it
will be found in state |1/angbracketright. Whenever we measure a qubit, it automatically becomes a
bit. So we shall never “see” a general qubit. Nevertheless, they do exist and are the

<<<PAGE 158>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
140 Architecture
main characters in our tale. We might visualize this “collapsing” of a qubit to a bit
as
[1,0]T
[c0,c1]T|c0|2/d55/d55/d55/d119 /d55/d119 /d55/d119 /d55/d119 /d55/d119 /d55/d119 /d55/d119 /d55/d119 /d55/d119 /d55/d119 /d55/d119 /d55/d119 /d55/d119 /d55/d119 /d55/d119 /d55/d119 /d55/d119
|c1|2
/d40/d40/d40/d104 /d40/d104 /d40/d104 /d40/d104 /d40/d104 /d40/d104 /d40/d104 /d40/d104 /d40/d104 /d40/d104 /d40/d104 /d40/d104 /d40/d104 /d40/d104 /d40/d104 /d40/d104 /d40/d104
[0,1]T(5.4)
It is easy to see that the bits |0/angbracketrightand|1/angbracketrightare the canonical basis of C2. Thus, any
qubit can be written as
⎡
⎢⎣c0
c1⎤
⎥⎦=c0·⎡
⎢⎣1
0⎤
⎥⎦+c1·⎡
⎢⎣0
1⎤
⎥⎦=c0|0/angbracketright+ c1|1/angbracketright. (5.5)
Exercise 5.1.1 Write V=/bracketleftbigg
3+2i
4−2i/bracketrightbigg
as a sum of |0/angbracketrightand|1/angbracketright. /squaresolid
Following the normalization procedures that we learned in Chapter 4 on
page 109, any nonzero element of C2can be converted into a qubit.
Example 5.1.1 The vector
V=⎡
⎢⎣5+3i
6i⎤
⎥⎦ (5.6)
has norm
|V|=/radicalbig
/angbracketleftV,V/angbracketright=/radicaltp/radicalvertex/radicalvertex/radicalvertex/radicalvertex/radicalbt
[5−3i,−6i]⎡
⎢⎣5+3i
6i⎤
⎥⎦=/radicalbig
34+36=√
70. (5.7)
SoVdescribes the same physical state as the qubit
V√
70=⎡
⎢⎣5+3i√
70
6i√
70⎤
⎥⎦=5+3i√
70|0/angbracketright+6i√
70|1/angbracketright. (5.8)
After measuring the qubitV√
70, the probability of it being found in state |0/angbracketrightis34
70and
the probability of it being found in state |1/angbracketrightis36
70. /square

<<<PAGE 159>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
5.1 Bits and Qubits 141
Exercise 5.1.2 Normalize V=/bracketleftbigg
15−3.4i
2.1−16i/bracketrightbigg
. /squaresolid
Let us look at several ways of denoting different qubits.1√
2/bracketleftbigg
1
1/bracketrightbigg
can be written as
⎡
⎢⎣1√
2
1√
2⎤
⎥⎦=1√
2|0/angbracketright+1√
2|1/angbracketright=|0/angbracketright+| 1/angbracketright√
2. (5.9)
Similarly,1√
2/bracketleftbigg
1
−1/bracketrightbigg
can be written as
⎡
⎢⎣1√
2
−1√
2⎤
⎥⎦=1√
2|0/angbracketright−1√
2|1/angbracketright=|0/angbracketright−| 1/angbracketright√
2. (5.10)
It is important to realize that
|0/angbracketright+| 1/angbracketright√
2=|1/angbracketright+| 0/angbracketright√
2. (5.11)
These are both ways of denoting/bracketleftbigg
1√
2
1√
2/bracketrightbigg
. In contrast,
|0/angbracketright−| 1/angbracketright√
2/negationslash=|1/angbracketright−| 0/angbracketright√
2. (5.12)
The left state is the vector/bracketleftbigg
1√
2
−1√
2/bracketrightbigg
and the right state is the vector/bracketleftbigg
−1√
2
1√
2/bracketrightbigg
. However,
the two states are related:
|0/angbracketright−| 1/angbracketright√
2=(−1)|1/angbracketright−| 0/angbracketright√
2. (5.13)
How are qubits to be implemented? In Chapter 11, several different methods
are explored. We simply state some examples of implementations for the time
being:/D2An electron might be in one of two different orbits around the nucleus of anatom (ground state and excited state)./D2A photon might be in one of two polarized states./D2A subatomic particle might have one of two spin directions.
There will be enough quantum indeterminacy and quantum superposition effects
within all these systems to represent a qubit.

<<<PAGE 160>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
142 Architecture
Computers with only one bit of storage are not very interesting. Similarly, we
will need quantum devices with more than one qubit. Consider a byte, or eight bits.
A typical byte might be
01101011 . (5.14)
If we were to follow the preceding method of describing bits, we would representthe bits as follows:
⎡
⎢⎣1
0⎤
⎥⎦,⎡
⎢⎣0
1⎤
⎥⎦,⎡
⎢⎣0
1⎤
⎥⎦,⎡
⎢⎣1
0⎤
⎥⎦,⎡
⎢⎣0
1⎤
⎥⎦,⎡
⎢⎣1
0⎤
⎥⎦,⎡
⎢⎣0
1⎤
⎥⎦,⎡
⎢⎣0
1⎤
⎥⎦. (5.15)
We learned previously that in order to combine quantum systems, one should use
the tensor product; hence, we can describe the byte in Equation (5.14) as
|0/angbracketright⊗| 1/angbracketright⊗| 1/angbracketright⊗| 0/angbracketright⊗| 1/angbracketright⊗| 0/angbracketright⊗| 1/angbracketright⊗| 1/angbracketright. (5.16)
As a qubit, this is an element
of
C2⊗C2⊗C2⊗C2⊗C2⊗C2⊗C2⊗C2. (5.17)
This vector space may be denoted as ( C2)⊗8. This is a complex vector space of di-
mension 28=256. Because there is essentially only one complex vector space of this
dimension, this vector space is isomorphic to C256.
We can describe our byte in yet another way: as a 28=256 row vector
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣00000000 0
00000001 0
......
01101010 0
01101011 1
01101100 0
......
11111110 0
11111111 0⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (5.18)
Exercise 5.1.3 Express the three bits 101 or |1/angbracketright⊗| 0/angbracketright⊗| 1/angbracketright∈C
2⊗C2⊗C2as a vec-
tor in ( C2)⊗3=C8. Do the same for 011 and 111. /squaresolid
This is ﬁne for the classical world. However, for the quantum world, in order
to permit superposition, a generalization is needed: every state of an eight-qubit

<<<PAGE 161>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
5.1 Bits and Qubits 143
system can be written as
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣00000000 c
0
00000001 c1
......
01101010 c
106
01101011 c107
01101100 c108
......
11111110 c254
11111111 c255⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦, (5.19)
where/summationtext
255
i=0|ci|2=1. Eight qubits together is called a qubyte.
In the classical world, it is necessary to indicate the state of each bit of a byte.
This amounts to writing eight bits. In the quantum world, a state of eight qubits is
given by writing 256 complex numbers. As we stated in Section 3.4, this exponen-
tial growth was one of the reasons researchers started giving thought to the notion
of quantum computing. If one wanted to emulate a quantum computer with a 64-qubit register, one would need to store 2
64=18,446, 744, 073, 709, 551, 616 com-
plex numbers. This is way beyond our current storage capability.
Let us practice writing two qubits in ket notation. A qubit pair can be written as
|0/angbracketright⊗| 1/angbracketright or|0⊗1/angbracketright, (5.20)
which means that the ﬁrst qubit is in state |0/angbracketrightand the second qubit is in state |1/angbracketright.
Because the tensor product is understood, we might also denote these qubits as|0/angbracketright|1/angbracketright,|0,1/angbracketright,o r|01/angbracketright. Yet another way to look at these two qubits as the 4-by-1 matrix
is
⎡
⎢⎢⎢⎣00 0
01 1
10 0
11 0⎤
⎥⎥⎥⎦. (5.21)
Exercise 5.1.4 What vector corresponds to the state 3 |01/angbracketright+ 2|11/angbracketright? /squaresolid
Example 5.1.2 The qubit corresponding to
1
√
3⎡
⎢⎢⎢⎢⎢⎢⎢⎣1
0
−1
1⎤
⎥⎥⎥⎥⎥⎥⎥⎦(5.22)

<<<PAGE 162>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
144 Architecture
can be written as
1√
3|00/angbracketright−1√
3|10/angbracketright+1√
3|11/angbracketright=|00/angbracketright−| 10/angbracketright+| 11/angbracketright√
3. (5.23)
/square
A general state of a two-qubit system can be written as
|ψ/angbracketright=c0,0|00/angbracketright+ c0,1|01/angbracketright+ c1,0|10/angbracketright+ c1,1|11/angbracketright. (5.24)
The tensor product of two states is not commutative:
|0⊗1/angbracketright=| 0/angbracketright⊗| 1/angbracketright=| 0,1/angbracketright=| 01/angbracketright /negationslash=| 10/angbracketright=| 1,0/angbracketright=| 1/angbracketright⊗| 0/angbracketright=| 1⊗0/angbracketright.
(5.25)
The left ket describes the state in which the ﬁrst qubit is in state 0 and the second
qubit is in state 1. The right ket indicates that ﬁrst qubit is in state 1 and the second
qubit is in state 0.
Let us brieﬂy revisit the notion of entanglement again. If the system is in the
state
|11/angbracketright+| 00/angbracketright√
2=1√
2|11/angbracketright+1√
2|00/angbracketright, (5.26)
then that means that the the two qubits are entangled. That is, if we measure the
ﬁrst qubit and it is found in state |1/angbracketrightthen we automatically know that the state of
the second qubit is |1/angbracketright. Similarly, if we measure the ﬁrst qubit and ﬁnd it in state |0/angbracketright
then we know the second qubit is also in state |0/angbracketright.
5.2 CLASSICAL GATES
Classical logical gates are ways of manipulating bits. Bits enter and exit logical gates.We will need ways of manipulating qubits and will study classical gates from thepoint of view of matrices. As stated in Section 5.1, we represent ninput bits as a
2
n-by-1 matrix and moutput bits as a 2m-by-1 matrix. How should we represent
our logical gates? When one multiplies a 2m-by-2nmatrix with a 2n-by-1 matrix, the
result is a 2m-by-1 matrix. In symbols:
(2m-by-2n)⋆(2n-by-1)=(2m-by-1) . (5.27)
So bits will be represented by column vectors and logic gates by matrices.
Let us try a simple example. Consider the NOT gate.

<<<PAGE 163>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
5.2 Classical Gates 145
NOT takes as input one bit, or a 2-by-1 matrix, and outputs one bit, or a 2-by-1
matrix. NOT of |0/angbracketrightequals|1/angbracketrightand NOT of |1/angbracketrightequals|0/angbracketright. Consider the matrix
NOT=⎡
⎢⎣01
10⎤
⎥⎦. (5.28)
This matrix satisﬁes
⎡
⎢⎣01
10⎤
⎥⎦⎡
⎢⎣1
0⎤
⎥⎦=⎡
⎢⎣0
1⎤
⎥⎦ and⎡
⎢⎣01
10⎤
⎥⎦⎡
⎢⎣0
1⎤
⎥⎦=⎡
⎢⎣1
0⎤
⎥⎦, (5.29)
which is exactly what we want.
What about the other gates? Consider the AND gate. The AND gate is different
from the NOT gate because AND accepts two bits and outputs one bit.
Because there are two inputs and one output, we will need a 21-by-22matrix.
Consider the matrix
AND=⎡
⎢⎣1110
0001⎤
⎥⎦. (5.30)
This matrix satisﬁes
⎡
⎢⎣1110
0001⎤
⎥⎦⎡
⎢⎢⎢⎢⎢⎢⎢⎣0
001⎤
⎥⎥⎥⎥⎥⎥⎥⎦=⎡
⎢⎣0
1⎤
⎥⎦. (5.31)
We can write this as
AND|11/angbracketright=| 1/angbracketright. (5.32)
In contrast, consider another 4-by-1 matrix:
⎡
⎢⎣1110
0001⎤
⎥⎦⎡
⎢⎢⎢⎢⎢⎢⎢⎣0
1
0
0⎤
⎥⎥⎥⎥⎥⎥⎥⎦=⎡
⎢⎣1
0⎤
⎥⎦. (5.33)
We can write this as
AND|01/angbracketright=| 0/angbracketright. (5.34)

<<<PAGE 164>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
146 Architecture
Exercise 5.2.1 Calculate AND|10/angbracketright. /squaresolid
What would happen if we put an arbitrary 4-by-1 matrix to the right of AND?
⎡
⎢⎣1110
0001⎤
⎥⎦⎡
⎢⎢⎢⎢⎢⎢⎢⎣3.5
2
0
−4.1⎤
⎥⎥⎥⎥⎥⎥⎥⎦=⎡
⎢⎣5.5
−4.1⎤
⎥⎦ (5.35)
This is clearly nonsense. We are allowed only to multiply these classical gates with
vectors that represent classical states, i.e., column matrices with a single 1 entry andall other entries 0. In the classical world, the bits are in only one state at a time and
are described by such vectors. Only later, when we delve into quantum gates, will
we have more room (and more fun).
The OR gate
can be represented by the matrix
OR=⎡
⎢⎣1000
0111⎤
⎥⎦. (5.36)
Exercise 5.2.2 Show that this matrix performs the OR operation. /squaresolid
The NAND gate
is of special importance because every logical gate can be composed of NAND gates.
Let us try to determine which matrix would correspond to NAND. One way is to
sit down and consider for which of the four possible input states of two bits (00, 01,10, 11) does NAND output a 1 (answer: 00, 01, 10), and in which states does NAND
output a 0 (answer: 11). From this, we realize that NAND can be written as
NAND =/bracketleftBigg00 01 10 11
0 0001
1 1110/bracketrightBigg
. (5.37)
Notice that the column names correspond to the inputs and the row names corre-
spond to the outputs. 1 in the jth column and ith row means that on entry jthe
matrix/gate will output i.

<<<PAGE 165>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
5.2 Classical Gates 147
There is, however, another way in which one can determine the NAND gate.
The NAND gate is really the AND gate followed by the NOT gate.
In other words, we can perform the NAND operation by ﬁrst performing the AND
operation and then the NOT operation. In terms of matrices we can write this as
NOT ⋆AND=⎡
⎢⎣01
10⎤
⎥⎦⋆⎡
⎢⎣1110
0001⎤
⎥⎦=⎡
⎢⎣0001
1110⎤
⎥⎦=NAND.
(5.38)
Exercise 5.2.3 Find a matrix that corresponds to NOR. /squaresolid
This way of thinking of NAND brings to light a general situation. When we per-
form a computation, we often have to carry out one operation followed by another.
/d47/d47A/d47/d47B/d47/d47 (5.39)
We call this procedure performing sequential operations. If matrix Acorre-
sponds to performing an operation and matrix Bcorresponds to performing another
operation, then the matrix B⋆Acorresponds to performing the operation sequen-
tially. Notice that B⋆Alooks like the reverse of our picture which has, from left to
right, Aand then B. Do not be alarmed by this. The reason for this is because we
read from left to right and hence we depict processes as ﬂowing from left to right.
We could have easily drawn the above ﬁgure as
B/d111/d111A/d111/d111 /d111/d111 (5.40)
with no confusion.1We shall follow the convention that computation ﬂows from left
to right and omit the heads of the arrows. And so a computation of Afollowed by
Bshall be denoted
A B (5.41)
1If the text were written in Arabic or Hebrew, this problem would not even arise.

<<<PAGE 166>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
148 Architecture
Let us be formal with the number of inputs and the number of outputs. If Ais
an operation with minput bits and noutput bits, then we shall draw this as
/mA /n(5.42)
The matrix Awill be of size 2n-by-2m. Say, Btakes the noutputs of Aas input
and outputs pbits, i.e.,
/mA /nB /p(5.43)
then Bis represented by a 2p-by-2nmatrix B, and performing one operation sequen-
tially followed by another operation corresponds to B⋆A, which is a (2p-by-2n)⋆
(2n-by-2m)=(2p-by-2m) matrix.
Besides sequential operations, there are parallel operations as well.
A
B(5.44)
Here we have Aacting on some bits and Bon others. This will be represented by
A⊗B(see Section 2.7). Let us be exact with the number of inputs and the number
of outputs.
/mA /n
/m/primeB /n/prime(5.45)
Awill be of size 2n-by-2m.Bwill be of size 2n/prime-by-2m/prime. Following Equation (2.174)
in Section 2.7, A⊗Bis of size 2n2n/prime=2n+n/prime-by-2m2m/prime=2m+m/prime.
Exercise 5.2.4 In Exercise 2.7.4, we proved that A⊗B∼=B⊗A. What does this
fact correspond to in terms of performing parallel operations on different bits? /squaresolid
Combinations of sequential and parallel operations gates/matrices will be called
circuits. We will, of course, construct some really complicated matrices, but they
will all be decomposable into the sequential and parallel compositions of simple
gates.
Exercise 5.2.5 In Exercise 2.7.9, we proved that for matrices of the appropriate
sizes A,A/prime,B, and B/primewe have the following equation:
(B⊗B/prime)⋆(A⊗A/prime)=(B⋆A)⊗(B/prime⋆A/prime). (5.46)

<<<PAGE 167>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
5.2 Classical Gates 149
To what does this correspond in terms of performing different operations on differ-
ent (qu)bits? (Hint: Consider the following ﬁgure.)
A B
A/primeB/prime(5.47)
/squaresolid
Example 5.2.1 LetAbe an operation that takes ninputs and gives moutputs. Let
Btake p<mof these outputs and leave the other m−poutputs alone. Boutputs
qbits.
/n
A/pB /q
/m−p(5.48)
Ais a 2m-by-2nmatrix. Bis a 2q-by-2pmatrix. As nothing should be done to the
m−pbits, we might represent this as the 2m−p-by-2m−pidentity matrix Im−p.W e
do not draw any gate for the identity matrix. The entire circuit can be representedby the following matrix:
(B⊗I
m−p)⋆A. (5.49)
/square
Example 5.2.2 Consider the circuit.
This is represented by
OR⋆(NOT⊗AND). (5.50)


<<<PAGE 168>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
150 Architecture
Let us see how the operations look like as matrices. Calculating, we get
NOT⊗AND=⎡
⎢⎣01
10⎤
⎥⎦⊗⎡
⎢⎣1110
0001⎤
⎥⎦=⎡
⎢⎢⎢⎢⎢⎢⎢⎣00001110
000000011110000000010000⎤
⎥⎥⎥⎥⎥⎥⎥⎦.
(5.51)
A n ds ow eg e t
OR⋆(NOT⊗AND)=⎡
⎢⎣00001110
11110001⎤
⎥⎦. (5.52)
/square
Let us see if we can formulate DeMorgan’s laws in terms of matrices. One of
DeMorgan’s laws states that ¬(¬ P/logicalandtext¬Q)=P/logicalortextQ. Here is a pictorial representa-
tion.
In terms of matrices this corresponds to
NOT ⋆AND ⋆(NOT⊗NOT)=OR. (5.53)
First, let us calculate the tensor product:
NOT⊗NOT=⎡
⎢⎣01
10⎤
⎥⎦⊗⎡
⎢⎣01
10⎤
⎥⎦=⎡
⎢⎢⎢⎢⎢⎢⎢⎣0001
0010
01001000⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (5.54)
This DeMorgan’s law corresponds to the following identity of matrices:
⎡
⎢⎣01
10⎤
⎥⎦⋆⎡
⎢⎣1110
0001⎤
⎥⎦⋆⎡
⎢⎢⎢⎢⎢⎢⎢⎣0001
001001001000⎤
⎥⎥⎥⎥⎥⎥⎥⎦=⎡
⎢⎣1000
0111⎤
⎥⎦. (5.55)

<<<PAGE 169>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
5.3 Reversible Gates 151
Exercise 5.2.6 Multiply out these matrices and conﬁrm the identity. /squaresolid
Exercise 5.2.7 Formulate the other DeMorgan’s law
¬(¬ P/logicalordisplay
¬Q)=P/logicalanddisplay
Q (5.56)
in terms of matrices. /squaresolid
Exercise 5.2.8 Write the matrix that would correspond to a one-bit adder. A one-
bit adder adds the bits x,y, and c(a carry-bit from an earlier adder) and outputs
the bits zand c/prime(a carry-bit for the next adder). There are three inputs and two
outputs, so the matrix will be of dimension 22-by-23. (Hint: Mark the columns as
000, 001, 010,...,110, 111, where column, say, 101 corresponds to x=1,y=0,c=
1. Mark the rows as 00, 01,10,11, where row, say, 10, corresponds to z=1,c/prime=0.
When x=1,y=0,c=1, the output should be z=0 and c/prime=1. So place a 1 in the
row marked 01 and a 0 in all other rows.) /squaresolid
Exercise 5.2.9 In Exercise 5.2.8, you determined the matrix that corresponds to a
one-bit adder. Check that your results are correct by writing the circuit in terms of
classical gates and then converting the circuit to a big matrix. /squaresolid
5.3 REVERSIBLE GATES
Not all the logical gates that we dealt with in Section 5.2 will work in quantumcomputers. In the quantum world, all operations that are not measurements are
reversible and are represented by unitary matrices. The AND operation is not re-
versible. Given an output of |0/angbracketrightfrom AND, one cannot determine if the input was
|00/angbracketright,|01/angbracketright,o r |10/angbracketright. So from an output of the AND gate, one cannot determine the
input and hence AND is not reversible. In contrast, the NOT gate and the identitygates are reversible. In fact, they are their own inverses:
NOT ⋆NOT=I
2 In⋆In=In. (5.57)
Reversible gates have a history that predates quantum computing. Our every-
day computers lose energy and generate a tremendous amount of heat. In the 1960s,
Rolf Landauer analyzed computational processes and showed that erasing informa-
tion, as opposed to writing information, is what causes energy loss and heat. Thisnotion has come to be known as the Landauer’s principle .
In order to gain a real-life intuition as to why erasing information dissipates en-
ergy, consider a tub of water with a wall separating the two sides as in Figure 5.1.
Figure 5.1. Tub with water in no state.

<<<PAGE 170>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
152 Architecture
Figure 5.2. Tub with water in state |0/angbracketrightand state |1/angbracketright.
This tub is used as a way of storing a bit of information. If all the water is pushed
to the left then the system is in state |0/angbracketright, and if all the water is pushed to the right
then the system is in state |1/angbracketright, as in Figure 5.2.
What would correspond to erasing information in such a system? If there were a
hole in the wall separating the 0 and 1 regions, then the water could seep out and we
would not know what state the system would be in. One can easily place a turbine
where the water is seeping out (see Figure 5.3) and generate energy. Hence, losing
information means energy is being dissipated.
Notice, also, that writing information is a reversible procedure. If the tub is in no
state and we push all the water to the left and set the water to state |0/angbracketright, all one needs
to do is remove the wall and the water will go into both regions resulting in no state.
This is shown in Figure 5.4. We have reversed the fact that information was written.
In contrast, erasing information is not reversible. Start at state |0/angbracketright, and then remove
the wall that separates the two parts of the tub. That is erasing the information. Howcould we return to the original state? There are two possible states to return to, asinFigure 5.5.
The obvious answer is that we should push all the water back to state |0/angbracketright.B u t
the only way we know that |0/angbracketrightis the original state is if that information is copied
to the brain. In that case, the system is both the tub and the brain, and we did not
really erase the fact that state |0/angbracketrightwas the original state. Our brain was still storing
the information.
Let us reexamine this intuition by considering two people, Alice and Bob. If
Alice writes a letter on an empty blackboard and then Bob walks into the room, he
can then erase the letter that Alice wrote on the board and return the blackboardinto its original pristine state. Thus, writing is reversible. In contrast, if there is aboard with writing on it and Alice erases the board, then when Bob walks into the
room he cannot write what was on the board. Bob does not know what was on the
board before Alice erased it. So Alice’s erasing was not reversible.
Figure 5.3. State|0/angbracketrightdissipating and
creating energy.

<<<PAGE 171>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
5.3 Reversible Gates 153
Figure 5.4. Reversibility of writing.
We have found that erasing information is an irreversible, energy-dissipating
operation. In the 1970s, Charles H. Bennett continued along these lines of thought.
If erasing information is the only operation that uses energy, then a computer that
is reversible and does not erase would not use any energy. Bennett started working
on reversible circuits and programs.
What examples of reversible gates are there? We have already seen that the
identity gate and NOT gates are reversible. What else is there? Consider the follow-ingcontrolled-NOT gate:
|x/angbracketright
•|x/angbracketright
|y/angbracketright/d31/d30/d29/d28 /d24/d25/d26/d27|x⊕y/angbracketright(5.58)
This gate has two inputs and two outputs. The top input is the control bit. It
controls what the output will be. If |x/angbracketright=| 0/angbracketright, then the bottom output of |y/angbracketrightwill be
the same as the input. If |x/angbracketright=| 1/angbracketright, then the bottom output will be the opposite. If we
write the top qubit ﬁrst and then the bottom qubit, then the controlled-NOT gatetakes|x,y/angbracketrightto|x,x⊕y/angbracketright, where ⊕is the binary exclusive or operation.
Figure 5.5. Irreversibility of erasing.

<<<PAGE 172>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
154 Architecture
The matrix that corresponds to this reversible gate is
⎡
⎢⎢⎢⎣00 01 10 11
00 1000
01 0100
10 0001
11 0010⎤
⎥⎥⎥⎦. (5.59)
The controlled-NOT gate can be reversed by itself. Consider the following ﬁg-
ure:
|x/angbracketright
•|x/angbracketright
•|x/angbracketright
|y/angbracketright/d31/d30/d29/d28 /d24/d25/d26/d27|x⊕y/angbracketright/d31/d30/d29/d28 /d24/d25/d26/d27|x⊕x⊕y/angbracketright(5.60)
State|x,y/angbracketrightgoes to |x,x⊕y/angbracketright, which further goes to |x,x⊕(x⊕y)/angbracketright. This last
state is equal to |x,(x⊕x)⊕y/angbracketrightbecause ⊕is associative. Because x⊕xis always
equal to 0, this state reduces to the original |x,y/angbracketright.
Exercise 5.3.1 Show that the controlled-NOT gate is its own inverse by multiplying
the corresponding matrix by itself and arriving at the identity matrix. /squaresolid
An interesting reversible gate is the Toffoli gate :
|x/angbracketright
•|x/angbracketright
|y/angbracketright
•|y/angbracketright
|z/angbracketright/d31/d30/d29/d28 /d24/d25/d26/d27|z⊕(x∧y)/angbracketright(5.61)
This is similar to the controlled-NOT gate, but with two controlling bits. The
bottom bit ﬂips only when both of the top two bits are in state |1/angbracketright. We can write this
operation as taking state |x,y,z/angbracketrightto|x,y,z⊕(x∧y)/angbracketright.
Exercise 5.3.2 Show that the Toffoli gate is its own inverse. /squaresolid

<<<PAGE 173>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
5.3 Reversible Gates 155
The matrix that corresponds to this gate is
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣000 001 010 011 100 101 110 111
000 10000000
001 01000000
010 00100000
011 00010000
100 00001000
101 00000100
110 00000001
111 00000010⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (5.62)
Example 5.3.1 The NOT gate has no controlling bit, the controlled-NOT gate has
one controlling bit, and the Toffoli gate has two controlling bits. Can we go on with
this? Yes. A gate with three controlling bits can be constructed from three Toffoligates as follows:
|x/angbracketright
• •|x/angbracketright
|y/angbracketright
• •|y/angbracketright
|0/angbracketright/d31/d30/d29/d28 /d24/d25/d26/d27 • /d31/d30/d29/d28 /d24/d25/d26/d27|0/angbracketright
|z/angbracketright
•|z/angbracketright
|w/angbracketright/d31/d30/d29/d28 /d24/d25/d26/d27|w⊕(x∧y∧z)/angbracketright(5.63)
/square
One reason why the Toffoli gate is interesting is that it is universal. In other
words, with copies of the Toffoli gate, you can make any logical gate. In particu-lar, you can make a reversible computer using only Toffoli gates. Such a computerwould, in theory, neither use any energy nor give off any heat.
In order to see that the Toffoli gate is universal, we will show that it can be used
to make both the AND and NOT gates. The AND gate is obtained by setting the

<<<PAGE 174>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
156 Architecture
bottom |z/angbracketrightinput to |0/angbracketright. The bottom output will then be |x∧y/angbracketright.
|x/angbracketright
•|x/angbracketright
|y/angbracketright
•|y/angbracketright
|0/angbracketright/d31/d30/d29/d28 /d24/d25/d26/d27|x∧y/angbracketright(5.64)
The NOT gate is obtained by setting the top two inputs to |1/angbracketright. The bottom output
will be|(1∧1)⊕z/angbracketright=| 1⊕z/angbracketright=| ¬ z/angbracketright.
|1/angbracketright
•|1/angbracketright
|1/angbracketright
•|1/angbracketright
|z/angbracketright/d31/d30/d29/d28 /d24/d25/d26/d27|¬z/angbracketright(5.65)
In order to construct all gates, we must also have a way of producing a fanout of
values. In other words, a gate is needed that inputs a value and outputs two of the
same values. This can be obtained by setting |x/angbracketrightto|1/angbracketrightand|z/angbracketrightto|0/angbracketright. This makes the
output|1,y,y/angbracketright.
|1/angbracketright
•|1/angbracketright
|y/angbracketright
•|y/angbracketright
|0/angbracketright/d31/d30/d29/d28 /d24/d25/d26/d27|y/angbracketright(5.66)
Exercise 5.3.3 Construct the NAND with one Toffoli gate. Construct the OR gate
with two Toffoli gates. /squaresolid

<<<PAGE 175>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
5.3 Reversible Gates 157
Another interesting reversible gate is the Fredkin gate . The Fredkin gate also
has three inputs and three outputs.
|x/angbracketright
•|x/angbracketright
|y/angbracketright
×|y/prime/angbracketright
|z/angbracketright
×|z/prime/angbracketright(5.67)
The top |x/angbracketrightinput is the control input. The output is always the same |x/angbracketright.I f| x/angbracketright
is set to |0/angbracketright, then |y/prime/angbracketright=| y/angbracketrightand|z/prime/angbracketright=| z/angbracketright, i.e., the values stay the same. If, on the
other hand, the control |x/angbracketrightis set to |1/angbracketright, then the outputs are reversed: |y/prime/angbracketright=| z/angbracketrightand
|z/prime/angbracketright=| y/angbracketright. In short, |0,y,z/angbracketright /mapsto→| 0,y,z/angbracketrightand|1,y,z/angbracketright /mapsto→| 1,z,y/angbracketright.
Exercise 5.3.4 Show that the Fredkin gate is its own inverse. /squaresolid
The matrix that corresponds to the Fredkin gate is
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣000 001 010 011 100 101 110 111
000 10000000
001 01000000
010 00100000
011 00010000
100 00001000
101 00000010
110 00000100
111 00000001⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (5.68)
The Fredkin gate is also universal. By setting |y/angbracketrightto|0/angbracketright, we get the AND gate as
follows:
|x/angbracketright
•|x/angbracketright
|0/angbracketright
×|x∧z/angbracketright
|z/angbracketright
×|(¬x)∧z/angbracketright(5.69)

<<<PAGE 176>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
158 Architecture
The NOT gate and the fanout gate can be obtained by setting |y/angbracketrightto|1/angbracketrightand|z/angbracketright
to|0/angbracketright. This gives us
|x/angbracketright
•|x/angbracketright
|1/angbracketright
×|¬x/angbracketright
|0/angbracketright
×|x/angbracketright(5.70)
So both the Toffoli and the Fredkin gates are universal. Not only are both re-
versible gates; a glance at their matrices indicates that they are also unitary. In the
next section, we look at other unitary gates.
5.4 QUANTUM GATES
Deﬁnition 5.4.1 Aquantum gate is simply an operator that acts on qubits. Such
operators will be represented by unitary matrices.
We have already worked with some quantum gates such as the identity operator I,
the Hadamard gate H, the NOT gate, the controlled-NOT gate, the Toffoli gate,
and the Fredkin gate. What else is there?
Let us look at some other quantum gates. The following three matrices are called
Pauli matrices and are very important:
X=⎡
⎢⎣01
10⎤
⎥⎦, Y=⎡
⎢⎣0−i
i0⎤
⎥⎦, Z=⎡
⎢⎣10
0−1⎤
⎥⎦. (5.71)
They occur everywhere in quantum mechanics and quantum computing.2Note that
theXmatrix is nothing more than our NOT matrix. Other important matrices that
will be used are
S=⎡
⎢⎣10
0i⎤
⎥⎦ and T=⎡
⎢⎣10
0eiπ/4⎤
⎥⎦. (5.72)
Exercise 5.4.1 Show that each of these matrices are unitary. /squaresolid
Exercise 5.4.2 Show the action of each of these matrices on an arbitrary qubit
[c0,c1]T. /squaresolid
2Sometimes the notation σx,σy,a n dσzis used for these matrices.

<<<PAGE 177>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
5.4 Quantum Gates 159
Exercise 5.4.3 These operations are intimately related to each other. Prove the
following relationships between the operations:
(i)X2=Y2=Z2=I,
(ii) H=1√
2(X+Z),
(iii) X=HZH ,
(iv) Z=HXH ,
(v)−1Y=HYH ,
(vi) S=T2,
(vii)−1Y=XYX . /squaresolid
There are still other quantum gates. Let us consider a one-qubit quantum gate
with an interesting name. The gate is called the square root of NOT and is denoted√
NOT. The matrix representation of this gate is
√
NOT=1√
2⎡
⎢⎣1−1
11⎤
⎥⎦. (5.73)
The ﬁrst thing to notice is that this gate is not its own inverse, that is,
√
NOT/negationslash=√
NOT†. (5.74)
In order to understand why this gate has such a strange name, let us multiply√
NOT
by itself:
√
NOT ⋆√
NOT=(√
NOT)2=⎡
⎢⎣0−1
10⎤
⎥⎦, (5.75)
which is very similar to the NOT gate. Let us put the qubits |0/angbracketrightand|1/angbracketrightthrough√
NOT gate twice. We get
|0/angbracketright=[1 ,0]T/mapsto→/bracketleftbigg1√
2,1√
2/bracketrightbiggT
/mapsto→[0,1]T=|1/angbracketright (5.76)
and
|1/angbracketright=[0 ,1]T/mapsto→/bracketleftbigg
−1√
2,1√
2/bracketrightbiggT
/mapsto→[−1, 0]T=−1|0/angbracketright. (5.77)
Remembering that |0/angbracketrightand−1|0/angbracketright both represent the same state, we are conﬁdent in
saying that the square of√
NOT performs the same operation as the NOT gate, and
hence the name.
There is one other gate we have not discussed: the measurement operation. This
is not unitary or, in general, even reversible. This operation is usually performed at
the end of a computation when we want to measure qubits (and ﬁnd bits). We shalldenote it as
/d70/d69/d13/d13/d13 (5.78)

<<<PAGE 178>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
160 Architecture
There is a beautiful geometric way of representing one-qubit states and op-
erations. Remember from Chapter 1, page 18, that for a given complex number
c=x+yiwhose modulus is 1, there is a nice way of visualizing cas an arrow of
length 1 from the origin to the circle of radius 1.
|c|2=c×c=(x+yi)×(x−yi)=x2+y2=1. (5.79)
In other words, every complex number of radius 1 can be identiﬁed by the angle φ
that the vector makes with the positive xaxis.
There is an analogous representation of a qubit as an arrow from the origin to a
three-dimensional sphere. Let us see how it works. A generic qubit is of the form
|ψ/angbracketright=c0|0/angbracketright+ c1|1/angbracketright, (5.80)
where|c0|2+|c1|2=1. Although at ﬁrst sight there are four real numbers involved
in the qubit given in Equation (5.80), it turns out that there are only two actualdegrees of freedom to the three-dimensional ball (as latitude and longitude on the
Earth). Let us rewrite the qubit in Equation (5.80) in polar form:
c
0=r0eiφ0(5.81)
and
c1=r1eiφ1, (5.82)
and so Equation (5.80) can be rewritten as
|ψ/angbracketright=r0eiφ0|0/angbracketright+ r1eiφ1|1/angbracketright. (5.83)
There are still four real parameters: r0,r1,φ0,φ1. However, a quantum physical state
does not change if we multiply its corresponding vector by an arbitrary complexnumber (of norm 1, see Chapter 4, page 109). We can therefore obtain an equivalentexpression for the qubit in Equation (5.80), where the amplitude for |0/angbracketrightis real, by
“killing” its phase:
e
−iφ0|ψ/angbracketright=e−iφ0(r0eiφ0|0/angbracketright+ r1eiφ1|1/angbracketright)=r0|0/angbracketright+ r1ei(φ1−φ0)|1/angbracketright. (5.84)
We now have only three real parameters, namely, r0,r1, and φ=φ1−φ0.B u tw e
can do better: using the fact that
1=|c0|2+|c1|2=|r0eiφ0|2+|r1eiφ1|2=|r0|2|eiφ0|2+|r1|2|eiφ1|2, (5.85)
we get that
r2
0+r2
1=1. (5.86)
We can rename them as
r0=cos(θ ) and r1=sin(θ ). (5.87)
Summing up, the qubit in Equation (5.80) is now in the canonical representation
|ψ/angbracketright=cos(θ )|0/angbracketright+eiφsin(θ )|1/angbracketright, (5.88)
with only two real parameters remaining.

<<<PAGE 179>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
5.4 Quantum Gates 161
φθψ
Figure 5.6. Bloch sphere.
What is the range of the two angles θandφ? We invite you to show that 0 ≤φ<
2πand 0≤θ<π
2are enough to cover all possible qubits.
Exercise 5.4.4 Prove that every qubit in the canonical representation given in
Equation (5.88) with θ>π
2is equivalent to another one where θlies in the ﬁrst
quadrant of the plane. (Hint: Use a bit of trigonometry and change φaccording to
your needs.) /squaresolid
As only two real numbers are necessary to identify a qubit, we can map it to an
arrow from the origin to the three-dimensional sphere of R3of radius 1 known as
theBloch sphere, as shown in Figure 5.6.
Every qubit can be represented by two angles that describe such an arrow. The
two angles will correspond to the latitude (θ ) and the longitude (φ ) needed to specify
any position on Earth. The standard parametrization of the unit sphere is
x=cosφsinθ, (5.89)
y=sinφsinθ, (5.90)
z=cosθ. (5.91)
where 0 ≤φ≤2πand 0≤θ≤π.
However, there is a caveat: suppose we use this representation to map our qubit
on the sphere. Then, the points ( θ,φ) and ( π−θ,φ+π) represent the same qubit,
up to the factor −1. Conclusion: the parametrization would map the same qubit
twice, on the upper hemisphere and on the lower one. To mitigate this problem, we
simply double the “latitude” to cover the entire sphere at “half speed”:
x=cosφsin 2θ, (5.92)
y=sin 2θ sinφ, (5.93)
z=cos 2θ. (5.94)
Let us spend a few moments familiarizing ourselves with the Bloch sphere and
its geometry. The north pole corresponds to the state |0/angbracketrightand the south pole corre-
sponds to the state 1 /angbracketright.These two points can be taken as the geometrical image of

<<<PAGE 180>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
162 Architecture
the good old-fashioned bit. But there are many more qubits out there, and the Bloch
sphere clearly shows it.
The precise meaning of the two angles in Equation (5.88) is the following: φis
the angle that |ψ/angbracketrightmakes from xalong the equator and θis half the angle that |ψ/angbracketright
makes with the zaxis.
When a qubit is measured in the standard basis, it collapses to a bit, or equiv-
alently, to the north or south pole of the Bloch sphere. The probability of whichpole the qubit will collapse to depends exclusively on how high or low the qubit ispointing, i.e., to its latitude. In particular, if the qubit happens to be on the equator,
there is a 50–50 chance of it collapsing to either |0/angbracketrightor|1/angbracketright. As the angle θexpresses
the qubit’s latitude, it controls its chance of collapsing north or south.
Exercise 5.4.5 Consider a qubit whose θis equal to
π
4. Change it toπ
3and picture
the result. Then compute its likelihood of collapsing to the south pole after being
observed. /squaresolid
Take an arbitrary arrow and rotate it around the zaxis; in the geographical
metaphor, you are changing its longitude:
Notice that the probability of which classical state it will collapse to is not af-
fected. Such a state change is called a phase change . In the representation given in
Equation (5.88), this corresponds to altering the phase parameter eiφ.
Before we move on, one last important item: just as |0/angbracketrightand|1/angbracketrightsit on opposite
sides of the sphere, so an arbitrary pair of orthogonal qubits is mapped to antipodalpoints of the Bloch sphere.
Exercise 5.4.6 Show that if a qubit has latitude 2 θand longitude φon the sphere,
its orthogonal lives in the antipode π−2θandπ+φ. /squaresolid
That takes care of states of a qubit. What about the dynamics? The Bloch sphere
is interesting in that every unitary 2-by-2 matrix (i.e., a one-qubit operation) can be
visualized as a way of manipulating the sphere. We have seen in Chapter 2, page 66,
that every unitary matrix is an isometry. This means that such a matrix maps qubits
to qubits and the inner product is preserved. Geometrically, this corresponds to arotation or an inversion of the Bloch sphere.
The X,Y, and ZPauli matrices are ways of “ﬂipping” the Bloch sphere 180
◦
about the x,y, and zaxes respectively. Remember that Xis nothing more than the

<<<PAGE 181>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
5.4 Quantum Gates 163
Figure 5.7. A rotation of the Bloch sphere at y.
NOT gate, and takes |0/angbracketrightto|1/angbracketrightand vice versa. But it does more; it takes everything
above the equator to below the equator. The other Pauli matrices work similarly.
Figure 5.7 shows the action of the Yoperation.
There are times when we are not interested in performing a total 180◦ﬂip but
just want to turn the Bloch sphere θdegrees along a particular direction.
The ﬁrst such gates are the phase shift gates. It is deﬁned as
R(θ)=⎡
⎢⎣10
0eθ⎤
⎥⎦. (5.95)
This gate performs the following operation on an arbitrary qubit:
cos(θ/prime)|0/angbracketright+ eiφsin(θ/prime)|1/angbracketright=⎡
⎢⎣cos(θ/prime)
eiφsin(θ/prime)⎤
⎥⎦/mapsto→⎡
⎢⎣cos(θ/prime)
eθeiφsin(θ/prime)⎤
⎥⎦. (5.96)
This corresponds to a rotation that leaves the latitude alone and just changes the
longitude. The new state of the qubit will remain unchanged. Only the phase will
change.
There are also times when we want to rotate a particular number of degrees
around the x,y,o rzaxis. These three matrices will perform the task:
Rx(θ)=cosθ
2I−isinθ
2X=⎡
⎢⎣cosθ
2−isinθ
2
−isinθ
2cosθ
2⎤
⎥⎦, (5.97)
Ry(θ)=cosθ
2I−isinθ
2Y=⎡
⎢⎣cosθ
2−sinθ
2
sinθ
2cosθ
2⎤
⎥⎦, (5.98)
Rz(θ)=cosθ
2I−isinθ
2Z=⎡
⎢⎣e−iθ/20
0 eiθ/2⎤
⎥⎦. (5.99)

<<<PAGE 182>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
164 Architecture
Figure 5.8. A rotation of the Bloch sphere at D.
There are rotations around axes besides the x,y, and zaxes. Let D=
(Dx,Dy,Dz) be a three-dimensional vector of size 1 from the origin. This determines
an axis of the Bloch sphere around which we can spin (see Figure 5.8). The rotation
matrix is given as
RD(θ)=cosθ
2I−isinθ
2(DxX+DyY+DzZ). (5.100)
As we have just seen, the Bloch sphere is a very valuable tool when it comes
to understanding qubits and one-qubit operations. What about n-qubits? It turns
out there is a higher-dimensional analog of the sphere, but coming to grips with
it is not easy. Indeed, it is a current research challenge to develop new ways of
visualizing what happens when we manipulate several qubits at once. Entanglement,for instance, lies beyond the scope of the Bloch sphere (as it involves at least two
qubits).
There are still other quantum gates. One of the central features of computer
science is an operation that is done only under certain conditions and not under
others. This is equivalent to an IF–THEN statement. If a certain (qu)bit is true,
then a particular operation should be performed, otherwise the operation is not
performed. For every n-qubit unitary operation U, we can create a unitary ( n+1)-
qubit operation controlled- Uor
CU.
|x/angbracketright
•|x/angbracketright
/nU /n(5.101)
This operation will perform the Uoperation if the top |x/angbracketrightinput is a |1/angbracketrightand will
simply perform the identity operation if |x/angbracketrightis|0/angbracketright.
For the simple case of
U=⎡
⎢⎣ab
cd⎤
⎥⎦, (5.102)

<<<PAGE 183>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
5.4 Quantum Gates 165
the controlled- Uoperation can be seen to be
CU=⎡
⎢⎢⎢⎢⎢⎢⎢⎣1000
0100
00 ab
00 cd⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (5.103)
This same construction works for matrices larger than 2-by-2.
Exercise 5.4.7 Show that the constructed
CUworks as it should when the top qubit
is set to |0/angbracketrightor set to |1/angbracketright. /squaresolid
Exercise 5.4.8 Show that if Uis unitary, then so isCU. /squaresolid
Exercise 5.4.9 Show that the Toffoli gate is nothing more thanC(CNOT). /squaresolid
It is well known that every logical circuit can be simulated using only the AND
gate and the NOT gate. We say that {AND, NOT }forms a set of universal logical
gates. The NAND gate by itself is also a universal logical gate. We have also seen in
Section 5.3 that both the Toffoli gate and the Fredkin gate are each universal logic
gates. This leads to the obvious question: are there sets of quantum gates that can
simulate all quantum gates? In other words, are there universal quantum gates?T h e
answer is yes.3One set of universal quantum gates is
/braceleftbigg
H,CNOT, R/parenleftbigg
cos−1/parenleftbigg3
5/parenrightbigg/parenrightbigg/bracerightbigg
, (5.104)
that is, the Hadamard gate, the controlled-NOT gate, and this phase shift gate.
There is also a quantum gate called the Deutsch gate ,D(θ), depicted as
|x/angbracketright
•|x/angbracketright
|y/angbracketright
•|y/angbracketright
|z/angbracketright
R(θ)|z/prime/angbracketright(5.105)
3We must clarify what we mean by “simulate.” In the classical world, we say that one circuit Circ sim-
ulates another circuit Circ/primeif for any possible inputs, the output for Circ will be the same for Circ/prime.
Things in the quantum world are a tad more complicated. Because of the probabilistic nature of quan-tum computation, the outputs of a circuit are always probabilistic. So we have to reformulate what wemean when we talk about simulate. We shall not worry about this here.

<<<PAGE 184>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
166 Architecture
which is very similar to the Toffoli gate. If the inputs |x/angbracketrightand|y/angbracketrightare both |1/angbracketright, then the
phase shift operation R(θ) will act on the |z/angbracketrightinput. Otherwise, the |z/prime/angbracketrightwill simply be
the same as the |z/angbracketright. When θis not a rational multiple of π,D(θ) by itself is a universal
three-qubit quantum gate. In other words, D(θ) will be able to mimic every other
quantum gate.
Exercise 5.4.10 Show that the Toffoli gate is nothing more than D(π
2). /squaresolid
Throughout the rest of this text, we shall demonstrate many of the operations
that can be performed with quantum gates. However, there are limitations to what
can be done with them. For one thing, every operation must be reversible. Another
limitation is a consequence of the the No-Cloning Theorem. This theorem says that
it is impossible to clone an exact quantum state. In other words, it is impossible to
make a copy of an arbitrary quantum state without ﬁrst destroying the original. In
“computerese,” this says that we can “cut” and “paste” a quantum state, but we
cannot “copy” and “paste” it. “Move is possible. Copy is impossible.”
What is the difﬁculty? How would such a cloning operation look? Let Vrepre-
sent a quantum system. As we intend to clone states in this system, we shall “dou-ble” this vector space and deal with V⊗V. A potential cloning operation would be
a linear map (indeed unitary!)
C:V⊗V−→V⊗V, (5.106)
that should take an arbitrary state |x/angbracketrightin the ﬁrst system and, perhaps, nothing in the
second system and clone |x/angbracketright, i.e.,
C(|x/angbracketright⊗0)=(|x/angbracketright⊗| x/angbracketright). (5.107)
This seems like a harmless enough operation, but is it? If Cis a candidate for
cloning, then certainly on the basic states
C(|0/angbracketright⊗| 0/angbracketright)=|0/angbracketright⊗| 0/angbracketright and C(|1/angbracketright⊗| 0/angbracketright)=|1⊗|1/angbracketright. (5.108)
Because Cmust be linear, we should have that
C((c
1|0/angbracketright+ c2|1/angbracketright)⊗|0/angbracketright)=c1|0/angbracketright⊗| 0/angbracketright+ c2|1/angbracketright⊗| 1/angbracketright, (5.109)
for an arbitrary quantum state, i.e., an arbitrary superposition of|0/angbracketrightand|1/angbracketright. Suppose
we start with|x/angbracketright+|y/angbracketright√
2. Cloning such a state would mean that
C/parenleftbigg|x/angbracketright+| y/angbracketright√
2⊗0/parenrightbigg
=/parenleftbigg|x/angbracketright+| y/angbracketright√
2⊗|x/angbracketright+| y/angbracketright√
2/parenrightbigg
. (5.110)
However, if we insist that Cis a quantum operation, then Cmust be linear,4and
hence, must respect the addition and the scalar multiplication in V⊗V.I f Cwas
4Just a reminder: Cbeing linear means that
C(|φ/angbracketright+|ψ/angbracketright)=C(|φ/angbracketright)+C(|ψ/angbracketright) (5.111)
and
C(c|φ/angbracketright)=cC(|φ/angbracketright). (5.112)

<<<PAGE 185>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
5.4 Quantum Gates 167
linear, then
C/parenleftbigg|x/angbracketright+| y/angbracketright√
2⊗0/parenrightbigg
=C/parenleftbigg1√
2(|x/angbracketright+| y/angbracketright)⊗0/parenrightbigg
=1√
2C((|x/angbracketright+| y/angbracketright)⊗0)
=1√
2(C(|x/angbracketright⊗0+|y/angbracketright⊗0))=1√
2(C(|x/angbracketright⊗0)+C(|y/angbracketright⊗0))
=1√
2((|x/angbracketright⊗| x/angbracketright)+(|y/angbracketright⊗| y/angbracketright))=(|x/angbracketright⊗| x/angbracketright)+(|y/angbracketright⊗| y/angbracketright)√
2.
(5.113)
But
/parenleftbigg|x/angbracketright+| y/angbracketright√
2⊗|x/angbracketright+| y/angbracketright√
2/parenrightbigg
/negationslash=(|x/angbracketright⊗| x/angbracketright)+(|y/angbracketright⊗| y/angbracketright)√
2. (5.114)
SoCis not a linear map,5and hence is not permitted.
In contrast to cloning, there is no problem transporting arbitrary quantum states
from one system to another. Such a transporting operation would be a linear map
T:V⊗V−→V⊗V, (5.115)
that should take an arbitrary state |x/angbracketrightin the ﬁrst system and, say, nothing in the
second system, and transport |x/angbracketrightto the second system, leaving nothing in the ﬁrst
system, i.e.,
T(|x/angbracketright⊗0)=(0⊗|x/angbracketright). (5.116)
We do not run into the same problem as earlier if we transport a superposition of
states. In detail,
T/parenleftbigg|x/angbracketright+| y/angbracketright√
2⊗0/parenrightbigg
=T/parenleftbigg1√
2(|x/angbracketright+| y/angbracketright)⊗0/parenrightbigg
=1√
2T((|x/angbracketright+| y/angbracketright)⊗0)=1√
2T((|x/angbracketright⊗0)+(|y/angbracketright⊗0))
=1√
2(T(|x/angbracketright⊗0)+T(|y/angbracketright⊗0))=1√
2((0⊗|x/angbracketright)+(0⊗|y/angbracketright))
=(|0⊗(|x/angbracketright+| y/angbracketright)√
2=0⊗(|x/angbracketright+| y/angbracketright)√
2. (5.117)
This is exactly what we would expect from a transporting operation.6
Fans of Star Trek have long known that when Scotty “beams” Captain Kirk
down from the Starship Enterprise to the planet Zygon, he is transporting Captain
Kirk to Zygon. The Kirk of the Enterprise gets destroyed and only the Zygon Kirksurvives. Captain Kirk is not being cloned. He is being transported. (Would we re-
ally want many copies of Captain Kirk all over the Universe?)
5Cis, however, a legitimate set map.
6In fact, we will show how to transport arbitrary quantum states at the end of Chapter 9.

<<<PAGE 186>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
168 Architecture
The reader might see an apparent contradiction in what we have stated. On
the one hand, we have stated that the Toffoli and Fredkin gates can mimic the
fanout gate. The matrices for the Toffoli and Fredkin gates are unitary, and hence
they are quantum gates. On the other hand, the no-cloning theorem says that noquantum gates can mimic the fanout operation. What is wrong here? Let us care-fully examine the Fredkin gate. We have seen how this gate performs the cloning
operation
(x,1,0)/mapsto→ (x,¬x,x). (5.118)
However, what would happen if the xinput was in a superposition of states say,
|0/angbracketright+|1/angbracketright√
2, while leaving y=1 and z=0. This would correspond to the state
/bracketleftBig000 001 010 011 100 101 110 111
001√
20001√
20/bracketrightBigT
. (5.119)
Multiplying this state with the Fredkin gate gives us
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣000 001 010 011 100 101 110 111
000 10000000
001 01000000
010 00100000
011 00010000
100 00001000
101 00000010
110 00000100
111 00000001⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣0
0
1√
2
00
0
1√
2
0⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣0
0
1√
2
00
1√
2
00⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦.(5.120)
The resulting state is
|0,1,0/angbracketright+| 1,0,1/angbracketright
√
2. (5.121)
So, whereas on a classical bit x, the Fredkin gate performs the fanout operation,
on a superposition of states the Fredkin gate performs the following very strange
operation:
/parenleftbigg|0/angbracketright+| 1/angbracketright√
2,1,0/parenrightbigg
/mapsto→|0,1,0/angbracketright+| 1,0,1/angbracketright√
2. (5.122)
This strange operation is not a fanout operation. Thus, the no-cloning theorem
safely stands.
Exercise 5.4.11 Do a similar analysis for the Toffoli gate. Show that the way we set
the Toffoli gate to perform the fanout operation does not clone a superposition of
states. /squaresolid

<<<PAGE 187>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
5.4 Quantum Gates 169
.................................................................................
Reader Tip. The no-cloning theorem is of major importance in Chapter 9. ♥.................................................................................
.................................................................................
References: The basics of qubits and quantum gates can be found in any text-
book on quantum computing. They were ﬁrst formulated by David Deutsch in 1989
(Deutsch, 1989).
Section 5.2 is simply a reformulation of basic computer architecture in terms of
matrices.
The history of reversible computation can be found in Bennett (1988). The read-
able article (Landauer, 1991) by one of the forefathers of reversible computation is
strongly recommended.
The no-cloning theorem was ﬁrst proved in Dieks (1982) and Wootters and
Zurek (1982).

<<<PAGE 188>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6
Algorithms
Computer Science is no more about computers than astron-
omy is about telescopes.
E.W. Dijkstra
Algorithms are often developed long before the machines they are supposed to
run on. Classical algorithms predate classical computers by millennia, and similarly,
there exist several quantum algorithms before any large-scale quantum computershave seen the light of day. These algorithms manipulate qubits to solve problemsand, in general, they solve these tasks more efﬁciently than classical computers.
Rather than describing the quantum algorithms in the chronological order in
which they were discovered, we choose to present them in order of increasing dif-ﬁculty. The core ideas of each algorithm are based on previous ones. We start at
tutorial pace, introducing new concepts in a thorough way. Section 6.1 describes
Deutsch’s algorithm that determines a property of functions from {0,1}to{0,1}.
In Section 6.2 we generalize this algorithm to the Deutsch–Jozsa algorithm, which
deals with a similar property for functions from {0,1}
nto{0,1}. Simon’s period-
icity algorithm is described in Section 6.3. Here we determine patterns of a func-
tion from {0,1}nto{0,1}n. Section 6.4 goes through Grover’s search algorithm
that can search an unordered array of size nin√ntime as opposed to the usual
ntime. The chapter builds up to the ground-breaking Shor’s factoring algorithm
done in Section 6.5. This quantum algorithm can factor numbers in polynomialtime. There are no known classical algorithms that can perform this feat in such
time.
.................................................................................
Reader Tip. This chapter may be a bit overwhelming on the ﬁrst reading. After
reading Section 6.1, the reader can move on to Section 6.2 or Section 6.4. Shor’salgorithm can safely be read after Section 6.2. ♥.................................................................................
170

<<<PAGE 189>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.1 Deutsch’s Algorithm 171
6.1 DEUTSCH’S ALGORITHM
All quantum algorithms work with the following basic framework:/D2The system will start with the qubits in a particular classical state./D2From there the system is put into a superposition of many states./D2This is followed by acting on this superposition with several unitary operations./D2And ﬁnally, a measurement of the qubits.
Of course, there will be several variations of this theme. Nevertheless, it will be
helpful to keep this general scheme in mind as we proceed.
The simplest quantum algorithm is Deutsch’s algorithm, which is a nice algo-
rithm that solves a slightly contrived problem. This algorithm is concerned withfunctions from the set {0,1}to the set {0,1}. There are four such functions that might
be visualized as
0•/d31 /d47/d47
•00 •/d31 /d47/d47•00 •/d1
/d32/d32/d65/d65/d65/d65/d65/d65/d65/d65•00 •/d1
/d32/d32/d65/d65/d65/d65/d65/d65/d65/d65•0
1•/d61/d62/d62/d125/d125/d125/d125/d125/d125/d125/d125
•11 •/d31 /d47/d47•11 •/d61/d62/d62/d125/d125/d125/d125/d125/d125/d125/d125
•11 •/d31 /d47/d47•1(6.1)
Call a function f:{0,1}− →{ 0,1}balanced iff(0)/negationslash=f(1), i.e., it is one to one.
In contrast, call a function constant iff(0)=f(1). Of the four functions, two are
balanced and two are constant.
Deutsch’s algorithm solves the following problem: Given a function f:
{0,1}− →{ 0,1}as a black box, where one can evaluate an input, but cannot “look
inside” and “see” how the function is deﬁned, determine if the function is balancedor constant.
With a classical computer, one would have to ﬁrst evaluate fon one input, then
evaluate fon the second input, and ﬁnally, compare the outputs. The following
decision tree shows what a classical computer must do:
•
/d122/d122/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117
/d36/d36/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73
f(0)=0
/d3/d3/d8/d8/d8/d8/d8/d8/d8/d8/d8/d8/d8/d8/d8/d8
/d27/d27/d54/d54/d54/d54/d54/d54/d54/d54/d54/d54/d54/d54/d54/d54f(0)=1
/d3/d3/d8/d8/d8/d8/d8/d8/d8/d8/d8/d8/d8/d8/d8/d8
/d27/d27/d54/d54/d54/d54/d54/d54/d54/d54/d54/d54/d54/d54/d54/d54
f(0)=0
f(1)=0
Constantf(0)=0
f(1)=1
Balancedf(0)=1
f(1)=0
Balancedf(0)=1
f(1)=1
Constant(6.2)
The point is that with a classical computer, fmust be evaluated twice. Can we
do better with a quantum computer?

<<<PAGE 190>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
172 Algorithms
A quantum computer can be in a superposition of two basic states at the same
time. We shall use this superposition of states to evaluate both inputs at one time.
In classical computing, evaluating a given function fcorresponds to performing
the following operation:
x
ff(x)
(6.3)
As we discussed in Chapter 5, such a function can be thought of as a matrix
acting on the input. For instance, the function
0•/d1
/d32/d32/d65/d65/d65/d65/d65/d65/d65/d65•0
1•/d61/d62/d62/d125/d125/d125/d125/d125/d125/d125/d125
•1(6.4)
is equivalent to the matrix
/bracketleftBigg01
001
110/bracketrightBigg
. (6.5)
Multiplying state |0/angbracketrighton the right of this matrix would result in state |1/angbracketright, and multi-
plying state |1/angbracketrighton the right of this matrix would result in state |0/angbracketright. The column name
is to be thought of as the input and the row name as the output.
Exercise 6.1.1 Describe the matrices for the other three functions from {0,1}to
{0,1}. /squaresolid
However, this will not be enough for a quantum system. Such a system demands
a little something extra: every gate must be unitary (and thus reversible). Given the
output, we must be able to ﬁnd the input. If fis the name of the function, then the
following black-box Ufwill be the quantum gate that we shall employ to evaluate
input:
|x/angbracketright
Uf|x/angbracketright
|y/angbracketright |y⊕f(x)/angbracketright(6.6)
The top input, |x/angbracketright, will be the qubit value that one wishes to evaluate and the
bottom input, |y/angbracketright, controls the output. The top output will be the same as the input
qubit|x/angbracketrightand the bottom output will be the qubit |y⊕f(x)/angbracketright, where ⊕is XOR, the
exclusive-or operation (binary addition modulo 2.) We are going to write from left
to right the top qubit ﬁrst and then the bottom. So we say that this function takes thestate|x,y/angbracketrightto the state |x,y⊕f(x)/angbracketright.I f y=0, this simpliﬁes |x,0/angbracketrightto|x,0⊕f(x)/angbracketright=
|x,f(x)/angbracketright.This gate can be seen to be reversible as we may demonstrate by simply

<<<PAGE 191>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.1 Deutsch’s Algorithm 173
looking at the following circuit:
|x/angbracketright
Uf|x/angbracketright
Uf|x/angbracketright
|y/angbracketright |y⊕f(x)/angbracketright |y/angbracketright
(6.7)
State|x,y/angbracketrightgoes to |x,y⊕f(x)/angbracketright, which further goes to
|x,(y⊕f(x))⊕f(x)/angbracketright=| x,y⊕(f(x)⊕f(x))/angbracketright=| x,y⊕0/angbracketright=| x,y/angbracketright,(6.8)
where the ﬁrst equality is due to the associativity of ⊕and the second equality holds
because ⊕is idempotent. From this we see that Ufis its own inverse.
In quantum systems, evaluating fis equivalent to multiplying a state by the uni-
tary matrix Uf. For function (6.4), the corresponding unitary matrix, Uf,i s
⎡
⎢⎢⎢⎣00 01 10 11
00 0100
01 1000
10 0010
11 0001⎤
⎥⎥⎥⎦. (6.9)
Remember that the top column name corresponds to the input |x,y/angbracketrightand the
left-hand row name corresponds to the outputs |x/prime,y/prime/angbracketright.A1i nt h e xycolumn and the
x/primey/primerow means that for input |x,y/angbracketright, the output will be |x/prime,y/prime/angbracketright.
Exercise 6.1.2 What is the adjoint of the matrix given in Equation (6.9)? Show that
this matrix is its own inverse. /squaresolid
Exercise 6.1.3 Give the unitary matrices that correspond to the other three func-
tions from {0,1}to{0,1}. Show that each of the matrices is its own adjoint and hence
all are reversible and unitary. /squaresolid
Let us remind ourselves of the task at hand. We are given such a matrix that ex-
presses a function but we cannot “look inside” the matrix to “see” how it is deﬁned.
We are asked to determine if the function is balanced or constant.
Let us take a ﬁrst stab at a quantum algorithm to solve this problem. Rather than
evaluating ftwice, we shall try our trick of superposition of states. Instead of having
the top input to be either in state |0/angbracketrightor in state |1/angbracketright, we shall put the top input in state
|0/angbracketright+| 1/angbracketright√
2, (6.10)
which is “half-way” |0/angbracketrightand “half-way” |1/angbracketright. The Hadamard matrix can place a qubit
in such a state.
H|0/angbracketright=⎡
⎢⎣1√
21√
2
1√
2−1√
2⎤
⎥⎦⎡
⎢⎣1
0⎤
⎥⎦=⎡
⎢⎣1√
2
1√
2⎤
⎥⎦=|0/angbracketright+| 1/angbracketright√
2. (6.11)

<<<PAGE 192>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
174 Algorithms
The obvious (but not necessarily correct) state to put the bottom input into is state
|0/angbracketright. Thus we have the following quantum circuit:
|0/angbracketright
H
Uf
|0/angbracketright
/d70/d69/d13/d13/d13
⇑
|ϕ0/angbracketright⇑
|ϕ1/angbracketright⇑
|ϕ2/angbracketright(6.12)
The|ϕj/angbracketrightat the bottom of the quantum circuit will be used to describe the state
of the qubits at each time click.
In terms of matrices this circuit corresponds to
Uf(H⊗I)(|0/angbracketright⊗| 0/angbracketright)=Uf(H⊗I)(|0, 0/angbracketright). (6.13)
The tensor product |0,0/angbracketrightcan be written as
⎡
⎢⎢⎢⎣00 1
01 0
10 0
11 0⎤
⎥⎥⎥⎦(6.14)
and the entire circuit is then
Uf(H⊗I)⎡
⎢⎢⎢⎣00 1
01 0
10 0
11 0⎤
⎥⎥⎥⎦. (6.15)
We shall carefully examine the states of the system at every time click. The sys-
tem starts in
|ϕ
0/angbracketright=| 0/angbracketright⊗| 0/angbracketright=| 0,0/angbracketright. (6.16)
We then apply the Hadamard matrix only to the top input – leaving the bottom
input alone – to get
|ϕ1/angbracketright=/bracketleftbigg|0/angbracketright+| 1/angbracketright√
2/bracketrightbigg
|0/angbracketright=|0,0/angbracketright+| 1,0/angbracketright√
2. (6.17)

<<<PAGE 193>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.1 Deutsch’s Algorithm 175
After multiplying with Uf, we have
|ϕ2/angbracketright=|0,f(0)/angbracketright+| 1,f(1)/angbracketright√
2. (6.18)
For function (6.4), the state |ϕ2/angbracketrightwould be
|ϕ2/angbracketright=⎡
⎢⎢⎢⎣00 01 10 11
00 0100
01 1000
10 0010
11 0001⎤
⎥⎥⎥⎦⎡
⎢⎢⎢⎣001√
2
01 0
101√
2
11 0⎤
⎥⎥⎥⎦=⎡
⎢⎢⎢⎢⎣00 0
01 1√
2
101√
2
11 0⎤
⎥⎥⎥⎥⎦=|0,1/angbracketright+| 1,0/angbracketright
√
2. (6.19)
Exercise 6.1.4 Using the matrices calculated in Exercise 6.1.3, determine the state
|ϕ2/angbracketrightfor the other three functions. /squaresolid
If we measure the top qubit, there will be a 50–50 chance of ﬁnding it in state |0/angbracketright
and a 50–50 chance of ﬁnding it in state |1/angbracketright. Similarly, there is no real information to
be gotten by measuring the bottom qubit. So the obvious algorithm does not work.
We need a better trick.
Let us take another stab at solving our problem. Rather than leaving the bottom
qubit in state |0/angbracketright, let us put it in the superposition state:
|0/angbracketright−| 1/angbracketright√
2=⎡
⎢⎣1√
2
−1√
2⎤
⎥⎦. (6.20)
Notice the minus sign. Even though there is a negation, this state is also “half-way”
in state |0/angbracketrightand “half-way” in state |1/angbracketright. This change of phase will help us get our
desired results. We can get to this superposition of states by multiplying state |1/angbracketright
with the Hadamard matrix. We shall leave the top qubit as an ambiguous |x/angbracketright.
|x/angbracketright
Uf
|1/angbracketright
H/d70/d69/d13/d13/d13
⇑
|ϕ0/angbracketright⇑
|ϕ1/angbracketright⇑
|ϕ2/angbracketright(6.21)
In terms of matrices, this becomes
Uf(I⊗H)|x,1/angbracketright. (6.22)

<<<PAGE 194>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
176 Algorithms
Let us look carefully at how the states of the qubits change.
|ϕ0/angbracketright=| x,1/angbracketright. (6.23)
After the Hadamard matrix, we have
|ϕ1/angbracketright=| x/angbracketright/bracketleftbigg|0/angbracketright−| 1/angbracketright√
2/bracketrightbigg
=|x,0/angbracketright−| x,1/angbracketright√
2. (6.24)
Applying Uf, we get
|ϕ2/angbracketright=| x/angbracketright/bracketleftbigg|0⊕f(x)/angbracketright−| 1⊕f(x)/angbracketright√
2/bracketrightbigg
=|x/angbracketright/bracketleftBigg
|f(x)/angbracketright−| f(x)/angbracketright√
2/bracketrightBigg
, (6.25)
where f(x) means the opposite of f(x). Therefore, we have
|ϕ2/angbracketright=⎧
⎪⎨
⎪⎩|x/angbracketright/bracketleftBig
|0/angbracketright−|1/angbracketright√
2/bracketrightBig
,iff(x)=0,
|x/angbracketright/bracketleftBig
|1/angbracketright−|0/angbracketright√
2/bracketrightBig
,iff(x)=1.(6.26)
Remembering that a−b=(−1)(b−a), we might write this as
|ϕ2/angbracketright=(−1)f(x)|x/angbracketright/bracketleftbigg|0/angbracketright−| 1/angbracketright√
2/bracketrightbigg
. (6.27)
What would happen if we evaluate either the top or the bottom state? Again,
this does not really help us. We do not gain any information if we measure the top
qubit or the bottom qubit. The top qubit will be in state |x/angbracketrightand the bottom qubit
will be either in state |0/angbracketrightor in state |1/angbracketright. We need something more.
Now let us combine both these attempts to actually give Deutsch’s algorithm.
Deutsch’s algorithm works by putting both the top and the bottom qubits into
a superposition. We will also put the results of the top qubit through a Hadamard
matrix.
|0/angbracketright
H
UfH/d70/d69/d13/d13/d13
|1/angbracketright
H
⇑
|ϕ0/angbracketright⇑
|ϕ1/angbracketright⇑
|ϕ2/angbracketright⇑
|ϕ3/angbracketright(6.28)
In terms of matrices this becomes
(H⊗I)Uf(H⊗H)|0,1/angbracketright (6.29)

<<<PAGE 195>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.1 Deutsch’s Algorithm 177
or
(H⊗I)Uf(H⊗H)⎡
⎢⎢⎢⎣00 0
01 1
10 0
11 0⎤
⎥⎥⎥⎦. (6.30)
At each point of the algorithm the states are as follows:
|ϕ
0/angbracketright=| 0,1/angbracketright, (6.31)
|ϕ1/angbracketright=/bracketleftbigg|0/angbracketright+| 1/angbracketright√
2/bracketrightbigg/bracketleftbigg|0/angbracketright−| 1/angbracketright√
2/bracketrightbigg
=+|0,0/angbracketright−| 0,1/angbracketright+| 1,0/angbracketright−| 1,1/angbracketright
2=⎡
⎢⎢⎢⎢⎣00+
1
2
01−1
2
10+1
2
11−1
2⎤
⎥⎥⎥⎥⎦.
(6.32)
We saw from our last attempt at solving this problem that when we put the bottom
qubit into a superposition and then multiply by U
f, we will be in the superposition
(−1)f(x)|x/angbracketright/bracketleftbigg|0/angbracketright−| 1/angbracketright√
2/bracketrightbigg
. (6.33)
Now, with |x/angbracketrightin a superposition, we have
|ϕ2/angbracketright=/bracketleftBigg
(−1)f(0)|0/angbracketright+ (−1)f(1)|1/angbracketright√
2/bracketrightBigg/bracketleftbigg|0/angbracketright−| 1/angbracketright√
2/bracketrightbigg
. (6.34)
For example, if f(0)=1 and f(1)=0, the top qubit becomes
(−1)|0/angbracketright+ (+1)|1/angbracketright√
2=(−1)/bracketleftbigg|0/angbracketright−| 1/angbracketright√
2/bracketrightbigg
. (6.35)
Exercise 6.1.5 For each of the other three functions from the set {0,1}to the set
{0,1}, describe what |ϕ2/angbracketrightwould be. /squaresolid
For a general function f, let us look carefully at
(−1)f(0)|0/angbracketright+ (−1)f(1)|1/angbracketright. (6.36)
Iffis constant, this becomes either
+1(|0/angbracketright+| 1/angbracketright)o r−1(|0/angbracketright+| 1/angbracketright) (6.37)
(depending on being constantly 0 or constantly 1).

<<<PAGE 196>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
178 Algorithms
Iffis balanced, it becomes either
+1(|0/angbracketright−| 1/angbracketright)o r−1(|0/angbracketright−| 1/angbracketright) (6.38)
(depending on which way it is balanced).
Summing up, we have that
|ϕ2/angbracketright=⎧
⎪⎨
⎪⎩(±1)/bracketleftBig
|0/angbracketright+|1/angbracketright√
2/bracketrightBig/bracketleftBig
|0/angbracketright−|1/angbracketright√
2/bracketrightBig
,iffis constant ,
(±1)/bracketleftBig
|0/angbracketright−|1/angbracketright√
2/bracketrightBig/bracketleftBig
|0/angbracketright−|1/angbracketright√
2/bracketrightBig
,iffis balanced .(6.39)
Remembering that the Hadamard matrix is its own inverse that takes|0/angbracketright+|1/angbracketright√
2to
|0/angbracketrightand takes|0/angbracketright−|1/angbracketright√
2to|1/angbracketright, we apply the Hadamard matrix to the top qubit to get
|ϕ3/angbracketright=⎧
⎪⎨
⎪⎩(±1)|0/angbracketright/bracketleftBig
|0/angbracketright−|1/angbracketright√
2/bracketrightBig
,iffis constant ,
(±1)|1/angbracketright/bracketleftBig
|0/angbracketright−|1/angbracketright√
2/bracketrightBig
,iffis balanced .(6.40)
For example, if f(0)=1 and f(1)=0, then we get
|ϕ3/angbracketright=− 1|0/angbracketright/bracketleftbigg|0/angbracketright−| 1/angbracketright√
2/bracketrightbigg
. (6.41)
Exercise 6.1.6 For each of the other three functions from the set {0,1}to the set
{0,1}, calculate the value of |ϕ3/angbracketright. /squaresolid
Now, we simply measure the top qubit. If it is in state |0/angbracketright, then we know that fis a
constant function, otherwise it is a balanced function. This was all accomplished with
only one function evaluation as opposed to the two evaluations that the classical
algorithm demands.
Notice that although the ±1 tells us even more information, namely, which of
the two balanced functions or two constant functions we have, measurement will
not grant us this information. Upon measuring, if the function is balanced, we will
measure |1/angbracketrightregardless if the state was ( −1)|1/angbracketrightor (+1)|1/angbracketright.
The reader might be bothered by the fact that the output of the top qubit of
Ufshould not change from being the same as the input. However, the inclusion of
the Hadamard matrices changes things around, as we saw in Section 5.3. This is the
essence of the fact that the top and the bottom qubits are entangled.
Did we perform a magic trick here? Did we gain information that was not there?
Not really. There are four possible functions, and we saw in decision tree (6.2) thatwith a classical computer we needed two bits of information to determine which ofthe four functions we were given. What we are really doing here is changing around
the information. We might determine which of the four functions is the case by ask-
ing the following two questions: “Is the function balanced or constant?” and “What

<<<PAGE 197>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.2 The Deutsch–Jozsa Algorithm 179
is the value of the function on 0?” The answers to these two questions uniquely
describe each of the four functions, as described by the following decision tree:
•
/d122/d122/d116/d116/d116/d116/d116/d116/d116/d116/d116/d116/d116/d116/d116/d116/d116/d116/d116/d116/d116/d116/d116
/d36/d36/d74/d74/d74/d74/d74/d74/d74/d74/d74/d74/d74/d74/d74/d74/d74/d74/d74/d74/d74/d74/d74
Balanced
/d3/d3/d6/d6/d6/d6/d6/d6/d6/d6/d6/d6/d6/d6/d6/d6
/d27/d27/d56/d56/d56/d56/d56/d56/d56/d56/d56/d56/d56/d56/d56/d56Constant
/d3/d3/d6/d6/d6/d6/d6/d6/d6/d6/d6/d6/d6/d6/d6/d6
/d27/d27/d56/d56/d56/d56/d56/d56/d56/d56/d56/d56/d56/d56/d56/d56
f(0)=0
f(1)=1f(0)=1
f(1)=0f(0)=0
f(1)=0f(0)=1
f(1)=1(6.42)
The Hadamard matrices are changing the question that we are asking (change
of basis). The intuition behind the Deutsch algorithm is that we are really just per-
forming a change of basis problem as discussed at the end of Section 2.3. We mightrewrite quantum circuit (6.28) as
|0/angbracketright
H
UfH/d70/d69/d13/d13/d13
|1/angbracketright
H/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d31
/d31
/d31/d31
/d31
/d31/d31/d31
/d31
/d31/d31
/d31
/d31/d31
/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95(6.43)
We start in the canonical basis. The ﬁrst Hadamard matrix is used as a change
of basis matrix to go into a balanced superposition of basic states. While in this
noncanonical basis, we evaluate fwith the bottom qubit in a superposition. The last
Hadamard matrix is used as a change of basis matrix to revert back to the canonicalbasis.
6.2 THE DEUTSCH–JOZSA ALGORITHM
Let us generalize the Deutsch algorithm to other functions. Rather than talkingabout functions f:{0,1}− →{ 0,1}, let us talk about functions with a larger domain.
Consider functions f:{0,1}
n−→ { 0,1}, which accept a string of n0’s and 1’s and
outputs a zero or one. The domain might be thought of as any natural number from0t o2
n−1.
We shall call a function f:{0,1}n−→ { 0,1}balanced if exactly half of the inputs
go to 0 (and the other half go to 1). Call a function constant ifallthe inputs go to 0
orallthe inputs go to 1.

<<<PAGE 198>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
180 Algorithms
Exercise 6.2.1 How many functions are there from {0,1}nto{0,1}? How many of
them are balanced? How many of them are constant? /squaresolid
The Deutsch–Jozsa algorithm solves the following problem: Suppose you are
given a function from {0,1}nto{0,1}which you can evaluate but cannot “see” the
way it is deﬁned. Suppose further that you are assured that the function is either
balanced or constant. Determine if the function is balanced or constant. Notice that
when n=1, this is exactly the problem that the Deutsch algorithm solved.
Classically, this algorithm can be solved by evaluating the function on different
inputs. The best case scenario is when the ﬁrst two different inputs have differentoutputs, which assures us that the function is balanced. In contrast, to be sure that
the function is constant, one must evaluate the function on more than half the pos-sible inputs. So the worst case scenario requires
2n
2+1=2n−1+1 function evalua-
tions. Can we do better?
In the last section, we solved the problem by entering into a superposition of two
possible input states. In this section, we solve the problem by entering a superposi-tion of all 2
npossible input states.
The function fwill be given as a unitary matrix that we shall depict as
|x/angbracketright
/n
Uf/n|x/angbracketright
|y/angbracketright |f(x)⊕y/angbracketright(6.44)
with nqubits (denoted as /n) as the top input and output. For the rest of
this chapter, a binary string is denoted by a boldface letter. So we write the top input
as|x/angbracketright=| x0x1...xn−1/angbracketright. The bottom entering control qubit is |y/angbracketright. The top output is
|x/angbracketrightwhich will not be changed by Uf. The bottom output of Ufis the single qubit
|y⊕f(x)/angbracketright. Remember that although xisnbits, f(x) is one bit and hence we can use
the binary operation ⊕. It is not hard to see that Ufis its own inverse.
Example 6.2.1 Consider the following balanced function from {0,1}2to{0,1}:
00•/d113
/d24/d24/d49/d49/d49/d49/d49/d49/d49/d49/d49/d49/d49/d49/d49/d49/d49
01•/d3
/d33/d33/d67/d67/d67/d67/d67/d67/d67/d67•0
10•/d59/d61/d61/d123/d123/d123/d123/d123/d123/d123/d123
•1
11•/d77/d70/d70/d13/d13/d13/d13/d13/d13/d13/d13/d13/d13/d13/d13/d13/d13/d13(6.45)

<<<PAGE 199>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.2 The Deutsch–Jozsa Algorithm 181
This function shall be represented by the following 8-by-8 unitary matrix:
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣00,00 0 ,10 1 ,00 1 ,11 0 ,01 0 ,11 1 ,01 1 ,1
00,0 1
00,1 1
01,0 1
01,1 1
10,0 1
10,1 1
11,0 1
11,1 1⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦(6.46)
(the zeros are omitted for readability). /square
Exercise 6.2.2 Consider the balanced function from {0,1}
2to{0,1}:
00•/d3
/d33/d33/d67/d67/d67/d67/d67/d67/d67/d67
01•/d31 /d47/d47•0
10•/d31 /d47/d47•1
11•/d59/d61/d61/d123/d123/d123/d123/d123/d123/d123/d123(6.47)
Give the corresponding 8-by-8 unitary matrix. /squaresolid
Exercise 6.2.3 Consider the function from {0,1}2to{0,1}that always outputs a 1.
Give the corresponding 8-by-8 unitary matrix. /squaresolid
In order to place a single qubit in a superposition of |0/angbracketrightand|1/angbracketright, we used a single
Hadamard matrix. To place nqubits in a superposition, we are going to use the
tensor product of nHadamard matrices. What does such a tensor product look like?
It will be helpful to do some warm-up exercises. Let us calculate H,H⊗Hwhich
we may write as H⊗2, and H⊗H⊗H=H⊗3; and look for a pattern. Our goal will
be to ﬁnd a pattern for H⊗n.
Remember that the Hadamard matrix is deﬁned as
H=1√
2/bracketleftBigg01
011
11−1/bracketrightBigg
. (6.48)

<<<PAGE 200>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
182 Algorithms
Notice that H[i,j]=1√
2(−1)i∧j, where iand jare the row and column numbers in
binary and ∧is the AND operation. We might then write the Hadamard matrix as
H=1√
2/bracketleftBigg01
0(−1)0∧0(−1)0∧1
1(−1)1∧0(−1)1∧1/bracketrightBigg
. (6.49)
Notice that we are thinking of 0 and 1 as both Boolean values and numbers that are
exponents. (Remember: ( −1)0=1 and (−1)1=−1.) With this trick in mind we can
then calculate
H⊗2=H⊗H=1√
2/bracketleftBigg01
0 (−1)0∧0(−1)0∧1
1 (−1)1∧0(−1)1∧1/bracketrightBigg
⊗1√
2/bracketleftBigg01
0 (−1)0∧0(−1)0∧1
1 (−1)1∧0(−1)1∧1/bracketrightBigg
=1√
2∗1√
2⎡
⎢⎢⎢⎣00 01 10 11
00 (−1)0∧0∗(−1)0∧0(−1)0∧0∗(−1)0∧1(−1)0∧1∗(−1)0∧0(−1)0∧1∗(−1)0∧1
01 (−1)0∧0∗(−1)1∧0(−1)0∧0∗(−1)1∧1(−1)0∧1∗(−1)1∧0(−1)0∧1∗(−1)1∧1
10 (−1)1∧0∗(−1)0∧0(−1)1∧0∗(−1)0∧1(−1)1∧1∗(−1)0∧0(−1)1∧1∗(−1)0∧1
11 (−1)1∧0∗(−1)1∧0(−1)1∧0∗(−1)1∧1(−1)1∧1∗(−1)1∧0(−1)1∧1∗(−1)1∧1⎤
⎥⎥⎥⎦
(6.50)
When we multiply ( −1)xby (−1)y, we are not interested in ( −1)x+y. Rather, we
are interested in the parity of xand y. So we shall not add xand ybut take their
exclusive-or ( ⊕). This leaves us with
H⊗2=1
2⎡
⎢⎢⎢⎣00 01 10 11
00 (−1)0∧0⊕0∧0(−1)0∧0⊕0∧1(−1)0∧1⊕0∧0(−1)0∧1⊕0∧1
01 (−1)0∧0⊕1∧0(−1)0∧0⊕1∧1(−1)0∧1⊕1∧0(−1)0∧1⊕1∧1
10 (−1)1∧0⊕0∧0(−1)1∧0⊕0∧1(−1)1∧1⊕0∧0(−1)1∧1⊕0∧1
11 (−1)1∧0⊕1∧0(−1)1∧0⊕1∧1(−1)1∧1⊕1∧0(−1)1∧1⊕1∧1⎤
⎥⎥⎥⎦
=1
2⎡
⎢⎢⎢⎣00 01 10 11
00 1 111
01 1−11 −1
10 11 −1−1
11 1−1−11⎤
⎥⎥⎥⎦. (6.51)
Exercise 6.2.4 Prove by induction that the scalar coefﬁcient of H⊗nis
1√
2n=2−n
2. (6.52)
/squaresolid
Thus, we have reduced the problem to determining if the exponent of ( −1) is odd
or even. The only time that this exponent should change is when the ( −1) is in the
lower-right-hand corner of a matrix. When we calculate H⊗3we will again multiply
each entry of H⊗2by the appropriate element of H. If we are in the lower-right-hand
corner, i.e., the (1, 1) position, then we should toggle the exponent of ( −1).

<<<PAGE 201>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.2 The Deutsch–Jozsa Algorithm 183
The following operation will be helpful. We deﬁne
/angbracketleft,/angbracketright:{0,1}n×{0,1}n−→ { 0,1} (6.53)
as follows: Given two binary strings of length n,x=x0x1x2...xn−1and y=
y0y1y2...yn−1,w es a y
/angbracketleftx,y/angbracketright=/angbracketleft x0x1x2...xn−1,y0y1y2...yn−1/angbracketright
=(x0∧y0)⊕(x1∧y1)⊕···⊕ (xn−1∧yn−1). (6.54)
Basically, this gives the parity of the number of times that both bits are at 1.1
Ifxand yare binary strings of length n, then x⊕yis the pointwise (bitwise)
exclusive-or operation, i.e.,
x⊕y=x1⊕y1,x2⊕y2,..., xn⊕yn. (6.55)
The function /angbracketleft,/angbracketright:{0,1}n×{0,1}n−→ { 0,1}satisﬁes the following properties:
(i)
/angbracketleftx⊕x/prime,y/angbracketright=/angbracketleft x,y/angbracketright⊕/angbracketleft x/prime,y/angbracketright, (6.56)
/angbracketleftx,y⊕y/prime/angbracketright=/angbracketleft x,y/angbracketright⊕/angbracketleft x,y/prime/angbracketright. (6.57)
(ii)
/angbracketleft0·x,y/angbracketright=/angbracketleft 0n,y/angbracketright= 0, (6.58)
/angbracketleftx,0·y/angbracketright=/angbracketleft x,0n/angbracketright=0. (6.59)
With this notation, it is easy to write H⊗3as
1
2√
2⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣000 001 010 011 100 101 110 111
000 (−1)
/angbracketleft000,000/angbracketright(−1)/angbracketleft000,001/angbracketright(−1)/angbracketleft000,010/angbracketright(−1)/angbracketleft000,011/angbracketright(−1)/angbracketleft000,100/angbracketright(−1)/angbracketleft000,101/angbracketright(−1)/angbracketleft000,110/angbracketright(−1)/angbracketleft000,111/angbracketright
001 (−1)/angbracketleft001,000/angbracketright(−1)/angbracketleft001,001/angbracketright(−1)/angbracketleft001,010/angbracketright(−1)/angbracketleft001,011/angbracketright(−1)/angbracketleft001,100/angbracketright(−1)/angbracketleft001,101/angbracketright(−1)/angbracketleft001,110/angbracketright(−1)/angbracketleft001,111/angbracketright
010 (−1)/angbracketleft010,000/angbracketright(−1)/angbracketleft010,001/angbracketright(−1)/angbracketleft010,010/angbracketright(−1)/angbracketleft010,011/angbracketright(−1)/angbracketleft010,100/angbracketright(−1)/angbracketleft010,101/angbracketright(−1)/angbracketleft010,110/angbracketright(−1)/angbracketleft010,111/angbracketright
011 (−1)/angbracketleft011,000/angbracketright(−1)/angbracketleft011,001/angbracketright(−1)/angbracketleft011,010/angbracketright(−1)/angbracketleft011,011/angbracketright(−1)/angbracketleft011,100/angbracketright(−1)/angbracketleft011,101/angbracketright(−1)/angbracketleft011,110/angbracketright(−1)/angbracketleft011,111/angbracketright
100 (−1)/angbracketleft100,000/angbracketright(−1)/angbracketleft100,001/angbracketright(−1)/angbracketleft100,010/angbracketright(−1)/angbracketleft100,011/angbracketright(−1)/angbracketleft100,100/angbracketright(−1)/angbracketleft100,101/angbracketright(−1)/angbracketleft100,110/angbracketright(−1)/angbracketleft100,111/angbracketright
101 (−1)/angbracketleft101,000/angbracketright(−1)/angbracketleft101,001/angbracketright(−1)/angbracketleft101,010/angbracketright(−1)/angbracketleft101,011/angbracketright(−1)/angbracketleft101,100/angbracketright(−1)/angbracketleft101,101/angbracketright(−1)/angbracketleft101,110/angbracketright(−1)/angbracketleft101,111/angbracketright
110 (−1)/angbracketleft110,000/angbracketright(−1)/angbracketleft110,001/angbracketright(−1)/angbracketleft110,010/angbracketright(−1)/angbracketleft110,011/angbracketright(−1)/angbracketleft110,100/angbracketright(−1)/angbracketleft110,101/angbracketright(−1)/angbracketleft110,110/angbracketright(−1)/angbracketleft110,111/angbracketright
111 (−1)/angbracketleft111,000/angbracketright(−1)/angbracketleft111,001/angbracketright(−1)/angbracketleft111,010/angbracketright(−1)/angbracketleft111,011/angbracketright(−1)/angbracketleft111,100/angbracketright(−1)/angbracketleft111,101/angbracketright(−1)/angbracketleft111,110/angbracketright(−1)/angbracketleft111,111/angbracketright⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
1This is reminiscent of the deﬁnition of an inner product. In fact, it isan inner product, but on an
interesting vector space. The vector space is not a complex vector space, nor a real vector space. It is
a vector space over the ﬁeld with exactly two elements {0,1}.This ﬁeld is denoted Z2orF2.T h es e to f
elements of the vector space is {0,1}n, the set of bit strings of length n, and the addition is pointwise ⊕.
The zero element is the string of nzeros. Scalar multiplication is obvious. We shall not list all the
properties of this inner product space but we strongly recommend that you do so. Meditate on a basisand on the notions of orthogonality, dimension, etc.

<<<PAGE 202>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
184 Algorithms
=1
2√
2⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣000 001 010 011 100 101 110 111
000 11111111
001 1−11 −11− 11− 1
010 11 −1−11 1− 1−1
011 1−1−11 1− 1−11
100 1111 −1−1−1−1
101 1−11 −1−11− 11
110 11 −1−1−1−11 1
111 1−1−11− 11 1− 1⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (6.60)
From this, we can write a general formula for H⊗nas
H⊗n[i,j]=1√
2n(−1)/angbracketlefti,j/angbracketright, (6.61)
where iandjare the row and column numbers in binary.
What happens if we multiply a state with this matrix? Notice that all the elements
of the leftmost column of H⊗nare+1. So if we multiply H⊗nwith the state
|0/angbracketright=| 00...0/angbracketright=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣00000000 1
00000001 0
00000010 0
......
11111110 0
11111111 0⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦, (6.62)
we see that this will equal the leftmost column of H
⊗n:
H⊗n|0/angbracketright= H⊗n[−,0]=1√
2n⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣00000000 1
00000001 100000010 1
......
11111110 1
11111111 1⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦=1
√
2n/summationdisplay
x∈{0,1}n|x/angbracketright. (6.63)
For an arbitrary basic state |y/angbracketright, which can be represented by a column vector
with a single 1 in position yand 0’s everywhere else, we will be extracting the yth
column of H⊗n:
H⊗n|y/angbracketright= H⊗n[−,y]=1√
2n/summationdisplay
x∈{0,1}n(−1)/angbracketleftx,y/angbracketright|x/angbracketright. (6.64)
Let us return to the problem at hand. We are trying to tell whether the given
function is balanced or constant. In the last section, we were successful by placing

<<<PAGE 203>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.2 The Deutsch–Jozsa Algorithm 185
the bottom control qubit in a superposition. Let us see what would happen if we did
the same thing here.
|x/angbracketright
/n
Uf/n
/d70/d69/d13/d13/d13
|1/angbracketright
H
⇑
|ϕ0/angbracketright⇑
|ϕ1/angbracketright⇑
|ϕ2/angbracketright(6.65)
In terms of matrices this amounts to
Uf(I⊗H)|x,1/angbracketright. (6.66)
For an arbitrary x=x0x1x2...xn−1as an input in the top nqubits, we will have
the following states:
|ϕ0/angbracketright=| x,1/angbracketright. (6.67)
After the bottom Hadamard matrix, we have
|ϕ1/angbracketright=| x/angbracketright/bracketleftbigg|0/angbracketright−| 1/angbracketright√
2/bracketrightbigg
=/bracketleftbigg|x,0/angbracketright−| x,1/angbracketright√
2/bracketrightbigg
. (6.68)
Applying Ufwe get
|ϕ2/angbracketright=| x/angbracketright/bracketleftbigg|f(x)⊕0/angbracketright−| f(x)⊕1/angbracketright√
2/bracketrightbigg
=|x/angbracketright/bracketleftBigg
|f(x)/angbracketright−| f(x)/angbracketright√
2/bracketrightBigg
, (6.69)
where f(x) means the opposite of f(x).
|ϕ2/angbracketright=⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩|x/angbracketright/bracketleftBig
|0/angbracketright−|1/angbracketright√
2/bracketrightBig
,iff(x)=0
|x/angbracketright/bracketleftBig
|1/angbracketright−|0/angbracketright√
2/bracketrightBig
,iff(x)=1=(−1)f(x)|x/angbracketright/bracketleftbigg|0/angbracketright−| 1/angbracketright√
2/bracketrightbigg
. (6.70)
This is almost exactly like Equation (6.27) in the last section. Unfortunately, it is just
as unhelpful.
Let us take another stab at the problem and present the Deutsch–Jozsa algo-
rithm. This time, we shall put |x/angbracketright=| x0x1···xn−1/angbracketrightinto a superposition in which all

<<<PAGE 204>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
186 Algorithms
2npossible strings have equal probability. We saw that we can get such a superposi-
tion by multiplying H⊗nby|0/angbracketright=| 000···0/angbracketright. Thus, we have
|0/angbracketright
/nH⊗n /n
Uf/nH⊗n /n
/d70/d69/d13/d13/d13
|1/angbracketright
H
⇑
|ϕ0/angbracketright⇑
|ϕ1/angbracketright⇑
|ϕ2/angbracketright⇑
|ϕ3/angbracketright(6.71)
In terms of matrices this amounts to
(H⊗n⊗I)Uf(H⊗n⊗H)|0,1/angbracketright. (6.72)
Each state can be written as
|ϕ0/angbracketright=| 0,1/angbracketright, (6.73)
|ϕ1/angbracketright=⎡
⎣/summationdisplay
x∈{0,1}n|x/angbracketright
√
2n⎤⎦/bracketleftbigg|0/angbracketright−| 1/angbracketright
√
2/bracketrightbigg
(6.74)
(as in Equation (6.63)). After applying the Ufunitary matrix, we have
|ϕ2/angbracketright=⎡⎣/summationdisplay
x∈{0,1}n(−1)f(x)|x/angbracketright
√
2n⎤⎦/bracketleftbigg|0/angbracketright−| 1/angbracketright
√
2/bracketrightbigg
. (6.75)
Finally, we apply H⊗nto the top qubits that are already in a superposition of differ-
entxstates to get a superposition of a superposition
|ϕ3/angbracketright=⎡⎣/summationdisplay
x∈{0,1}n(−1)f(x)/summationdisplay
z∈{0,1}n(−1)/angbracketleftz,x/angbracketright|z/angbracketright
2n⎤⎦/bracketleftbigg|0/angbracketright−| 1/angbracketright
√
2/bracketrightbigg
(6.76)
from Equation (6.64). We can combine parts and “add” exponents to get
|ϕ3/angbracketright=⎡⎣/summationdisplay
x∈{0,1}n/summationdisplay
z∈{0,1}n(−1)f(x)(−1)/angbracketleftz,x/angbracketright|z/angbracketright
2n⎤⎦/bracketleftbigg|0/angbracketright−| 1/angbracketright
√
2/bracketrightbigg
(6.77)
=⎡⎣/summationdisplay
x∈{0,1}n/summationdisplay
z∈{0,1}n(−1)f(x)⊕/angbracketleftz, x/angbracketright|z/angbracketright
2n⎤⎦/bracketleftbigg|0/angbracketright−| 1/angbracketright
√
2/bracketrightbigg
.

<<<PAGE 205>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.3 Simon’s Periodicity Algorithm 187
Now the top qubits of state |ϕ3/angbracketrightare measured. Rather than ﬁguring out what we
will get after measuring the top qubit, let us ask the following question: What is the
probability that the top qubits of |ϕ3/angbracketrightwill collapse to the state |0/angbracketright? We can answer
this by setting z=0and realizing that /angbracketleftz,x/angbracketright=/angbracketleft 0,x/angbracketright= 0 for all x. In this case, we
have reduced |ϕ3/angbracketrightto
⎡
⎣/summationdisplay
x∈{0,1}n(−1)f(x)|0/angbracketright
2n⎤⎦/bracketleftbigg|0/angbracketright−| 1/angbracketright
√
2/bracketrightbigg
. (6.78)
So, the probability of collapsing to |0/angbracketrightis totally dependent on f(x). If f(x) is con-
stant at 1, the top qubits become
/summationdisplay
x∈{0,1}n(−1)|0/angbracketright
2n =−(2n)|0/angbracketright
2n=−1|0/angbracketright. (6.79)
Iff(x) is constant at 0, the top qubits become
/summationdisplay
x∈{0,1}n1|0/angbracketright
2n=2n|0/angbracketright
2n=+1|0/angbracketright. (6.80)
And ﬁnally, if fis balanced, then half of the x’s will cancel the other half and the
top qubits will become
/summationdisplay
x∈{0,1}n(−1)f(x)|0/angbracketright
2n =0|0/angbracketright
2n=0|0/angbracketright. (6.81)
When measuring the top qubits of |ϕ3/angbracketright, we will only get |0/angbracketrightif the function is constant.
If anything else is found after being measured, then the function is balanced.
In conclusion, we have solved the – admittedly contrived – problem in one func-
tion evaluation as opposed to the 2n−1+1 function evaluations needed in classical
computations. That is an exponential speedup!
Exercise 6.2.5 What would happen if we were tricked and the given function was
neither balanced nor constant? What would our algorithm produce? /squaresolid
6.3 SIMON’S PERIODICITY ALGORITHM
Simon’s algorithm is about ﬁnding patterns in functions. We will use methods that
we already learned in previous sections, but we will also employ other ideas. Thisalgorithm is a combination of quantum procedures as well as classical procedures.
Suppose that we are given a function f:{0,1}
n−→ { 0,1}nthat we can evaluate
but it is given to us as a black box. We are further assured that there exists a secret(hidden) binary string c=c
0c1c2···c n−1, such that for all strings x,y∈{0,1}n,w e
have
f(x)=f(y) if and only if x=y⊕c, (6.82)

<<<PAGE 206>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
188 Algorithms
where⊕is the bitwise exclusive-or operation. In other words, the values of frepeat
themselves in some pattern and the pattern is determined by c. We call ctheperiod
off. The goal of Simon’s algorithm is to determine c.
Example 6.3.1 Let us work out an example. Let n=3. Consider c=101. Then we
are going to have the following requirements on f:/D2000⊕101=101; hence, f(000)=f(101)./D2001⊕101=100; hence, f(001)=f(100)./D2010⊕101=111; hence, f(010)=f(111)./D2011⊕101=110; hence, f(011)=f(110)./D2100⊕101=001; hence, f(100)=f(001)./D2101⊕101=000; hence, f(101)=f(000)./D2110⊕101=011; hence, f(110)=f(011)./D2111⊕101=010; hence, f(111)=f(010). /square
Exercise 6.3.1 Work out the requirements on fifc=011. /squaresolid
Notice that if c=0n, then the function is one to one. Otherwise the function is
two to one.
The function fwill be given as a unitary operation that can be visualized as
|x/angbracketright
/n
Uf/n|x/angbracketright
|y/angbracketright
/n/n|y⊕f(x)/angbracketright(6.83)
where|x,y/angbracketrightgoes to |x,y⊕f(x)/angbracketright. Ufis again its own inverse. Setting y=0nwould
give us an easy way to evaluate f(x).
How would one solve this problem classically? We would have to evaluate f
on different binary strings. After each evaluation, check to see if that output has
already been found. If one ﬁnds two inputs x1and x2such that f(x1)=f(x2), then
we are assured that
x1=x2⊕c (6.84)
and can obtain cby⊕-ing both sides with x2:
x1⊕x2=x2⊕c⊕x2=c. (6.85)
If the function is a two-to-one function, then we will not have to evaluate more than
half the inputs before we get a repeat. If we evaluate more than half the strings and
still cannot ﬁnd a match, then we know that fis one to one and that c=0n. So,
in the worst case,2n
2+1=2n−1+1 function evaluations will be needed. Can we do
better?

<<<PAGE 207>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.3 Simon’s Periodicity Algorithm 189
The quantum part of Simon’s algorithm basically consists of performing the fol-
lowing operations several times:
|0/angbracketright
/nH⊗n /n
Uf/nH⊗n /n
/d70/d69/d13/d13/d13
|0/angbracketright
/n/n
⇑
|ϕ0/angbracketright⇑
|ϕ1/angbracketright⇑
|ϕ2/angbracketright⇑
|ϕ3/angbracketright(6.86)
In terms of matrices this is
(H⊗n⊗I)Uf(H⊗n⊗I)|0,0/angbracketright. (6.87)
Let us look at the states of the system. We start at
|ϕ0/angbracketright=| 0,0/angbracketright. (6.88)
We then place the input in a superposition of all possible inputs. From Equa-
tion (6.63) we know that it looks like
|ϕ1/angbracketright=/summationdisplay
x∈{0,1}n|x,0/angbracketright
√
2n. (6.89)
Evaluation of fon all these possibilities gives us
|ϕ2/angbracketright=/summationdisplay
x∈{0,1}n|x,f(x)/angbracketright
√
2n. (6.90)
And ﬁnally, let us apply H⊗nto the top output, as in Equation (6.64):
|ϕ3/angbracketright=/summationdisplay
x∈{0,1}n/summationdisplay
z∈{0,1}n(−1)/angbracketleftz,x/angbracketright|z,f(x)/angbracketright
2n . (6.91)
Notice that for each input xand for each z, we are assured by the one who gave us
the function that the ket |z,f(x)/angbracketright is the same ket as |z,f(x⊕c)/angbracketright. The coefﬁcient for
this ket is then
(−1)/angbracketleftz,x/angbracketright+(−1)/angbracketleftz,x⊕c/angbracketright
2. (6.92)
Let us examine this coefﬁcient in depth. We saw that /angbracketleft−,−/angbracketrightis an inner product
and from Equation (6.57)
(−1)/angbracketleftz,x/angbracketright+(−1)/angbracketleftz,x⊕c/angbracketright
2=(−1)/angbracketleftz,x/angbracketright+(−1)/angbracketleftz,x/angbracketright⊕/angbracketleftz, c/angbracketright
2
=(−1)/angbracketleftz,x/angbracketright+(−1)/angbracketleftz,x/angbracketright(−1)/angbracketleftz,c/angbracketright
2. (6.93)
So, if/angbracketleftz,c/angbracketright= 1, the terms of the numerator of this coefﬁcient will cancel each other
out and we would get0
2. In contrast, if /angbracketleftz,c/angbracketright= 0, the sum will be±2
2=±1. Hence,

<<<PAGE 208>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
190 Algorithms
upon measuring the top qubits, we will only ﬁnd those binary strings such that
/angbracketleftz,c/angbracketright= 0.
This algorithm becomes completely clear only after we look at a concrete exam-
ple.
.................................................................................
Reader Tip. Warning: admittedly, working out all the gory details of an example can
be a bit scary. We recommend that the less meticulous reader move on to the nextsection for now. Return to this example on a calm sunny day, prepare a good cup ofyour favorite tea or coffee, and go through the details: the effort will pay off. ♥.................................................................................
Consider the function f:{0,1}
3−→ { 0,1}3deﬁned as
000•/d119
/d27/d27/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55•000
001•/d31 /d47/d47•001
010•/d127
/d31/d31/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63•010
011•/d119
/d27/d27/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55/d55•011
100•/d63/d63/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0
•100
101•/d42/d52/d52/d106/d106/d106/d106/d106/d106/d106/d106/d106/d106/d106/d106/d106/d106/d106/d106/d106/d106•101
110•/d20
/d42/d42/d84/d84/d84/d84/d84/d84/d84/d84/d84/d84/d84/d84/d84/d84/d84/d84/d84/d84 •110
111•/d53/d58/d58/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117
•111(6.94)
Let us go through the states of
the algorithm with this function:
|ϕ0/angbracketright=| 0,0/angbracketright=| 0/angbracketright⊗| 0/angbracketright, (6.95)
|ϕ1/angbracketright=/summationdisplay
x∈{0,1}3|x/angbracketright
√
8⊗|0/angbracketright. (6.96)
We might also write this as
|ϕ1/angbracketright=1√
8(|000/angbracketright⊗| 000/angbracketright+| 001/angbracketright⊗| 000/angbracketright+| 010/angbracketright⊗| 000/angbracketright+| 011/angbracketright⊗| 000/angbracketright
+|100/angbracketright⊗| 000/angbracketright+| 101/angbracketright⊗| 000/angbracketright+| 110/angbracketright⊗| 000/angbracketright+| 111/angbracketright⊗| 000/angbracketright).

<<<PAGE 209>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.3 Simon’s Periodicity Algorithm 191
After applying Uf, we have
|ϕ2/angbracketright=/summationdisplay
x∈{0,1}3|x/angbracketright⊗| f(x)/angbracketright
√
8(6.97)
or
|ϕ2/angbracketright=1√
8(|000/angbracketright⊗| 100/angbracketright+| 001/angbracketright⊗| 001/angbracketright+| 010/angbracketright⊗| 101/angbracketright+| 011/angbracketright⊗| 111/angbracketright
+|100/angbracketright⊗| 001/angbracketright+| 101/angbracketright⊗| 100/angbracketright+| 110/angbracketright⊗| 111/angbracketright+| 111/angbracketright⊗| 101/angbracketright).
Then applying H⊗n⊗Iwe get
|ϕ3/angbracketright=/summationdisplay
x∈{0,1}3/summationdisplay
z∈{0,1}3(−1)/angbracketleftz,x/angbracketright|z/angbracketright⊗ f(x)/angbracketright
8. (6.98)
This amounts to
|ϕ3/angbracketright=1
8((+1)|000/angbracketright⊗| f(000)/angbracketright+(+1)|000/angbracketright⊗| f(001)/angbracketright+( +1)|000/angbracketright⊗| f(010)/angbracketright+(+1)|000/angbracketright⊗| f(011)/angbracketright
+(+1)|000/angbracketright⊗| f(100)/angbracketright+ (+1)|000/angbracketright⊗| f(101)/angbracketright+( +1)|000/angbracketright⊗| f(110)/angbracketright+( +1)|000/angbracketright⊗| f(111)/angbracketright
+(+1)|001/angbracketright⊗| f(000)/angbracketright+ (−1)|001/angbracketright⊗| f(001)/angbracketright+( +1)|001/angbracketright⊗| f(010)/angbracketright+(−1)|001/angbracketright⊗| f(011)/angbracketright
+(+1)|001/angbracketright⊗| f(100)/angbracketright+ (−1)|001/angbracketright⊗| f(101)/angbracketright+(+1)|001/angbracketright⊗| f(110)/angbracketright+(−1)|001/angbracketright⊗| f(111)/angbracketright
+(+1)|010/angbracketright⊗| f(000)/angbracketright+ (+1)|010/angbracketright⊗| f(001)/angbracketright+(−1)|010/angbracketright⊗| f(010)/angbracketright+(−1)|010/angbracketright⊗| f(011)/angbracketright
+(+1)|010/angbracketright⊗| f(100)/angbracketright+ (+1)|010/angbracketright⊗| f(101)/angbracketright+(−1)|010/angbracketright⊗| f(110)/angbracketright+(−1)|010/angbracketright⊗| f(111)/angbracketright
+(+1)|011/angbracketright⊗| f(000)/angbracketright+ (−1)|011/angbracketright⊗| f(001)/angbracketright+(−1)|011/angbracketright⊗| f(010)/angbracketright+(+1)|011/angbracketright⊗| f(011)/angbracketright
+(+1)|011/angbracketright⊗| f(100)/angbracketright+ (−1)|011/angbracketright⊗| f(101)/angbracketright+(−1)|011/angbracketright⊗| f(110)/angbracketright+(+1)|011/angbracketright⊗| f(111)/angbracketright
+(+1)|100/angbracketright⊗| f(000)/angbracketright+ (+1)|100/angbracketright⊗| f(001)/angbracketright+(+1)|100/angbracketright⊗| f(010)/angbracketright+( +1)|100/angbracketright⊗| f(011)/angbracketright
+(−1)|100/angbracketright⊗| f(100)/angbracketright+ (−1)|100/angbracketright⊗| f(101)/angbracketright+(−1)|100/angbracketright⊗| f(110)/angbracketright+( −1)|100/angbracketright⊗| f(111)/angbracketright
+(+1)|101/angbracketright⊗| f(000)/angbracketright+ (−1)|101/angbracketright⊗| f(001)/angbracketright+(+1)|101/angbracketright⊗| f(010)/angbracketright+( −1)|101/angbracketright⊗| f(011)/angbracketright
+(−1)|101/angbracketright⊗| f(100)/angbracketright+ (+1)|101/angbracketright⊗| f(101)/angbracketright+(−1)|101/angbracketright⊗| f(110)/angbracketright+(+1)|101/angbracketright⊗| f(111)/angbracketright
+(+1)|110/angbracketright⊗| f(000)/angbracketright+ (+1)|110/angbracketright⊗| f(001)/angbracketright+(−1)|110/angbracketright⊗| f(010)/angbracketright+(−1)|110/angbracketright⊗| f(011)/angbracketright
+(−1)|110/angbracketright⊗| f(100)/angbracketright+ (−1)|110/angbracketright⊗| f(101)/angbracketright+(+1)|110 /angbracketright⊗| f(110)/angbracketright+(+1)|110/angbracketright⊗| f(111)/angbracketright
+(+1)|111/angbracketright⊗| f(000)/angbracketright+ (−1)|111/angbracketright⊗| f(001)/angbracketright+(−1)|111/angbracketright⊗| f(010)/angbracketright+(+1)|111/angbracketright⊗| f(011)/angbracketright
+(−1)|111/angbracketright⊗| f(100)/angbracketright+ (+1)|111/angbracketright⊗| f(101)/angbracketright+(+1)|111/angbracketright⊗| f(110)/angbracketright+(−1)|111/angbracketright⊗| f(111)/angbracketright).
Notice that the coefﬁcients follow the exact pattern as H⊗3on page 184.

<<<PAGE 210>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
192 Algorithms
Evaluating the function fgives us
|ϕ3/angbracketright=1
8((+1)|000/angbracketright⊗| 100/angbracketright+ (+1)|000/angbracketright⊗| 001/angbracketright+ (+1)|000/angbracketright⊗| 101/angbracketright+ (+1)|000/angbracketright⊗| 111/angbracketright
+(+1)|000/angbracketright⊗| 001/angbracketright+ (+1)|000/angbracketright⊗| 100/angbracketright+ (+1)|000/angbracketright⊗| 111/angbracketright+ (+1)|000/angbracketright⊗| 101/angbracketright
+(+1)|001/angbracketright⊗| 100/angbracketright+ (−1)|001/angbracketright⊗| 001/angbracketright+ (+1)|001/angbracketright⊗| 101/angbracketright+ (−1)|001/angbracketright⊗| 111/angbracketright
+(+1)|001/angbracketright⊗| 001/angbracketright+ (−1)|001/angbracketright⊗| 100/angbracketright+ (+1)|001/angbracketright⊗| 111/angbracketright+ (−1)|001/angbracketright⊗| 101/angbracketright
+(+1)|010/angbracketright⊗| 100/angbracketright+ (+1)|010/angbracketright⊗| 001/angbracketright+ (−1)|010/angbracketright⊗| 101/angbracketright+ (−1)|010/angbracketright⊗| 111/angbracketright
+(+1)|010/angbracketright⊗| 001/angbracketright+ (+1)|010/angbracketright⊗| 100/angbracketright+ (−1)|010/angbracketright⊗| 111/angbracketright+ (−1)|010/angbracketright⊗| 101/angbracketright
+(+1)|011/angbracketright⊗| 100/angbracketright+ (−1)|011/angbracketright⊗| 001/angbracketright+ (−1)|011/angbracketright⊗| 101/angbracketright+ (+1)|011/angbracketright⊗| 111/angbracketright
+(+1)|011/angbracketright⊗| 001/angbracketright+ (−1)|011/angbracketright⊗| 100/angbracketright+ (−1)|011/angbracketright⊗| 111/angbracketright+ (+1)|011/angbracketright⊗| 101/angbracketright
+(+1)|100/angbracketright⊗| 100/angbracketright+ (+1)|100/angbracketright⊗| 001/angbracketright+ (+1)|100/angbracketright⊗| 101/angbracketright+ (+1)|100/angbracketright⊗| 111/angbracketright
+(−1)|100 /angbracketright⊗| 001/angbracketright+ (−1)|100/angbracketright⊗| 100/angbracketright+ (−1)|100/angbracketright⊗| 111/angbracketright+ (−1)|100/angbracketright⊗| 101/angbracketright
+(+1)|101/angbracketright⊗| 100/angbracketright+ (−1)|101/angbracketright⊗| 001/angbracketright+ (+1)|101/angbracketright⊗| 101/angbracketright+ (−1)|101/angbracketright⊗| 111/angbracketright
+(−1)|101/angbracketright⊗| 001/angbracketright+ (+1)|101/angbracketright⊗| 100/angbracketright+ (−1)|101/angbracketright⊗| 111/angbracketright+ (+1)|101/angbracketright⊗| 101/angbracketright
+(+1)|110/angbracketright⊗| 100/angbracketright+(+1)|110/angbracketright⊗| 001/angbracketright+ (−1)|110/angbracketright⊗| 101/angbracketright+ (−1)|110/angbracketright⊗| 111/angbracketright
+(−1)|110/angbracketright⊗| 001/angbracketright+ (−1)|110/angbracketright⊗| 100/angbracketright+ (+1)|110/angbracketright⊗| 111/angbracketright+ (+1)|110/angbracketright⊗| 101/angbracketright
+(+1)|111/angbracketright⊗| 100/angbracketright+ (−1)|111/angbracketright⊗| 001/angbracketright+ (−1)|111/angbracketright⊗| 101/angbracketright+ (+1)|111/angbracketright⊗| 111/angbracketright
+(−1)|111/angbracketright⊗| 001/angbracketright+ (+1)|111/angbracketright⊗| 100/angbracketright+ (+1)|111/angbracketright⊗| 111/angbracketright+ (−1)|111/angbracketright⊗| 101/angbracketright).
Combining like terms and canceling out gives us
|ϕ3/angbracketright=1
8((+2)|000/angbracketright⊗| 100/angbracketright+ (+2)|000/angbracketright⊗| 001/angbracketright+ (+2)|000/angbracketright⊗| 101/angbracketright+ (+2)|000/angbracketright⊗| 111/angbracketright
+(+2)|010/angbracketright⊗| 100/angbracketright+ (+2)|010/angbracketright⊗| 001/angbracketright+ (−2)|010/angbracketright⊗| 101/angbracketright+ (−2)|010/angbracketright⊗| 111/angbracketright
+(+2)|101/angbracketright⊗| 100/angbracketright+ (−2)|101/angbracketright⊗| 001/angbracketright+ (+2)|101/angbracketright⊗| 101/angbracketright+ (−2)|101/angbracketright⊗| 111/angbracketright
+(+2)|111/angbracketright⊗| 100/angbracketright+ (−2)|111/angbracketright⊗| 001/angbracketright+ (−2)|111/angbracketright⊗| 101/angbracketright+ (+2)|111/angbracketright⊗| 111/angbracketright)
or
|ϕ3/angbracketright=1
8((+2)|000/angbracketright⊗ (|100/angbracketright+| 001/angbracketright+| 101/angbracketright+| 111/angbracketright)
+(+2)|010/angbracketright⊗ (|100/angbracketright+| 001/angbracketright−| 101/angbracketright−| 111/angbracketright)
+(+2)|101/angbracketright⊗ (|100/angbracketright−| 001/angbracketright+| 101/angbracketright−| 111/angbracketright)
+(+2)|111/angbracketright⊗ (|100/angbracketright−| 001/angbracketright−| 101/angbracketright+| 111/angbracketright)).
When we measure the top output, we will get, with equal probability, 000 ,010, 101,
or 111. We know that for all these, the inner product with the missing cis 0. This

<<<PAGE 211>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.3 Simon’s Periodicity Algorithm 193
gives us the set of equations:
(i)/angbracketleft000, c/angbracketright= 0
(ii)/angbracketleft010, c/angbracketright= 0
(iii)/angbracketleft101, c/angbracketright= 0
(iv)/angbracketleft111, c/angbracketright= 0.
If we write casc=c1c2c3, then Equation (ii) tells us that c2=0. Equation (iii)
tells us that c1⊕c3=0 or that either c1=c3=0o r c1=c3=1. Because we know
that c/negationslash=000, we come to the conclusion that c=101.
Exercise 6.3.2 Do a similar analysis for the function fdeﬁned as
000•/d31 /d47/d47•000
001•/d127
/d31/d31/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63/d63•001
010•/d9
/d36/d36/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73/d73•010
011•/d64/d63/d63/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0/d0
•011
100•/d53/d58/d58/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117/d117
•100
101•/d20
/d42/d42/d84/d84/d84/d84/d84/d84/d84/d84/d84/d84/d84/d84/d84/d84/d84/d84/d84/d84 •101
110•/d31 /d47/d47•110
111•/d76/d70/d70/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12/d12
•111(6.99)
/squaresolid
After running Simon’s algorithm several times, we will get ndifferent zisuch that
/angbracketleftzi,c/angbracketright= 0. We then put these results into a classical algorithm that solves “linear
equations.” They are linear equations; rather than using the usual +operation, we
use⊕on binary strings. Here is a nice worked-out example.
Example 6.3.2 Imagine that we are dealing with a case where n=7. That means
we are given a function f:{0,1}7−→ { 0,1}7. Let us assume that we ran the algo-
rithm 7 times and we get the following results:
(i)/angbracketleft1010110, c/angbracketright= 0
(ii)/angbracketleft0010001, c/angbracketright= 0
(iii)/angbracketleft1100101, c/angbracketright= 0

<<<PAGE 212>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
194 Algorithms
(iv)/angbracketleft0011011, c/angbracketright= 0
(v)/angbracketleft0101001, c/angbracketright= 0
(vi)/angbracketleft0011010, c/angbracketright= 0
(vii)/angbracketleft0110111, c/angbracketright= 0.
To clear the ﬁrst column of 1’s, we are going to “add” (really pointwise exclusive
or) the ﬁrst equation to the third equation. This gives us
(i)/angbracketleft1010110, c/angbracketright= 0
(ii)/angbracketleft0010001, c/angbracketright= 0
(iii)/angbracketleft0110011, c/angbracketright= 0
(iv)/angbracketleft0011011, c/angbracketright= 0
(v)/angbracketleft0101001, c/angbracketright= 0
(vi)/angbracketleft0011010, c/angbracketright= 0
(vii)/angbracketleft0110111, c/angbracketright= 0.
To clear the second column of 1’s, we are going to “add” the third equation to
the ﬁfth and seventh equations. This gives us
(i)/angbracketleft1010110, c/angbracketright= 0
(ii)/angbracketleft0010001, c/angbracketright= 0
(iii)/angbracketleft0110011, c/angbracketright= 0
(iv)/angbracketleft0011011, c/angbracketright= 0
(v)/angbracketleft0011010, c/angbracketright= 0
(vi)/angbracketleft0011010, c/angbracketright= 0
(vii)/angbracketleft0000100, c/angbracketright= 0.
To clear the third column of 1’s,
we are going to “add” the second equation to
Equations (i), (iii), (iv), (v), and (vi). This gives us
(i)/angbracketleft1000111, c/angbracketright= 0
(ii)/angbracketleft0010001, c/angbracketright= 0
(iii)/angbracketleft0100010, c/angbracketright= 0
(iv)/angbracketleft0001010, c/angbracketright= 0
(v)/angbracketleft0001011, c/angbracketright= 0
(vi)/angbracketleft0001011, c/angbracketright= 0
(vii)/angbracketleft0000100, c/angbracketright= 0.
To clear the fourth column of 1’s, we are going to “add” Equation (iv) to Equa-
tions (v) and (vi). We are going to clear the ﬁfth column by adding Equation (vii) to
Equation (i). This gives us
(i)/angbracketleft1000011, c/angbracketright= 0
(ii)/angbracketleft0010001, c/angbracketright= 0
(iii)/angbracketleft0100010, c/angbracketright= 0
(iv)/angbracketleft0001010, c/angbracketright= 0
(v)/angbracketleft0000001, c/angbracketright= 0
(vi)/angbracketleft0000001, c/angbracketright= 0
(vii)/angbracketleft0000100, c/angbracketright= 0.

<<<PAGE 213>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.4 Grover’s Search Algorithm 195
And ﬁnally, to clear the sixth column of 1’s, we are going to “add” Equation (v)
to Equations (i), (ii), and (vi). We get
(i)/angbracketleft1000010, c/angbracketright= 0
(ii)/angbracketleft0010000, c/angbracketright= 0
(iii)/angbracketleft0100010, c/angbracketright= 0
(iv)/angbracketleft0001010, c/angbracketright= 0
(v)/angbracketleft0000001, c/angbracketright= 0
(vi)/angbracketleft0000000, c/angbracketright= 0
(vii)/angbracketleft0000100, c/angbracketright= 0.
We can interpret these equations as
(i)c1⊕c6=0
(ii)c3=0
(iii) c2⊕c6=0
(iv) c4⊕c6=0
(v)c7=0
(vi)
(vii) c5=0.
Notice that if c6=0, then c1=c2=c4=0 and that if c6=1, then c1=c2=c4=1.
Because we are certain that fis not one to one and c/negationslash=0000000, we can conclude
that c=1101010. /square
Exercise 6.3.3 Solve the following linear equations in a similar manner:
(i)/angbracketleft11110000, c/angbracketright= 0
(ii)/angbracketleft01101001, c/angbracketright= 0
(iii)/angbracketleft10010110, c/angbracketright= 0
(iv)/angbracketleft00111100, c/angbracketright= 0
(v)/angbracketleft11111111, c/angbracketright= 0
(vi)/angbracketleft11000011, c/angbracketright= 0
(vii)/angbracketleft10001110, c/angbracketright= 0
(viii)/angbracketleft01110001, c/angbracketright= 0.
(Hint: The answer is c=10011001.) /squaresolid
In conclusion, for a given periodic f, we can ﬁnd the period cinnfunction eval-
uations. This is in contrast to the 2n−1+1 needed with the classical algorithm.
.................................................................................
Reader Tip. We shall see this concept of ﬁnding the period of a function in Section
6.5 when we present Shor’s algorithm. ♥.................................................................................
6.4 GROVER’S SEARCH ALGORITHM
How do you ﬁnd a needle in a haystack? You look at each piece of hay separately
and check each one to see if it is the desired needle. That is not very efﬁcient.

<<<PAGE 214>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
196 Algorithms
The computer science version of this problem is about unordered arrays instead of
haystacks. Given an unordered array of melements, ﬁnd a particular element. Clas-
sically, in the worst case, this takes mqueries. On average, we will ﬁnd the desired
element in m/2 queries. Can we do better?
Lov Grover’s search algorithm does the job in√mqueries. Although this is not
the exponential speedup of the Deutsch–Jozsa algorithm and Simon’s algorithm, it
is still very good. Grover’s algorithm has many applications to database theory and
other areas.
Because, over the past few sections, we have become quite adept at functions,
let us look at the search problem from the point of view of functions. Imagine thatyou are given a function f:{0,1}
n−→ { 0,1}and you are assured that there exists
exactly one binary string x0such that
f(x)=⎧
⎪⎨
⎪⎩1, ifx=x0,
0, ifx/negationslash=x0.(6.100)
We are asked to ﬁnd x0. Classically, in the worst case, we would have to evaluate
all 2nbinary strings to ﬁnd the desired x0. Grover’s algorithm will demand only√
2n=2n
2evaluations.
fwill be given to us as the unitary matrix Ufthat takes |x,y/angbracketrightto|x,f(x)⊕y/angbracketright.
For example, for n=2, if fis the unique function that “picks out” the binary string
10, then Uflooks like
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣00,00 0 ,10 1 ,00 1 ,11 0 ,01 0 ,11 1 ,01 1 ,1
00,0 1
00,1 1
01,0 1
01,1 1
10,0 1
10,1 1
11,0 1
11,1 1⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (6.101)
Exercise 6.4.1 Find the matrices that correspond to the other three functions from
{0,1}
2to{0,1}that have exactly one element xwith f(x)=1. /squaresolid
As a ﬁrst try at solving this problem, we might try placing |x/angbracketrightinto a superposition
of all possible strings and then evaluating Uf.
|0/angbracketright
/nH⊗n /n
Uf/n
/d70/d69/d13/d13/d13
|0/angbracketright
⇑
|ϕ0/angbracketright⇑
|ϕ1/angbracketright⇑
|ϕ2/angbracketright(6.102)

<<<PAGE 215>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.4 Grover’s Search Algorithm 197
In terms of matrices this becomes
Uf(H⊗n⊗I)|0,0/angbracketright. (6.103)
The states are
|ϕ0/angbracketright=| 0,0/angbracketright, (6.104)
|ϕ1/angbracketright=⎡
⎣/summationdisplay
x∈{0,1}n|x/angbracketright
√
2n⎤⎦|0/angbracketright, (6.105)
and
|ϕ
2/angbracketright=/summationdisplay
x∈{0,1}n|x,f(x)/angbracketright
√
2n. (6.106)
Measuring the top qubits will, with equal probability, give one of the 2nbinary
strings. Measuring the bottom qubit will give |0/angbracketrightwith probability2n−1
2n, and|1/angbracketrightwith
probability1
2n. If you are lucky enough to measure |1/angbracketrighton the bottom qubit, then, be-
cause the top and the bottom are entangled, the top qubit will have the correct an-
swer. However, it is improbable that you will be so lucky. We need something new.
Grover’s search algorithm uses two tricks. The ﬁrst, called phase inversion ,
changes the phase of the desired state. It works as follows. Take Ufand place the
bottom qubit in the superposition
|0/angbracketright−| 1/angbracketright√
2(6.107)
state. This is similar to quantum circuit (6.21). For an arbitrary x, this looks like
|x/angbracketright
/n
Uf/n
/d70/d69/d13/d13/d13
|1/angbracketright
H
⇑
|ϕ0/angbracketright⇑
|ϕ1/angbracketright⇑
|ϕ2/angbracketright(6.108)
In terms of matrices this becomes
Uf(In⊗H)|x,1/angbracketright. (6.109)
Because both Ufand Hare unitary operations, it is obvious that phase inversion is
a unitary operation.
The states are
|ϕ0/angbracketright=| x,1/angbracketright, (6.110)
|ϕ1/angbracketright=| x/angbracketright/bracketleftbigg|0/angbracketright−| 1/angbracketright√
2/bracketrightbigg
=/bracketleftbigg|x,0/angbracketright−| x,1/angbracketright√
2/bracketrightbigg
, (6.111)

<<<PAGE 216>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
198 Algorithms
Figure 6.1. Five numbers and their average
and
|ϕ2/angbracketright=| x/angbracketright/bracketleftbigg|f(x)⊕0/angbracketright−| f(x)⊕1/angbracketright√
2/bracketrightbigg
=|x/angbracketright/bracketleftBigg
|f(x)/angbracketright−| f(x)/angbracketright√
2/bracketrightBigg
. (6.112)
Remembering that a−b=(−1)(b−a), we may write
|ϕ2/angbracketright=(−1)f(x)|x/angbracketright/bracketleftbigg|0/angbracketright−| 1/angbracketright√
2/bracketrightbigg
=⎧
⎪⎨
⎪⎩−1|x/angbracketright/bracketleftBig
|0/angbracketright−|1/angbracketright√
2/bracketrightBig
,ifx=x0,
+1|x/angbracketright/bracketleftBig
|0/angbracketright−|1/angbracketright√
2/bracketrightBig
,ifx/negationslash=x0.(6.113)
How does this unitary operation act on states? If |x/angbracketrightstarts off in a equal superpo-
sition of four different states, i.e.,/bracketleftbig1
2,1
2,1
2,1
2/bracketrightbigT, and fchooses the string “10,” then
after performing a phase inversion, the state looks like/bracketleftbig1
2,1
2,−1
2,1
2/bracketrightbigT. Measuring |x/angbracketright
does not give any information: both |1
2|2and|−1
2|2are equal to +1
4. Changing the
phase from positive to negative separates the phases, but does not separate them
enough. We need something else.
What is needed is a way of boosting the phase separation of the desired bi-
nary string from the other binary strings. The second trick is called inversion about
the mean orinversion about the average. This is a way of boosting the separation
of the phases. A small example will be helpful. Consider a sequence of integers:
53,38,17,23, and 79. The average of these numbers is a=42. We might picture
these numbers as in Figure 6.1.
The average is the number such that the sum of the lengths of the lines above
the average is the same as the sum of the lengths of the lines below. Suppose we
wanted to change the sequence so that each element of the original sequence abovethe average would be the same distance from the average but below. Furthermore,
each element of the original sequence below the average would be the same distance
from the average but above. In other words, we are inverting each element aroundthe average. For example, the ﬁrst number, 53 is a−53=−11 units away from the
average. We must add a=42 to−11 and get a+(a−53)=31. The second element
of the original sequence, 38, is a−38=4 units below the average and will go to

<<<PAGE 217>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.4 Grover’s Search Algorithm 199
Figure 6.2. After an inversion about the mean.
a+(a−38)=46. In general, we shall change each element vto
v/prime=a+(a−v) (6.114)
or
v/prime=−v+2a. (6.115)
The above sequence becomes 31 ,46,67,61, and 5. Notice that the average of this
sequence remains 42 as in Figure 6.2.
Exercise 6.4.2 Consider the following number: 5, 38, 62, 58, 21, and 35. Invert these
numbers around their mean. /squaresolid
Let us write this in terms of matrices. Rather than writing the numbers as a
sequence, consider a vector V=[53,38,17,23,79]T. Now consider the matrix
A=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣1
51
51
51
51
5
1
51
51
51
51
5
1
51
51
51
51
5
1
51
51
51
51
5
1
51
51
51
51
5⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (6.116)
It is easy to see that Ais a matrix that ﬁnds the average of a sequence:
AV=[42,42,42,42,42]
T. (6.117)
In terms of matrices, the formula v/prime=−v+2abecomes
V/prime=−V+2AV=(−I+2A)V. (6.118)

<<<PAGE 218>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
200 Algorithms
Let us calculate
(−I+2A)=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣(−1+
2
5)2
52
52
52
5
2
5(−1+2
5)2
52
52
5
2
52
5(−1+2
5)2
52
5
2
52
52
5(−1+2
5)2
5
2
52
52
52
5(−1+2
5)⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦.
(6.119)
And, as expected,
(−I+2A)V=V
/prime, (6.120)
or in our case,
(−I+2A)[53, 38,17,23,79]T=[31,46,67,61,5]T. (6.121)
Let us generalize: rather than dealing with ﬁve numbers, let us deal with 2nnum-
bers. Given nqubits, there are 2npossible states. A state is a 2nvector. Consider the
following 2n-by-2nmatrix:
A=⎡
⎢⎢⎢⎢⎢⎢⎢⎣1
2n1
2n···1
2n
1
2n1
2n···1
2n
............
1
2n1
2n···1
2n⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (6.122)
Exercise 6.4.3 Prove that A
2=A. /squaresolid
Multiplying any state by Awill give a state where each amplitude will be the av-
erage of all the amplitudes. Building on this, we form the following 2n-by-2nmatrix
−I+2A=⎡
⎢⎢⎢⎢⎢⎢⎢⎣−1+
2
2n2
2n···2
2n
2
2n−1+2
2n···2
2n
............
2
2n2
2n··· − 1+2
2n⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (6.123)
Multiplying a state by −I+2Awill invert amplitudes about the mean.
We must show that −I+2Ais a unitary matrix. First, observe that the adjoint of
−I+2Ais itself. Then, using the properties of matrix multiplication and realizing
that matrices act very much like polynomials, we have
(−I+2A)⋆(−I+2A)=+ I−2A−2A+4A
2
=I−4A+4A2=I−4A+4A=I, (6.124)

<<<PAGE 219>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.4 Grover’s Search Algorithm 201
where the ﬁrst equality is from distributivity of matrix multiplication, the second
equality comes from combining like terms, and the third equality is from the fact
that A2=A. We conclude that ( −I+2A) is a unitary operation and acts on states
by inverting the numbers about the mean.
When considered separately, phase inversion and inversion about the mean are
each innocuous operations. However, when combined, they are a very powerful op-
eration that separates the amplitude of the desired state from those of all the other
states.
Example 6.4.1 Let us do an example that shows how both these techniques work
together. Consider the vector
[10,10,10,10,10]T. (6.125)
We are always going to perform a phase inversion to the fourth of the ﬁve numbers.
There is no difference between the fourth number and all the other numbers. We
start by doing a phase inversion to the fourth number and get
[10,10,10,−10, 10]T. (6.126)
The average of these ﬁve numbers is a=6. Calculating the inversion about the mean
we get
−v+2a=−10+(2×6)=2 (6.127)
and
−v+2a=10+(2×6)=22. (6.128)
Thus, our ﬁve numbers become
[2,2,2,22,2]T. (6.129)
The difference between the fourth element and all the others is 22 −2=20.
Let us do these two operations again to our ﬁve numbers. Another phase inver-
sion on the fourth element gives us
[2,2,2,−22, 2]T. (6.130)
The average of these numbers is a=−2.8. Calculating the inversion about the mean
we get
−v+2a=−2+(2×−2.8)=−7.6 (6.131)
and
−v+2a=22+(2×−2.8)=16.4. (6.132)
Hence, our ﬁve numbers become
[−7.6,−7.6,−7.6, 16.4,−7.6]T. (6.133)
The difference between the fourth element and all the others is 16.4 +7.6=24. We
have further separated the numbers. This was all done with unitary operations. /square

<<<PAGE 220>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
202 Algorithms
Exercise 6.4.4 Do the two operations again on this sequence of ﬁve numbers. Did
our results improve? /squaresolid
How many times should these operations be done?√
2ntimes. If you do it more
than that, the process will “overcook” the numbers. The proof that√
2ntimes is
needed is beyond this text. Sufﬁce it to say that the proof actually uses some very
pretty geometry (well worth looking into!).
We are ready to state Grover’s algorithm:
Step 1. Start with a state |0/angbracketright
Step 2. Apply H⊗n
Step 3. Repeat√
2ntimes:
Step 3a. Apply the phase inversion operation: Uf(I⊗H)
Step 3b. Apply the inversion about the mean operation: −I+2A
Step 4. Measure the qubits.
We might view this algorithm as
Repeat√
2ntimes
Phase
inversionInversion
about mean
|0/angbracketright
/nH⊗n /n
Uf/n−I+2A /n
/d62/d61/d13/d13
|1/angbracketright
H
⇑
|ϕ1/angbracketright⇑
|ϕ2/angbracketright⇑
|ϕ3a/angbracketright⇑
|ϕ3b/angbracketright/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d31
/d31/d31/d31
/d31
/d31/d31/d31
/d31
/d31/d31/d31/d31/d31/d31/d31/d31
/d31
/d31/d31/d31
/d31
/d31/d31/d31/d31
/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95/d95
(6.134)
Example 6.4.2 Let us look at an example of an execution of this algorithm. Let f
be a function that picks out the string “101.” The states after each step will be
|ϕ1/angbracketright=/bracketleftbig000 001 010 011 100 101 110 111
00000000/bracketrightbigT
, (6.135)

<<<PAGE 221>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.4 Grover’s Search Algorithm 203
|ϕ2/angbracketright=/bracketleftBig000 001 010 011 100 101 110 111
1√
8,1√
8,1√
8,1√
8,1√
8,1√
8,1√
8,1√
8/bracketrightBigT
, (6.136)
|ϕ3a/angbracketright=/bracketleftBig000 001 010 011 100 101 110 111
1√
8,1√
8,1√
8,1√
8,1√
8,−1√
8,1√
8,1√
8/bracketrightBigT
.(6.137)
The average of these numbers is
a=7∗1√
8−1√
8
8=6√
8
8=3
4√
8. (6.138)
Calculating the inversion about the mean we have
−v+2a=−1√
8+/parenleftbigg
2×3
4√
8/parenrightbigg
=1
2√
8(6.139)
and
−v+2a=1√
8+/parenleftbigg
2×3
4√
8/parenrightbigg
=5
2√
8. (6.140)
Thus, we have
|ϕ3b/angbracketright=/bracketleftBig000 001 010 011 100 101 110 111
1
2√
8,1
2√
8,1
2√
8,1
2√
8,1
2√
8,5
2√
8,1
2√
8,1
2√
8/bracketrightBigT
.
(6.141)
A phase inversion will give us
|ϕ3a/angbracketright=/bracketleftBig000 001 010 011 100 101 110 111
1
2√
8,1
2√
8,1
2√
8,1
2√
8,1
2√
8,−5
2√
8,1
2√
8,1
2√
8/bracketrightBigT
.
(6.142)
The average of these numbers is
a=7∗1
2√
8−5
2√
8
8=1
8√
8. (6.143)
Calculating for the inversion about the mean we have
−v+2a=−1
2√
8+/parenleftbigg
2×1
8√
8/parenrightbigg
=−1
4√
8(6.144)
and
−v+2a=5
2√
8+/parenleftbigg
2×1
8√
8/parenrightbigg
=11
4√
8. (6.145)

<<<PAGE 222>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
204 Algorithms
Hence, we have
|ϕ3b/angbracketright=/bracketleftBig000 001 010 011 100 101 110 111
−1
4√
8,−1
4√
8,−1
4√
8,−1
4√
8,−1
4√
8,11
4√
8,−1
4√
8,−1
4√
8/bracketrightBigT
.
(6.146)
For the record,11
4√
8=0.97227 and−1
4√
8=−0.08839. Squaring the numbers gives
us the probability of measuring those numbers. When we measure the state in
Step 4, we will most likely get the state
|ϕ4/angbracketright=/bracketleftbig000 001 010 011 100 101 110 111
00000100/bracketrightbigT
, (6.147)
which is exactly what we wanted. /square
Exercise 6.4.5 Do a similar analysis for the case where n=4 and fchooses the
“1101” string. /squaresolid
A classical algorithm will search an unordered array of size ninnsteps. Grover’s
algorithm will take time√n. This is what is referred to as a quadratic speedup. Al-
though this is very good, it is not the holy grail of computer science: an exponentialspeedup. In the next section we shall meet an algorithm that does have such aspeedup.
What if we relax the requirements that there be only one needle in the haystack?
Let us assume that there are tobjects that we are looking for (with t<
2n
2). Grover’s
algorithm still works, but now one must go through the loop/radicalBig
2n
ttimes. There are
many other types of generalizations and assorted changes that one can do withGrover’s algorithm. Several references are given at the end of the chapter. We dis-cuss some complexity issues with Grover’s algorithm at the end of Section 8.3.
6.5 SHOR’S FACTORING ALGORITHM
The problem of factoring integers is very important. Much of the World Wide Web’ssecurity is based on the fact that it is “hard” to factor integers on classical comput-ers. Peter Shor’s amazing algorithm factors integers in polynomial time and reallybrought quantum computing into the limelight.
Shor’s algorithm is based on the following fact: the factoring problem can be
reduced to ﬁnding the period of a certain function. In Section 6.3 we learned howto ﬁnd the period of a function. In this section, we employ some of those periodicity
techniques to factor integers.
We shall call the number we wish to factor N. In practice, Nwill be a large
number, perhaps hundreds of digits long. We shall work out all the calculations forthe numbers 15 and 371. For exercises, we ask the reader to work with the number
247. We might as well give away the answer and tell you that the only nontrivialfactors of 247 are 19 and 13.
We assume that the given Nis not a prime number but is a composite number.
There now exists a deterministic, polynomial algorithm that determines if Nis prime

<<<PAGE 223>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.5 Shor’s Factoring Algorithm 205
(Agrawal, Kayal, and Saxena, 2004). So we can easily check to see if Nis prime
before we try to factor it.
.................................................................................
Reader Tip. There are several different parts of this algorithm and it might be too
much to swallow in one bite. If you are stuck at a particular point, may we suggest
skipping to the next part of the algorithm. At the end of this section, we summarize
the algorithm. ♥.................................................................................
Modular Exponentiation. Before we go on to Shor’s algorithm, we have to re-
mind ourselves of some basic number theory. We begin by looking at some modular
arithmetic. For a positive integer Nand any integer a, we write aMod Nfor the
remainder (or residue) of the quotient a/N. (For C/C++ and Java programmers,
Mod is recognizable as the % operation.)
Example 6.5.1 Some examples:/D27 Mod 15 =7 because 7/15 =0 remainder 7./D299 Mod 15 =9 because 99/15 =6 remainder 9./D2199 Mod 15 =4 because 199 /15=13 remainder 4./D25,317 Mod 371 =123 because 5,317/371 =14 remainder 123./D22,3374 Mod 371 =1 because 2,3374/371 =63 remainder 1./D21,446 Mod 371 =333 because 1,446/371 =3 remainder 333./square
Exercise 6.5.1 Calculate
(i) 244,443 Mod 247
(ii) 18,154 Mod 247
(iii) 226,006 Mod 247./squaresolid
We write
a≡a/primeMod Nif and only if ( aMod N)=(a/primeMod N), (6.148)
or equivalently, if Nis a divisor of a−a/prime, i.e., N|(a−a/prime).
Example 6.5.2 Some examples:/D217≡2 Mod 15/D2126≡1,479,816 Mod 15/D2534≡1,479 Mod 15/D22,091≡236 Mod 371/D23,350≡2237 Mod 371/D23,325,575 ≡2,765,365 Mod 371./square
Exercise 6.5.2 Show that
(i) 1,977 ≡1 Mod 247
(ii) 16,183 ≡15,442 Mod 247
(iii) 2,439,593 ≡238,082 Mod 247.
/squaresolid

<<<PAGE 224>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
206 Algorithms
With Mod understood we can start discussing the algorithm. Let us randomly
choose an integer athat is less than Nbut does not have a nontrivial factor in com-
mon with N. One can test for such a factor by performing Euclid’s algorithm to
calculate GCD( a,N). If the GCD is not 1, then we have found a factor of Nand we
are done. If the GCD is 1, then ais called co-prime toNand we can use it. We shall
need to ﬁnd the powers of amodulo N, that is,
a0Mod N,a1Mod N,a2Mod N,a3Mod N,. . . (6.149)
In other words, we shall need to ﬁnd the values of the function
fa,N(x)=axMod N. (6.150)
Some examples are in order.
Example 6.5.3 LetN=15 and a=2. A few simple calculations show that we get
the following:
x 01234567891 01 11 2···
f2,15(x)1248124812 4 8 1 ···.
(6.151)
Fora=4, we have
x 01234567891 01 11 2···
f4,15(x)1414141414 1 4 1 ···.
(6.152)
Fora=13, we have
x 0 1 234 5 678 9 1 01 11 2 ···
f13,15(x)11 34711 34711 3 4 7 1 ···.
(6.153)
/square
The ﬁrst few outputs of f13,15function can be viewed as the bar graph in Fig-
ure 6.3.
Example 6.5.4 Let us work out some examples with N=371. This is a little harder
and probably cannot be done with a handheld calculator. The numbers simply get
too large. However, it is not difﬁcult to write a small program, use MATLAB orMicrosoft Excel. Trying to calculate a
xMod Nby ﬁrst calculating axwill not go
very far, because the numbers will usually be beyond range. Rather, the trick is to
calculate axMod Nfrom ax−1Mod Nby using the standard number theoretic fact

<<<PAGE 225>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.5 Shor’s Factoring Algorithm 207
Figure 6.3. The ﬁrst few outputs of f13,15 .
that
ifa≡a/primeMod Nandb≡b/primeMod N,then a×b≡a/prime×b/primeMod N. (6.154)
Or, equivalently
a×bMod N=(aMod N)×(bMod N)M o d N. (6.155)
From this fact we get the formula
axMod N=ax−1×aMod N=((ax−1Mod N)×(aMod N)) Mod N.
(6.156)
Because a<NandaMod N=a, this reduces to
axMod N=((ax−1Mod N)×a)M o d N. (6.157)
Using this, it is easy to iterate to get the desired results. For N=371 and a=2,
we have
x 0123 4 5 6 7 ··· 78··· 155 156 157 158 ···
f2,371(x)12481 63 26 41 2 8 ··· 211··· 186 1 2 4 ···.
(6.158)
ForN=371 and a=6, we have
x 0 1 2 34567 ··· 13··· 25 26 27 28 ···
f6,371(x) 1 6 36 216 183 356 281 202 ··· 370··· 62 1 6 36 ···.
(6.159)

<<<PAGE 226>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
208 Algorithms
Figure 6.4. The output of f24,371 .
ForN=371 and a=24, we have
x 0 1 2 3 4567 ··· 39··· 77 78 79 80 ···
f24,371(x) 1 24 205 97 102 222 134 248 ··· 160··· 201 1 24 205 ···.
(6.160)
/square
We can see the results of f24,371as a bargraph in Figure 6.4.
Exercise 6.5.3 Calculate the ﬁrst few values of fa,NforN=247 and
(i)a=2
(ii)a=17
(iii) a=23.
/squaresolid
In truth, we do not really need the values of this function, but rather we need to
ﬁnd the period of this function, i.e., we need to ﬁnd the smallest rsuch that
fa,N(r)=arMod N=1. (6.161)
It is a theorem of number theory that for any co-prime a≤N, the function fa,N
will output a 1 for some r<N. After it hits 1, the sequence of numbers will simply
repeat. If fa,N(r)=1, then
fa,N(r+1)=fa,N(1) (6.162)
and in general
fa,N(r+s)=fa,N(s). (6.163)

<<<PAGE 227>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.5 Shor’s Factoring Algorithm 209
Example 6.5.5 Charts (6.151), (6.152), and (6.153) show us that the periods for
f2,15,f4,15,and f13,15are 4, 2, and 4, respectively. Charts (6.158), (6.159), and (6.160)
show us that the periods for f2,371,f6,371,and f24,371are 156, 26, and 78, respectively.
In fact, it is easy to see the periodicity of f24,371in Figure 6.4. /square
Exercise 6.5.4 Find the period of the functions f2,247,f17,247, and f23,247. /squaresolid
The Quantum Part of the Algorithm . For small numbers like 15, 371, and 247,
it is fairly easy to calculate the periods of these functions. But what about a large
Nthat is perhaps hundreds of digits long? This will be beyond the ability of any
conventional computers. We will need a quantum computer with its ability to be in
a superposition to calculate fa,N(x)f o rall needed x.
How do we get a quantum circuit to ﬁnd the period? First we have to show that
there is a quantum circuit that can implement the function fa,N. The output of this
function will always be less than N, and so we will need n=log2Noutput bits. We
will need to evaluate fa,Nfor at least the ﬁrst N2values of xand so will need at least
m=logN2=2l o g N=2n (6.164)
input qubits. The quantum circuit that we would get will be the operator Ufa,N, which
we may visualize as
|x/angbracketright
/m
Ufa,N/m|x/angbracketright
|y/angbracketright
/n/n|y⊕fa,N(x)/angbracketright(6.165)
where|x,y/angbracketrightgoes to |x,y/circleminusfa,N(x)/angbracketright=| x,y⊕axMod N/angbracketright.2How is this circuit
formed? Rather than destroying the ﬂow of the discussion, we leave that technical
discussion for a mini appendix at the end of this section.
With Ufa,N, we can go on to use it in the following quantum algorithm. The ﬁrst
thing is to evaluate allthe input at one time. From earlier sections, we know how to
putxinto an equally weighted superposition. (In fact, the beginning of this algorithm
is very similar to Simon’s algorithm.) We shall explain all the various parts of this
quantum circuit:
|0/angbracketright
/mH⊗m /m
Ufa,N/mQFT†/m
/d70/d69/d13/d13/d13
|0/angbracketright
/n/n
/d70/d69/d13/d13/d13
⇑
|ϕ0/angbracketright⇑
|ϕ1/angbracketright⇑
|ϕ2/angbracketright⇑
|ϕ3/angbracketright⇑
|ϕ4/angbracketright(6.166)
2Until now, we have thought of xas any number and now we are dealing with xas its binary expansion x.
This is because we are thinking of xas described in a (quantum) computer. We shall use both notations
interchangeably.

<<<PAGE 228>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
210 Algorithms
In terms of matrices this is
(Measur e ⊗I)(QFT†⊗I)(I⊗Measur e )Ufa,N(H⊗m⊗I)|0m,0n/angbracketright, (6.167)
where 0mand0nare qubit strings of length mandn, respectively.
Let us look at the states of the system. We start at
|ϕ0/angbracketright=| 0m,0n/angbracketright. (6.168)
We then place the input in an equally weighted superposition of all possible inputs:
|ϕ1/angbracketright=/summationdisplay
x∈{0,1}m|x,0n/angbracketright
√
2m. (6.169)
Evaluation of fon all these possibilities gives us
|ϕ2/angbracketright=/summationdisplay
x∈{0,1}m|x,fa,N(x)/angbracketright
√
2m=/summationdisplay
x∈{0,1}m|x,axMod N/angbracketright
√
2m. (6.170)
As the examples showed, these outputs repeat and repeat. They are periodic. We
have to ﬁgure out what is the period. Let us meditate on what was just done. Itis right here where the fantastic power of quantum computing is used. We have
evaluated allthe needed values at one time! Only quantum parallelism can perform
such a task.
Let us pause and look at some examples.
Example 6.5.6 For N=15, we will have n=4 and m=8. For a=13, the state
|ϕ
2/angbracketrightwill be
|0,1/angbracketright+| 1,13/angbracketright+| 2,4/angbracketright+| 3,7/angbracketright+| 4,1/angbracketright+···+| 254, 4/angbracketright+| 255, 7/angbracketright√
256. (6.171)
/square
Example 6.5.7 ForN=371, we will have n=9 and m=18. For a=24, the state
|ϕ2/angbracketrightwill be
|0,1/angbracketright+| 1,24/angbracketright+| 2,205/angbracketright+| 3,97/angbracketright+| 4,102/angbracketright+···+| 218−1,24218−1Mod 371/angbracketright√
218.
(6.172)
/square
Exercise 6.5.5 Write the state |ϕ2/angbracketrightforN=247 and a=9. /squaresolid
Going on with the algorithm, we measure the bottom qubits of |ϕ2/angbracketright, which is in a
superposition of many states. Let us say that after measuring the bottom qubits we
ﬁnd
axMod N (6.173)

<<<PAGE 229>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.5 Shor’s Factoring Algorithm 211
for some x. However, by the periodicity of fa,Nwe also have that
ax≡ax+rMod N (6.174)
and
ax≡ax+2rMod N. (6.175)
In fact, for any s∈Zwe have
ax≡ax+srMod N. (6.176)
How many of the 2msuperpositions xin|ϕ2/angbracketrighthave axMod Nas the output? Answer:
⌊2m
r⌋.S o
|ϕ3/angbracketright=/summationdisplay
ax≡axMod N|x,axMod N/angbracketright
⌊2m
r⌋. (6.177)
We might also write this as
|ϕ3/angbracketright=/summationdisplay 2m/r−1
j=0|t0+jr,axMod N/angbracketright
/bracketleftbig2m
r/bracketrightbig , (6.178)
where t0is the ﬁrst time that at0≡axMod N, i.e., the ﬁrst time that the measured
value occurs. We shall call t0theoffset of the period for reasons that will soon be-
come apparent.
It is important to realize that this stage employs entanglement in a serious fash-
ion. The top qubits and the bottom qubits are entangled in a way that when the top
is measured, the bottom stays the same.
Example 6.5.8 Continuing Example 6.5.6, let us say that after measurement of the
bottom qubits, 7 is found. In that case |ϕ3/angbracketrightwould be
|3,7/angbracketright+| 7,7/angbracketright+| 11,7/angbracketright+| 15,7/angbracketright+···+| 251, 7/angbracketright+| 255, 7/angbracketright/bracketleftbig256
4/bracketrightbig . (6.179)
For example, if we looked at the f13,15rather than the bargraph in Figure 6.3, we
would get the bargraph shown in Figure 6.5. /square

<<<PAGE 230>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
212 Algorithms
Figure 6.5. f13,15 after a measurement of 7.
Example 6.5.9 Continuing Example 6.5.7, let us say that after measurement of the
bottom qubits we ﬁnd 222 (which is 245Mod 371.) In that case |ϕ3/angbracketrightwould be
|5,222/angbracketright+| 83,222/angbracketright+| 161, 222/angbracketright+| 239, 222/angbracketright+···/bracketleftBig
218
78/bracketrightBig . (6.180)
We can see the result of this measurement in Figure 6.6/square
Exercise 6.5.6 Continuing Exercise 6.5.5, let us say that after measuring the bot-
tom qubits, 55 is found. What would |ϕ3/angbracketrightbe? /squaresolid
The ﬁnal step of the quantum part of the algorithm is to take such a superposition
and return its period. This will be done with a type of Fourier transform .W ed on o t
Figure 6.6. f24,371 after a measurement of 222.

<<<PAGE 231>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.5 Shor’s Factoring Algorithm 213
assume the reader has seen this before and some motivation is in order. Let us step
away from our task at hand and talk about evaluating polynomials. Consider the
polynomial
P(x)=a0+a1x1+a2x2+a3x3+···+ an−1xn−1. (6.181)
We can represent this polynomial with a column vector [ a0,a1,a2,..., an−1]T. Sup-
pose we wanted to evaluate this polynomial at the numbers x0,x1,x2,..., xn−1, i.e.,
we wanted to ﬁnd P(x0),P(x1),P(x2),..., P(xn−1). A simple way of performing the
task is with the following matrix multiplication:
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣1 x
0 x2
0··· xj
0··· xn−1
0
1 x1 x2
1··· xj
1··· xn−1
1
1 x2 x2
2··· xj
2··· xn−1
2
.........
1 x
k x2
k··· xj
k··· xn−1
k
.........
1x
n−1x2
n−1··· xj
n−1··· xn−1
n−1⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣a
0
a1
a2
...
ak
...
a
n−1⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣P(x
0)
P(x1)
P(x2)
...
P(xk)
...
P(x
n−1)⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦.(6.182)
The matrix on the left, where every row is a geometric series, is called the Van-
dermonde matrix and is denoted V(x
0,x1,x2,xn−1). There is no restriction on the
type of numbers we are permitted to use in the Vandermonde matrix, and hence,
we are permitted to use complex numbers. In fact, we shall need them to be pow-ers of the Mth roots of unity, ω
M(see page 26 of Chapter 1 for a quick reminder).
Because Mis ﬁxed throughout this discussion, we shall simply denote this as ω.
There is also no restriction on the size of the Vandermonde matrix. Letting M=2m,
which is the amount of numbers that can be described with the top qubits, there is
a need for the Vandermonde matrix to be an M-by-Mmatrix. We would like to
evaluate the polynomials at ω0=1,ω,ω2,...,ωM−1. To do this, we need to look at
V(ω0,ω1,ω2,...,ωM−1). In order to evaluate P(x) at the powers of the Mth root of
unity, we must multiply
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣11 1 ··· 1··· 1
1ω
1ω2··· ωj··· ωM−1
1ω2ω2×2··· ω2j··· ω2(M−1)
.........
1ωkωk2··· ωkj··· ωk(M−1)
.........
1ω
M−1ω(M−1)2···ω(M−1)j···ω(M−1)( M−1)⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣a
0
a1
a2
...
ak
...
a
M−1⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣P(ω
0)
P(ω1)
P(ω2)
...
P(ωk)
...
P(ωM−1)⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦.
(6.183)

<<<PAGE 232>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
214 Algorithms
Figure 6.7. The action of DFT†.
[P(ω0),P(ω1),P(ω2),..., P(ωk),..., P(ωM−1)]Tis the vector of the values of
the polynomial at the powers of the Mth root of unity.
Let us deﬁne the discrete Fourier transform , denoted DFT ,a s
DFT=1√
MV(ω0,ω1,ω2,...,ωM−1). (6.184)
Formally, DFT is deﬁned as
DFT [j,k]=1√
Mωjk. (6.185)
It is easy to see that DFT is a unitary matrix: the adjoint of this matrix, DFT†,
is formally deﬁned as
DFT†[j,k]=1√
Mωkj=1√
Mω−jk. (6.186)
To show that DFT is unitary, let us multiply
(DFT⋆DFT†)[j,k]=1
MM−1/summationdisplay
i=0(ωjiω−ik)=M−1/summationdisplay
i=0ω−i(k−j). (6.187)
Ifk=j, i.e., if we are along the diagonal, this becomes
1
MM−1/summationdisplay
i=0ω0=1
MM−1/summationdisplay
i=01=1. (6.188)
Ifk/negationslash=j, i.e., if we are off the diagonal, then we get a geometric progression which
sums to 0. And so DFT⋆DFT†=I.
What task does DFT†perform? Our text will not get into the nitty-gritty of
this important operation, but we shall try to give an intuition of what is going on.
Let us forget about the normalization1√
Mfor a moment and think about this intu-
itively. The matrix DFT acts on polynomials by evaluating them on different equally
spaced points of the circle. The outcomes of those evaluations will necessarily haveperiodicity because the points go around and around the circle. So multiplying a col-umn vector with DFT takes a sequence and outputs a periodic sequence. If we start
with a periodic column vector, then the DFT will transform the periodicity. Simi-
larly, the inverse of the Fourier transform, DFT
†, will also change the periodicity.
Sufﬁce it to say that the DFT†does two tasks as shown in Figure 6.7:/D2It modiﬁes the period from rto2m
r./D2It eliminates the offset.

<<<PAGE 233>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.5 Shor’s Factoring Algorithm 215
Circuit (6.166) requires a variant of a DFT called a quantum Fourier transform
and denoted as QFT . Its inverse is denoted QFT†.T h e QFT†performs the same
operation but is constructed in a way that is more suitable for quantum computers.
(We shall not delve into the details of its construction.) The quantum version is veryfast and made of “small” unitary operators that are easy for a quantum computer to
implement.
3
The ﬁnal step of the circuit is to measure the top qubits. For our presentation,
we shall make the simplifying assumption that revenly divides into 2m. Shor’s actual
algorithm does not make this assumption and goes into details about ﬁnding the
period for any r. When we measure the top qubit we will ﬁnd it to be some multiple
of2m
r. That is, we will measure
x=λ2m
r(6.191)
for some whole number λ. We know 2m, and after measuring we will also know x.
We can divide the whole number xby 2mand get
x
2m=λ2m
r2m=λ
r. (6.192)
One can then reduce this number to an irreducible fraction and take the denomina-tor to be the long sought-after r. If we do not make the simplifying assumption that
revenly divides into 2
m, then we might have to perform this process several times
and analyze the results.
From the Period to the Factors. Let us see how knowledge of the period rwill
help us ﬁnd a factor of N. We shall need a period that is an even number. There is a
theorem of number theory that tells us that for the majority of a, the period of fa,N
will be an even number. If, however, we do choose an asuch that the period is an
odd number, simply throw that aaway and choose another one. Once an even ris
found so that
ar≡1M o d N, (6.193)
3There are slight variations of Shor’s algorithm: For one, rather than using the H⊗mto put the mqubits
in a superposition in the beginning of circuit (6.166), we could have used QFT and get the same results.
However, we leave it as is because at this point the reader has familiarity with the Hadamard matrix.
Another variation is not measuring the bottom qubits before performing the QFT†operation. This
makes the mathematics slightly more complicated. We leave it as is for simplicity sakes.
However, if we take both of these variants, our quantum circuit would look like
|0/angbracketright
/mQFT /m
Ufa,N/mQFT†/m
/d62/d61/d13/d13
|0/angbracketright
/n/n(6.189)
This would have been more in line with our discussion at the end of Section 2.3, where we wrote about
solving problems using
Translation /mapsto→Calculation /mapsto→Reverse Translation (6.190)
where QFT and QFT†would be our two translations.

<<<PAGE 234>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
216 Algorithms
we may subtract 1 from both sides of the equivalence to get
ar−1≡0M o d N, (6.194)
or equivalently
N|(ar−1). (6.195)
Remembering that 1 =12and x2−y2=(x+y)(x−y) we get that
N|(√
ar+1)(√
ar−1) (6.196)
or
N|(ar
2+1)(ar
2−1). (6.197)
(Ifrwas odd, we would not be able to evenly divide by 2.) This means that any factor
ofNis also a factor of either( ar
2+1) or ( ar
2−1) or both. Either way, a factor for N
can be found by looking at
GCD(( ar
2+1),N) (6.198)
and
GCD(( ar
2−1),N). (6.199)
Finding the GCD can be done with the classical Euclidean algorithm. There is, how-
ever, one caveat. We must make sure that
ar
2/negationslash=−1M o d N (6.200)
because if ar
2≡−1M o d N, then the right side of Equation (6.197) would be 0. In
that case we do not get any information about Nand must throw away that particu-
laraand start over again.
Let us work out some examples.
Example 6.5.10 In chart (6.151), we saw that the period of f2,15is 4, i.e., 24≡
1 Mod 15. From Equation (6.197), we get that
15|(22+1)(22−1). (6.201)
And, hence, we have that GCD(5 ,15)=5 and GCD(3 ,15)=3. /square
Example 6.5.11 In chart (6.159), we saw that the period of f6,371is 26, i.e., 626≡
1 Mod 371. However, we can also see that 626
2=613≡370≡−1 Mod 371. So we
cannot use a=6. /square
Example 6.5.12 In chart (6.160), we saw that the period of f24,371is 78, i.e., 2478≡
1 Mod 371. We can also see that 2478
2=2439≡160/negationslash=−1 Mod 371. From Equation
(6.197), we get that
371|(2439+1)(2439−1). (6.202)
And, thus, GCD(161, 371)=7 and GCD(159, 371)=53 and 371 =7∗53. /square

<<<PAGE 235>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.5 Shor’s Factoring Algorithm 217
Exercise 6.5.7 Use the fact that the period of f7,247is 12 to determine the factors
of 247. /squaresolid
Shor’s Algorithm. We are, at last, ready to put all the pieces together and formally
state Shor’s algorithm :
Input: A positive integer Nwith n=⌈log2N⌉.
Output: A factor pofNif it exists.
Step 1. Use a polynomial algorithm to determine if Nis prime or a power of prime.
If it is a prime, declare that it is and exit. If it is a power of a prime number, declare
that it is and exit.
Step 2. Randomly choose an integer asuch that 1 <a<N. Perform Euclid’s algo-
rithm to determine GCD( a,N).If the GCD is not 1, then return it and exit.
Step 3. Use quantum circuit (6.166) to ﬁnd a period r.
Step 4. Ifris odd or if ar≡−1M o d N, then return to Step 2 and choose another a.
Step 5. Use Euclid’s algorithm to calculate GCD(( ar
2+1),N) and GCD(( ar
2−
1),N). Return at least one of the nontrivial solutions.
What is the worst case complexity of this algorithm? To determine this, one
needs to have an in-depth analysis of the details of how Ua,Nand QFT†are im-
plemented. One would also need to know what percentage of times things can go
wrong. For example, what percentage of awould fa,Nhave an odd period? Rather
than going into the gory details, let us just state that Shor’s algorithm works in
O(n2lognlog log n) (6.203)
number of steps, where nis the number of bits needed to represent the number
N. That is polynomial in terms of n. This is in contrast to the best-known classical
algorithms that demand
O(ecn1/3log2/3n) (6.204)
steps, where cis some constant. This is exponential in terms of n. Shor’s quantum
algorithm is indeed faster.
Appendix: Implementing Ufa,Nwith quantum gates. In order for Ufa,Nto be imple-
mented with unitary matrices, we need to “break up” the operations into small little
jobs. This is done by splitting up x. Let us write xin binary. That is,
x=xn−1xn−2···x2x1x0. (6.205)
Formally, xas a number is
x=xn−12n−1+xn−22n−2+···+ x222+x12+x0. (6.206)

<<<PAGE 236>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
218 Algorithms
Using this description of x, we can rewrite our function as
fa,N(x)=axMod N=axn−12n−1+xn−22n−2+···+ x222+x12+x0Mod N (6.207)
or
axn−12n−1×axn−22n−2×···× ax222×ax12×ax0Mod N. (6.208)
We can convert this formula to an inductive deﬁnition4offa,N(x). We shall deﬁne
y0,y1,y2,..., yn−2,yn−1, where yn−1=fa,N(x): the base case is
y0=ax0. (6.209)
If we have yj−1, then to get yjwe use the trick from Equation (6.157):
yj=yj−1×axj2jMod N. (6.210)
Notice that if xj=0 then yj=yj−1. In other words, whether or not we should
multiply yj−1bya2jMod Nis dependent on whether or not xj=1. It turns out
that as long as aand Nare co-prime, the operation of multiplying a number times
a2jMod Nis reversible and, in fact, unitary. So for each j, there is a unitary operator
Ua2jMod N(6.211)
that we shall write as Ua2j. As we want to perform this operation conditionally, we
will need controlled- Ua2j,o rCUa2j, gates. Putting this all together, we have the fol-
lowing quantum circuit that implements fa,Nin a polynomial number of gates:
x0•x0
x1•x1
x2•x2
.........x
n−1•xn−1
/m Ua20 Ua21 Ua22 U··· Ua2n−1/m
(6.212)
Even if a real implementation of large-scale quantum computers is years away,
the design and study of quantum algorithms is something that is ongoing and is an
exciting ﬁeld of interest.
.................................................................................
References:
(i) A version of Deutsch’s algorithm was ﬁrst stated in Deutsch (1985).
(ii) Deutsch–Jozsa was given in Deutsch and Jozsa (1992).
(iii) Simon’s algorithm was ﬁrst presented in Simon (1994).
4This inductive deﬁnition is nothing more than the modular-exponentiation algorithm given in, say,Section 31.6 of Corman et al. (2001) or Section 1.2 of Dasgupta, Papadimitriou, and Vazirani (2006).

<<<PAGE 237>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
6.5 Shor’s Factoring Algorithm 219
(iv) Grover’s search algorithm was originally presented in Grover (1997). Fur-
ther developments of the algorithm can be found in Chapter 6 of Nielsen
and Chuang (2000). For nice applications of Grover’s algorithm to graph
theory, see Cirasella (2006).
(v) Shor’s algorithm was ﬁrst announced in Shor (1994). There is also a very
readable presentation of it in Shor (1997). There are several slight varia-
tions to the algorithm and there are many presentations at different lev-els of complexity. Chapter 5 of Nielsen and Chuang (2000) goes through
it thoroughly. Chapter 10 of Dasgupta, Papadimitriou, and Vazirani (2006)
goes from an introduction to quantum computing through Shor’s algorithmin 20 pages.
Every quantum computer textbook works through several algorithms. See, e.g.,
Hirvensalo (2001) and Kitaev, Shen, and Vyalyi (2002) and, of course, Nielsen and
Chuang (2000). There is also a very nice short article by Shor that discusses several
algorithms (Shor, 2002). Dorit Aharonov has written a nice survey article that goes
through many of the algorithms (Aharonov, 1998)
Peter Shor has written a very interesting article on the seeming paucity of quan-
tum algorithms in Shor (2003).

<<<PAGE 238>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
7
Programming Languages
The computer programmer is a creator of universes for
which he alone is the lawgiver . . . universes of virtually un-
limited complexity can be created in the form of computerp r o g r a m s ....T h e y c o m p l i a n t l y o b e y t h e i r l a w s a n d v i v i d l y
exhibit their obedient behavior. No playwright, no stage di-
rector, no emperor, however powerful, has ever exercisedsuch absolute authority to arrange a stage or a ﬁeld of battle
and to command such unswervingly dutiful actors or troops.
J. Weizmann, Computer Power and Human
Reason: From Judgement to Calculation
In this chapter we are going to describe quantum programming , i.e., the art and sci-
ence of programming a quantum computer. In Section 7.1, we brieﬂy sketch what
it means to program a quantum computing device. Section 7.2 covers a simple ver-
sion of quantum assembler, based on the so-called QRAM architecture. Section 7.3describes possible steps leading to higher-level programming languages and con-structs. We conclude this chapter with Section 7.4, a short discussion on quantum
emulators.
7.1 PROGRAMMING IN A QUANTUM WORLD
As you are about to read this chapter, you have undoubtedly been exposed to com-
puter programming in a variety of ﬂavors, and are perhaps already an accomplished
programmer of real-life applications. Programming a classical machine carries an
immediate, unambiguous sense. However, we are going to leave the familiar worldof binary chips, and learn how to program some as yet unspeciﬁed quantum hard-ware. Thus, it is appropriate to spend a minute pondering what it can possibly mean
to write code for a quantum computing device.
As we all know, programming a computer means to tell it to carry out certain ac-
tions in a speciﬁc language that the machine understands, either directly or through
220

<<<PAGE 239>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
7.2 Quantum Assembly Programming 221
the intermediary of an interpreter. A program is a set of instructions, planning out
the behavior of the computing machine. Stripped of all its complexity, this set of in-
structions prescribes how to manipulate data in a controlled fashion, as summarized
by the following slogan:
DATA + CONTROL = PROGRAMMING
Control here means that the program is built from a small set of basic instructions
and a set of control structures (conditionals, jumps, loops, etc.).
This scheme carries over to the world of quantum computers. We can assume in
the following that a machine sits in front of us; also, the machine is a computer thatoperates at least partially at the quantum level. For the time being, you can imaginethat our computer comprises a quantum device, with an input area of quantum data,
represented by an addressable set of qubits, together with a set of prebuilt opera-
tions that can manipulate quantum data. These operations are of two types: unitary
operations, which will evolve quantum data, and measuring, which will inspect the
value of data. We shall also assume that we can assemble more and more com-
plicated operations out of the basic ones. Loosely speaking, the set of instructionsthat specify such assemblages will be our quantum programs. Here is the updated
“quantum” slogan:
QUANTUM DATA + CONTROL = QUANTUM PROGRAMMING
Let us now imagine that we have a concrete problem to solve, where additional
quantum speedup might be highly beneﬁcial, and that after some pondering we havecome up with some effective quantum algorithm, perhaps similar to those we have
already encountered in Chapter 6.
A basic ingredient is still missing, namely, a programming language for writing
down our instructions . Such a language will enable us to control the quantum com-
puting device and implement our quantum algorithm.
1
7.2 QUANTUM ASSEMBLY PROGRAMMING
Nowadays, there is a plethora of programming languages for classical machines.Most programmers write their source code in one or more of the high-level pro-
gramming languages, such as C++, Perl, or Java. Quite often a developer ignores
the architecture of the machines he/she is working with, or how the underlying op-erating system will handle the requests of the program. There is an obvious advan-
tage in this state of affairs: we can concentrate on the task at hand, and simply let
1We have deliberately separated algorithms from the language in which they are implemented to em-
phasize the fact that the focus of quantum programming is not quantum algorithms per se, but the waythey are expressed in a quantum language (thus, we can think of the description of the algorithms inChapter 6 as given in some sort of quantum pseudo-code). In real life, though, there is a tight synergybetween algorithm design and the choice of a speciﬁc programming language, as every experiencedsoftware engineer knows well: a good language’s choice fosters good algorithm’s design.

<<<PAGE 240>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
222 Programming Languages
the interpreter/compiler take care of what goes on under the hood. It should be
remembered though that somebody has to have the know-how necessary to build
such interpreters–compilers; simply, this expertise has been conﬁned to a relatively
small subgroup within the vast community of software developers. We should bearin mind, though, that things were not always this way: only a few decades ago assem-bler was pretty much the only game in town. Before those times, the only option was
crude machine language.
2
In our exploration of quantum programming languages we shall not begin with
raw quantum machine language, a territory at the frontier between quantum hard-
ware and quantum software; we touch this area a bit in Chapter 11. It goes without
saying that to be able to program at the true quantum machine level, a vast amountof know-how in the ﬁelds of quantum physics and quantum engineering is required.
The future quantum developer will not be expected to have such an in-depth exper-
tise, just as modern-day programmers have for the most part a scanty knowledge ofhardware issues. Furthermore, the need for a quantum programming language thatis to some extent machine independent is rather obvious: the algorithms presented
in Chapter 6 have clearly nothing to do with speciﬁc physical implementations. We
should thus be able to specify them much in the same way as we are used to withclassical algorithms. To do all these we need, at a minimum, a quantum assembler .
Although we can describe a quantum assembler without entering into the speci-
ﬁcs of quantum hardware, we still need to select an architecture for the underlyingquantum machine.
3
There are at least three quite different, although provably equivalent, candidate
architectures for quantum computation.4In Chapter 5, as you may recall, quantum
gates were introduced. By combining quantum gates, one ends up with a computa-tion model known as quantum circuits. Here is how:/D2The ﬁrst ingredient is an input device, through which we can feed quantum data./D2The second ingredient is a set of basic gates. Gates can be applied sequentiallyand in parallel, forming an acyclic-directed graph known as quantum circuit./D2The third ingredient is a device that enables us to carry out measurements. The
result of this operation will be a sequence of standard bits that can be read off
and further displayed, stored, and manipulated.
For a description of quantum circuits, their graphical notation, and some examples,
you can refer back to Chapters 5 and 6.
We could describe a quantum assembler using quantum circuits as our back-
ground architecture. Notice that in the model we have just presented, measuring oc-
curs only at the very end of the computing process. This is not a theoretical limitation
2Assembler and machine language are often confused. Indeed, for most practical purposes, they can besafely identiﬁed. Nevertheless, assembler represents a minimum of abstraction: register have names,and so do basic machine operations, such as ADD, PUSH, and REMOVE.
3It is exactly the same in the classical case. In any compiler design class, ﬁnite state machines, registers,heaps, stacks are introduced in order to illustrate what happens in response to speciﬁc commands.
4As a matter of fact, there are at least four: the last one is described in Raussendorf and Briegel (2001).In this model, there is no network involved. Instead, a cluster of entangled qubit is the starting point.Information is extracted via a sequence of one-qubit measurements. We are indebted to Stefano Bet-telli for pointing this out.

<<<PAGE 241>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
7.2 Quantum Assembly Programming 223
Figure 7.1. A simpliﬁed QRAM machine.
of the quantum circuits architecture, as it can be formally shown that measurements
can always be pushed to the end. However, it is perhaps a bit awkward from the
programming standpoint, as developers generally wish to inspect their variables any-where during the computation.
As a second option, we could choose the quantum Turing machine model, which
is presented in Chapter 8. These are precisely the quantum analog of Turing ma-chines. Much like classical Turing machines, this model is very convenient for dis-
cussing quantum complexity classes and other theoretical computer science issues,
but is not conducive to the design of algorithms or programming languages.
A third more convenient alternative, which we shall therefore adopt throughout
this chapter, is known as Quantum Random Access Memory Model (QRAM). The
QRAM is made of the following parts:/D2A classical computer, playing the role of the master./D2A quantum computing device (either internal or external), that can be accessedby the master computer on request.
Figure 7.1 is a simpliﬁed sketch of a QRAM machine.
The idea behind the QRAM is that the programmer writes classical code in a
standard classical language, say, C. When she needs the extra quantum power, shewill add a few lines of quantum assembler to her code.
5This q-assembler is the
way to access and use the quantum device. Notice that the programmer is not re-
quired to know anything about the internals of the quantum device. There is no
need to know how qubits are physically stored, initialized, manipulated, or mea-sured. The only information she may need concerns the capacity of the device, i.e.,
the maximum size of available quantum memory. Everything else will happen by
means of a Quantum Hardware Interface,o rQHI, which will translate assembler
commands issued by the master into explicit actions performed by the quantum
device.
As you have certainly not failed to notice, the description of the QRAM model
has been very vague (there are just two empty boxes in the picture). Let us ﬂesh
5This concept is not far-fetched: think of a graphic developer programming a sophisticated 3D game.
When she needs to carry out computationally intensive operations, such as fast matrix multiplicationsfor repositioning her objects in the scene, she can take advantage of a graphic accelerator via a fewsnippets of code embedded in the main program.

<<<PAGE 242>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
224 Programming Languages
Figure 7.2. A 9-qubit register.
it out a bit ...The ﬁrst box is a classical computer. Inside the master computer, the
control register will be used to store q-assembler instruction (after all, the instruc-
tions themselves are encodable as sequences of bits!). When the control pointer is
on one or the other of the quantum instructions, the master will use the quantumhardware interface to push it over to the servant device. What is inside the second
box? Essentially two things: a set of quantum data storage registers (we are going to
introduce them in a minute) and utilities that apply operations on the storage.
Note: Let us recall in passing that the no-cloning theorem will prevent quantum
assembler from having copying instructions . There is no way to copy the content of
a register to another one, a familiar and pervasive operation in ordinary assemblers.
The ﬁrst thing our programmer will do is to ask the quantum device through
the quantum hardware interface to initialize an addressable sequence of qubits.
These transactions happen through an interface known as the quantum register ,o r
q-register.
Deﬁnition 7.2.1 Aquantum register is an interface to an addressable sequence of
qubits (see Figure 7.2). Each q-register has a unique identiﬁer by which it is referred.
For the purpose of this discussion, we can safely think of the quantum register as
an array of adjacent qubits. Where and how they are actually stored in the quantum
chip is irrelevant in this context.
What is the actual size of the register, and how many registers are available?
Both questions will be left unanswered, as they depend on the progress made in
quantum hardware. For the time being, we can think of each register as having a
ﬁxed size, and a numerical code, by which it can be addressed.
After the quantum register has been initialized and manipulated, the program-
mer can issue a command that will measure selected portions thereof. The quantumdevice will perform the requested measurement, and it will return a classical value
that can be displayed and/or stored somewhere in the main program (e.g., as anarray of classical bits). This is depicted in Figure 7.3.
The loop-back arrow in Figure 7.3 means that the same pipeline can be repeated
as many times as needed.
As we have already mentioned, in this model measuring is interleaved with other
commands: our quantum programmer can ask at any time after initialization for the
value of an arbitrary section of the register.
6
6With one important caveat: whenever she observes parts of the register, she destroys its state.

<<<PAGE 243>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
7.2 Quantum Assembly Programming 225
Figure 7.3. Flowchart of quantum control.
We are now armed with the necessary understanding to begin the design of a
quantum assembler for the QRAM model. The toy assembler we are going to de-
scribe is not standard in any way.7It is here just for illustration purposes: real-life
q-assemblers may differ from the one in this section.8For a thorough presentation
of a quantum assembler in a real-life QRAM setting, you can read the article by
R. Nagarajan, N. Papanikolaou, and D. Williams (2005).
Let us begin. In the following we shall denote by the letters R1,R2,... , the iden-
tiﬁers (numerical codes) of the available q-registers. We shall also assume, for thesake of our discussion, that all registers are of size 8, i.e., they can store the quantum
analog of a byte, a qubyte . The preﬁx Rwill stand for the code of an unspeciﬁed
q-register.
We are now going to list the set of basic instructions comprising our language.
The QRAM architecture enables the calling program to push each individual in-
struction over to the quantum chip one at a time.
We need a way to initialize q-registers. More speciﬁcally, we need to pass a bit
array from the main program to a given q-register, and ask the quantum device to
initialize it accordingly./D2Initialize the register R:
INITIALIZE R [INPUT]
The optional INPUT is a classical array of bits, whose size matches the size of the
register (i.e., a byte). If it is not speciﬁed, it is assumed to be ﬁlled with zeros.
Example 7.2.1 The example below initializes a register Rof eight qubits; it then
reinitializes it using as input the bit array B=[00001111].
...
var B=[00001111] // before invoking quantum assembler
...
INITIALIZE R1
INITIALIZE R1 B
... /square
We shall assume that the default initialization procedure “cools off” all the
qubits to the ground state |0/angbracketright. In other words, if we initialize a q-register of size
7As a matter of fact, we extracted it from a few extant proposals of imperative quantum languages, by
discarding their high-level constructs.
8They almost certainly will, by taking advantage of a speciﬁc target hardware. The same happens in theclassical case. There is no universal assembly language, but a family or closely related languages, eachgeared toward a speciﬁc platform.

<<<PAGE 244>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
226 Programming Languages
5, the joint state is |00000/angbracketright. If, on the other hand, we do provide an INPUT such as
[00101], the system will take care of initializing our register to |00101/angbracketright.
Let us proceed. Once we have a register, we can address its individual qubits
for manipulation. For instance, R[0] will denote its ﬁrst qubit, and so on. As a con-
venience, though, we shall enrich our assembler with the capability of selecting a
subregister variable, which we can use later on for our needs. Subregister variables
will be denoted by the preﬁx letter S./D2Select from R the subregister made up of NUMQUBITS qubits starting at
R[OFFSET]. Store the address in the variable S.SELECT S R OFFSET NUMQUBITS
Example 7.2.2 We can iterate the instruction, extracting a subregister from an ex-
isting one:
...
INITIALIZE R1
S E L E C TSR 123
...
In this fragment of quantum assembler we have initialized a quantum register, and
we have then extracted a subregister formed by the qubits of index 2 ,3,4 and rep-
resented by the variable S(notice that we assume indices starting from 0, just like C
arrays). /square
Exercise 7.2.1 Consider the snippet of program:
INITIALIZE R1 [01110001]SELECT S1 R1 2 4
SELECT S2 S1 0 2
...
Which qubits of R1 have we selected in S2? /squaresolid
As we have already mentioned, the second essential ingredient is the basic uni-
tary transformations, known as gates (we have dedicated Section 5.4 to quantum
gates; our reader is referred there for details):
GATES ={G
0,G1,..., Gn−1}. (7.1)
Note: Different choices9of basic quantum gates can be made, as long as the set
GATES is auniversal set of gates, i.e., it generates allunitary transformations on
a ﬁnite-dimensional Hilbert space via successive applications of composition andtensoring. In practice, gates like Hadamard that are constantly used should be partof the primitives, so GATES does not necessarily have to be a minimal generating
set (redundancy is allowed).
9In the design of real-life quantum assembler, the choice would be dictated, at least in part, by whichgates are easily implementable on the target hardware.

<<<PAGE 245>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
7.2 Quantum Assembly Programming 227
In the following exercises and examples we shall adopt the following set of
gates:
GATES ={H,Rθ,In,CNOT}, (7.2)
where H,Rθ,In, and CNOT denote the Hadamard, the phase shift by an angle θ,
then×nidentity matrix, and the controlled-NOT gate, respectively./D2The basic instruction will look like
APPLY U R
where U will be a suitable unitary gate matching the size of the register R.
Most classical assemblers have some support for macros , and here we shall take
the same course. We need ways to build new unitary transformations by concatenat-
ing more basic building blocks and by taking inverses (Remember: Unitary trans-
formations are closed by composition and inverse!). The resulting transformation is
given a name, and each time we intend to use it, it will be expanded inline by theassembler into its constituents. Let us now see how:/D2The composition operation, that executes sequentially from right to left two uni-tary transformations U
1andU2, and saves the result in a variable U:
U CONCAT U 1U2/D2The tensor product (alias the parallelization) of operations: Uis the result of
tensoring U1andU2:
U TENSOR U 1U2/D2The inverse: Uis the result of taking the inverse of U1(i.e., the transformation
that “undoes” U1):
U INVERSE U 1
Note: Why the identity matrix? The simple reason is that it is needed to pad uni-
tary transformations to the appropriate size. Suppose, for instance, that you havea q-register of four qubits, but you want to manipulate only the ﬁrst two, via, say,Hadamard. What you are going to do is to tensor Hwith I
2, which leaves the third
and fourth qubit unchanged.
Example 7.2.3 Let us express some simple unitary transformations in our assem-
bler:
U1CONCAT R π
4Rπ
2
U2CONCAT U 1U1
U3CONCAT U 2H
Which unitary transformation corresponds to U3? We just follow the sequence
of matrix operations:
U3=U2⋆H=(U1⋆U1)⋆H
=(Rπ
4⋆Rπ
2)⋆(Rπ
4⋆Rπ
2)⋆H
=Rπ
4⋆Rπ
2⋆Rπ
4⋆Rπ
2⋆H. (7.3)

<<<PAGE 246>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
228 Programming Languages
We are now to going to replace each gate with the corresponding matrix:
U3=1√
2⎡
⎢⎣10
0eπ
4⎤
⎥⎦⎡
⎢⎣10
0eπ
2⎤
⎥⎦⎡
⎢⎣10
0eπ
4⎤
⎥⎦⎡
⎢⎣10
0eπ
2⎤
⎥⎦⎡
⎢⎣11
1−1⎤
⎥⎦
=⎡
⎢⎣0.70711 0.70711
0.70711 i0.70711 i⎤
⎥⎦. (7.4)
/square
It is your turn: in the following exercise we are going to use tensoring.
Exercise 7.2.2 Here is a snippet of quantum code:
...
U1TENSOR CNOT CNOT
U2CONCAT U 1U1
...
Which unitary transformation corresponds to the variable U2? On how many
qubits does it act? /squaresolid
Exercise 7.2.3 Write down the assembler code that generates the following unitary
transformation in terms of the basic gates set GATES:
U=⎡
⎢⎢⎢⎢⎢⎢⎢⎣10 0 0
0−10 0
00 1 000 0 −1⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (7.5)
What is the action of Uon a 2-qubit subregister? /squaresolid
Let us move forward. We need to measure a register:/D2Measure the register Rand put the results in the classical variable RES, pointing
to a bit array:
MEASURE R RES
Example 7.2.4 Here is a fragment of a program in quantum assembler:
INITIALIZE R 2
U TENSOR H H
APPLY U R
MEASURE R RES

<<<PAGE 247>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
7.2 Quantum Assembly Programming 229
We can now read the bit array RES . What is the chance that we ﬁnd the sequence
11? Let us read the code one line at time.
(i) The ﬁrst instruction allocates a 2-qubit register named Rand initializes it
to|00/angbracketright.
(ii) The second line creates a unitary matrix Uof size 4 ×4:
U=H⊗H=1
2∗⎡
⎢⎢⎢⎢⎢⎢⎢⎣11 1 1
1−11 −1
11−1 −1
1−1−11⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (7.6)
(iii) The third line applies UtoR:
1
2⎡
⎢⎢⎢⎢⎢⎢⎢⎣1 111
1−11 −1
11 −1−1
1−1−11⎤
⎥⎥⎥⎥⎥⎥⎥⎦⎡
⎢⎢⎢⎢⎢⎢⎢⎣1
000⎤
⎥⎥⎥⎥⎥⎥⎥⎦=⎡
⎢⎢⎢⎢⎢⎢⎢⎣
1
2
1
21
21
2⎤
⎥⎥⎥⎥⎥⎥⎥⎦=1
2|00/angbracketright+1
2|01/angbracketright+1
2|10/angbracketright+1
2|11/angbracketright.
(7.7)
(iv) Finally, the last line measures the q-register R1and stores the result in
the bit array RES . What is the probability that RES=|11/angbracketright?W es i m p l y
calculate it from the coefﬁcient of |11/angbracketright:
|1
2|2=1
4=0.25. (7.8)
This is no surprise: the parallel application of Hto the two qubits puts the
register in a balanced superposition of the four basic states. /square
In the last example, measurement was the last step. The following exercise shows
a bit of code where gates and measurement are interleaved, and measurement is
restricted to a subregister.
Exercise 7.2.4 Consider the quantum assembler code:
INITIALIZE R 2
U TENSOR H I 2
APPLY U RSELECT S1 R 0 1MEASURE S1 RESAPPLY CNOT R
MEASURE R RES

<<<PAGE 248>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
230 Programming Languages
We can now read the bit array RES . What is the chance that we ﬁnd the bit
sequence 10? /squaresolid
So far, there is a glaring omission: no control structures, such as the familiar
conditional jumps. The reason is that they are dispensable. If our programmer
wants to implement a if–then–else, she can issue a measurement statement, getback a bit array, and use a classical conditional structure (if, while, case, etc.) to
branch out. For instance, going back to the last exercise, she could add a statementsuch as
IF(RES==[10]) THEN APPLY CNOT R ELSE APPLY H R
The exact syntax of the conditional would depend on the classical “host” lan-
guage, i.e., the language she adopts to run the master machine.
Exercise 7.2.5 Go back to the last exercise. After initialization (ﬁrst instruction),
add a while loop that includes all other instructions in the while block and stops only
when RES=[10]. Is it guaranteed that the program will always terminate? /squaresolid
What we have presented so far is a rather minimalist q-assembler: it contains
only one data type, namely quantum binary strings. However, we have accomplished
what we set forth to do: we now have a quantum language that can express quantumalgorithms (try your hand with the following exercise).
Exercise 7.2.6 Write a program that implements Deutsch’s algorithm described in
Chapter 6. /squaresolid
In the next section, we investigate how we could expand it with more sophisti-
cated constructs.Programming Drill 7.2.1 Write a lexical analyzer for the quantum assembler de-
scribed in this section. You can use a large variety of tools, including Lex on UNIX,
Bison on Linux, JavaCC for Java, or Parsec for Haskell.
7.3 TOWARD HIGHER-LEVEL QUANTUM PROGRAMMING
The quantum assembler described in the last section is sufﬁcient, at least in princi-
ple, to implement quantum algorithms such as the ones seen in Chapter 6. Just like
everything in classical computing is ultimately represented as a sequence of bits,in quantum computing the basic constituents are sequences of qubits. However, in
classical computation we have a vast array of languages that provide several built-in
data types, such as integers, ﬂoating numbers, character strings, and the capabilityof creating new user-deﬁned types (such as structures in C, or objects in C++, Java,or Perl). It would be great if the same happened here.
Indeed, even from the standpoint of the algorithms we presented, this need
emerges quite naturally: Shor’s algorithm, for instance, is about integers , not bit

<<<PAGE 249>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
7.3 Toward Higher-Level Quantum Programming 231
sequences. An implementation in quantum assembler would entail representing in-
tegers as sequences of bits, and thus as sequences of qubits (via the usual identi-
ﬁcation of 0 with |0/angbracketrightand of 1 with |1/angbracketright), all done explicitly by us. Similarly, if one
wants to add two integers, one must ﬁnd a unitary transformation that corresponds
to addition, and moreover write it as a sequence of basic gates.
To gauge what is involved here, it is worth exploring how classical operations
can be implemented as unitary transformations. Let us start with a boolean map
f:{0,1}n−→ { 0,1}n, (7.9)
in other words, a map from a sequence of nbits to itself. We intend to produce a
map
Uf:C2n−→C2n, (7.10)
such that its “restriction” to regular bit sequences, when we identify the bit sequenceb
1...bNwith the corresponding qubit sequence |b1/angbracketright...|bN/angbracketright=| b1...bN/angbracketright, is precisely
f:f(|b1...bN/angbracketright)=|f(b1...bN)/angbracketright.
Iffwere an invertible map, it would have been easy: in this case, it sufﬁces to
extend flinearly by deﬁning Ufas
Uf(c0(|0...00/angbracketright+ c1|0...01/angbracketright+···+ c2n−1|1...11/angbracketright)
=c0(|f(0...00/angbracketright)+c1f(|0...01/angbracketright)+···+ c2n−1f(|1...11/angbracketright). (7.11)
As you can easily check, Ufis not only linear, but unitary, and thus within reach of
our quantum device.
Exercise 7.3.1 Verify that finvertible implies that Ufis a unitary map. /squaresolid
Unfortunately, if fis not invertible, Uffails to be unitary.
Exercise 7.3.2 Provide a simple example of the fact that a noninvertible fgener-
ates, following the recipe given in Equation (7.11), a nonunitary map. /squaresolid
Luckily, things are not so bad. There is a way around, that comes at some price,
as it requires extra quantum memory. Let us see how it works. The basic idea is
that we can turn an irreversible function from bit sequences to bit sequences into a
reversible one , by carrying the input along with the result:
Uf:|x/angbracketright|y/angbracketright /mapsto−→ | x/angbracketright|f(x)⊕y/angbracketright. (7.12)
In particular, for y=0, we get
Uf:|x/angbracketright|0/angbracketright /mapsto−→ | x/angbracketright|f(x)⊕0/angbracketright=| x/angbracketright|f(x)/angbracketright. (7.13)
Ifx1/negationslash=x2, where x1,x2are two bit sequences of the same length n,
Uf(|x1/angbracketright|0/angbracketright)=|x1/angbracketright|f(x1)/angbracketright /negationslash=| x2/angbracketright|f(x2)/angbracketright= Uf(|x2/angbracketright|0/angbracketright). (7.14)

<<<PAGE 250>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
232 Programming Languages
Ufis injective on the standard basis padded with zeros. As a matter of fact, Uf
is reversible on all inputs.
Exercise 7.3.3 Prove that Ufis a reversible map from 22nto itself. /squaresolid
We can thus extend it by linearity on a generic input, using the recipe given in
Equation (7.13).
The map Ufassociated with the function fshould sound familiar to you if you
have gone through Chapter 6: it is indeed the same map that was used to represent
classical functions in many of the algorithms.
Observe that our input register has doubled its length: each time we wish to
apply fto an input |x/angbracketright, we must pad it with a sequence of 0s as long as the input
itself.
A simple example will illustrate the foregoing.
Example 7.3.1 Consider the boolean function fgiven by the following table:
xf (x)
00 00
01 0010 0111 11(7.15)
The function fis clearly not invertible. Let us turn it into a reversible one.
x,yf (x)⊕y,xx ,yf (x)⊕y,x
0000 0000 1000 10010001 0001 1001 10000010 0010 1010 10110011 0011 1011 10100100 0100 1100 11110101 0101 1101 1110
0110 0110 1110 1101
0111 0111 1111 1100
(7.16)

<<<PAGE 251>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
7.3 Toward Higher-Level Quantum Programming 233
Now, we can simply extend the foregoing chart by linearity to obtain the desired
Uf:
Uf(c0|0000/angbracketright+ c1|0001/angbracketright+···+ c16|1111/angbracketright)=c0|0000/angbracketright+ c1|0001/angbracketright+···+ c16|1100/angbracketright.
(7.17)
To compute fon the input 11, we simply “pad” it with the appropriate number
of zeros (in this case two) and set our register to |1100/angbracketright. Now, we apply Ufto it and
get 1011. Finally, we measure the subregister given by its ﬁrst two indexes, obtaining
01, as desired. /square
It may seem as an idle and a bit silly exercise to go through this roundabout way,
simply to carry out classical computation which could be safely performed on a clas-sical machine in a snapshot. But it is not so: think again the role that U
fplayed in
Deutsch’s algorithm. We can use it to compute fon a superposition of classical in-
puts. For instance, if fstands for some arithmetical operation, we can now perform
it on allclassical inputs, in one single step: applying Uf.
Exercise 7.3.4 Consider the set of positive integers {0,1,..., 15}. In other words,
the numbers that one can express with four bits. Write the unitary map that corre-sponds to the map f(n)=n+2, ifn≤13, and f(n)=n, otherwise. /squaresolid
The trick described earlier has two main costs:/D2The reversibilization operation we performed by hand requires explicit calcula-tions of fon all the input values, and the table grows exponentially in the size of
the input. That is, of course, unacceptable because such a preprocessing woulderode all the beneﬁts of quantum speedup (not to mention the unpleasant factthat to carry out simple arithmetical operations via U
f, we must already compute
allf’s values!)./D2The extra qubits one needs to allocate. As it stands, it could create a big quantummemory issue, in case we needed to carry out several operations in a row.
As for the ﬁrst issue, there are effective ways to turn an irreversible function into
a reversible one in polynomial time, at least for certain function classes, withoutexplicit calculations. The key idea is that one analyses the function in terms of itsrecursive deﬁnition, and uses that representation to rebuild it as a reversible one. We
shall not pursue this fascinating topic here, but you can ﬁnd some useful references
in Bennett (1988).
Concerning the second item, there is an elegant solution, due to Bennett, known
as the quantum scratch pad . Here is how it works: suppose you apply the function g
to the output of function f:
|x,0,0/angbracketright /mapsto−→ | x,f(x),0/angbracketright /mapsto−→ | x,f(x),g(f(x))/angbracketright /mapsto−→ | x,0,g(f(x)/angbracketright. (7.18)
Notice that in the last step we have just “undone” |x,f(x)/angbracketrightby applying the inverse
ofU
f. Now, the unused zero qubit can be recycled for future computations.

<<<PAGE 252>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
234 Programming Languages
Exercise 7.3.5 Try to use the scratch-pad trick to compute f◦fwhere fis as in
Exercise 7.3.4. /squaresolid
What have we learned? Suppose that we want to represent a classical data type
such as Int, and its basic operations, on our quantum device. The steps involved are
as follows:/D2Represent the data type in the usual way, as bit sequences./D2Represent each of its operations as a unitary map, by turning it ﬁrst into a re-versible map./D2Analyze the unitary operations obtained in the previous item as quantum cir-cuits, i.e., decompose them in terms of quantum gates.
10
The use of our quantum assembler makes these steps entirely our responsibil-
ity. A bit cumbersome, isn’t it? We can then envision future quantum languageswhere all this happens under the hood, at the compiler level. For instance, ourprogrammer declares a classical variable of type integer and initializes it to some
value:
Int n=3. (7.19)
She then decides to “quantize” it, so she creates a “quantum integer value” qn,o f
type QInt, and sets it equal to n. She then applies some gate Gtoqn, measure it,
and stores the value back into n.
QInt qn= n
...
APPLY G qnMEASURE qn n
We are going to conclude this section with a very sketchy survey on where we ac-
tually are, as far as designing higher-level quantum languages. The interested reader
can consult the three excellent surveys by P. Selinger (2004b), by J. Gay (2005), and
one by R. R ¨udiger (2007) for fairly comprehensive views.
Classical higher-level languages are classiﬁed into broad groups, the broadest
and most famous one being imperative programming . This class contains most
of the languages that are commonly used in the workplace. A typical programis mainly a sequence of commands, interspersed with ﬂow control statements. C,C++, Java, PERL, Python, and many, many others, all ﬁt within this programming
paradigm.
Some of the ﬁrst proposals of quantum languages have been inspired by the
imperative model. A typical example is QCL, written by Bernhard ¨Omer. QCL has
a C-like syntax, augmented by a new QReg type, which lets the programmer access
quantum registers. There is an important difference with respect to the registerswe have encountered in the previous section: here, registers are variables . Just like
10We have already mentioned that only certain classes of functions can been effectively turned into re-versible maps and realized as quantum circuits. This point is critical, else the potentially huge beneﬁtsof quantum speedup could be easily eroded by these preprocessing steps.

<<<PAGE 253>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
7.3 Toward Higher-Level Quantum Programming 235
in classical high-level languages, you do not need to specify any concrete memory
location. You just say: “give me a register of size N,” and the compiler takes care of
allocating quantum memory. In the same spirit, in QCL unitary gates are operators(they look and feel like C functions). A QCL developer can write familiar classicalC-like code, interspersed with instantiation and manipulation of q-registers.
...
quregR [4]; // 4-qubit quantum register
...
H(R[2]); // Hadamard operation on the third qubit of the register
...
QCL is more than quantum assembler with memory management, as it sup-
ports user-deﬁned operators and functions, much in a same way as in modernclassical languages. Here is a simple example:
...
operator myop (qureg q)
H(q); // Hadamard transform on q
Not(q); / /t h eN O Tg a t eo nq
CPhase(pi, q); // Controlled phase shift on q; it rotates it if q =1111 . . .
QCL is not just a speciﬁcation of a quantum language. An implementation in C++
exists and is downloadable at ¨Omer’s Web site.
Programming Drill 7.3.1 Download and install QCL, and then write an implemen-
tation of Grover’s algorithm.
An imperative quantum language akin to QCL is Q, by S. Bettelli and others. Q
takes the stance of promoting operators to full-ﬂedged objects , like in C++. Unlike
QCL, which is in a sense self-contained, Q looks like an extension of C++, enrichedby QRegisters and QOperators.
For a comparison of QCL and Q, you can read the joint interview of ¨Omer and
Bettelli (the reference is in R ¨udiger (2007), where they expound their guiding design
philosophies.
In spite of their popularity, imperative languages are by no means the only op-
tion available; for instance, Prolog is a language that belongs to the so-called logic
programming class, where a program is a speciﬁcation of properties and relations in
a fragment of ﬁrst-order logic, and then queries such as: Is it true that the variable aenjoys the property P? As of the time of this writing, no quantum logic programming
language has been proposed yet, but things may change in the future.
A third subclass is known as functional programming . Here a program can be
seen as the speciﬁcation of a function. The program will be provided with an accept-
able value for the function and it will compute the return value. The prototypical
example is LISP, a language you may have met already if you have taken a class on
expert systems. There are many other functional programming languages, such as

<<<PAGE 254>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
236 Programming Languages
Figure 7.4. A snippet of a Quantum Flow-
chart (QFC) program.
ML, Miranda, or Haskell. These languages are very powerful and extremely ﬂexible,
but not very popular in the industrial world.11Their chief users are academicians
and industrial researchers working in the areas of theoretical computer science andartiﬁcial intelligence. It thus comes as no surprise that some of the ﬁrst proposalsfor a high-level quantum programming language are functional languages. Thereare, however, other deeper motivations: functional languages, classical or quantum,
lend themselves nicely to compile-time-type checking and correctness proofs. For
languages in this category, there is an extensive body of work on denotational andoperational semantics, that can be used as a baseline for the designer of new quan-
tum languages.
The “quantum slogan” at page 221 says that quantum programming is quantum
data plus control. But, what kind of control? Peter Selinger (2004b) has proposed a
functional quantum programming language, known as QFC , which combines quan-
tum data and classical control. Selinger’s variant of the quantum slogan is
QUANTUM DATA AND CLASSICAL CONTROL
Control is speciﬁed using a ﬂowchart type of syntax. Figure 7.4 is a ﬂowchart of
a program.
11Though things are rapidly changing: the newly popular Ruby is an OOP imperative language which
incorporates some features of the functional paradigm (most notably the capability of writing meta-programs. The web framework Rails, entirely written in Ruby, is based on Ruby’s meta-programmingfeatures). We expect that mixed languages similar to Ruby will play an important role in the future ofIT, as programs will process not only data, but other programs as well.

<<<PAGE 255>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
7.4 Quantum Computation Before Quantum Computers 237
The same program in text syntax is
new qbit p, q : =0// initializes two qubits to |0/angbracketright
q*= H //multiply the second qubit by Hadamard
measure q then //start conditional: measures second qubit
{p* =H} //if the result is 0, apply Hadamard to the ﬁrst qubit
else //if the result is 1
{p* =NOT } // ﬂips the ﬁrst qubit
Exercise 7.3.6 Download Selinger’s paper on QFC, and write down a simple pro-
gram that (1) initializes three qubits to zero, (2) applies Hadamard to the ﬁrst one,
and (3) measures the ﬁrst qubit. If it is zero, it ﬂips the second qubit; else, it maxi-
mally entangles the second and the third. /squaresolid
In classical functional programming, the distinction between data and control is
blurred: programs themselves can be handled as data, naturally generating metapro-gramming patterns (i.e., programs that manipulate other programs, or even them-selves). Indeed, this feature is one of the strongest edges of the functional paradigm.Recently, Grattage and Alterlich have proposed a new functional quantum pro-
gramming language, known as QML (see Grattage and Altenkirch, 2005), for which
the claim is made that both data and control are quantum.
12
7.4 QUANTUM COMPUTATION BEFORE QUANTUM COMPUTERS
For the time being, there are no quantum computers available aside a few exper-imental devices that operate on very small qubit registers (more on this in Chap-
ter 11).
Nevertheless, things are not too gloomy: we can still emulate quantum comput-
ers on classical ones, as long as their quantum data storage is small. As we will learn
in Chapter 8, in principle quantum machines can be successfully simulated by Turing
machines, and thus by ordinary computers. Unfortunately, this emulation grows ex-ponentially in the size of the qubit register, making it soon unfeasible. However, if
we work with programs involving only a small amount of qubits, a successful emu-
lation can be run on your desktop.
What is actually required to build a quantum emulator from scratch? As we have
seen in Section 7.2, a quantum computing device consists of quantum registers andoperations acting on them. To simulate a quantum register, we ﬁrst need to simu-late individual qubits. Now, via the standard representation, a qubit is just a (nor-malized) pair of complex numbers. Some languages, such as MATLAB or Maple,
already come equipped with complex numbers (see the MATLAB Appendix for a
tutorial on using MATLAB for quantum computing emulations). With others, you
12To which extent the claim is correct is, at the time of writing, debatable. On the one hand, QML doesprovide new conditional constructs, such as the new “quantum if” statements. On the other hand, suchconditional constructs cannot be nested, restricting considerably the notion of control as it commonlyintended.

<<<PAGE 256>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
238 Programming Languages
can either use suitable external libraries or deﬁne them yourself. A quantum reg-
ister of size Ncan be represented as an array of 2Ncomplex numbers, whereas a
unitary transformation of the register will be represented by a 2N×2Nmatrix (as
you can imagine, things get out of hand pretty fast!).
You can ﬁnd a list of numerous quantum emulators at the Quantiki Web site
http://www.quantiki.org/wiki/index.php/Main Page. You just have to choose the
language. Even better, you can build your own!
Programming Drill 7.4.1 Design and implement a quantum computer emulator in the
language of your choice. (Hint: If you have done consistently all other programming
drills, you are almost done.)
.................................................................................
References: QRAM was ﬁrst introduced in Knill (1996). According to the survey
on quantum programming languages by Peter Selinger (2004a), Knill’s paper is also
the ﬁrst known paper on quantum programming.
These are nice survey articles on quantum programming: Bettelli, Calarco, and
Seraﬁni (2001), Gay (2005), andSelinger (2004a).

<<<PAGE 257>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
8
Theoretical Computer Science
The meaning of the world is the separation of wish and fact.
Kurt G ¨odel, quoted in Hao Wang’s AL o g i c a l
Journey: From G ¨odel to Philosophy, page 3091
In a sense, theoretical computer science is uniquely qualiﬁed to study quantum com-
puting. After all, Alan Turing and the other founders of theoretical computer sci-ence studied formal computation long before engineers actually produced a real-life
computer. At present, large-scale quantum computers are not a reality yet. Never-
theless, the theoretical analysis of quantum computability and complexity is well onits way.
In Section 8.1, we start with a quick review of some of the basics of determinis-
tic and nondeterministic Turing machines and the complexity classes that they en-gender. However, we shall discuss them in a way that is easily generalizable for
our purposes. Section 8.2 moves on to probabilistic Turing machines and their zoo
of complexity classes. Our main objective is found in Section 8.3, where we meetquantum Turing machines and their complexity classes. We shall also state somebasic theorems and ideas about quantum computation.
8.1 DETERMINISTIC AND NONDETERMINISTIC COMPUTATIONS
Theoretical computer science deals with the question, “What is computable?” Wemust immediately qualify the question: “computable according to which model of
computation?” It turns out that if we omit the question of efﬁciency, all sufﬁciently
complicated formal models of computation can simulate each other. However, in
order to ﬁx our ideas and notation, we have to stick with one and work with it. Forhistorical reasons, we choose the Turing machine model.
We are going to assume that our reader already knows the basic “yoga” of Tur-
ing machines (see Figure 8.1). The simple facts are that a Turing machine is a device
1We are indebted to John D. Barrow for the source of this quote.
239

<<<PAGE 258>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
240 Theoretical Computer Science
Figure 8.1. Turing machine.
with a two-way inﬁnite tape that serves as a place to read input, write output, do
scrap work, and to store a potentially inﬁnite amount of information. The tape issplit into a one-dimensional inﬁnite array of boxes, each of which can hold exactly
one symbol at a time. The machine can be in one of a ﬁnite set of states at any given
moment and “see” one box at a time. It can move along the tape in any of two di-rections: left (L) or right (R). At each time step, the machine can read one box onthe tape, write on that box, move, and change states.
Formally, a deterministic Turing machine Mis a 6-tuple
M=(Q,/Sigma1,q
start,qaccept,qreject,δ), (8.1)
where Qis a ﬁnite set of states, /Sigma1is a nonempty ﬁnite alphabet that includes a
symbol # which we call “blank”; qstart,qaccept,qreject are all elements of Q; and a
transition function δ,
δ:Q×/Sigma1−→ Q×/Sigma1×{L,R}. (8.2)
For a given q∈Qandσ∈/Sigma1ifδ(q,σ)=(q/prime,σ/prime,D), we mean that
If Turing machine Mis in state qand the eye encounters symbol σ, then the
machine should exchange symbol σforσ/prime, move one box in the direction D∈
{L,R}, and enter state q/prime∈Q.
Equivalently, we can write the function δas
δ/prime:Q×/Sigma1×Q×/Sigma1×{L,R}− →{ 0,1}, (8.3)
where
δ/prime(q,σ,q/prime,σ/prime,D)=1 if and only if δ(q,σ)=(q/prime,σ/prime,D). (8.4)
Because for every q∈Qandσ∈/Sigma1,δhas exactly one output ( q/prime,σ/prime,D)∈Q×/Sigma1×
{L,R}, our (deterministic) transition functions must satisfy the following require-
ment:
(∀q∈Q)(∀σ∈/Sigma1)/summationdisplay
q/prime∈Q,σ/prime∈/Sigma1,D∈{L,R}δ/prime(q,σ,q/prime,σ/prime,D)=1. (8.5)
It is not hard to see that any δis equivalent to a δ/primethat satisﬁes Equation (8.5).

<<<PAGE 259>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
8.1 Deterministic and Nondeterministic Computations 241
The set of all words in /Sigma1without blanks is denoted ( /Sigma1−{#})∗. An input string
from this set is placed on the tape at a speciﬁc starting place. The rest of boxes on
the tape are assumed to have blanks. The Turing machine is then “let loose” fromstate q
startand follows the rules that are described by δ/prime. There are three possibilities
that can occur to such a machine: (1) the Turing machine can reach state qaccept ,( 2 )
the Turing machine can reach state qreject , or (3) the Turing machine can enter an
inﬁnite loop and never reach qaccept orqreject . Think of a Turing machine as solving a
decision problem by being presented with an input and then examining which state
the machine will enter. Each such machine determines a language L⊆(/Sigma1−{#})∗of
those words that the machine accepts.
Although there are many other models of computation, we are comfortable with
the deterministic Turing machine because of the following thesis:
Thesis. The Classical Church–Turing Thesis states that any problem that is intu-
itively computable can be computed by a deterministic Turing machine.
This thesis cannot be proved because it is impossible to give an exact deﬁnition
of what is meant by “intuitively computable.” However, most researchers agree that
the thesis is a true statement.
In this chapter, we work through several examples and present some exercises
involving Turing machines that follow the same theme. These machines are buildup to a crescendo until we reach a Turing machine version of the double-slit exper-iment.
Example 8.1.1 Consider the following problem: a word of odd length in the al-
phabet /Sigma1={0,1,#}is given as input and we are asked if this string contains a “1.”
Words that have at least one “1” are accepted and words that are all “0’s” are re-
jected. We are deciding the language
L={w∈/Sigma1
∗:|w|=2m+1,(∃i)wi=“1”}. (8.6)
The usual convention is that the head of the Turing machine is at the leftmost letterof the input, but we shall be slightly unconventional and assume that the head is
reading the center symbol of the odd-length string.
Let us describe a deterministic Turing machine to solve this problem. The ma-
chine should start with its head in the center.
2The head should move to the left
looking for a “1.” If the left end of the word is reached, then the head should move
to the right searching for a “1.” If a “1” is found, then the computer should enter
qaccept . If the head reaches the right end of the word without ﬁnding a “1,” then the
machine goes into state qreject . By convention, if the machine enters a halting state,
then the head just stays there. This Turing machine will not change anything on thetape.
3
2We have the adopted the convention that if the word is empty it is rejected.
3In fact, what we have described is a two-way ﬁnite automaton. This example does not require the fulldeﬁnition of a Turing machine.

<<<PAGE 260>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
242 Theoretical Computer Science
Formally, the set of states will be Q={qstart,qaccept,qreject,qL,qR}andδis de-
ﬁned by the following table:
δ 01#
qstart qL,Lq accept qreject
qL qL,Lq accept qR,R
qR qR,Rq accept qreject(8.7)
Each row tells what should be done in that state. The columns describe which
symbol is seen. The entry tells us which state to enter and in which direction to move.
In words, the search begins by going to qLthat continually moves to the left. When
the machine hits #, the state enters qRthat always moves to the right. At any time, if
a “1” is found, the machine enters qaccept .Aconﬁguration (also called a snapshot ,o r
instantaneous description ) of a Turing machine contains the complete information
of the machine at a particular time step. There are three pieces of information that
have to be described:/D2the tape’s contents,/D2the state of the machine, and/D2the position of the head of the Turing machine.
We shall summarize all three pieces of information by writing the contents of thetape and the state exactly to the left of the position that the machine is reading. An
example of a conﬁguration is
#00001001 q
450010101#, (8.8)
which means that #000010010010101# is on the tape, the state is q45, and the head is
reading the ninth symbol which is a “0.” (We will later need the obvious fact that all
the conﬁgurations can be put in lexicographical order.)
A typical computation, i.e., a sequence of conﬁgurations, might look like this:
#000 qstart0010#/mapsto−→ #00qL00010#/mapsto−→ #0qL000010# /mapsto−→ #qL0000010# /mapsto−→
qL#0000010# /mapsto−→ #qR0000010# /mapsto−→ #0qR000010# /mapsto−→ #00qR00010#/mapsto−→
#000 qR0010#/mapsto−→ #0000 qR010#/mapsto−→ #00000 qR10#/mapsto−→ #00000 qaccept 10#. (8.9)
In the worst-case scenario, for an input of size n, the machine will have to per-
form n+n
2operations before a “1” is found or before it realizes that no “1” is in the
word. We shall revisit this example in the next section. /square
Exercise 8.1.1 Write a deterministic Turing machine that determines if the input
string has a substring “101.” You might have to begin by moving off the center a

<<<PAGE 261>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
8.1 Deterministic and Nondeterministic Computations 243
little. For an input of size n, how many moves does the Turing machine have to
make in the worst case? /squaresolid
What can and cannot be computed is not our exclusive interest. Another impor-
tant issue is what can be computed efﬁciently . We shall be looking at different sets
of problems of various degrees of difﬁculty. A complexity class is a set of problems
that can all be solved by a certain model of computation within certain efﬁciency
bounds. By examining and comparing different complexity classes, we shall derive
principles about different models of computation.
The number of computational time steps that a machine must undergo before it
enters an accepting or rejecting state is the number of steps for the computation. Thenumber will usually depend on the size of the input. Hence we describe a functionfrom the size of an input to the number of steps in the computation. Such a function
might be a polynomial. If every input to a problem can be solved within a polynomial
number of steps, then the problem is said to be solvable in a polynomial number ofsteps.
Complexity Class. P is the set of problems that can be solved by a deterministic
Turing machine in a Polynomial number of steps.
This complexity class is important because of the following thesis:
Thesis. The Cook–Karp Thesis states that problems that are “tractably com-
putable” can be computed by a deterministic Turing machine in polynomial time,
i.e., are in P.
This thesis also cannot be proved because it is impossible to give an exact def-
inition of what we informally mean by “tractably computable.” In fact, one would
be hard-pressed to argue that a problem that demands n100steps for an input of size
nis tractable. Nevertheless, n100is a function that grows slower than any nontrivial
exponential function (including 1.001n).
Exercise 8.1.2 Find the least nsuch that 1.001n≥n100. /squaresolid
There are other interesting models of computation. A nondeterministic Turing
machine is similar to a deterministic Turing machine, but we eliminate the require-
ment that at every step of the computation, the machine proceeds to exactly one
subsequent step. In other words, for a given q∈Qand a σ∈/Sigma1, the machine can
enter into a subset (possibly empty) of Q×/Sigma1×{L,R}. Formally, a nondeterminis-
tic Turing machine Mis a 6-tuple
M=(Q,/Sigma1,qstart,qaccept,qreject,δ), (8.10)
where Q,/Sigma1,qstart,qaccept,qreject are as before and δis a function
δ:Q×/Sigma1−→℘(Q×/Sigma1×{L,R}), (8.11)

<<<PAGE 262>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
244 Theoretical Computer Science
where ℘is the powerset function. For a given q∈Qandσ∈/Sigma1if (q/prime,σ/prime,D)∈
δ(q,σ), we mean that
If Turing machine Mis in state qand the eye encounters symbol σ,t h e n one of
the actions that the machine could perform is to exchange symbol σforσ/prime,m o v e
one box in the direction D∈{L,R}, and enter state q/prime∈Q.
Just as we rewrote function (8.2), we might also rewrite function (8.11) as
δ:Q×/Sigma1−→ { 0,1}Q×/Sigma1×{L,R}, (8.12)
where{0,1}Q×/Sigma1×{L,R}is the set of functions from Q×/Sigma1×{L,R}to{0,1}. Whereas
δin function (8.11) chooses a subset of Q×/Sigma1×{L,R},δin function (8.12) chooses
the characteristic function of the same subset. We may write this δsimilar to function
(8.3):
δ/prime:Q×/Sigma1×Q×/Sigma1×{L,R}− →{ 0,1}, (8.13)
but this time we do not insist on the requirement that δ/primemust satisfy Equation (8.5).
In other words,
(∀q∈Q)(∀σ∈/Sigma1)/summationdisplay
q/prime∈Q,σ/prime∈/Sigma1,D∈{L,R}δ/prime(q,σ,q/prime,σ/prime,D)=0,or 1, or 2, or..., orn.
(8.14)
The largest nis|Q×/Sigma1×{L,R}|.
Exercise 8.1.3 Show that every nondeterministic Turing machine is equivalent to
a nondeterministic Turing machine that bifurcates into exactly two states at every
time step. Another way of stating this is that the summation in Equation (8.14) isexactly 2. /squaresolid
In nondeterministic Turing machines, a computation can perform one of several
different tasks at each time step. We say that a word is accepted by such a machine
Mif there exists a computational path that ends in q
accept .
Complexity Class. NP is the set of problems that can be solved by Nondeter-
ministic Turing machines in a Polynomial number of steps.
Because every deterministic Turing machine is also a nondeterministic Turing
machine (i.e., any δ/primethat satisﬁes Equation (8.5) also satisﬁes Equation (8.14)), every
problem that can be solved in polynomial time by a deterministic Turing machinecan also be solved by a nondeterministic Turing machine in polynomial time. Hence,P⊆NP. The million-dollar question is whether P=NP. Alas, this question shall
not be answered in this text.

<<<PAGE 263>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
8.1 Deterministic and Nondeterministic Computations 245
If a problem has a “yes” answer, then the complement of the problem has a “no”
answer, and vice versa. Hence, we deﬁne the following:
Complexity Class. coP is the set of problems whose complements can be solved
by a deterministic Turing machine in a Polynomial number of steps.
Complexity Class. coNP is the set of problems whose complements can be
solved by a Nondeterministic Turing machine in a Polynomial number of steps.
If we can solve a problem with a deterministic Turing machine, then by swapping
theqaccept and the qreject states, we can solve the complement of the problem. From
this we know that P=coP. Notice that this trick does not work for nondeterministic
Turing machines: a nondeterministic Turing machine accepts a word if there exists at
least one computational path that ends with an accepting state. If a computation has
all but one path ending with an accepting state, then the word would be accepted.
If we swapped the accepting and rejecting states, then all but one path would end
in a rejecting state and exactly one path would end in an accepting state. Because
of the single accepting state, the computation would also be accepted. So a wordwould be accepted by both a problem in NPand its corresponding problem in coNP.
This cannot be. In conclusion, although it is known that P=coP, we do not know if
NP=coNP. In fact, most researchers believe that NP/negationslash=coNP . For the same reason
that P⊆NP, we have that
P=coP⊆coNP. (8.15)
We are interested in not only how much time a computation uses but also how
much of the Turing machine’s inﬁnite tape is used.
Complexity Class. PSPACE is the set of problems that can be solved by deter-
ministic Turing machines using a Polynomial number of SPACE s on the tape.
We could have written the same deﬁnition using a nondeterministic Turing machine.
It is a consequence of Savitch’s theorem4that when looking at space (as opposed to
time), the distinction between deterministic polynomial space and nondeterministic
polynomial space is not essential.
Because a (nondeterministic) Turing machine can change only one box per time
step, machines that use p(n) time steps to solve a problem cannot use more than
p(n) spaces of its inﬁnite tape. Hence, we have NP⊆PSPACE . For similar reasons,
coNP⊆PSPACE .
4Savitch’s theorem states that any nondeterministic computation that uses f(n) space can be simulated
by a deterministic computation that uses at most ( f(n))2space. If f(n) is a polynomial, then ( f(n))2is
also a polynomial. See, e.g., page 306 of Sipser (2005) or page 149 of Papadimitriou (1994).

<<<PAGE 264>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
246 Theoretical Computer Science
We may summarize the inclusions of the complexity classes that we have deﬁned
s of a ra sf o l l o w s :
PSPACE
coNP/d108/d108/d108/d108/d108/d108/d108/d108/d108/d108/d108/d108/d108/d108
NP/d82/d82/d82/d82/d82/d82/d82/d82/d82/d82/d82/d82/d82/d82
P/d108/d108/d108/d108/d108/d108/d108/d108/d108/d108/d108/d108/d108/d108/d108/d108/d82/d82/d82/d82/d82/d82/d82/d82/d82/d82/d82/d82/d82/d82/d82/d82(8.16)
A line between one complexity class and another means that the lower one is in-
cluded in the higher one. It must be stressed that it is unknown if any of these inclu-
sions are proper inclusions.
8.2 PROBABILISTIC COMPUTATIONS
Probabilistic computations occur when there is a random choice among several pos-
sible transitions during a computation. Probabilities can be described with real num-bers in the interval [0, 1]⊆R. No computer’s memory can hold an arbitrary real
number,
5and so this set is beyond our bounds. Some tractable computable subset
of [0,1] is needed. Consider the set /tildewideR⊆Roftractably computable real numbers .
These are real numbers such that a deterministic Turing machine can calculate their
nth digit in polynomial time. We shall be concerned with
/tildewide[0,1]=[0,1]/intersectiondisplay/tildewideR. (8.17)
A probabilistic Turing machine is a Turing machine that randomly performs one
of several tasks at each time step. Formally, a probabilistic Turing machine is a 6-
tuple
M=(Q,/Sigma1,qstart,qaccept,qreject,δ), (8.18)
where everything is as before except the transition function δ.δis now a function
δ:Q×/Sigma1−→/tildewide[0,1]Q×/Sigma1×{L,R}
, (8.19)
where /tildewide[0,1]Q×/Sigma1×{L,R}
is the set of functions from the set of all possible actions, Q×
/Sigma1×{L,R},t o/tildewide[0,1]. For a given state and symbol, δwill describe the probabilities of
the moves that the machine can make. An arbitrary function from Q×/Sigma1×{L,R}
to/tildewide[0,1] is not good enough. We must also restrict δso that the sum of all the prob-
abilities is equal to 1. δis restricted as follows: as an analogy to functions (8.3)
and (8.13), we deﬁne
δ/prime:Q×/Sigma1×Q×/Sigma1×{L,R}− → /tildewide[0,1], (8.20)
5An arbitrary real number might have an inﬁnite expansion. One could encode any language in that
expansion.

<<<PAGE 265>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
8.2 Probabilistic Computations 247
where
δ/prime(q,σ,q/prime,σ/prime,D)=r∈/tildewide[0,1] (8.21)
if and only if
δ(q,σ) is the function that takes ( q/prime,σ/prime,D)t or∈/tildewide[0,1]. (8.22)
It is not hard to see that for every δthere is a unique δ/primethat performs the same job.
However, we insist that δ/primesatisfy the following requirement (analogous to Equations
(8.5) and (8.14)):
(∀q∈Q)(∀σ∈/Sigma1)/summationdisplay
q/prime∈Q,σ/prime∈/Sigma1,D∈{L,R}δ/prime(q,σ,q/prime,σ/prime,D)=1. (8.23)
This means that at every state and when viewing every symbol, the sum of all the
probabilities of possible moves is equal to 1.
How does this machine work? At every time step, the machine will be in a certain
state, say q6, and will be looking at a certain symbol, say σ16, on the tape. The func-
tionδgives the nonzero probabilities where we list all possibilities in lexicographical
order using the ordering of Q,/Sigma1, and{L,R}.
(q9,σ2,L)
(q17,σ18,R)
(q6,σ16)0.14/d59/d59/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d1200.23/d53/d53/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107
0.08
/d41/d41/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83
0.55
/d35/d35/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70
(q17,σ19,R)
(q21,σ23,L)(8.24)
A real number between 0 and 1 is randomly chosen. This real number will de-termine which operation the Turing machine should perform. For example, if
the real number is 0.12, which is between 0.0 and 0.14, then the machine will
perform the ( q
9,σ2,L) operation. If the real number is 0.39, which is between
0.14+0.23 and 0.14 +0.23+0.08, then the machine will perform the ( q17,σ19,R)
operation.
Exercise 8.2.1 Following the spirit of Exercise 8.1.3, show that every probabilistic
Turing machine is equivalent to a Turing machine that can enter one of exactly two
conﬁgurations. The machine can choose one of these two conﬁgurations by ﬂipping
a fair coin or by looking at a tape with a random sequence of “0’s” and “1’s.” The

<<<PAGE 266>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
248 Theoretical Computer Science
machine will choose one operation if there is a “0” and the other one if there is a
“1.” (Hint: Write the probability ras a ﬁnite binary sequence.) /squaresolid
As with a regular Turing machine, the input will be placed on the tape, the com-
puter will be put in the qstart state, and then the machine will “run.” At each time
step, an arbitrary real number is randomly chosen and the Turing machine performsthe appropriate next action. At some point, the computer might enter a halting state
and stop.
Exercise 8.2.1 Following Example 8.1.1, let us describe a probabilistic Turing ma-
chine that solves the same problem. Because we are dealing with probabilistic algo-
rithms, we shall permit false negatives, i.e., the machine might report that there is
no “1” when, in fact, there is one.
We place the probability of performing a given action to the left of the action.
δ 01 #
qstart1
2:qL,L;1
2:qR,R1:qaccept 1:qreject
qL 1:qL,L 1:qaccept 1:qreject
qR 1:qR,R 1:qaccept 1:qreject(8.25)
How does this work? When the computer starts, 50% of the time the head moves
to the left and 50% of the time it moves to the right. The machine will examinen
2+1
boxes and hence will give a correct answer more than half the time. The machinewill have to go through
n
2time steps in the worst case. /squaresolid
Exercise 8.2.2 Describe a probabilistic Turing machine that does not generate any
false negatives. The machine should start by randomly moving to the left or to theright. However, regardless of direction, if it hits the left end or the right end of the
word without ﬁnding a “1,” it should reverse itself. Make sure that the machine does
not end up in an inﬁnite loop! Show that in the worst case, there will have to be
3n
2
time steps. /squaresolid
Exercise 8.2.3 Describe a probabilistic Turing machine that determines if there is
a substring “101” in the input string. Do the same for a solution that permits falsenegatives and one that does not permit false negatives. /squaresolid
Let us look at the different complexity classes that are deﬁned for probabilistic
Turing machines. Because of the probabilistic nature of the execution of such aTuring machine, there is a chance that when you execute the same program on thesame input, there will be a different ﬁnal state, i.e., there is a chance that the Turing
machine will produce an error. An input should be accepted by a Turing machine,
but the machine rejects it (false negative), or an input should be rejected and themachine accepts it (false positive).

<<<PAGE 267>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
8.2 Probabilistic Computations 249
We shall also restrict our attention to those probabilistic Turing machines that
stop within a polynomial number of time steps in the length of the input.
In terms of permitting errors, the largest class of problems that we will be in-
terested in are those that can be solved by probabilistic Turing machines that allow
some false negatives and some false positives.
Complexity Class. BPP is the set of problems that can be solved by a Prob-
abilistic Turing machine in Polynomial time with the possibility of some errors.
To be precise, if M is a probabilistic Turing machine that decides L∈BPP and
ifxis a word, then
x∈L⇒Prob( Maccepts x)>2
3(8.26)
and
x/negationslash∈L⇒Prob( Mrejects x)>2
3. (8.27)
We shall discuss the use of the fraction2
3presently.
A smaller set of problems are those that can be solved with a probabilistic Turing
machine that permits false positives but does not permit false negatives.
Complexity Class. RP is the set of problems that can be solved by a probabilis-
tic (i.e. Random) Turing machine in Polynomial time with only the possibility
of false negatives. In other words, if M is a probabilistic Turing machine thatdecides L∈RPand if xis a word, then
x∈L⇒Prob( Maccepts x)>2
3(8.28)
and
x/negationslash∈L⇒Prob( Mrejects x)=1. (8.29)
We can also consider problems that can be solved by probabilistic Turing ma-
chines that permit only false positives.
Complexity Class. coRP is the set of problems that can be solved by a Prob-
abilistic Turing machine in Polynomial time with only the possibility of false
positives. In other words, if M is a probabilistic Turing machine that decides
L∈coRP and if xis a word, then
x∈L⇒Prob( Maccepts x)=1 (8.30)
and
x/negationslash∈L⇒Prob( Mrejects x)>2
3. (8.31)

<<<PAGE 268>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
250 Theoretical Computer Science
The easiest problems are those that can be solved by probabilistic Turing ma-
chines in which no errors are permitted.
Complexity Class. ZPP is the set of problems that can be solved by a Prob-
abilistic Turing machine in Polynomial time with Zero error. In other words, if
M is a probabilistic Turing machine that decides L∈ZPP and if xis a word,
then there is a less than 50% chance that the machine will ﬁnish in a “do not
know” state, otherwise if the machine does know
x∈L⇒Prob (Maccepts x)=1 (8.32)
and
x/negationslash∈L⇒Prob (Mrejects x)=1. (8.33)
It is a fact that RP/intersectiontextcoRP=ZPP.6
If we can solve a problem with no errors ( ZPP), then we can deﬁnitely solve the
problem permitting false negatives ( RP) and we can deﬁnitely solve the problem
permitting false positives ( coRP ). Furthermore, if we can solve a problem permit-
ting only false negatives (RP), then we can deﬁnitely solve the problem permittingboth false negatives and false positives ( BPP ). A similar argument can be made for
coRP. Thus we have the following inclusion diagram:
BPP
coRP/d109/d109/d109/d109/d109/d109/d109/d109/d109/d109/d109/d109
RP/d80/d80/d80/d80/d80/d80/d80/d80/d80/d80/d80/d80
ZPP/d110/d110/d110/d110/d110/d110/d110/d110/d110/d110/d110/d110/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81(8.34)
It must be stressed that it is unknown if any of these inclusions are proper inclusions.
One might wonder why the fraction
2
3plays such an important role here. In fact,
we could have used any fraction greater than1
2and the classes of problems would
have been the same. The reason for this is the ampliﬁcation lemma .7The idea is that
one can execute the Turing machine a polynomial amount of times and accept orreject the input depending on the results of the majority of executions. This methodprovides exponential growth in the likelihood of excluding false positives and false
negatives.
Let us relate the complexity classes of this section with those of Section 8.1.
One can consider a deterministic Turing machine a probabilistic Turing machinethat does not make any guesses and always comes up with the right answer. From
this, we have that P⊆ZPP . Another way of thinking about L∈RPis that if x∈L,
then at least two-thirds of the computational paths end in q
accept , and if x/negationslash∈L, then
6See, e.g., page 256 of Papadimitriou (1994).
7E.g., see Zachos (1982), page 369 of Sipser (2005), or page 259 of Papadimitriou (1994).

<<<PAGE 269>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
8.3 Quantum Computations 251
all the computational paths end in qreject . Similarly, one can think of L∈NPas
stating that if x∈L, then at least one of the computational paths ends in qaccept , and
ifx/negationslash∈L, then all the computational paths end in qreject . Because two-thirds of the
computational paths (of an RPcomputation) are greater than one computational
path (of an NPcomputation), it is not hard to see that RP⊆NP. Similarly, coRP⊆
coNP.
For every L∈BPP , we can create a machine that traverses all the computational
paths and keeps track of the paths ending in qaccept and qreject . There is no reason
to save the path once it is calculated, so we might as well reuse the space. Such
a machine will take a very long time to calculate an answer, but it will use only a
polynomial amount of space. From this, it can be seen that BPP⊆PSPACE .B ya
similar analysis, it can be seen that NP⊆PSPACE andcoNP⊆PSPACE .
We can sum up our results with the following diagram.
PSPACE
coNP/d103/d103/d103/d103/d103/d103/d103/d103/d103/d103/d103/d103/d103/d103/d103/d103/d103/d103/d103/d103/d103/d103/d103BPP NP/d86/d86/d86/d86/d86/d86/d86/d86/d86/d86/d86/d86/d86/d86/d86/d86/d86/d86/d86/d86/d86
coRP/d114/d114/d114/d114/d114/d114/d114/d114/d114/d114/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81/d81
RP/d75/d75/d75/d75/d75/d75/d75/d75/d75/d111/d111/d111/d111/d111/d111/d111/d111/d111/d111/d111/d111/d111
ZPP/d115/d115/d115/d115/d115/d115/d115/d115/d115/d76/d76/d76/d76/d76/d76/d76/d76/d76/d76
P/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d122/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71/d71(8.35)
Again, it must be stressed that it is unknown if any of these inclusions are properinclusions. The relationship between BPP andNPis also unknown.
Because probabilistic Turing machines are so general and because they permit
some error (“noise”), we have the following thesis:
Thesis. The Strong Church–Turing Thesis states that any efﬁcient computation that
can be performed by any physical machine can be simulated by a probabilistic
Turing machine in polynomial time, i.e., in BPP .
We reexamine this thesis at the end of the next section.
8.3 QUANTUM COMPUTATIONS
As you have probably guessed, quantum Turing machines will have something to do
with complex numbers. As in the last section, general complex numbers Care be-
yond the reach of a ﬁnite machine. Thus, we are in need of the subset of all tractably
computable complex numbers /tildewideC⊆C./tildewideCconsists of those complex numbers such

<<<PAGE 270>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
252 Theoretical Computer Science
that the nth digit of their real and imaginary parts can be deterministically com-
puted in polynomial time.8
At last, we come to the deﬁnition of a quantum Turing machine. A quantum
Turing machine is a 6-tuple
M=(Q,/Sigma1,qstart,qaccept,qreject,δ/prime) (8.38)
where everything is as before except the transition function δ/prime(analogous to func-
tions (8.3),(8.13), and (8.20))
δ/prime:Q×/Sigma1×Q×/Sigma1×{L,R}− →/tildewideC. (8.39)
We require9thatδ/primesatisfy (analogous to Equations (8.5), (8.14), and (8.23))
(∀q∈Q)(∀σ∈/Sigma1)/summationdisplay
q/prime∈Q,σ/prime∈/Sigma1,D∈{L,R}|δ/prime(q,σ,q/prime,σ/prime,D)|2=1. (8.40)
In plain English, a quantum Turing machine is like a probabilistic Turing ma-
chine but the probabilities are given as complex number amplitudes.10And we re-
quire that for any particular q∈Qandσ∈/Sigma1, the sum of those squared norms of
the amplitudes equals 1. This can be visualized by a diagram similar to diagram
(8.24) but with complex numbers. Another way of thinking about it is to consider
what conﬁguration the machine is in and what conﬁgurations it will enter with the
actions. The complex numbers determine the probabilities of which conﬁguration it
8We do this for the reasons given in the last section. It was proven in Adleman, DeMarrais, and Huang(1997) that any quantum Turing machine can be simulated by a machine that uses only the numbers
/braceleftbigg
−1,−4
5,−3
5,0,3
5,4
5,1/bracerightbigg
(8.36)
or, if irrationals are permitted,
/braceleftbigg
−1,−1√
2,0,1√
2,1/bracerightbigg
. (8.37)
9This requirement is not strictly needed because we are going to impose a much stronger requirementpresently. (It is left in the text to make the connection between classic probabilistic Turing machinesand quantum Turing machines.) Furthermore, we can permit arbitrary tractably computable com-plex numbers and then calculate probabilities with a normalization trick as we did in Section 4.1 onpage 103.
10The clever reader will notice the progression of δ/primes in this chapter. They were all the same functions,
except they take values in different sets. We went from {0,1}to real numbers (of the appropriate type)
to complex numbers (of the appropriate type.) This progression is exactly the same as the progression
of entries in the adjacency matrices of the weighted graphs discussed in Chapter 3. That makes sense;
after all, the different systems discussed in Chapter 3 were introduced to bring to light the differ-ent types of computational power. However, the analogy highlights a problem with Chapter 3. Justas we restricted the values of the real and complex numbers in this chapter to tractably computable
real and complex numbers, so too we should have restricted the values of the entries in the matri-ces of classical probabilistic systems and quantum systems. However, we wrote it as is for simplicity’ssake.

<<<PAGE 271>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
8.3 Quantum Computations 253
will change as follows:
(Conﬁg9)
(Conﬁg16)
(Conﬁg6)c0/d59/d59/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120/d120c1/d53/d53/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107/d107
...
/d41/d41/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83/d83
cn−1
/d35/d35/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70/d70
(Conﬁg7)
(Conﬁg17)(8.41)
A quantum Turing machine works differently than a probabilistic Turing ma-
chine. Rather than carrying out one of the possibilities, it performs allthe opera-
tions and enters a superposition of allthe resulting states. The quantum Turing ma-
chine will collapse to a single conﬁguration only when it is measured. In fact, if we
observe the state and the contents of the tape of the quantum Turing machine aftereach step, then a quantum Turing machine will be the same as a probabilistic Turing
machine. The difference is that when we do not observe the state and the contents
of the tape, the probabilities of performing one operation followed by another sum
upas complex numbers (a short review of Section 3.3 would be in order). Hence
when we do not observe, there will be interference and superposition of contents of
the tape.
Bernstein and Vazirani (1997) have many conventions that they insist their quan-
tum Turing machine follow. There are many different reasons for this. Althoughthese conventions are important for their work, we shall ignore most of them be-
cause we want to show only the basic workings of a quantum Turing machine.
There are, of course, many variants of quantum Turing machines, such as ma-
chines with many tapes and many tracks. It was shown in Yao (1993) that manyof these are polynomially equivalent to the quantum Turing machine describedearlier.
Many of the properties that one would want in a Turing machine, such as it-
eration, subroutines, and looping, are shown to exist with a quantum Turing ma-chine in Bernstein and Vazirani (1997). Some of them are done with great effort.All these different properties are combined to show that one can actually con-
struct a universal quantum Turing machine, i.e., a quantum Turing machine that
can simulate
11every other quantum Turing machine. With such a universal quan-
tum Turing machine, we acquire many results similar to those of classical recursion
theory.
11The notion of simulation has to be suitably adjusted because of the probabilistic nature of the com-
putation. We cannot simply state that one machine outputs as the other. There must be a statementabout “how far away” the simulated output is from the real one.

<<<PAGE 272>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
254 Theoretical Computer Science
There is another way of thinking about quantum Turing machines. For a given
machine, there is the set of all possible conﬁgurations of that machine. We can form
a countably inﬁnite dimensional complex vector space Cfrom these conﬁgurations.
The vectors in this vector space will be ﬁnite complex linear combinations of con-
ﬁgurations.12One can think of a vector as a countably inﬁnite sequence of complex
numbers indexed by the conﬁgurations of the Turing machine, where all but a ﬁnite
number of the complex numbers are 0.
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣Conﬁg
0c0
Conﬁg1c1
Conﬁg2c2
......
Conﬁgjc
j
......⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦(8.42)
A classical state of a quantum Turing machine will be a vector for which all but one
complex number is 0 and the unique nonzero c
iis 1. This states that the conﬁgura-
tion of the Turing machine is Conﬁgi. An arbitrary vector in Cwill correspond to a
superposition of classical conﬁgurations that can be written as
|ψ/angbracketright=/summationdisplay
jcj|Conﬁgj/angbracketright, (8.43)
where the sum is over a ﬁnite set.
This is ﬁne for states of the system. How does the system itself change? We shall
make a countably inﬁnite “matrix” UM
UM:C−→ C. (8.44)
Every row and column of this matrix will correspond to a possible conﬁguration ofthe machine.
U
M=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣Conﬁg
0Conﬁg1Conﬁg2··· ConﬁgX
Conﬁg0 c0,0 c0,1 c0,2··· c0,j···
Conﬁg1 c1,0 c1,1 c1,2··· c1,j···
Conﬁg2 c2,0 c2,1 c2,2··· c2,j···
..................
Conﬁgj cj,0 cj,1 cj,2··· cj,j···
..................⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦(8.45)
12This complex vector space is an inner product space but not a Hilbert space because of the ﬁniteness in
the deﬁnition. If we relax the ﬁniteness requirement, then the inner product space is, in fact, completeand thus a Hilbert space.

<<<PAGE 273>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
8.3 Quantum Computations 255
The entries of the matrix will be the complex numbers that describe the amplitude of
going from one conﬁguration to another. That is, ci,jwill be the amplitude described
byδ/primethat would change conﬁguration jinto conﬁguration ias depicted in diagram
(8.41). Obviously, most of the entries of this matrix will be 0.
Deﬁnition 8.3.1 A quantum Turing machine is well formed if the constructed U M
preserves the inner product (is an isometry) in C.
With a well-formed quantum Turing machine, one is back into the familiar
world of unitary matrices. If we let |ConﬁgI/angbracketrightbe the initial conﬁguration, then
UM|ConﬁgI/angbracketrightwill be a conﬁguration or a superposition of conﬁgurations after one
time step. U2
M|ConﬁgI/angbracketrightwill be the (superposition of) conﬁguration(s) after two
steps. If the Turing machine runs in time t(n), then we would have to observe the
state
UM◦UM◦···◦ UM/bracehtipupleft/bracehtipdownright/bracehtipdownleft /bracehtipupright
t(n)times|ConﬁgI/angbracketright=Ut(n)
M|ConﬁgI/angbracketright. (8.46)
Example 8.3.1 There is nothing particularly quantum about the set Cof conﬁgura-
tions and the matrix acting upon it. In fact, the same can be done for a deterministic
Turing machine. In the deterministic case, we will only be concerned with vectors
that have exactly one entry as 1 and all others as 0 (note that this is not a subvectorspace of Cbecause it is not closed under addition). The U
Mwill be such that every
column has exactly one 1 and the remaining entries 0. /square
Exercise 8.3.1 Do a similar analysis to the one in Example 8.3.1 for a reversible
deterministic Turing machine and for a probabilistic Turing machine. /squaresolid
Example 8.3.2 In the spirit of Examples 8.1.1 and 8.2.1, let us describe a quantum
Turing machine that solves the same problem.
δ 01 #
qstart1√
2:qL,L1√
2:qR,R1:qaccept 1:qreject
qL 1:qL,L 1:qaccept 1:qreject
qR 1:qR,R 1:qaccept 1:qreject(8.47)
This quantum Turing machine does not start by moving either to the right or to
the left. Rather it moves both to the right andto the left simultaneously.
A typical computation might look like this:
|#000 qstart0010#/angbracketright /mapsto−→|#00qL00010#/angbracketright+| #0000 qR010#/angbracketright√
2/mapsto−→
|#0qL000010#/angbracketright+| #00000 qR10#/angbracketright√
2/mapsto−→|#qL0000010#/angbracketright+| #00000 qaccept 10#/angbracketright√
2.(8.48)

<<<PAGE 274>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
256 Theoretical Computer Science
It is obvious that the machine will solve this problem without false positives or
false negatives inn
2steps. Again, we want to stress that this is not really a quan-
tum Turing machine because it does not satisfy all the conventions laid down in
Bernstein and Vazirani (1997).
We feel conﬁdent in identifying this as “a Turing machine version of the double-
slit experiment.” The double-slit experiment is performed by physicists who are in-
terested in where a photon lands. A photon exhibits the superposition phenomenon,
and hence the photon passes through both slits simultaneously. We are computerscientists and solve searching problems. This problem is solved in
n
2time by splitting
into a simultaneous superposition of two computational paths. (Of course, it is notreally the double-split experiment because there is no interference, only superposi-tion.) /square
Let us summarize what we have done in Examples 8.1.1, 8.2.1, and 8.3.2 and in
Exercise 8.2.2. For the same problem, i.e., given a string to determine if it containsa “1,” we formulated deterministic, probabilistic, and quantum Turing machines.Some of these machines solved the problem without error and some of them gave
us probabilistic solutions. The problems were solved in the following time.
13
Turing Machine Running Time
Exact Probable
Deterministic n+n
2NA
Probabilistic n+n
2n
2
Quantumn
2NA(8.49)
Exercise 8.3.2 Write a quantum Turing machine that determines if there is a sub-
string “101” on the tape. /squaresolid
A quantum Turing machine is just one model of quantum computation. In Chap-
ters 5 and 6 we dealt with another one, namely, quantum circuits. (The QRAM
model, dealt with in Chapter 7, is yet another way of describing quantum compu-tations.) In the classical case, logical circuits and deterministic Turing machines are
polynomially equivalent. That means that each model can implement the other with
only polynomial amount of “overhead.” Yao (1993) proved a similar result for thequantum case. That is, quantum circuits and quantum Turing machines are polyno-mially equivalent.
The following simple example shows how a quantum Turing machine would im-
plement a common quantum circuit:
13We have deliberately omitted the nondeterministic case from our chart. The reason is that a nonde-terministic Turing machine can also solve the problem in
n
2steps. This is just as fast as the quantum
Turing machine and would have “stolen its thunder.” We should remind the reader that nondetermin-ism is a mathematical ﬁction whereas the laws of quantum mechanics are a physical fact.

<<<PAGE 275>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
8.3 Quantum Computations 257
Example 8.3.3 Many of the algorithms in Chapter 6 required that we apply H⊗n
to a string of qubits. Let us show how one would do this with a quantum Turing
machine. Suppose that a string of n“0’s” and “1’s” are on a tape and that the head
is pointing to the leftmost symbol of the string.
δ 01 #
qstart (1√
2:0,qstart,L)(1√
2:0,qstart,L)1 : qstop
(1√
2:1,qstart,L)(−1√
2:1,qstart,L)(8.50)
Basically, the quantum Turing machine will go through the string and changethe “0’s” or “1’s” the way a Hadamard matrix would. (This is a simpliﬁcation ofTheorem 8.4.1 of Bernstein and Vazirani (1997). Ours is simpler because we have
not followed all their conventions.) /square
Let us have a look at complexity classes for quantum Turing machines. As in
Section 8.2, because of the probabilistic nature of the computations, there is thepossibility of false positives and false negatives. We are led to the following three
deﬁnitions:
Complexity Class. BQP is the set of problems that can be solved by a Quantum
Turing machine in Polynomial time with Bounded error on both sides. In other
words, if M is a quantum Turing machine that decides L∈BQP and if xis a
word, then
x∈L⇒Prob( Maccepts x)>2
3(8.51)
and
x/negationslash∈L⇒Prob( Mrejects x)>2
3. (8.52)
It was proven in Bennett et al. (1997) that the same ampliﬁcation lemma that
worked for probabilistic complexity classes also works for BQP. Hence, the fraction
2
3is not of major signiﬁcance.
Complexity Class. ZQP is the set of problems that can be solved by a Quantum
Turing machine in Polynomial time with Bounded error on both sides. In other
words, if M is a quantum Turing machine that decides L∈ZQP and if xis a
word, then there is a less than 50% chance that the machine will ﬁnish in a “do
not know” state, otherwise if the machine does know then
x∈L⇒Prob( Maccepts x)=1 (8.53)
and
x/negationslash∈L⇒Prob( Mrejects x)=1. (8.54)

<<<PAGE 276>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
258 Theoretical Computer Science
Complexity Class. EQP is the set of problems that can be solved with a
Quantum Turing machine in Polynomial time Exactly (without error). In other
words, if M is a quantum Turing machine that decides L∈EQP and if xis a
word, then
x∈L⇒Prob (Maccepts x)=1 (8.55)
and
x/negationslash∈L⇒Prob (Mrejects x)=1. (8.56)
It should be obvious that
EQP⊆ZQP⊆BQP. (8.57)
Now relate these complexity classes with those of Sections 8.1 and 8.2. Because a
deterministic Turing machine can be seen as a type of quantum Turing machine, we
have that P⊆EQP. Given that we can have a quantum Turing machine simulate a
probabilistic Turing machine by using the Hadamard matrix as a fair coin toss, wehave that BPP⊆BQP. Also, for the same reason that BPP can be mimicked by a
machine that uses only polynomial amount of space, so too BQP can be mimicked
by such a machine. Such a machine is the theoretical version of a quantum emulator.The fact that every problem in BQP can be simulated by something in PSPACE
shows that every quantum computation can be simulated by a classical computer.Of course, the simulation will probably use exponential time if it was to be exact.
14
Summing up, we have the following:
PSPACE
BQP
coNP/d113/d113/d113/d113/d113/d113/d113/d113/d113/d113/d113/d113/d113/d113/d113/d113/d113/d113/d113/d113/d113/d113/d113/d113/d113
ZQP/d117/d117/d117/d117/d117/d117/d117/d117/d117
BPP/d73/d73/d73/d73/d73/d73/d73/d73/d73
NP/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77
EQP
coRP/d8/d8/d8/d8/d8/d8/d8/d8/d8/d8/d8/d8/d8/d8/d8/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77/d77
RP/d127/d127/d127/d127/d127/d127/d127/d127/d127/d127/d127/d127/d127/d127/d127/d127/d127/d127
ZPP/d117/d117/d117/d117/d117/d117/d117/d117/d117
P/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d3/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d60/d47/d47/d47/d47/d47/d47/d47/d47/d47/d47/d47/d47/d47/d47/d47/d47/d47/d47/d47/d47/d47(8.58)
14We can also make the obvious deﬁnition of QSPACE . It was shown in Watrous (1999) that
QSPACE( f(n))⊆SPACE ((f(n))2).This is analogous to Savitch’s theorem about nondeterministic
computation.

<<<PAGE 277>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
8.3 Quantum Computations 259
It is unknown if any of these inclusions are proper inclusions. There is much still
open about the relationships among these complexity classes.
Because of Shor’s algorithm and the belief that there is no polynomial prob-
abilistic algorithm to factor numbers, it is strongly believed that BPP /subsetornotdbleqlBQP.I t
should be noticed that if it were to be proved that BPP/negationslash=BQP, then we would
know that P/negationslash=PSPACE , which has been an open problem for a very long time.
It should be noted that Shor’s algorithm is not the only algorithm that we saw
that has an exponential speedup. As we saw in Chapter 6, the Deutsch–Jozsa algo-
rithm and Simon’s algorithm also had exponential speedups over any known classi-cal algorithm.
If a large-scale quantum computer is ever built, then there would be evidence
that the strong Church–Turing Thesis would be invalidated. Such a quantum com-puter will be a physical machine that can perform a computation (e.g., factor-
ing large numbers) for which there are no known polynomial time probabilistic
machines. (Of course, someone might create such a probabilistic machine in thefuture.)
It is to be stressed that although Shor’s algorithm solves the factoring problem,
factoring is not believed to be an NP-complete problem. The factoring problem, asa decision problem, is an NPproblem (and a coNP problem) but has never been
shown to be harder than any known NP-complete problem. In terms of quantum
computers, this means that even if there were a large-scale quantum computer,we would not be able to use Shor’s algorithm to solve all known NP-complete
problems.
Some researchers believe that the fact that there is a quantum algorithm for the
factoring problem is a “ﬂuke” and not something that should be expected for manyproblems. They believe that methods similar to Shor’s algorithm will not be veryhelpful for other hard problems.
In contrast to Shor’s algorithm, Grover’s algorithm can be very interesting in
terms of NPproblems. Although the speedup using Grover’s algorithm is from n
to√
n, which is quadratic and not exponential, it is still signiﬁcant. Consider your
favorite NPproblem. The search space for such a problem is, in general, either n!o r
2n. One can set up Grover’s algorithm to search through the problem’s search space.
So if the problem is SAT, we can use Grover’s algorithm to search through all 2npos-
sible valuations of the nvariables in the formula. If the problem is HAMILTONIAN
GRAPH, then search through all n! paths on the graph to ﬁnd one that is hamilto-
nian. In fact, we are solving a search problem rather than a decision problem.15
Let us perform some calculations to show how signiﬁcant Grover’s speedup
can be. Say, we would like to solve some NPproblem whose search space is 2n.
Imagine a quantum computer running Grover’s algorithm that can perform 1,000function evaluations per second. This quantum computer will have to perform√
2n
function evaluations. Contrast this with a classical computer running a brute-forcesearch through all 2
npossible members of the search space. We shall assume that
15We showed that we can solve an NPproblem in O(2n
2) time using Grover’s algorithm. We are led to
the obvious question of whether we can do better. It has been shown in Bennett (1997) that relative toan oracle chosen uniformly at random with probability 1, the class of NPcannot be solved by quantum
Turing machines in o(2n
2)t i m e .

<<<PAGE 278>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
260 Theoretical Computer Science
this classical computer is 100 times faster than the quantum computer, i.e., it can
perform 100,000 function evaluations per second. The following table shows how
these two algorithms compare on different values of n:
Classical Brute-Force Search Quantum Grover’s Algorithm Search
n 2nops Time√
2nops Time
5 32 0.00032 second 5.656854249 0.00566 second
10 1,024 0.01024 second 32 0.032 second
15 32,768 0.32768 second 181.019336 0.18102 second
20 1,048,576 10.48576 seconds 1,024 1,024 seconds
25 33,554,432 335.54432 seconds 5792.618751 5.79261 seconds30 1,073,741,824 10737.41824 seconds 32,768 32.768 seconds40 1.09951E +12 127.25829 days 1,048,576 1048.576 seconds
50 1.1259E +15 356.77615 years 33,554,432 33554.432 seconds
60 1.15292E +18 365338.7788 years 1,073,741,824 12.42756 days
70 1.18059E +21 374106909.5 years 34,359,738,368 397.68215 days
100 1.26765E +30 4.01694E+17 years 1.1259E+15 35677.61512 years
125 4.25353E +37 1.34786E+25 years 6.52191E +18 206666822.3 years(8.59)
We can see that for n=15, the quantum computer will run faster than the classical
computer. We conclude that Grover’s algorithm might have major signiﬁcance when
dealing with “hard” computer problems.
Exercise 8.3.3 Write a short program or use either MATLAB or Microsoft Ex-
cel to determine the exact nwhen the slower quantum computer running Grover’s
algorithm runs faster than the classical computer running a brute-force algorithm.
/squaresolid
Exercise 8.3.4 Perform a similar analysis to that shown in table (8.59) for an NP
problem whose search space is n!. /squaresolid
.................................................................................
References: For general Turing machines, see Davis, Weyuker, and Sigal (1994)
orGarey and Johnson (1979). Another excellent text is Sipser (2005).
For probabilistic Turing machines, see Section 10.2 of Sipser (2005) or Chap-
ter 11 of Papadimitriou (1994). For general complexity theory, see Papadimitriou
(1994).
For Section 8.3, we mostly followed Bernstein and Vazirani (1997). Their deﬁ-
nition of a quantum Turing machine is a variant of the one formulated in Deutsch
(1985). Much was gained from the following survey papers: Cleve (1999), Fortnow
(2003), and Vazirani (2002).

<<<PAGE 279>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
8.3 Quantum Computations 261
Scott Aaronson has a very interesting blog “Shtetl-Optimized” that looks
at current issues in quantum computability and complexity theory: http://www.
scottaaronson.com/blog/. Well worth the read. He is also the “Zookeeper” at a
Web page (http://qwiki.caltech.edu/wiki/Complexity Zoo) that has more than 400
different complexity classes. These are great places to start learning more about this
topic.

<<<PAGE 280>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
9
Cryptography
We dance round in a ring and suppose,
But the Secret sits in the middle and knows.
Robert Frost, The Secret Sits (1942)
In this chapter we explore the merging of quantum computation and classical cryp-
tography. This is a new and exciting ﬁeld of pure and applied research known asquantum cryptography.
We begin with the basics of classical cryptography in Section 9.1. Section 9.2
demonstrates a quantum cryptographic protocol that uses two different bases. Weimprove on this in Section 9.3, where a protocol with one basis is employed. Section9.4 shows how to use entanglement to secretly send a message. We conclude with
Section 9.5, in which teleportation is demonstrated.
9.1 CLASSICAL CRYPTOGRAPHY
Before delving into quantum cryptography, we need to familiarize ourselves with
the core ideas of classical cryptography. A good place to start is the following deﬁ-
nition.
Deﬁnition 9.1.1 Cryptography is the art of concealing messages.
Indeed, this is precisely what the etymology reveals: “Cryptography” is a compound
of two Greek words, crypton1and graphein, which mean, respectively, hidden and
writing.
Turning an ordinary message into an indecipherable one is called encryption.
The opposite action, i.e., restoring the original message, is decryption. The original
message is generally referred to as the plaintext , and the encrypted message is the
ciphertext . A method for encryption is often referred to as an encryption protocol .
1Now you know where the Kryptonite got its name. It is rare to ﬁnd and hence is “hidden.” It usually
stays concealed unless Lex Luthor gets hold of it!
262

<<<PAGE 281>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
9.1 Classical Cryptography 263
Figure 9.1. A basic communication scheme.
The history of cryptography is a very long one. As soon as people started sending
messages to each other that were not intended for the public, the need for privacy
arose. At the very moment encryption ideas and techniques were devised by some
smart individual, another one, just as smart set out to break them. Thus, cryptology
was born.
To present encryption and decryption methods, we need to set the scene. First,
we need two characters – the sender of messages and the receiver . In the standard
cryptology literature, these two are named Alice and Bob. Alice wants to send amessage to Bob, say, a string of plaintext T. We assume that Alice and Bob are
physically separated and that they can communicate with each other over some kindofinsecure channel.
2
Alice uses an encryption algorithm – let’s call it ENC – that turns Tinto some
encrypted text E. We can think of ENC as some computable function, taking Tand
an additional parameter KE, known as the encryption key , as inputs. ENC computes
the encrypted message E, which is transmitted to Bob.
ENC (T,KE)=E. (9.1)
Bob receives E(assuming there is no noise involved) and applies a decryption algo-
rithm, DEC , to the encrypted message to reconstruct T.DEC requires a decryption
keyKDas input.
DEC (E,KD)=T. (9.2)
The entire scheme is shown in Figure 9.1.
Summing up, ENC (−,KE) and DEC (−,KD) are a pair of computable functions
such that for every message T, the following equation holds:
DEC (ENC (T,KE),KD)=T. (9.3)
What does this equation tell us? It states that as long as we use the right keys, wecan always retrieve the original message intact without any loss of information.
Exercise 9.1.1 Does Equation (9.3) imply that ENC (−,K
E) and DEC (−,KD)a r e
a pair of bijective functions that are inverse to each other? /squaresolid
Let us now examine a concrete example of an encryption protocol, a method
known as the Caesar’s protocol .3Arrange the letters of the English alphabet on a
2Why insecure? First of all, if the channel were foolproof beyond any reasonable doubt, we would have
no story. Why bother with cryptography if no one else can spy on the message? Second, in the context
of secure message transmission, every channel must be assumed insecure unless proven safe.
3Julius Caesar apparently used an encryption technique like this one to communicate with his generals
during his military campaigns. See Suetonius’ Life of Julius Caesar, Paragraph 56.

<<<PAGE 282>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
264 Cryptography
Figure 9.2. A children’ s encryption toy.
circle, so that the order is
..., A,B,C,..., X,Y,Z,A,B,.... (9.4)
LetENC=DEC=shift(−,−), where shift( T,n)=T/prime, the string obtained from T
by shifting each character nsteps clockwise if nis positive, or counterclockwise if it is
negative (for instance, shift(“MOM,” 3) =“PRP”). Children actually make a helpful
toy for this encryption protocol as depicted in Figure 9.2. This toy consists of two
concentric circles with the alphabet written clockwise on each circle. The circles can
be turned until the desired letters are matched up. With this encryption protocol,the decryption key is just the encryption key with the sign changed: K
D=− KE.
Exercise 9.1.2 Decipher the following message “JNTGMNF VKRIMHZKTIAR
BL YNG.” (Hint: Use Figure 9.2.) /squaresolid
Programming Drill 9.1.1 Implement the encryption and decryption of text with the
Caesar’s protocol. Using ASCII makes this particularly easy.
To make our story a bit more exciting, we need a third character, Eve, the eaves-
dropper, who can intercept the encrypted message and try to decode it. As previ-
ously noted, Alice is using an insecure channel (such as a public telephone wire) to
transmit messages to Bob. Eve can thus tap into the channel and eavesdrop on its
content. The protocol we have just presented is quite primitive and would not standEve’s scrutiny for too long.
Imagine that you are Eve and that by tapping into the insecure channel you
can save fairly long encrypted messages from Alice. How would you discover theencryption mechanism? If you were Eve, you might have a hunch about the weak
side of the simple-minded protocol we have just introduced. The weakness lies in
the fact that the original message and the encrypted one are highly correlated.B y
calculating simple statistics on the encrypted text, Eve may easily ﬁnd her way backto the original text. Aside from her malicious purposes, Eve works exactly like an
archeologist decoding an ancient unknown language.
To counter Eve’s insight, Alice and Bob change their protocol. Their ideal strat-
egy is to create an encrypted message Ethat bears no statistical correlation with the

<<<PAGE 283>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
9.1 Classical Cryptography 265
original message T. How can this be accomplished? Here is a surprisingly simple an-
swer: a straightforward protocol known as the One-Time-Pad protocol orVernam
cipher .
As we are computer scientists, for the rest of this chapter, we shall refer to Tas
a binary string of length n. Alice tosses a coin ntimes and generates a sequence of
random bits that she uses as her random key K. Assuming Alice and Bob both share
K, they can exchange messages by means of the following protocol:
Step 1. Alice calculates E=T⊕K, where ⊕stands for the bitwise XOR opera-
tion.4
Step 2. Alice sends Ealong a public insecure channel.
Step 3. Bob retrieves Eand calculates Tfrom T=E⊕K.
In this notation that we have introduced,
KE=KD=K, (9.5)
ENC (T,K)=DEC (T,K)=T⊕K, (9.6)
and
DEC (ENC (T,K),K)=DEC (T⊕K,K)
=(T⊕K)⊕K=T⊕(K⊕K)=T. (9.7)
Example 9.1.1 The following table shows an example of an implementation of the
One-Time-Pad protocol:
One-Time-Pad Protocol
Original message T 0 1 1 0 1 1
Encryption key K ⊕ 111010
Encrypted message E 1 0 0 0 0 1
Public channel ⇓⇓⇓⇓⇓⇓
Received message E 1 0 0 0 0 1
Decryption key K ⊕ 111010
Decrypted message T 0 1 1 0 1 1(9.8)
/square
4A quick reminder on XOR: it is simply bitwise addition modulo two. 01001101 ⊕11110001 =10111100.

<<<PAGE 284>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
266 Cryptography
Exercise 9.1.3 Find a friend and ﬂip a coin to get an encryption key K. Then use
Kto send a message. See if it works. /squaresolid
Programming Drill 9.1.2 Implement the One-Time-Pad protocol.
Exercise 9.1.4 Suppose Alice generates only one pad key K, and uses it to encrypt
two messages T1and T2(we are assuming they have exactly the same length). Show
that by intercepting E1and E2, Eve can get T1⊕T2and hence is closer to the original
text. /squaresolid
There are a couple of issues with the One-Time-Pad protocol:
1. As Exercise 9.1.4 shows, the generation of a new key Kis required each time
a new message is sent. If the same key is used twice, the text can be discovered
through statistical analysis, and hence the name “One-Time-Pad.”
2. The protocol is secure only insofar as the key Kis not intercepted by Eve
(remember, Alice and Bob must share the same pad in order to communicate). Wesee in the next section that quantum computing comes to the rescue for this crucialissue.
So far, we have assumed that the pair of keys K
Eand KDare kept secret. In fact,
only one key was needed because knowledge of the ﬁrst key implies knowledgeof the second and vice versa.
5A cryptographic protocol where the two keys are
computable from one another, thus requiring that both keys be kept secret, is said
to be private key.
There is yet another game in town: in the 1970s, Ronald Rivest, Adi Shamir, and
Leonard Adleman introduced one of the ﬁrst examples of public-key cryptography,
now simply known as RSA (Rivest, Shamir, and Adleman, 1978). In public-key pro-
tocols, the knowledge of one key does not enable us to calculate the second one. Tobe precise, the requirement is that the computation of the second key from the ﬁrstshould be hard.
6
Now, suppose that Bob has computed such a pair of keys KEand KD. Further-
more, suppose that brute force trial and error to ﬁnd KDgiven KEis totally infeasi-
ble by Eve or anyone else (for instance, there could be an endless list of candidate
keys). Bob’s course of action is as follows: he places the encryption key KE,i ns o m e
public domain, where anyone can get it. He can safely advertise his protocol, i.e., the
knowledge of ENC (−,−) and DEC (−,−). At the same time, he guards the decryp-
tion key for himself. When Alice wants to send a message to Bob, she simply uses
KEon her message. Even if Eve intercepts the encrypted text, she cannot retrieve
Bob’s decryption key, and so the message is safe. This scheme is shown in Figure 9.3.
Let us rephrase the foregoing: once Bob has his magic pair of keys, he ﬁnds
himself with two computable functions
FE(−)=ENC (−,KE) (9.9)
FD(−)=DEC (−,KD) (9.10)
5In Caesar’s protocol, the decryption key is just the encryption key with changed sign, whereas in the
One-Time-Pad protocol, the two keys are exactly the same.
6By “hard,” we mean that the number of computational steps to get from the ﬁrst key to the second keyis more than polynomial in the length of the ﬁrst key.

<<<PAGE 285>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
9.1 Classical Cryptography 267
Figure 9.3. A cryptographic communication scheme with a public KE.
such that FDis the inverse of FEbut cannot easily be calculated from knowledge of
FE. A function like FE, which is easy to compute yet hard to invert without extra
information, is known as a trapdoor function . The name is quite suggestive: like a
trapdoor in an old-fashioned Gothic castle, it opens under your feet but does not let
you come back easily. So a trapdoor function is what Bob needs.7
Public-key cryptography has pros and cons. On the plus side, it solves the key
distribution problem that hinders private-key protocols. If Alice wants to send a
message to Bob, she does not need to know Bob’s private key. On the minus side,
all public-key protocols to date rely on the fact that the computation of the pri-vate key from the public key appears to be hard. This just means that as of yet,
there are no known algorithms that do the job. The possibility is still open for somebreakthrough result in computational complexity that would put all existing public-key cryptographic schemes out of business.
8Finally, public-key protocols tend to be
considerably slower than their private-key peers.
In light of the aforementioned, cryptographers devised a marriage of the two ap-
proaches to achieve the best of both worlds: public-key cryptography is used only todistribute a key K
Eof some private-key protocol, rather than an entire text message.
Once Alice and Bob safely share KE, they can continue their conversation using the
faster private-key scheme. Therefore, for the rest of this chapter, our only concernis to communicate a binary K
Eof the appropriate length.
Before ending this section, we must expand on the picture of cryptography we
have sketched so far. Secure communication of messages is only one of the issues atstake. Here are two others:
Intrusion Detection . Alice and Bob would like to determine whether Eve is, in
fact, eavesdropping.
Authentication. We would like to ensure that nobody is impersonating Alice and
sending false messages.
We shall show how to implement protocols that include the ﬁrst of these fea-
tures. The second feature is also discussed within the context of quantum cryptog-raphy but is outside the purview of this text.
7Where can Bob ﬁnd trapdoor functions? There are, at present, quite a few public-key protocols about,drawing their techniques from advanced mathematics such as number theory (prime factorization) oralgebraic curves theory (elliptic curves). We invite you to read about them in Koblitz (1994). (Caution:be prepared to perform some calculations!)
8Quantum computing itself offers unprecedented opportunities for breaking codes, as the celebratedresult by Shor amply shows (see Section 6.5). For a discussion of the relationship between quantumcomputing and computational complexity, see Section 8.3.

<<<PAGE 286>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
268 Cryptography
Exercise 9.1.5 Suppose Alice and Bob communicate using some kind of public-key
protocol. Alice has a pair of keys (one public, one private), and so does Bob. Devise
a way in which Alice and Bob can communicate simultaneously while authenticating
their messages. (Hint: Think of encoding one message “inside” another.) /squaresolid
9.2 QUANTUM KEY EXCHANGE I: THE BB84 PROTOCOL
While discussing the One-Time-Pad protocol, we pointed out that the problem ofsecurely transmitting the key is a serious one. During the 1980s, two authors came
up with a clever idea that exploits quantum mechanics. This idea formed the basis
of the ﬁrst quantum key exchange (QKE) protocol.
Before presenting QKE in some detail, let us ﬁrst see if we can guess which
features of the quantum world are appealing to cryptographers. In the classical case,Eve is somewhere along the insecure channel listening for some bits of information.What can she do?
1. She can make copies of arbitrary portions of the encrypted bit stream and
store them somewhere to be used for later analysis and investigations.
2. Eve can listen without affecting the bitstream, i.e., her eavesdropping does not
leave traces.
Now, assume that Alice sends qubits, rather than bits, over some channel.
9
1/prime. Eve cannot make perfect copies of the qubit stream: the no-cloning theorem
discussed in Section 5.4 prevents this from happening.
2/prime. The very act of measuring the qubit stream alters it.
At ﬁrst sight, the points raised above seem like limitations, but from the point
of view of Alice and Bob, they actually turn out to be great opportunities. How?For one thing, the no-cloning theorem hampers Eve’s ability to use past messagesto conduct her analysis. Even more important, each time she measures the qubit
stream, she disturbs it, allowing Alice and Bob to detect her presence along the
channel.
The ﬁrst quantum key exchange protocol was introduced by Charles Bennett
and Gilles Brassard in 1984, and hence the name BB84. This section describes this
important protocol.
Alice’s goal is to send Bob a key via a quantum channel. Just as in the One-Time-
Pad protocol, her key is a sequence of random (classical) bits obtained, perhaps, bytossing a coin. Alice will send a qubit each time she generates a new bit of her key.But which qubit should she send?
In this protocol, Alice will employ two different orthogonal bases shown in Fig-
ure 9.4:
+={ |→ /angbracketright ,|↑ /angbracketright }=/braceleftbig
[1,0]T,[0,1]T/bracerightbig
(9.11)
9This chapter is not concerned with hardware implementation of quantum cryptography. That topic istackled in Chapter 11. For the time being, sufﬁce it to note that any two-dimensional quantum system(like spin or photon polarization) could be employed for transmission.

<<<PAGE 287>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
9.2 Quantum Key Exchange I: The BB84 Protocol 269
Figure 9.4. Two bases used for BB84.
and
X={ |/arrownorthwest /angbracketright ,|/arrownortheast /angbracketright }=/braceleftbigg1√
2[−1, 1]T,1√
2[1,1]T/bracerightbigg
. (9.12)
We shall refer to the ﬁrst basis as the “plus” basis and the second as the “times”
basis. Essentially, they are two alternative vocabularies that Alice and Bob will use
to communicate.
In these vocabularies, the states |0/angbracketrightand|1/angbracketrightshall be described by the following
table:
State / Basis + X
|0/angbracketright| → /angbracketright | /arrownortheast /angbracketright
|1/angbracketright| ↑ /angbracketright | /arrownorthwest /angbracketright(9.13)
For example, in the +basis, a |→ /angbracketright will correspond to a |0/angbracketright. If Alice wants to work
in the Xbasis and wants to convey a |1/angbracketright, she will send a |/arrownorthwest /angbracketright . Similarly, if Alice sends
a|↑ /angbracketrightand Bob measures a |↑ /angbracketrightin the +basis, he should record a |1/angbracketright.
This is ﬁne for basic states, but what about superpositions? If Bob measures
photons using the +basis, he will only see photons as |→ /angbracketright or|↑ /angbracketright. What if Alice
sends a |/arrownortheast /angbracketright and Bob measures it in the +basis? Then it will be in a superposition
of states
|/arrownortheast /angbracketright=1√
2|↑ /angbracketright+1√
2|→ /angbracketright. (9.14)
In other words, after measurement, there is a 50–50 chance of Bob’s recording a |0/angbracketright
or a|1/angbracketright. Again, Alice could use the Xbasis, intending to send a |0/angbracketright, and Bob has a
50–50 chance of recording a |1/angbracketrightand a 50–50 chance of recording a |0/angbracketright. In all, there
are four possible superpositions:/D2|/arrownorthwest /angbracketright with respect to +will be1√
2|↑ /angbracketright−1√
2|→ /angbracketright ./D2|/arrownortheast /angbracketright with respect to +, will be1√
2|↑ /angbracketright+1√
2|→ /angbracketright ./D2|↑ /angbracketrightwith respect to X, will be1√
2|/arrownortheast /angbracketright+1√
2|/arrownorthwest /angbracketright ./D2|→ /angbracketright with respect to X, will be1√
2|/arrownortheast /angbracketright−1√
2|/arrownorthwest /angbracketright .

<<<PAGE 288>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
270 Cryptography
Exercise 9.2.1 Work out what |← /angbracketright,|↓ /angbracketright,|/arrowsouthwest /angbracketright , and|/arrowsoutheast /angbracketright would be in terms of the
two bases. /squaresolid
Armed with this vocabulary and the inherent indeterminacy of the two bases,
Alice and Bob are ready to start communicating. Here are the steps of the protocol:
Step 1. Alice ﬂips a coin ntimes to determine which classical bits to send. She
then ﬂips the coin another ntimes to determine in which of the two bases to send
those bits. She then sends the bits in their appropriate basis.
For example, if nis 12, we might have something like this:
Step 1: Alice sends nrandom bits in random bases
Bit number 1 2 3 4 5 6 7 8 9 10 11 12
Alice’s random bits 0 1 1 0 1 1 1 0 1 0 1 0
Alice’s random bases ++ X+++ X+ XXX +
Alice sends →↑/arrownorthwest→↑ ↑/arrownorthwest→/arrownorthwest/arrownortheast/arrownorthwest→
Quantum channel ⇓⇓⇓⇓⇓⇓⇓⇓⇓⇓⇓⇓
(9.15)
Step 2. As the sequence of qubits reaches Bob, he does not know which basis
Alice used to send them, so to determine the basis by which to measure them he
also tosses a coin ntimes. He then goes on to measure the qubit in those random
bases.
In our example, we might have something like this:
Step 2: Bob receives nrandom bits in random measurements
Bit number 1 2 3 4 5 6 7 8 9 10 11 12
Bob’s random bases X+ XX + X++ XXX +
Bob observes /arrownortheast↑/arrownorthwest/arrownorthwest↑/arrownortheast↑→/arrownorthwest/arrownortheast/arrownorthwest→
B o b ’ s b i t s 01111010101 0
(9.16)
Here is the catch: for about half of the time, Bob’s basis will be the same as
Alice’s, in which case his result after measuring the qubit will be identical to Alice’soriginal bit. The other half of the time, though, Bob’s basis will differ from Alice’s.
In that case, the result of Bob’s measurement will agree with Alice’s original bit
about 50% of the time.

<<<PAGE 289>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
9.2 Quantum Key Exchange I: The BB84 Protocol 271
Figure 9.5. Eve “cutting” the quantum wire and transmitting her own message.
Programming Drill 9.2.1 Write functions that mimic Alice, Bob, and their inter-
actions. Alice should generate two random bit strings of the same length. Call one
BitSent and the other SendingBasis.
Bob will be a function that generates a random bit string of the same length called
ReceivingBasis .
All three of these bit strings should be sent to an “all-knowing” function named
Knuth. This function must look at all three and create a fourth bit string named
BitReceived. This is deﬁned by the following instruction:
BitReceived [i]=⎧
⎪⎨
⎪⎩BitSent [i], if SendingBasis [i]=ReceivingBasis [i],
random {0,1}, otherwise.(9.17)
This random {0,1}is the classical analog of a qubit collapsing to a bit.
Knuth must furthermore evaluate the percentage of bits that Bob receives accu-
rately.
Let us continue with the protocol: If evil Eve is eavesdropping, she must be read-
ing the information that Alice transmits and sending that information onward to
Bob, as shown in Figure 9.5.
Eve also does not know in which basis Alice sent each qubit, so she must act like
Bob. She will also toss a coin each time. If Eve’s basis is identical to Alice’s, hermeasure will be accurate and she will, in turn, send accurate information on to Bob.
If, on the other hand, her basis is different from Alice’s, her bit will be in agreementwith Alice’s only 50% of the time. However, here’s the rub: the qubit has now col-lapsed to one of the two elements of Eve’s basis. Because of the no-cloning theorem,
Eve does not have the luxury of making a copy of the original qubit and then send-ing it on (after her probe), so she just sends the qubit after her observation. Now

<<<PAGE 290>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
272 Cryptography
Figure 9.6. Alice and Bob communicating on quantum and public channels, with Eve
eavesdropping.
Bob will receive it in the wrong basis. What are his chances of getting the same bit
Alice has? Answer: His chances are 50–50.10
Therefore if Eve intercepts and measures each qubit sent, she will negatively
affect Bob’s chances of agreement with Alice.
Exercise 9.2.2 Give an estimate of how frequently Bob’s bit will agree with Alice’s
if Eve is constantly eavesdropping. /squaresolid
By computing some simple statistics, a potential intrusion by Eve would be de-
tected. This suggests how to complete BB84. Let us examine the details.
After Bob has ﬁnished decoding the qubit stream, he has in his hands a bit stream
of length n. Bob and Alice will discuss which of the nbits were sent and received
in the same basis. They can do this on a public channel, such as a telephone line.
Figure 9.6 is helpful.
Step 3. Bob and Alice publicly compare which basis they used chose at each step.
For instance, he can tell her X,+,X,X,.... Alice replies by telling him when he was
right, and when he was not. Each time they disagreed, Alice and Bob scratch outthe corresponding bit. Proceeding this way until the end, they are each left with a
subsequence of bits that were sent and received in the same basis. If Eve was not
listening to the quantum channel, this subsequence should be exactly identical. Onaverage, this subsequence is of length
n
2.
Step 3: Alice and Bob publicly compare bases used
Bit number 1 2 3 4 5 6 7 8 9 10 11 12
Alice’s random bases ++ X+++ X+ XXX +
Public channel /arrowdblbothv/arrowdblbothv/arrowdblbothv/arrowdblbothv/arrowdblbothv/arrowdblbothv/arrowdblbothv/arrowdblbothv/arrowdblbothv/arrowdblbothv/arrowdblbothv/arrowdblbothv
Bob’s random bases X+ XX + X++ XXX +
Which agree? /check/check /check /check/check/check/check/check
Shared secret keys 1 1 1 0 1 0 1 0
(9.18)
10Eve does, in fact, have other options. For example, she can “listen in” with a third basis. However,such considerations would take us too far aﬁeld.

<<<PAGE 291>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
9.3 Quantum Key Exchange II: The B92 Protocol 273
Programming Drill 9.2.2 Continuing with the last programming drill, write a func-
tion named Knuth2 that accepts all three-bit strings and creates a bit string (of pos-
sibly shorter length) called AgreedBits, which is a substring of both BitSent and
BitReceived.
But what if Eve was eavesdropping? Alice and Bob would also like to engage in
some intrusion detection. They want to know if Eve (or anyone else) was listening
in. They do this by comparing some of the bits of the subsequence.
Step 4. Bob randomly chooses half of then
2bits and publicly compares them with
Alice. If they disagree by more than a tiny percentage (that could be attributed tonoise), they know that Eve was listening in and then sending what she received.In that case, they scratch the whole sequence and try something else. If the ex-
posed sequence is mostly similar, it means that either Eve has great guessing abil-
ity (improbable) or Eve was not listening in. In that case, they simply scratch outthe revealed test subsequence and what remains is the unrevealed secret private
key.
Step 4: Alice and Bob publicly compare half of the remaining bits
B i t n u m b e r 12 3 45678 9 1 01 11 2
Shared secret keys 1 1 1 0 1 0 1 0
Randomly chosen to compare /check/check /check /check
Public channel /arrowdblbothv/arrowdblbothv /arrowdblbothv /arrowdblbothv
Shared secret keys 1 1 1 0 1 0 1 0
Which agree? /check/check /check /check
Unrevealed secret keys: 1 1 0 1
In this protocol, Step 3 has eliminated half of the original qubits sent. So if we
begin with nqubits, onlyn
2qubits will be available after Step 3. Furthermore, Alice
and Bob publicly display half of the resulting qubits in Step 4. This leaves us withn
4
of the original qubits. Do not be disturbed about this, as Alice can make her qubit
stream as large as she needs. Hence, if Alice is interested in sending an mbit key,
she simply starts with a 4 mqubit stream.
9.3 QUANTUM KEY EXCHANGE II: THE B92 PROTOCOL
In the previous section, we introduced the ﬁrst quantum key exchange protocol.
Alice had two distinct orthogonal bases at her disposal. It turns out that the use of
two different bases is redundant, provided one employs a slightly slicker means ofmeasuring. This simpliﬁcation results in another quantum key distribution protocol,
known as B92. Bstands for its inventor, Charles Bennett, and 1992 is the year it was
published.

<<<PAGE 292>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
274 Cryptography
The main idea in B92 is that Alice uses only one nonorthogonal basis. Let us
work out the protocol with the following example:
{|→ /angbracketright|/arrownortheast /angbracketright }=/braceleftbigg
[1,0]T,1√
2[1,1]T/bracerightbigg
. (9.19)
Exercise 9.3.1 Verify that these two vectors are, in fact, not orthogonal. /squaresolid
Before going into detail, we need to pause and reﬂect a little. We know that all
observables have an orthogonal basis of eigenvectors. This means that if we consider
a nonorthogonal basis, there is no observable whose basis of eigenvectors is the
one we have chosen. In turn, this means that there is no single experiment whoseresulting states are precisely the members of our basis. Stated differently, no single
experiment can be set up for the speciﬁc purpose of discriminating unambiguously
between the nonorthogonal states of the basis.
Alice takes |→ /angbracketright to be 0 and |/arrownortheast /angbracketright to be 1. Using this language, we can begin the
protocol.
Step 1. Alice ﬂips a coin ntimes and transmits to Bob the nrandom bits in the
appropriate polarization with a quantum channel.
Here is an example.
Step 1: Alice sends nrandom bits in the ∠basis
B i t n u m b e r 123456789 1 0 1 1 1 2
Alice’s random bits 0 01010101110
Alice’s qubits →→/arrownortheast→/arrownortheast→/arrownortheast→/arrownortheast/arrownortheast/arrownortheast→
Quantum channel ⇓⇓⇓⇓⇓⇓⇓⇓⇓⇓⇓⇓
(9.20)
Step 2. For each of the nqubits, Bob measures the received qubits in either
the+basis or the Xbasis. He ﬂips a coin to determine which basis to use.
There are several possible scenarios that can occur:/D2If Bob uses the +basis and observes a |↑ /angbracketright, then he knows that Alice must have
sent a|/arrownortheast /angbracketright=| 1/angbracketrightbecause if Alice had sent a |→ /angbracketright , Bob would have received a
|→ /angbracketright ./D2If Bob uses the +basis and observes a |→ /angbracketright , then it is not clear to him which
qubit Alice sent. She could have sent a |→ /angbracketright but she could also have sent a |/arrownortheast /angbracketright
that collapsed to a |→ /angbracketright . Because Bob is in doubt, he will omit this bit./D2If Bob uses the Xbasis and observes a |/arrownorthwest /angbracketright , then he knows that Alice must have
sent a|→ /angbracketright=| 0/angbracketrightbecause if Alice had sent a |/arrownortheast /angbracketright , Bob would have received a
|/arrownortheast /angbracketright ./D2If Bob uses the Xbasis and observes a |/arrownortheast /angbracketright , then it is not clear to him which
qubit Alice sent. She could have sent a |/arrownortheast /angbracketright but she could also have sent a |→ /angbracketright
that collapsed to a |/arrownortheast /angbracketright . Because Bob is in doubt, he will omit this bit.

<<<PAGE 293>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
9.4 Quantum Key Exchange III: The EPR Protocol 275
Continuing the example, we have the following:
Step 2: Bob receives nrandom bits in a random basis
B i t n u m b e r 123456789 1 0 1 1 1 2
Alice’s random bits →→/arrownortheast→/arrownortheast→/arrownortheast→/arrownortheast/arrownortheast/arrownortheast→
Quantum channel ⇓⇓⇓⇓⇓⇓⇓⇓⇓⇓⇓⇓
Bob’s random bases X+ XX + X++ X+ X+
Bob’s observations /arrownorthwest→/arrownortheast/arrownorthwest↑/arrownorthwest→→/arrownortheast↑/arrownortheast→
B o b ’ s b i t s 0??010???1??
(9.21)
There are two possible bases that Bob could have used to measure. For each
basis, there are two types of results. For half of those four results, the bit sent is
certain. For the other half, there is uncertainty. Bob must omit the uncertain ones
and keep the others hidden. He must inform Alice of this.
Step 3. Bob publicly tells Alice which bits were uncertain and they both omit
them.
At this point, Alice and Bob know which bits are secret, so they may use those.
But there is one more step if they want to detect whether or not Eve was listening in.They can, as in Step 4 of BB84, sacriﬁce half their hidden bits and publicly comparethem. If they do not agree for a signiﬁcant number, then they know that evil Eve hasbeen doing her wicked deeds and the entire bit string should be ignored.
Programming Drill 9.3.1 Write three functions that mimic Alice, Bob, and their
interactions. Use functions named Alice92, Bob92, and Knuth92 . They should create
bit strings that perform the B92 protocol.
9.4 QUANTUM KEY EXCHANGE III: THE EPR PROTOCOL
In 1991, Artur K. Ekert proposed a completely different type of quantum key distri-
bution protocol based on entanglement (Ekert, 1991). We shall present a simpliﬁed
version of the protocol and then point to the original version.
We remind the reader that it is possible to place two qubits in the following
entangled state11:
|00/angbracketright+| 11/angbracketright√
2. (9.22)
11In the real world, the entangled pairs will probably be in a state
|01/angbracketright+| 10/angbracketright√
2. (9.23)
as explained on page 136 of Chapter 4. When one is measured, they will both collapse to oppositevalues. We shall deal with the slightly easier version given in Equation (9.22). It will become apparentthat if we use Equation (9.23), then Alice and Bob will have inverted bit strings. But if we use thesimpliﬁed one given in Equation (9.22), they will share the exact same bit string.

<<<PAGE 294>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
276 Cryptography
We saw in Section 4.5 that when one of the qubits is measured, they both will col-
lapse to the same value.
Suppose Alice wants to send Bob a secret key. A sequence of entangled pairs of
qubits can be generated and each of our communicators can be sent one of the pairs.When Alice and Bob are ready to communicate, they can measure their respectivequbits. It does not matter who measures ﬁrst, because whoever does it ﬁrst will col-
lapse the other qubit to the same random value. We are done! Alice and Bob now
have a sequence of random bits that no one else has.
There are more sophisticated protocols that will be useful to detect eavesdrop-
pers or if the qubits fell out of entanglement. As in BB84, rather than measure aqubit in one basis, we can measure it in two different bases, say
Xand+.
Following the vocabulary of Xand+of Section 9.2, we present the protocol.
Step 1. Alice and Bob are each assigned one of each of the pairs of a sequence
of entangled qubits.
When they are ready to communicate, they move on to Step 2.
Step 2. Alice and Bob separately choose a random sequence of bases to measure
their particles. They then measure their qubits in their chosen basis.
An example might look like this:
Step 2: Alice and Bob measure in each of their random bases
Bit number 1 2 3 4 5 6 7 8 9 10 11 12
Alice’s random bases XX ++ X+ X++ X+ X
Alice’s observations /arrownortheast/arrownorthwest→↑/arrownortheast→/arrownorthwest→→/arrownortheast→/arrownortheast
Bob’s random bases X++ XX ++++ XX +
Bob’s observations /arrownortheast→→/arrownortheast/arrownortheast→↑→→/arrownortheast/arrownorthwest→
(9.24)
Step 3. Alice and Bob publicly compare what bases were used and keep only
those bits that were measured in the same basis.
Step 3: Alice and Bob publicly compare their bases
B i t n u m b e r 123456789 1 0 1 1 1 2
Alice’s random bases XX ++ X+ X++ X+ X
Public channel /arrowdblbothv/arrowdblbothv/arrowdblbothv/arrowdblbothv/arrowdblbothv/arrowdblbothv/arrowdblbothv/arrowdblbothv/arrowdblbothv/arrowdblbothv/arrowdblbothv/arrowdblbothv
Bob’s random bases X++ XX ++++ XX +
Which agree? /check/check/check /check/check /check /check
(9.25)

<<<PAGE 295>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
9.5 Quantum Teleportation 277
If everything worked ﬁne, Alice and Bob share a totally random secret key. But
problems could have occurred. The entangled pairs could have been exposed to the
environment and become disentangled,12or wicked Eve could have taken hold of
one of the pairs, measured them, and sent along disentangled qubits.
We solve this problem by doing what we did in Step 4 of BB84. Alice or Bob
randomly choose half of the remaining qubits and publicly compare the bits (notthe bases). If they agree, then the last quarter of hidden qubits are probably good.
If more than a small part disagree (from noise), then we must suspect Eve is
up to her evil ways and our friendly communicators must throw away the entiresequence.
Ekert’s original protocol is even more sophisticated. For Step 4, rather than mea-
suring the qubits in two different bases, they will be measured in three differentbases. As in BB84, Alice and Bob will publicly compare the results of half of their
measured sequences to detect if the qubits are still entangled. They will then per-
form certain tests on the results to determine if they were still entangled. If not, thenthey throw away the entire sequence.
The test that they will perform is based on John Bell’s famous Bell’s inequality ,
13
which is central to the foundations of quantum mechanics.
Bell’s inequality is a way of describing the results of measurements of three dif-
ferent bases on two particles. If the particles are independent of each other, like
classical objects, then the measurements will satisfy the inequality. If the particles
are not independent of each other, i.e., they are entangled particles, then Bell’s in-equality fails.
Ekert proposed to use Bell’s inequality to test Alice and Bob’s bit sequences
to make sure that when they were measured they were, in fact, entangled. This isdone by publicly comparing a randomly chosen part of the sequences. We are goingto look at one of three possible directions x,y, and zof spin of particles. If the re-
vealed part of the sequence respects Bell’s inequality, then we know that the qubitsare not entangled (i.e., not independent) and they are acting like classical objects.In such a case, we throw away the entire sequence and start over. If the revealed
portion fails Bell’s inequality, then we can assume that the whole sequence was
measured when it was in a quantum entangled state, and hence the sequence is stillprivate.
9.5 QUANTUM TELEPORTATION
In the last section, we became experts at dealing with entangled qubits. We would
like to use this expertise to perform quantum teleportation.
Deﬁnition 9.5.1 Quantum teleportation is the process by which the state of an arbi-
trary qubit is transferred from one location to another.
12Entanglement is indeed a volatile property. See Chapter 11 for a further discussion of entanglement
and what happens when it is exposed to the environment.
13In fact, a similar inequality that describes classical independent objects was noticed in the nineteenthcentury by one of the forefathers of computer science, George Boole. Boole called them “conditionsof possible experience.” See Pitowsky (1994).

<<<PAGE 296>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
278 Cryptography
It is important to realize that what we describe in this section is not science ﬁc-
tion. Quantum teleportation has already been performed in the laboratory. The fu-
ture of teleportation is, indeed, something to look forward to.
Recall that in Section 5.4 we met the no-cloning theorem, which states that we
are not able to make a copy of the state of an arbitrary qubit. That means that
when the state of the original qubit is teleported to another location, the state of
the original will necessarily be destroyed. As stated on page 166, “Move is possible.
Copy is impossible.”
Before moving on to the protocol, some preliminaries must be dealt with. In our
journey, we have found that working with a cleverly chosen noncanonical basis and
switching between the canonical basis and the noncanonical basis is helpful. When
working with a single qubit, we worked with the canonical basis
{|0/angbracketright,|1/angbracketright} (9.26)
and the noncanonical basis
/braceleftbigg|0/angbracketright+| 1/angbracketright√
2,|0/angbracketright−| 1/angbracketright√
2/bracerightbigg
. (9.27)
The teleportation algorithm will work with two entangled qubits, one held by Aliceand one held by Bob. The obvious canonical basis for this four-dimensional space is
{|0
A0B/angbracketright,|0A1B/angbracketright,|1A0B/angbracketright,|1A1B/angbracketright}. (9.28)
A noncanonical basis, called the Bell basis in honor of John Bell, consists of the
following four vectors:
|/Psi1+/angbracketright=|0A1B/angbracketright+| 1A0B/angbracketright√
2, (9.29)
|/Psi1−/angbracketright=|0A1B/angbracketright−| 1A0B/angbracketright√
2, (9.30)
|/Phi1+/angbracketright=|0A0B/angbracketright+| 1A1B/angbracketright√
2, (9.31)
|/Phi1−/angbracketright=|0A0B/angbracketright−| 1A1B/angbracketright√
2. (9.32)
Every vector in this basis is entangled.
In order to show that these vectors form a basis, we must show that they are
linearly independent (we leave this to the reader) and that every vector in C2⊗C2
can be written as a linear combination of vectors from the Bell basis. Rather than
showing it for every vector in C2⊗C2, we show it is true for every vector in the
canonical basis of C2⊗C2:
|0A0B/angbracketright=1√
2(|/Phi1+/angbracketright+|/Phi1−/angbracketright), (9.33)
|1A1B/angbracketright=1√
2(|/Phi1+/angbracketright−|/Phi1−/angbracketright), (9.34)

<<<PAGE 297>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
9.5 Quantum Teleportation 279
|0A1B/angbracketright=1√
2(|/Psi1+/angbracketright+|/Psi1−/angbracketright), (9.35)
|1A0B/angbracketright=1√
2(|/Psi1+/angbracketright−|/Psi1−/angbracketright). (9.36)
Because every vector in C2⊗C2is a linear combination of canonical basis vectors
and every canonical basis vector is a linear combination of Bell basis vectors, we
have that the Bell basis is, in fact, a basis.
How are the Bell basis vectors formed? In the two-dimensional case, we saw that
the elements of the noncanonical basis can be formed using the Hadamard matrix.Remember that Hdoes the following:
|0/angbracketright /mapsto−→|0/angbracketright+| 1/angbracketright
√
2and|1/angbracketright /mapsto−→|0/angbracketright−| 1/angbracketright√
2. (9.37)
In the four-dimensional case, we need something a little more complicated:
|x/angbracketright
H •
|y/angbracketright/d31/d30/d29/d28 /d24/d25/d26/d27(9.38)
It can easily be seen that this quantum circuit with the appropriate inputs creates
the elements of the Bell basis:
|00/angbracketright /mapsto−→ | /Phi1+/angbracketright,|01/angbracketright /mapsto−→ | /Psi1+/angbracketright,|10/angbracketright /mapsto−→ | /Phi1−/angbracketright,|11/angbracketright /mapsto−→ | /Psi1−/angbracketright.
(9.39)
We now have enough tool in our toolbox to move ahead with the quantum tele-
portation protocol. Alice has a qubit |ψ/angbracketright=α|0/angbracketright+β|1/angbracketrightin an arbitrary state that she
would like to teleport to Bob.
Step 1. Two entangled qubits are formed as |/Phi1+/angbracketright. One is given to Alice and one
is given to Bob.
We may envision these three qubits as three lines.
|ψ/angbracketright
A
H •
B/d31/d30/d29/d28 /d24/d25/d26/d27
⇑
|ϕ0/angbracketright⇑
|ϕ1/angbracketright⇑
|ϕ2/angbracketright(9.40)

<<<PAGE 298>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
280 Cryptography
The top two lines are in Alice’s possession and the bottom line is in Bob’s pos-
session. The states are as follows:
|ϕ0/angbracketright=|ψ/angbracketright⊗| 0A/angbracketright⊗| 0B/angbracketright=|ψ/angbracketright⊗| 0A0B/angbracketright, (9.41)
|ϕ1/angbracketright=|ψ/angbracketright⊗|0A/angbracketright+| 1A/angbracketright√
2⊗|0B/angbracketright, (9.42)
|ϕ2/angbracketright=|ψ/angbracketright⊗|/Phi1+/angbracketright=|ψ/angbracketright⊗|0A0B/angbracketright+| 1A1B/angbracketright√
2(9.43)
=(α|0/angbracketright+β|1/angbracketright)⊗|0A0B/angbracketright+| 1A1B/angbracketright√
2
=α|0/angbracketright(|0 A0B/angbracketright+| 1A1B/angbracketright)+β|1/angbracketright(|0 A0B/angbracketright+| 1A1B/angbracketright)√
2.
Step 2. Alice lets her |ψ/angbracketrightinteract with her entangled qubit.
Steps 1, 2, and 3 can be seen in the following diagram:
|ψ/angbracketright
• H/d70/d69/d13/d13/d13
A
H • /d31/d30/d29/d28 /d24/d25/d26/d27
/d70/d69/d13/d13/d13
B/d31/d30/d29/d28 /d24/d25/d26/d27
⇑
|ϕ0/angbracketright⇑
|ϕ1/angbracketright⇑
|ϕ2/angbracketright⇑
|ϕ3/angbracketright⇑
|ϕ4/angbracketright(9.44)
We have
|ϕ3/angbracketright=α|0/angbracketright(|0 A0B/angbracketright+| 1A1B/angbracketright)+β|1/angbracketright(|1 A0B/angbracketright+| 0A1B/angbracketright)√
2,
|ϕ4/angbracketright=1
2(α(|0/angbracketright+| 1/angbracketright)(|0 A0B/angbracketright+| 1A1B/angbracketright)+β(|0/angbracketright−| 1/angbracketright)(|1 A0B/angbracketright+| 0A1B/angbracketright)
=1
2(α(|000/angbracketright+| 011/angbracketright+| 100/angbracketright+| 111/angbracketright)+β(|010/angbracketright+| 001/angbracketright−| 110/angbracketright−| 101/angbracketright)).
(9.45)

<<<PAGE 299>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
9.5 Quantum Teleportation 281
Regrouping these triplets |xyz/angbracketrightin terms of |xy/angbracketright, which is in Alice’s possession,
we have
|φ4/angbracketright=1
2(|00/angbracketright(α|0/angbracketright+β|1/angbracketright)+|01/angbracketright(β|0/angbracketright+α|1/angbracketright)
+|10/angbracketright(α|0/angbracketright−β|1/angbracketright)+|11/angbracketright(−β|0/angbracketright+α|1/angbracketright)). (9.46)
So the system of three qubits is now in a superposition of four possible states.
Step 3. Alice measures her two qubits and determines to which of the four pos-
sible states the system collapses.
At the moment Alice measures her two qubits; all three qubits collapse to
one of four possibilities. So if she measures |10/angbracketright then the third qubit is in state
α|0/angbracketright−β|1/angbracketright.
There are two problems to deal with:
(a) Alice knows this state but Bob does not; and
(b) Bob has α|0/angbracketright−β|1/angbracketright, not the desired α|0/angbracketright+β|1/angbracketright. Both problems are solved
by Step 4.
Step 4. Alice sends copies of her two bits (not qubits) to Bob who uses that
information to achieve the desired state |ψ/angbracketright.
In other words, if Bob receives |01/angbracketright from Alice, he then knows that his qubit is
in state
α|0/angbracketright−β|1/angbracketright=⎡
⎢⎣α
−β⎤
⎥⎦; (9.47)
hence he should act on his qubit with the following matrix:
⎡
⎢⎣10
0−1⎤
⎥⎦⎡
⎢⎣α
−β⎤
⎥⎦=⎡
⎢⎣α
β⎤
⎥⎦=α|0/angbracketright+β|1/angbracketright=| ψ/angbracketright. (9.48)
In detail, Bob must apply the following matrices upon receiving information
from Alice:
Bob’s reconstruction matrices
Bits received |00/angbracketright| 01/angbracketright| 10/angbracketright| 11/angbracketright
Matrix to apply⎡
⎢⎣10
01⎤
⎥⎦⎡
⎢⎣01
10⎤
⎥⎦⎡
⎢⎣10
0−1⎤
⎥⎦⎡
⎢⎣01
−10⎤
⎥⎦(9.49)
After applying the matrix, Bob will have the same qubit that Alice had.

<<<PAGE 300>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
282 Cryptography
The following space–time diagram might be helpful. We use the convention that
straight arrows correspond to the movement of bits and curvy arrows correspond to
qubits on the move.
|ψ/angbracketright
•Step 4 • reconstruct |ψ/angbracketright/d79/d79/d79/d15/d79/d15/d79/d15/d79/d15/d79/d15/d79/d15/d79/d15
Step 3 measure/d52/d52/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d52/d52/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d105/d79/d79 /d79/d79
Step 2|ψ/angbracketright,Ai n t e r a c t/d79/d79/d79/d15/d79/d15/d79/d15/d79/d15/d79/d15/d79/d15/d79/d15/d79/d79/d79/d15/d79/d15/d79/d15/d79/d15/d79/d15/d79/d15/d79/d15
•Time/d79/d79
Step 1 |ψ/angbracketright/d79/d79/d79/d15/d79/d15/d79/d15/d79/d15/d79/d15/d79/d15/d79/d15
A,Be n ta n g l e dA/d101/d101/d101/d37/d101/d37/d101/d37/d101/d37/d101/d37/d101/d37/d101/d37/d101/d37/d101/d37/d101/d37/d101/d37/d101/d37/d101/d37B/d70/d70/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6/d70/d6
Alice Bob
•
Space/d47/d47•
(9.50)
Notice that |ψ/angbracketrightmoves from the lower-left corner in Alice’s possession to the upper-
right corner in Bob’s possession. Mission accomplished!
Several points should be made about this protocol:/D2Alice is no longer in possession of |ψ/angbracketright. She has only two classical bits./D2As we have seen, to “teleport” a single quantum particle, Alice has to send twoclassical bits. Without receiving them, there is no way that Bob can know what
he has. These classical bits travel along a classical channel and thus they prop-agate at ﬁnite speed (less than the speed of light). Entanglement, in spite of itsundisputable magic, does notallow you to communicate faster than the speed of
light. Einstein’s theory of relativity would not permit such communication.

<<<PAGE 301>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
9.5 Quantum Teleportation 283/D2αandβwere arbitrary complex numbers satisfying |α|2+|β|2=1.They could
have had an inﬁnite decimal expansion. And yet, this potentially inﬁnite amount
of information has gone from Alice to Bob across the universe by passing only
two bits. However, it is important to realize that this potentially inﬁnite amountof information is passed as a qubit and useless to Bob. As soon as he measures
the qubit, it will collapse to a bit./D2Someone might argue that calling all the foregoing teleportation is a bit of astretch. Indeed, no particle has been moved at all. However, from the point
of view of quantum mechanics, two particles having exactly the same quantum
state are, from the standpoint of physics, indistinguishable and can therefore betreated as the same particle. If you are conﬁgured like Captain Kirk down to theminutest details, you areCaptain Kirk!
Exercise 9.5.1 What about Eve? She can certainly tap into the classical channel
and snatch the two bits. But will it be useful to her? /squaresolid
Exercise 9.5.2 There was nothing special about Alice using |/Phi1
+/angbracketrightto entangle her
|ψ/angbracketright. She could have just as easily used any of the other three Bell vectors. Work out
the result if she had used |/Phi1−/angbracketright. /squaresolid
.................................................................................
References: A comprehensive text on classical cryptography is Schneier (1995). For
a more mathematical treatment, see Koblitz (1994). A general introduction to quan-
tum cryptography is Lomonaco (2001).
BB84 was ﬁrst described in Bennett and Brassard (1984). B92 was the ﬁrst pre-
sentation of Bennett (1992). The EPR protocol was ﬁrst described in Ekert (1991).
A short history of quantum cryptography can be found in Brassard and Cr ´epeau
(1993), and a bibliography in Brassard (1993).
Quantum teleportation was ﬁrst presented in Bennett et al. (1993).

<<<PAGE 302>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
10
Information Theory
I ﬁnd that a great part of the information I have
was acquired by looking up something
and ﬁnding something else on the way.
Franklin P. Adams
The topic of this chapter is quantum information , i.e., information in the quantum
world. The material that is presented here lies at the core of a variety of areas within
the compass of quantum computation, such as quantum cryptography, described in
Chapter 9, and quantum data compression. As quantum information extends andmodiﬁes concepts developed in classical information theory, a brief review of the
mathematical notion of information is in order.
In Section 10.1, we recall the basics of classical information theory. Section 10.2
generalizes this work to get quantum information theory. Section 10.3 discusses clas-sical and quantum data compression. We conclude with a small section on error-
correcting codes.
10.1 CLASSICAL INFORMATION AND SHANNON ENTROPY
What isinformation really? In the mid-forties, an American mathematician named
Claude Shannon set out to establish a mathematical theory of information on a ﬁrm
basis. To see this, we use Alice and Bob. Alice and Bob are exchanging messages.
Let us say that Alice can only send one of four different messages coded by theletters A,B,C,and D.
In our story, the meaning of the four letters is as following:
Symbol Meaning
A “I feel sad now”
B “I feel angry now”
C “I feel happy now”
D “I feel bored now”(10.1)
284

<<<PAGE 303>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
10.1 Classical Information and Shannon Entropy 285
1 
0.8 
0.6 0.4 0.2 
01 
0.8 
0.6 0.4 0.2 
0
1 
0.8 0.6 0.4 0.2 
0AB C D
AB C DAB CD
0.5
0.25
0.125 0.125GeneralConstant Uniform
Figure 10.1. Three possible probability distributions.
Bob is a careful listener, so he keeps track of the frequency of each letter. By
observing Nconsecutive messages from Alice, he reports the following:
Aappeared NAtimes
Bappeared NBtimes
Cappeared NCtimes
Dappeared NDtimes
where NA+NB+NC+ND=N. Bob concludes that the probability of each letter
showing up is given by
p(A)=NA
N,p(B)=NB
N,p(C)=NC
N,and p(D)=ND
N. (10.2)
The table that associates with each basic symbol its probability is known as the
probability distribution Function (pdf for short) of the source. Of course, the prob-
ability distribution may have different shapes (Figure 10.1). For instance, Alice may
be always happy (or at least say so to Bob), so that the pdf looks like
p(A)=0
N=0, p(B)=0
N=0, p(C)=N
N=1, and p(D)=0
N=0.
(10.3)

<<<PAGE 304>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
286 Information Theory
Such a pdf is called the constant distribution. In this case, Bob knows with cer-
tainty that the next symbol he will receive from Alice is C. It stands to reason that in
this scenario Cdoes not bring any new information : its information content is zero.
On the opposite side of the spectrum, let us assume that Alice is very moody, in
fact totally unpredictable, as far as her emotional state goes. The pdf will then look
like
p(B)=1
4,p(B)=1
4,p(C)=1
4,and p(D)=1
4. (10.4)
Such a pdf is called the uniform distribution. In this case, when Bob will observe
the new symbol from Alice, he will gain information, indeed the maximum amount
of information this limited alphabet could convey.
These two scenarios are just two extremes among inﬁnitely many others. For
instance, the pdf might look like
P(A)=1
2,P(B)=1
4,P(C)=1
8,and P(D)=1
8. (10.5)
It is quite obvious that this general scenario stands in between the other two, in
the sense that its outcome is less certain than the one afforded by the constant pdf,
but more so than the uniform pdf.
We have just found a deep connection between uncertainty andinformation .T h e
more uncertain the outcome, the more Bob will gain information by knowing theoutcome. What Bob can predict beforehand does not count: only novelty brings
forth information!
1The uniform probability distribution represents the greatest un-
certainty about the outcome: everything can happen with equal likelihood; likewise,
its information content is the greatest.
It now becomes clear what we need: a way to quantify the amount of uncertainty
in a given probability distribution. Shannon, building on classical statistical thermo-dynamics, introduced precisely such a measure.
Deﬁnition 10.1.1 The Shannon entropy of a source with probability distribution {p
i}
is the quantity
HS=−n/summationdisplay
i=1pi×log2(pi)=n/summationdisplay
i=1pi×log2/parenleftbigg1
pi/parenrightbigg
, (10.6)
where the following convention has been adopted :0×log2(0)=0.2
Note: The minus sign is there to make sure that entropy is always positive or zero,
as shown by the following exercise.Exercise 10.1.1 Prove that Shannon entropy is always positive or zero. /squaresolid
1After all, this is just common sense. Would you bother reading a daily newspaper if you knew its content
beforehand?
2The calculus savvy reader will promptly recognize the soundness of this convention: the limit of thefunction y=xlog
2(x)i sz e r oa s xapproaches zero. There is another more philosophical motivation: if
a symbol is never sent, its contribution to the calculation of entropy should be zero.

<<<PAGE 305>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
10.1 Classical Information and Shannon Entropy 287
Why should we believe that the formula presented in Equation (10.6) does in-
deed capture the uncertainty of the source? The better course is to calculate Hfor
each of the aforementioned scenarios above.
Let us compute the entropy for the constant pdf:
HS=−0×log2(0)−0×log2(0)−1×log2(1)−0×log2(0)
=− log2(1)=0. (10.7)
As we see, the entropy is as low as it can be, just as we would expect. When the
entropy equals zero, that means there is absolutely no uncertainty in the source.
Let us move to the uniform pdf:
HS=−1
4×log2/parenleftbigg1
4/parenrightbigg
−1
4×log2/parenleftbigg1
4/parenrightbigg
−1
4×log2/parenleftbigg1
4/parenrightbigg
−1
4×log2/parenleftbigg1
4/parenrightbigg
=− log2/parenleftbigg1
4/parenrightbigg
=2. (10.8)
This makes sense. After all, because Bob has no real previous information, he
needs no less than two bits of information to describe which letter is being sentto him.
And now the general scenario:
H
S=−1
2×log2/parenleftbigg1
2/parenrightbigg
−1
4×log2/parenleftbigg1
4/parenrightbigg
−1
8×log2/parenleftbigg1
8/parenrightbigg
−1
8×log2/parenleftbigg1
8/parenrightbigg
=1.75. (10.9)
We have thus veriﬁed, at least for the preceding examples, that the entropy formula
does indeed classify the amount of uncertainty of the system.
Exercise 10.1.2 Create a fourth scenario that is strictly in between the general pdf
in Equation (10.9) and the uniform distribution. In other words, determine a pdf for
the four-symbol source whose entropy veriﬁes 1.75 <H<2. /squaresolid
Exercise 10.1.3 Find a pdf for the four-symbol source so that the entropy will be
less than 1 but strictly positive. /squaresolid
Summing up, we can recapitulate the above into two complementary slogans:
Greater entropy means greater uncertainty
Greater entropy means more information(10.10)
Programming Drill 10.1.1 Write a simple program that lets the user choose how
many letters the source alphabet has, and then enter the probability distribution. Theprogram should visualize it, and compute its Shannon entropy.

<<<PAGE 306>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
288 Information Theory
10.2 QUANTUM INFORMATION AND VON NEUMANN ENTROPY
The previous section dealt with the transmission of classical information, i.e., infor-
mation that can be encoded as a stream of bits . We are now going to investigate to
what extent things change when we are concerned with sources emitting streams of
qubits .
As it turns out, there is a quantum analog of entropy, known as von Neumann
entropy . Just as Shannon entropy measures the amount of order in a classical sys-
tem, von Neumann entropy will gauge order in a given quantum system. Let us set
the quantum scenario ﬁrst. Alice has chosen as her quantum alphabet a set of nor-
malized states in Cm:
{|w 1/angbracketright,|w2/angbracketright,...,|wn/angbracketright}. (10.11)
If she wishes to notify Bob of her moods, as in the previous section, she can choose
four normalized states in some state space. Even the single qubit space is quiteroomy (there are inﬁnitely many distinct qubits), so she could select the following
set:
/braceleftbigg
|A/angbracketright=| 0/angbracketright,|B/angbracketright=| 1/angbracketright,|C/angbracketright=1
√
2|0/angbracketright+1√
2|1/angbracketright,|D/angbracketright=1√
2|0/angbracketright−1√
2|1/angbracketright/bracerightbigg
.
(10.12)
Notice that Alice does not have to choose an orthogonal set of states, they simply
need to be distinct.
Now, let us assume that she sends to Bob her states with probabilities:
p(|w 1/angbracketright)=p1,p(|w 2/angbracketright)=p2,..., p(|w n/angbracketright)=pn. (10.13)
We can associate with the table above a linear operator, known as the density oper-
ator,3deﬁned by the following expression:
D=p1|w1/angbracketright/angbracketleftw1|+p2|w2/angbracketright/angbracketleftw 2|+···+ pn|wn/angbracketright/angbracketleftw n|. (10.14)
D does not look like anything we have met so far. It is the weighted sum of a basicexpression of the form |w/angbracketright/angbracketleftw|, i.e., products of a bra with their associated ket .T o
get some sense for what Dactually does, let us study ﬁrst how its building blocks
operate. |w
i/angbracketright/angbracketleftwi|acts on a ket vector |v/angbracketrightin the following way:
|wi/angbracketright/angbracketleftw i|(|v/angbracketright)=(/angbracketleftw i|v/angbracketright)|w i/angbracketright. (10.15)
In plain words, the result of applying |wi/angbracketright/angbracketleftwi|to a generic ket |v/angbracketrightis simply the
projection of |v/angbracketrightonto|wi/angbracketright, as shown in Figure 10.2. The length of the projection is
the scalar product /angbracketleftwi|v/angbracketright(we are here using the fact that all wi’s are normalized).
3The origin of the density operator lies in statistical quantum mechanics. The formalism that we havepresented thus far works well if we assume that the quantum system is in a well-deﬁned state. Now,when studying large ensembles of quantum particles, the most we can assume is that we know theprobability distribution of the quantum states of the individual particles, i.e., we know that a randomlyselected particle will be in state |w
1/angbracketrightwith probability p1,e t c .

<<<PAGE 307>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
10.2 Quantum Information and von Neumann Entropy 289
Figure 10.2. The projection of |v/angbracketrightonto|wi/angbracketright.
Exercise 10.2.1 Assume Alice always sends only one vector, say, w1. Show that D
in this case just looks like |w1/angbracketright/angbracketleftw1|. /squaresolid
Now that we know how each component acts on a ket, it is not difﬁcult to under-
stand the entire action of D. It acts on ket vectors on the left:
D|v/angbracketright=p1/angbracketleftw1|v/angbracketright|w 1/angbracketright+p2/angbracketleftw2|v/angbracketright|w 2/angbracketright+···+ pn/angbracketleftwn|v/angbracketright|w n/angbracketright. (10.16)
In words, Dis the sum of projections onto all the |wi/angbracketright’s, weighted by their respective
probabilities.
Exercise 10.2.2 Show that the action we have just described makes Da linear op-
erator on kets (check that it preserves sums and scalar multiplication). /squaresolid
AsDis now a legitimate linear operator on the ket space, it can be represented
by a matrix, once a basis is speciﬁed. Here is an example:
Example 10.2.1 Let|w1/angbracketright=1√
2|0/angbracketright+1√
2|1/angbracketrightand|w2/angbracketright=1√
2|0/angbracketright−1√
2|1/angbracketright. Assume that
|w1/angbracketrightis sent with probability p1=1
4and|w2/angbracketrightis sent with probability p2=3
4. Let us
now describe the corresponding density matrix in the standard basis. In order to do
so, we just compute the effect of Don the two basis vectors:
D(|0/angbracketright)=1
4/angbracketleftw1|0/angbracketright|w 1/angbracketright+3
4/angbracketleftw2|0/angbracketright|w 2/angbracketright=/parenleftbigg1
41√
2/parenrightbigg
|w1/angbracketright+/parenleftbigg3
41√
2/parenrightbigg
|w2/angbracketright
=1
4√
2/parenleftbigg1√
2|0/angbracketright+1√
2|1/angbracketright/parenrightbigg
+3
4√
2/parenleftbigg1√
2|0/angbracketright−1√
2|1/angbracketright/parenrightbigg
=/parenleftbigg1
8|0/angbracketright+3
8|0/angbracketright/parenrightbigg
+/parenleftbigg1
8|1/angbracketright−3
8|1/angbracketright/parenrightbigg
=1
2|0/angbracketright−1
4|1/angbracketright (10.17)
D(|1/angbracketright)=1
4/angbracketleftw1|1/angbracketright|w 1/angbracketright+3
4/angbracketleftw2|1/angbracketright|w 2/angbracketright=/parenleftbigg1
41√
2/parenrightbigg
|w1/angbracketright−/parenleftbigg3
41√
2/parenrightbigg
|w2/angbracketright
=1
4√
2/parenleftbigg1√
2|0/angbracketright+1√
2|1/angbracketright/parenrightbigg
−3
4√
2/parenleftbigg1√
2|0/angbracketright−1√
2|1/angbracketright/parenrightbigg
=/parenleftbigg1
8|0/angbracketright−3
8|0/angbracketright/parenrightbigg
+/parenleftbigg1
8|1/angbracketright+3
8|1/angbracketright/parenrightbigg
=−1
4|0/angbracketright+1
2|1/angbracketright. (10.18)

<<<PAGE 308>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
290 Information Theory
The density matrix is thus
D=⎡
⎢⎣1
2−1
4
−1
41
2⎤
⎥⎦. (10.19)
/square
Exercise 10.2.3 Write the density matrix of the alphabet in Equation (10.12),
where
p(|A/angbracketright)=1
2,p(|B/angbracketright)=1
6,p(|C/angbracketright)=1
6,and p(|D/angbracketright)=1
6. (10.20)
/squaresolid
Dalso acts on bra vectors on the right, using a mirror recipe:
/angbracketleftv|D=p1/angbracketleftv|w1/angbracketright/angbracketleftw1|+p2/angbracketleftv|w2|/angbracketright/angbracketleftw 2+···+ pn/angbracketleftv|wn/angbracketright/angbracketleftwn|. (10.21)
What we have just found, namely, that Dcan operate on both bras and kets at the
same time, suggests that we combine the action on the left and the right in one shot.
Given any state |v/angbracketright, we can form
/angbracketleftv|D|v/angbracketright=p1|/angbracketleftv|w1/angbracketright|2+p2|/angbracketleftv|w2/angbracketright|2+···+ pn|/angbracketleftv|wn/angbracketright|2. (10.22)
The meaning of the number /angbracketleftv|D|v/angbracketrightwill become apparent in a moment. Suppose
Alice sends a state and Bob performs a measurement whose possible outcomes is
the set of orthonormal states
{|v1/angbracketright,|v2/angbracketright,...,|vn/angbracketright}. (10.23)
Let us compute the probability that Bob observes the state |vi/angbracketright.
Alice sends |w1/angbracketrightwith probability p1. Each time Bob receives |w1/angbracketright, the probabil-
ity that the outcome is |vi/angbracketrightis precisely |/angbracketleftvi|w1/angbracketright|2. Thus p1|/angbracketleftvi|w1/angbracketright|2is the probability
that Alice has sent |w1/angbracketrightandBob has observed |vi/angbracketright. Similarly for |w2/angbracketright,...,|wn/angbracketright. Con-
clusion: /angbracketleftvi|D|vi/angbracketrightis the probability that Bob will see |vi/angbracketrightregardless of which state
Alice has sent him.
Example 10.2.2 Assume Alice has a quantum alphabet consisting of only two sym-
bols, the vectors
|w1/angbracketright=1√
2|0/angbracketright+1√
2|1/angbracketright (10.24)
and
|w2/angbracketright=| 0/angbracketright. (10.25)
Notice that, unlike Example 10 .2.1, here the two states are not orthogonal. Alice
sends|w1/angbracketrightwith frequency p1=1
3and|w2/angbracketrightwith frequency p2=2
3. Bob uses the
standard basis {|0/angbracketright,|1/angbracketright}for his measurements.

<<<PAGE 309>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
10.2 Quantum Information and von Neumann Entropy 291
The density operator is
D=1
3|v1/angbracketright/angbracketleftv1|+2
3|v2/angbracketright/angbracketleftv2|. (10.26)
Let us write down the density matrix in the standard basis:
D(|0/angbracketright)=1
3√
2/parenleftbigg1√
2|0/angbracketright+1√
2|1/angbracketright/parenrightbigg
+2
3|0/angbracketright=5
6|0/angbracketright+1
6|1/angbracketright, (10.27)
D(|1/angbracketright)=1
3√
2/parenleftbigg1√
2|0/angbracketright+1√
2|1/angbracketright/parenrightbigg
+0|0/angbracketright=1
6|0/angbracketright+1
6|1/angbracketright. (10.28)
The density matrix is thus
D=⎡
⎢⎣5
61
6
1
61
6⎤
⎥⎦. (10.29)
Now we can calculate /angbracketleft0|D|0/angbracketrightand/angbracketleft1|D|1/angbracketright:
/angbracketleft0|D|0/angbracketright= [1,0]⎡
⎢⎣5
61
6
1
61
6⎤
⎥⎦⎡
⎢⎣1
0⎤
⎥⎦=5
6, (10.30)
/angbracketleft1|D|1/angbracketright= [0,1]⎡
⎢⎣5
61
6
1
61
6⎤
⎥⎦⎡
⎢⎣0
1⎤
⎥⎦=1
6. (10.31)
If we calculate Shannon entropy with respect to this basis, we get
−1
6log2/parenleftbigg1
6/parenrightbigg
−5
6log2/parenleftbigg5
6/parenrightbigg
=0.65. (10.32)
/square
Even though Alice is sending |wi/angbracketright’s, from Bob’s standpoint, the source behaves
as an emitter of states
|v1/angbracketright,|v2/angbracketright,...,|vn/angbracketright (10.33)
with probability distribution given by
/angbracketleftv1|D|v1/angbracketright,/angbracketleftv2|D|v2/angbracketright,...,/angbracketleftvn|D|vn/angbracketright. (10.34)
It would be tempting to conclude that the source has entropy given by the same
recipe as in the classical case:
−/summationdisplay
i/angbracketleftvi|D|vi/angbracketright×log2(/angbracketleftvi|D|vi/angbracketright). (10.35)

<<<PAGE 310>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
292 Information Theory
However, things are a bit more complicated and more interesting also. Bob can
choose different measurements, each associated with its own orthonormal basis. The
probability distribution will change as he changes basis, as shown by the following
example.
Example 10.2.3 Suppose Bob settles for the basis
|v1/angbracketright=1√
2|0/angbracketright+1√
2|1/angbracketright, (10.36)
|v2/angbracketright=1√
2|0/angbracketright−1√
2|1/angbracketright. (10.37)
Let us calculate /angbracketleftv1|D|v1/angbracketrightand/angbracketleftv2|D|v2/angbracketright(the density matrix is the same as in Exam-
ple 10.2.1):
/angbracketleftv1|D|v1/angbracketright=/bracketleftbigg1√
2,1√
2/bracketrightbigg⎡
⎢⎣5
61
6
1
61
6⎤
⎥⎦⎡
⎢⎣1√
2
1√
2⎤
⎥⎦=2
3, (10.38)
/angbracketleftv2|D|v2/angbracketright=/bracketleftbigg1√
2,−1√
2/bracketrightbigg⎡
⎢⎣5
61
6
1
61
6⎤
⎥⎦⎡
⎢⎣1√
2
−1√
2⎤
⎥⎦=1
3. (10.39)
Let us calculate the Shannon entropy for this pdf:
−1
3log2/parenleftbigg1
3/parenrightbigg
−2
3log2/parenleftbigg2
3/parenrightbigg
=0.9183. (10.40)
Compared to Equation (10.32), the Shannon entropy, as perceived by Bob, has
increased, because the pdf is less sharp than before. The source, however, hasn’t
changed at all: quite simply, Bob has replaced his “pair of glasses” (i.e., his measure-
ment basis) with a new one! /square
Exercise 10.2.4 Write the matrix of the general density operator D described by
Equation 10.14 in the standard basis of Cn, and verify that it is always hermitian.
Verify that the trace of this matrix, i.e., the sum of its diagonal entries, is 1. /squaresolid
We can ask ourselves if there is a privileged basis, among the ones Bob can
choose. Put differently, is there a basis that minimizes the calculation of Shannonentropy in Equation (10.35)? It turns out that such a basis does exist. Because the
density operator is hermitian, we saw using the spectral theorem for self-adjoint op-erators on page 64, that it can be put in diagonal form. Assuming that its eigenvaluesare
λ
1,λ2,...,λ n, (10.41)
we can then deﬁne the von Neumann entropy as follows:

<<<PAGE 311>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
10.2 Quantum Information and von Neumann Entropy 293
Deﬁnition 10.2.1 The von Neumann entropy4for a quantum source represented by
a density operator D is given by
HV=−n/summationdisplay
1λilog2(λi), (10.42)
where λ1,λ2,...,λ nare the eigenvalues of D.
If Bob selects the basis
{|e1/angbracketright,|e2/angbracketright,...,|en/angbracketright} (10.43)
of orthonormal eigenvectors of Dcorresponding to the eigenvalues listed in Equa-
tion (10.47), the von Neumann entropy is precisely identical to the calculation of
Shannon entropy in Equation (10.40) with respect to the basis of eigenvectors. Why?If you compute
/angbracketlefte
1|D|e1/angbracketright, (10.44)
you get
/angbracketlefte1|λ1e1/angbracketright=λ1 (10.45)
(we have used the orthonormality of |e1/angbracketright).
The same holds true for all eigenvectors: the eigenvalue λiis the probability that
Bob will observe |ei/angbracketrightwhen he measures incoming states in the eigenvector basis!
Example 10.2.4 Let us continue the investigation we began in Example 10.2.2. The
density matrix D has eigenvalues
λ1=0.1273 and λ2=0.8727 (10.46)
corresponding to the normalized eigenvectors
|e1/angbracketright=+ 0.2298|0/angbracketright− 0.9732|1/angbracketright and|e2/angbracketright=− 0.9732|0/angbracketright− 0.2298|1/angbracketright.
(10.47)
The von Neumann entropy of Dis given by
HV(D)=−0.1273∗log2(0.1273)−0.8727∗log2(0.8727)=0.5500. (10.48)
Let us verify that von Neumann’s entropy is identical to Shannon’s entropy whencalculated with respect to the orthonormal basis of eigenvectors of D:
/angbracketlefte
1|D|e1/angbracketright=[0 .2298,−0.9732]⎡
⎢⎣5
61
6
1
61
6⎤
⎥⎦⎡
⎢⎣0.2298
−0.9732⎤
⎥⎦=0.1273, (10.49)
4Most texts introduce von Neumann entropy using the so-called Trace operator, and then recover our
expression by means of diagonalization. We have sacriﬁced mathematical elegance for the sake ofsimplicity, and also because for the present purposes the explicit formula in terms of the eigenvalues isquite handy.

<<<PAGE 312>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
294 Information Theory
/angbracketlefte2|D|e2/angbracketright=[−0.9732, −0.2298]⎡
⎢⎣5
61
6
1
61
6⎤
⎥⎦⎡
⎢⎣−0.9732
−0.2298⎤
⎥⎦=0.8727. (10.50)
Observe that the sum of eigenvalues 0 .8727+0.1273 is 1, and both eigenvalues
are positive, as beﬁts true probabilities. Also notice that the entropy is lower than
the one calculated using the other two bases; it can indeed be proven that it is as low
as it can possibly be. /square
Exercise 10.2.5 Go through all the steps of Examples 10.2.1, 10.2.2, and 10.2.3,
assuming that Alice sends the same states, but with equal probability.
Note that for this exercise, you will need to calculate eigenvectors and eigenval-
ues. In Chapter 2 we stated what eigenvalues and eigenvectors are, but not how tocompute them for a given symmetric or hermitian matrix. To complete this exercise,
you have two equally acceptable options:
1. Look up any standard reference on linear algebra for the eigenvalues formula
(search for “characteristic polynomial”).
2. Use a math library to do the work for you. In MATLAB, for instance, the
function eigis the appropriate one (Mathematica and Maple come equipped with
similar functions). /squaresolid
As we have said, Alice is at liberty in choosing her alphabet. What would happen
if she selected a set of orthogonal vectors? The answer is in the following pair of
exercises.
Exercise 10.2.6 Go back to Example 10.2.1. The two states |w
1/angbracketrightand|w2/angbracketrightare a pair
of orthonormal vectors, and thus an orthonormal basis for the one qubit space. Show
that they are eigenvectors for the density matrix given in Equation (10.19), and thusBob’s best choice for measuring incoming messages. /squaresolid
Exercise 10.2.7 This exercise is just the generalization of the previous one, in
a more formal setting. Suppose Alice chooses from a set of orthonormal statevectors
{|w
1/angbracketright,|w2/angbracketright,...,|wn/angbracketright} (10.51)
with frequencies
p1,p2,..., pn (10.52)
to code her messages. Prove that in this scenario each of the |wi/angbracketright’s is a normalized
eigenvector of the density matrix with eigenvalue pi. Conclude that in this case the
source behaves like a classical source (provided of course that Bob knows the or-thonormal set and uses it to measure incoming states). /squaresolid
In the wake of the two foregoing exercises, we now know that orthogonal quan-
tum alphabets are the less surprising ones. Let us go back brieﬂy to Example 10.2.2:there Alice’s choice is a nonorthogonal set. If you calculate explicitly its von Neu-
mann entropy, you will ﬁnd that it is equal to 0 .55005, whereas the classical entropy

<<<PAGE 313>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
10.3 Classical and Quantum Data Compression 295
for a source of bits such that p(0)=1
3and p(1)=2
3is 0.91830.
We have just unraveled yet another distinct feature of the quantum world: if
we stick to the core idea that entropy measures order, then we come to the in-
escapable conclusion that the quantum source above exhibits more order than its
classical counterpart. Where does this order come from? If the alphabet is orthog-
onal, the two numbers are the same. Therefore, this apparent magic is due to thefact that there is additional room in the quantum via superposition of alternatives.
5
Our discovery is a valuable one, also in light of the important connection betweenentropy and data compression, the topic of the next section.
Programming Drill 10.2.1 Write a program that lets the user choose how many qubits
the alphabet of the quantum source consists of, enter the probability associated with
each qubit, and compute von Neumann entropy as well as the orthonormal basis forthe associated density matrix.
10.3 CLASSICAL AND QUANTUM DATA COMPRESSION
In this section, we introduce the basic ideas of data compression for bit and qubit
streams. Let us begin with bits ﬁrst.
What is data compression? Alice has a message represented by a stream of bits.
She wants to encode it either for storage or for transmission in such a way that theencoded stream is shorter than the original message. She has two main options:/D2Lossless data compression , meaning that her compression algorithm must have
an inverse that perfectly reconstruct her message./D2Lossy data compression , if she allows a loss of information while compressing
her data.
In data compression, a notion of similarity between strings is always assumed,
i.e., a function that enables us to compare different strings (in our scenario, themessage before compression and the one after it has been decompressed):
µ:{0,1}
∗×{0,1}∗−→R+(10.53)
such that/D2µ(s,s)=0 (a string is identical to itself), and/D2µ(s 1,s2)=µ(s 2,s1) (symmetry of similarity).6
Armed with such a notion of similarity, we can now deﬁne compression.
5The difference between entropy in classical and quantum domains becomes even sharper when we
consider composite sources. There entanglement creates a new type of order that is reﬂected by the
global entropy of the system. If you want to know more about this phenomenon, go to Appendix E atthe end of the book.
6There are several notions of similarity used by the data compression community, depending on theparticular needs one may have. Most are actually distances, meaning that they satisfy the triangularinequality, besides the two conditions mentioned here.

<<<PAGE 314>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
296 Information Theory
Deﬁnition 10.3.1 Letµbe a measure of similarity for binary strings, /epsilon1a ﬁxed thresh-
old, and len ()the length of a binary string. A compression scheme for a given source
S is a pair of functions (ENC, DEC) from the set of ﬁnite binary strings to itself, such
that/D2len(ENC (s))<len(s)on average, and/D2µ(s,DEC (ENC (s)))≤/epsilon1for all sequences.
Ifµ(s,DEC (ENC (s)))=0for all strings, then the compression scheme is lossless.
In the ﬁrst item, we said “on average,” in other words, for most messages sent by
the source. It is important to realize that compression schemes are always coupled
with a source: if the source’s pdf changes, a scheme may become useless.
Which of the two options listed in Deﬁnition 10.3.1 is actually chosen depends
on the problem at hand. For instance, if the sender wants to transmit an image, shemay decide to go for lossy compression, as small detail losses hardly affect the recon-
structed image.
7On the other hand, if she is transmitting or storing, say, the source
code of a program, every single bit may count. Alice here does not have the luxuryto waste bits; she must resort to lossless compression.
8As a rule of thumb, lossy
compression allows you to achieve much greater compression (its requirements areless stringent!), so if you are not concerned with exact reconstruction, that is theobvious way to go.
There is a fundamental connection between Shannon entropy and data compres-
sion. Once again, let us build our intuition by working with the general pdf given inSection 10.1.
Note: We make an assumption throughout this section: the source is indepen-
dently distributed. This simply means that each time Alice sends a fresh new symbol,the probability stays the same and there is no correlation with previous sent symbols.
Alice must transmit one of four symbols. Using the binary alphabet 0 ,1, she can
encode her A,B,C,Dusing log
2(4)=2 bits. Suppose she follows this coding
A0 0
B0 1
C1 0
D1 1(10.54)
How many bits will she send on average per symbol?
2×1
2+2×1
4+2×1
8+2×1
8=2 (10.55)
Doesn’t sound too good, does it? Alice can deﬁnitely do better than that. How?The core idea is quite simple: she will use an encoding that uses fewer bits for
7The extremely popular JPEG and MPEG formats, for images and videos, respectively, are two popular
examples of lossy compression algorithms.
8ZIP is a widely popular application based on the so-called Lempel–Ziv lossless compression algorithm,
generally used to compress text ﬁles.

<<<PAGE 315>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
10.3 Classical and Quantum Data Compression 297
symbols that have a higher probability. After a little thinking, Alice comes up with
this encoding:
A0
B1 1
C 100
D 101(10.56)
Let us now compute the average number of bits per symbol Alice is going to
transmit using this encoding:
1×1
2+2×1
4+3×1
8+3×1
8=1.75. (10.57)
As you have already noticed, this is precisely the value we have found for the en-
tropy of the source.
Exercise 10.3.1 Try to determine the most efﬁcient coding for a four-symbol
source whose pdf looks like
P(A)=1
2,P(B)=1
6,P(C)=1
6,and P(D)=1
6. (10.58)
/squaresolid
What we have just seen is far from accidental: indeed, it represents a concrete
example of a general fact discovered by Shannon, namely, an entropy-related bound
on how good compression can be for a given source.
Theorem 10.3.1 (Shannon’s Noiseless Channel Coding Theorem). Let a source S
emit symbols from an alphabet with a given probability distribution. A message of
length n, with n sufﬁciently large, sent over a noiseless channel can be compressed on
average without loss of information to a minimum of H (S)×n bits.
We shall not provide a formal proof of Shannon’s theorem, only the underlying
heuristics behind it. Imagine for simplicity’s sake that the source transmits only bi-
nary sequences. If the length nof the message is large enough, most sequences will
have a distribution of 0’s and 1’s, which will approximately correspond to their re-
spective probability. These well-behaved sequences are called typical, and all to-
gether they form a subset of all messages, known as the typical set . For instance,
suppose that 1 appears with probability p=1
3and 0 with probability p=2
3. A typi-
cal sequence of length, say, 90, would have exactly 30 bits set to 1.
How many typical sequences are there? It turns out that their number is roughly
given by 2H(S)n. As you can see from Figure 10.3, this is a proper subset of the set of
all sequences of length n(the entire set has 2nelements), as long as H<1.
An ideal compression strategy is then the following:/D2Create a lookup table for all the typical sequences of length n. The key for the
table needs exactly H(S)nbits. This lookup table is shared by Alice and Bob.

<<<PAGE 316>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
298 Information Theory
Figure 10.3. p(0)=1
4,p(1)=3
4,n=12,H (S)=0.81128./D2When a message of length nis sent, Alice sends one bit to inform Bob that the
sequence is typical, and the bits to look up the result. If the sequence is not
typical, Alice sends the bit that says “not typical,” and the original sequence.
For nlarge enough, almost all sequences will be typical or near typical, so the
average number of bits transmitted will get very close to Shannon’s bound.
Exercise 10.3.2 Assume that the source emits 0 with probabilityn0
nand 1 with
probability1−n0
n. Count how many typical sequences of length nare there. (Hint:
Start with some concrete example, setting n=2,3,.... Then generalize.) /squaresolid
Programming Drill 10.3.1 Write a program that accepts a pdf for 0and 1, a given
length n, and produces as output the list of all typical sequences of length n.
Note: Shannon’s theorem does notsay that all sequences will be compressed, only
that what the average compression rate for an optimal compression scheme will be.
Indeed, a universal recipe for lossless compression of all binary sequences does notexist, as you can easily show doing the following exercise.
Exercise 10.3.3 Prove that there is no bijective map ffrom the set of ﬁnite binary
strings to itself such that for each sequence s,length (f(s))<length (s). (Hint: Start
from a generic sequence s
0. Apply fto it. Now iterate. What happens to the series
of sequences {s0,f(s0),f(f(s0)),...}?) /squaresolid
Shannon’s theorem establishes a bound for lossless compression algorithms, but
it does not provide us with one. In some cases, as we have seen in the previous ex-
amples, we can easily ﬁnd the optimal protocol by hand. In most situations though,
we must resort to suboptimal protocols. The most famous and basic one is known
asHuffman’s algorithm .9You may have met it already in an Algorithms and Data
Structures class.
9Huffman’s algorithm is actually optimal, i.e., it reaches Shannon’s bound, but only for special pdfs.

<<<PAGE 317>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
10.3 Classical and Quantum Data Compression 299
Figure 10.4. Alice sending messages to Bob in a four-qubit alphabet.
Programming Drill 10.3.2 Implement Huffman’s algorithm, and then experiment
with it by changing the pdf of the source. For which source types does it perform
poorly?
It is now time to discuss qubit compression. As we already mentioned in the be-
ginning of Section 10.3, Alice is now emitting sequences of qubits with certain fre-quencies to send her messages. More speciﬁcally, assume that Alice draws from a
qubit alphabet {|q
1/angbracketright,...,|qk/angbracketright}ofkdistinct but not necessarily orthogonal qubits,
with frequency p1,..., pk. A typical message of length ncould look like
|q1q1q3...q2/angbracketright; (10.59)
in other words, any such message will be a point of the tensor product C2⊗C2⊗
···⊗ C2=C2n. If you recall Alice’s story, she was sending bits to inform Bob about
her moods, as depicted in Figure 10.4. Alice is sending out streams of particles with
spin.
We would like to know if there are ways for Alice to compress her quantum
messages to shorter qubit strings.
We need to deﬁne ﬁrst what a quantum compressor is, and see if and how the
connection between entropy and compression carries over to the quantum world. To
do so, we must upgrade our vocabulary: whereas in classical data compression wetalk about compression/decompression functions and typical subsets, here we shall
replace them with compression/decompression unitary maps and typical subspaces,
respectively.
Deﬁnition 10.3.2 Ak−nquantum data compression scheme for an assigned quan-
tum source is speciﬁed by a change-of-basis unitary transformation
QC:C
2n−→C2n(10.60)
and its inverse
QC−1:C2n−→C2n. (10.61)
The ﬁdelity of the quantum compressor is deﬁned as follows: consider a mes-
sage from the source of length n, say, |m/angbracketright.L e tP k(QC(|m/angbracketright)be the truncation of
the transformed message to a compressed version consisting of the ﬁrst k qubits
(the length of P k(QC(|m/angbracketright)is therefore k). Now, pad it with n −k zeros, getting
Pi(QC(|m/angbracketright)00...0/angbracketright. The ﬁdelity is the probability
/angbracketleftQC−1(|Pk(QC(|m/angbracketright)00...0/angbracketright)|m/angbracketright|2, (10.62)

<<<PAGE 318>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
300 Information Theory
Figure 10.5. A quantum compression scheme.
i.e., the likelihood that the original message will be perfectly retrieved after the receiver
pads the compressed message, applies the inverse maps and ﬁnally measures it.
In plain words, a quantum compressor is a unitary (and therefore invertible)
map such that most transformed messages have only ksigniﬁcant qubits, i.e.,
they lie almost completely within a k-dimensional subspace known as the typical
subspace.
If Alice owns such a quantum compressor, she and Bob have a well-deﬁned strat-
egy to compress qubit streams (shown in Figure 10.5):
Step 1. She applies the compressor to her message. The result’s amplitudes can
be safely set to zero except for the ones corresponding to the typical subspace. Aftera rearrangement, the amplitudes have been listed so that the ﬁrst kbelong to the
subspace and the other n−kare the ones that are negligible and can be thus set to
zero.
Step 2. Alice truncates her message to the signiﬁcant kqubits, and sends it to
Bob.
Step 3. Bob appends to the received message the missing zeros (padding step),
and
Step 4. Bob changes back the padded message to the original basis.
Step 5. He then measures the message and reads it.
How and where is Alice to ﬁnd her quantum processor? As before, to build up
our intuition, we are going to analyze a concrete example. Let us go back to Example
10.2.2 and use the same setup. Alice’s quantum alphabet consists of the two vectors
|w
1/angbracketrightand|w2/angbracketright, which she sends with frequency1
3and2
3, respectively. A message of
length nwill look like
|ψ1ψ2...ψ n/angbracketright, (10.63)

<<<PAGE 319>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
10.3 Classical and Quantum Data Compression 301
where
|ψi/angbracketright=|w1/angbracketrightor|ψi/angbracketright=|w2/angbracketright. (10.64)
Suppose that Alice, before sending the message, changes basis. Instead of the canon-
ical basis, she chooses the eigenvector basis of the density matrix, i.e., the vectors |e1/angbracketright
and|e2/angbracketrightthat we explicitly computed in Example 10 .2.4.
Alice’s message can be described in this basis as
c1|e1e1...e1/angbracketright+c2|e1e1...e2/angbracketright+···+ c2n|e2e2...e2/angbracketright. (10.65)
What is the beneﬁt of this change of basis? As a vector, the message is still a point
inC2n, and so its length has not changed. However, something quite interesting is
happening here. We are going to ﬁnd out that quite a few of the ci’s are indeed so
small that they can be discarded. Let us calculate ﬁrst the projections of |w1/angbracketrightand
|w2/angbracketrightalong the eigenvectors e1ande2:
|/angbracketlefte1|w1/angbracketright| = 0.255,|/angbracketlefte1|w2/angbracketright| = 0.229,|/angbracketlefte2|w1/angbracketright| = 0.850, and|/angbracketlefte2|w2/angbracketright| = 0.973.
(10.66)
We have just discovered that the projection of either |w1/angbracketrightor|w2/angbracketrightalong|e1/angbracketrightis smaller
than their components along |e2/angbracketright.
Using the projections of Equation (10.71), we can now calculate the components
ciin the eigenbasis decomposition of a generic message. For instance, the message
|w1w1w1w1w1w1w1w1w1w2w2/angbracketrighthas the component along |e1e1e1e1e1e1e1e1e1e1e1e1/angbracketright
equal to
|c1|=(|/angbracketlefte1|w1/angbracketright|8(|/angbracketlefte1|w2/angbracketright|2=9.37∗10−7. (10.67)
Exercise 10.3.4 Assume the same setup as the previous one, and consider the mes-
sage|v1/angbracketright|v1/angbracketright|v1/angbracketright|v1/angbracketright|v2/angbracketright|v1/angbracketright|v1/angbracketright|v1/angbracketright|v1/angbracketright|v2/angbracketright. What is the value of the component along
|e2/angbracketright|e2/angbracketright|e2/angbracketright|e1/angbracketright|e1/angbracketright|e2/angbracketright|e2/angbracketright|e2/angbracketright|e1/angbracketright|e1/angbracketright? /squaresolid
Many of the coefﬁcients ciare dispensable, as we anticipated (see Figure 10.6.)
The signiﬁcant coefﬁcients turn out to be the ones that are associated with typ-
ical sequences of eigenvectors, i.e., sequences whose relative proportions of |e1/angbracketright
and|e2/angbracketrightare consistent with their probabilities, calculated in Equations (10 .54) and
(10.55). The set of all these typical sequences spans a subspace of C2n, the typical sub-
space we were looking for. Its dimension is given by 2N×H(S), where H(S) is the von
Neumann entropy of the source. Alice and Bob now have a strategy for compress-ing and decompressing qubit sequences, following the recipe sketched earlier in
Steps 1–5.
We have just shown a speciﬁc example. However, what Alice found out can be
generalized and formally proved, leading to the quantum analog of Shannon’s cod-
ing theorem, due to Benjamin Schumacher (1995b).
Theorem 10.3.2 (Schumacher’s Quantum Coding Theorem.) A qubit stream of
length n emitted from a given quantum source QS of known density can be com-
pressed on average to a qubit stream of length n ×H(QS), where H (QS)is the von
Neumann entropy of the source. The ﬁdelity approaches one as n goes to inﬁnity.

<<<PAGE 320>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
302 Information Theory
Figure 10.6. Source as in Example 10.2.2: p(|w 1/angbracketright)=1
3,p (|w 2/angbracketright)=2
3,n=12,
H(S)=0.54999.
Note: In a sense, the bound n×H(QS) represents the best we can do with quantum
sources. This theorem is particularly exciting in light of what we have seen at the
end of the last section, namely, that von Neumann entropy can be lower than clas-sical entropy. This means that, at least in principle, quantum compression schemescan be designed that compress quantum information in a tighter way than classical
information can be in the classical world.
However, this magic comes at a price: whereas in the classical arena one can cre-
ate purely lossless data compression schemes, this is not necessarily so in the quan-tum domain. Indeed, if Alice chooses her quantum alphabet as a set of nonorthogo-
nal states, there is no measurement on Bob’s side whose eigenvectors are preciselyAlice’s “quantum letters.” This means that perfect reconstruction of the message
cannot be ensured. There is a trade-off here: the quantum world is deﬁnitely more
spacious than our own macroscopic world, thereby allowing for new compressionschemes, but at the same time it is also fuzzy, carrying an unavoidable element ofintrinsic indeterminacy that cannot be ignored.
Programming Drill 10.3.3 Write a program that lets the user enter two qubits and
their corresponding probabilities. Then calculate the density matrix, diagonalize it,
and store the corresponding eigenbasis. The user will then enter a quantum message.
The program will write the message in the eigenbasis and return the truncated part
belonging to the typical subspace.
10.4 ERROR-CORRECTING CODES
There is yet another aspect of information theory that cannot be ignored. Informa-tion is always sent or stored through some physical medium. In either case, randomerrors may happen: our valuable data can degrade over time.
Errors occur with classical data, but the problem is even more serious in the
quantum domain: as we shall see in Chapter 11, a new phenomenon known as

<<<PAGE 321>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
10.4 Error-Correcting Codes 303
decoherence makes this issue absolutely critical for the very existence of a reliable
quantum computer.
As a way to mitigate this unpleasant state of affairs, information theory re-
searchers have developed a large variety of techniques to detect errors, as well as
tocorrect them. In this last section we brieﬂy showcase one of these techniques,
both in its classical version and in its quantum version.
As we have just said, our enemy here is random errors. By their very deﬁnition,
they are unpredictable. However, frequently we can anticipate which types of errors
our physical devices are subjected to. This is important: by means of this knowledge
we can often elaborate adequate defense strategies.
Suppose you send a single bit, and you expect a bit ﬂip error 25% of the time.
What would you do? A valid trick is simply repetition. Let us thus introduce anelementary repetition code :
0 000
1 111(10.68)
We have simply repeated a bit three times. One can decode the triplet by majority
law: if at least two of the qubits are zeros, it is zero; else, it is one.
Exercise 10.4.1 What is the probability of incorrectly decoding one bit? /squaresolid
Now, let us move on to qubit messages. Qubits are less “rigid” than bits, so new
types of errors can occur: for instance, aside qubit-ﬂips
α|0/angbracketright+β|1/angbracketright /mapsto−→ β|0/angbracketright+α|1/angbracketright (10.69)
signs can be ﬂipped too:
α|0/angbracketright+β|1/angbracketright /mapsto−→ α|0/angbracketright−β|1/angbracketright. (10.70)
Exercise 10.4.2 Go back to Chapter 5 and review the Block sphere representation
of qubits. What is the geometric interpretation of sign ﬂip? /squaresolid
To be sure, when dealing with qubits other types of errors can occur, not just
“jumpy” errors (i.e., discrete ones). For instance, either αorβcould change by a
small amount. For example, αmight have a change of phase by 15◦. For the sake of
simplicity though, we shall only envision bit and sign ﬂips.
If we are looking for the quantum analog of the repetition code given in Equa-
tion (10.68), we must make sure that we can detect both types of errors. There is a
code that does the job, due to Peter W. Shor (1995), known as the 9-qubit code10:
|0/angbracketright (|000/angbracketright+| 111/angbracketright)⊗(|000/angbracketright+| 111/angbracketright)⊗(|000/angbracketright+| 111/angbracketright)
|1/angbracketright (|000/angbracketright−| 111/angbracketright)⊗(|000/angbracketright−| 111/angbracketright)⊗(|000/angbracketright−| 111/angbracketright)(10.71)
109-qubit code is the ﬁrst known quantum code.

<<<PAGE 322>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
304 Information Theory
Why nine qubits? 3 ×3=9: by employing the majority rule twice, once for qubit
ﬂip and once for sign, we can correct both.
Exercise 10.4.3 Suppose that a sign ﬂip occurs 25% of the times, and a single qubit
ﬂip 10% of the times. Also suppose that these two errors are independent of each
other. What is the likelihood that we incorrectly decode the original qubit? /squaresolid
We have barely scraped the tip of an iceberg. Quantum error-correction is a
ﬂourishing area of quantum computing, and a number of interesting results havealready emerged. If, as we hope, this small section has whetted your appetite, youcan look into the references and continue your journey beyond the basics.
.................................................................................
References: The ﬁrst formulation of the basic laws of information theory is con-
tained in the seminal (and readable!) paper “The mathematical theory of communi-
cation” written by Claude Shannon (Shannon, 1948). This paper is freely available
online. A good reference for information theory and Shannon’s theorem is Ash(1990).
Huffman’s algorithm can be found, e.g., on pages 385–393 of Corman et al.
(2001).
An excellent all-round reference on data compression is the text by Sayood
(2005). For Schumacher’s theorem, take a look at the PowerPoint presentation by
Nielsen.
Finally, Knill et al. (2002) is a panoramic survey of quantum error-correction.

<<<PAGE 323>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
11
Hardware
The machine does not isolate man from the great problems
of nature, but plunges him more deeply into them.
Antoine de Saint Exupery, Wind, Sand, and Stars
In this chapter, we discuss a few hardware issues and proposals. Most certainly you
have wondered (perhaps more than once!) whether all we have presented up to now
is nothing more than elegant speculation, with no practical impact for the real world.
To bring things down to earth, we must address a very basic question: do we
actually know how to build a quantum computer ?
It turns out that the implementation of quantum computing machines repre-
sents a formidable challenge to the communities of engineers and applied physicists.However, there is some hope in sight: quite recently, some simple quantum devices
consisting of a few qubits have been successfully built and tested. Considering the
amount of resources that have been poured into this endeavor from different quar-ters (academia, private sector, and the military), it would not be entirely surprising
if noticeable progress were made in the near future.
In Section 11.1 we spell out the hurdles that stand in the way, chieﬂy related
to the quantum phenomenon known as decoherence. We also enumerate the wish
list of desirable features for a quantum device. Sections 11.2 and 11.3 are devoted
to describing two of the major proposals around: the ion trap and optical quantum
computers. The last section mentions two other proposals, and lists some milestonesthat have been achieved so far. We conclude with some musings on the future of
quantum ware.
A small disclaimer is in order. Quantum hardware is an area of research that
requires, by its very nature, a deep background in quantum physics and quantumengineering, way beyond the level we have asked of our reader. The presentation
will have perforce a rather elementary character. Refer to the bibliography for moreadvanced references.
Note to the Reader: We would have loved to assign exercises such as “build
a quantum microcontroller for your robot,” or “assemble a network of quantum
305

<<<PAGE 324>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
306 Hardware
Figure 11.1. A PC that is uncoupled from the environment.
chips,” or something along these lines. Alas, we cannot. Nor, without violating the
aforementioned disclaimer, could we ask you to carry out sophisticated calculations
concerning modulations of electromagnetic ﬁelds, or similar matters. Thus, there areonly few exercises scattered in this chapter (do not skip them though: your effort will
be rewarded).
11.1 QUANTUM HARDWARE: GOALS AND CHALLENGES
In Chapter 6 we described the generic architecture of a quantum computing device:
we need a number of addressable qubits, the capability of initializing them properly,applying a sequence of unitary transformation to them, and ﬁnally measuring them.
Initialization of a quantum computer is similar to initialization of a classical one:
at the beginning of our computation, we set the machine in a well-deﬁned state.
It is absolutely crucial that the machine stay in the state we have put it in, till we
modify it in a controlled way by means of known computational steps. For a classical
computer, this is in principle quite easy to do
1: a classical computer can be thought of
as an isolated system . Inﬂuences from the environment can theoretically be reduced
to zero. You might keep Figure 11.1 in mind.
The case of a quantum computer is rather different. As we have already seen,
one of the core features of quantum mechanics is entanglement: if a system Sis com-
posed of two subsystems S1and S2, their states may become entangled. In practice,
this means that we cannot ignore what happens to S2if we are interested in the way
S1evolves (and vice versa). Moreover, this odd phenomenon happens regardless of
how physically separated the two subsystems actually are. How is this relevant to
the task of building a quantum computer? The machine and its environment be-
come entangled, preventing the evolution of the state of the quantum register fromdepending exclusively on which gates are applied to it. To ﬁx our ideas, let us sup-
pose that the quantum register in our device is a sequence of 1,000 electrons, qubits
being encoded as their spin state. In this scenario, initialization means setting all theelectrons to some deﬁned spin state, as in Figure 11.2. For instance, they could be
all in spin up, or all in spin down. The key point is that we need to control the global
state of the register. In physics jargon, a well-deﬁned state is known as pure state,a s
inFigure 11.2.
1In reality, of course, classical machines are also prone to errors.

<<<PAGE 325>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
11.1 Quantum Hardware: Goals and Challenges 307
Figure 11.2. An uncoupled register initialized to spin up.
When we take our register out of isolation, these electrons tend to couple with
the billions of other electrons in the environment, shifting to some superposition of
spin up and spin down, as in Figure 11.3.
The problem here lies in that we have absolutely no idea about the precise initial
state of the environment’s electrons, nor do we know the details of their interactionwith the electrons in the quantum register. After a while, the global state of the
register is no longer pure; rather, it has become a probabilistic mix of pure states,or what is known in quantum jargon as a mixed state.
2Pure states and mixed states
have a different status in quantum mechanics. There is always a speciﬁc measurement
that invariably returns true on a pure state . Instead, there is no such thing for mixed
states, as shown by the following exercise.
Exercise 11.1.1 Consider the pure state |ψ/angbracketright=|0/angbracketright+|1/angbracketright√
2, and the mixed state obtained
by tossing a coin and setting it equal to |0/angbracketrightif the result is heads, or |1/angbracketrightif the result
is tails.3Devise an experiment that discriminates between these two states. Hint:
What would happen if we measured the qubit in the following basis?
/braceleftbigg|0/angbracketright+| 1/angbracketright√
2,|0/angbracketright−| 1/angbracketright√
2/bracerightbigg
(11.1)
/squaresolid
Where precisely lies the difference between pure and mixed states?
Consider the following family of spin states:
|ψθ/angbracketright=|0/angbracketright+ exp( iθ)|1/angbracketright√
2. (11.2)
For every choice of the angle θ, there is a distinct pure state. Each of these states is
characterized by a speciﬁc relative phase, i.e., by the difference between the angles
of the components of |0/angbracketrightand|1/angbracketrightin the polar representation.4How can we physically
detect their difference? A measurement in the standard basis would not do (theprobabilities with respect to this basis haven’t been affected). However, a change
2The density matrix, which we introduced in Section 10.2 in order to talk about entropy, is also thefundamental tool for studying mixed states. Indeed, a single pure quantum state |ψ/angbracketrightis associated with
the special form of the density operator |ψ/angbracketright/angbracketleftψ|, whereas an arbitrary mixed state can be represented
by a generic density operator.
3For the readers of Section 10.2: the mixed state is represented by the density matrix|0/angbracketright/angbracketleft0|+|1/angbracketright/angbracketleft1|√
2.
4It is only this relative phase that has some physical impact, as we are going to see in a minute. Indeed,multiplying both components by exp( iθ) would simply rotate them by the same angle and generate an
entirely equivalent physical state, as we pointed out in Section 4.1.

<<<PAGE 326>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
308 Hardware
Figure 11.3. The qubits decohered as a result of coupling with the environment.
of basis will do. Observe |ψθ/angbracketrightalong the xaxis, and compute the average spin value
along this direction5:/angbracketleftψθ|Sx|ψθ/angbracketright. As you can verify for yourself in the next exercise,
the average depends on θ!
Exercise 11.1.2 Calculate /angbracketleftψθ|Sx|ψθ/angbracketright. For which value of θis the average maxi-
mum? /squaresolid
If you now consider the mixed state of the last exercise, namely the one you get
by tossing a coin and deciding for either |0/angbracketrightor|1/angbracketright, the relative phase and its con-
comitant information is lost. It is precisely the lack of relative phase that separates
pure states and mixed ones. One way states change from pure to mixed is through
uncontrollable interaction with the environment.
Deﬁnition 11.1.1 The loss of purity of the state of a quantum system as the result of
entanglement with the environment is known as decoherence.
We are not going to provide a full account of decoherence6.However, it is well
worth sketching how it works, as it is our formidable challenger in the path to real-
life quantum computation (the Art of War states: “know thy enemy!”).
In all our descriptions of quantum systems, we have implicitly assumed that they
are isolated from their environment. To be sure, they can interact with the exter-nal world. For instance, an electron can be affected by an electromagnetic ﬁeld,but the interaction is, as it were, under control. The evolution of the system is de-
scribed by its hamiltonian (see Section 4.3), which may include components account-
ing for external inﬂuences. Therefore, as long as we know the hamiltonian and the
5The formula for the average as well as the hermitian Sxwere described in Section 4.2.
6Decoherence has been known since the early days of quantum mechanics. However, in recent times ithas received a great deal of attention, not only in relation to quantum computing, but as a formidabletool for understanding how our familiar classical world emerges out of the uncanny quantum world.How come we do not normally see interference when dealing with macroscopic objects? An answer isprovided by decoherence: large objects tend to decohere very fast, thereby losing their quantum fea-tures. An intriguing survey of decoherence as a way of accounting for classical behavior of macroscopicobjects is Zurek (2003).

<<<PAGE 327>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
11.1 Quantum Hardware: Goals and Challenges 309
initial state, it is totally predictable. Under such circumstances, the system will al-
ways evolve from pure states to other pure states. The only unpredictable factor is
measurement. Summing up: we always implictly assumed that we knew exactly how
the environment affects the quantum system .
Let us now turn to a more realistic scenario: our system, say, a single electron
spin, is immersed in a vast environment. Can we model this extended system? Yes,we can, by thinking of the environment as a huge quantum system, assembled out
of its components.
To understand what happens, let us start small. Instead of looking at the entire
environment, we shall restrict ourselves to interactions with a single external elec-
tron. Let us go back to our electron of a moment ago, and let us assume that it hasbecome entangled with another electron to form the global state
|ψ
global/angbracketright=|00/angbracketright+exp( iθ)|11/angbracketright√
2. (11.3)
Now, let us only measure the spin of our electron in the xdirection, just as we have
done before. This step corresponds to the observable Sx⊗I, i.e., the tensor of Sx
with the identity on the second electron: we must therefore compute
/angbracketleftψglobal|(Sx⊗I)|ψ global/angbracketright. (11.4)
Let us do it. In matrix notation (written in the standard basis),
|ψglobal/angbracketright=1√
2[1,0,0,exp( iθ)]T(11.5)
and (we are ignoring here the constant factor/planckover2pi
2)
Sx⊗I=⎡
⎢⎣01
10⎤
⎥⎦⊗⎡
⎢⎣10
01⎤
⎥⎦; (11.6)
thus we are simply evaluating
/bracketleftbigg1√
2,0,0,exp(− iθ)1√
2/bracketrightbigg⎡
⎢⎢⎢⎢⎢⎢⎢⎣0010
000110000100⎤
⎥⎥⎥⎥⎥⎥⎥⎦/bracketleftbigg1
√
2,0,0,exp( iθ)1√
2/bracketrightbiggT
=0.
(11.7)
The net result of our calculation is that the phase is apparently gone: there is no a
trace of θin the average value! We say this – apparently – for a reason: the phase
is simply hiding behind the curtain afforded by entanglement. To “smoke the phase
out,” we have to perform a measurement on both electrons. How? We simply com-
pute the average of Sx⊗Sxon|ψglobal/angbracketright. The value now does indeed depend on θ,a s
you can check in the following exercise:
Exercise 11.1.3 Compute /angbracketleftψglobal|Sx⊗Sx|ψglobal/angbracketright. /squaresolid

<<<PAGE 328>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
310 Hardware
It is time to wrap up what we have learned. We were able to recover the pre-
cious phase information only after measuring the second electron. Now, imagine our
electron interacting with a great many peers from the environment, in an unknown
manner. If we could track them all down, and measure their respective states, justlike we have done above, there would be no issue. Alas, we cannot: our phase is irre-trievably lost, turning our pure state into a mixed one. Note that decoherence does
not cause any real collapse of the state vector. The information is still out there,
marooned, as it were, in the vast quantum ocean.
Decoherence presents us with a two-pronged challenge:/D2On the one hand, adopting basic quantum systems that are very prone to “hookup” with the environment (electrons are a very good example, as they tend to
interact with other peers in their vicinity) makes it quite difﬁcult to manage the
state of our machine./D2On the other hand, we doneed to interact with the quantum device after all,
to initialize it, apply gates, and so on. We are part of the environment. A quan-tum system that tends to stay aloof (photons are the primary example) makes itdifﬁcult to access its state.
How serious is the challenge afforded by decoherence? How quick are its ef-
fects? The answer varies, depending on the implementation one chooses (for in-
stance, for single-ion qubits, as described in the next section, it is a matter of sec-
onds). But it is serious enough to raise major concerns. You can read a leisurelyaccount in the sprightly Scientiﬁc American article “Quantum Bug” by Graham P.
Collins.
How can we even hope to build a reliable quantum computing device if decoher-
ence is such a big part of quantum life? It sounds like a Catch-22, doesn’t it? Thereare, however, two main answers:/D2A possible way out is fast gates execution : one tries to make decoherence sufﬁ-
ciently slow in comparison to our control, so that one has time to safely applyquantum gates ﬁrst. By striving to beat Nature in the speed race, at least on veryshort runs, we can still hope to get meaningful results./D2The other strategy is fault-tolerance . How can one practically achieve fault-
tolerance? In Section 10.4, we have brieﬂy sketched the topic of quantum error-correcting codes. The rationale is that using a certain redundancy, we can thwartat least some types of errors. Also, another possible strategy under the redun-
dancy umbrella is repeating a calculation enough times, so that random errors
cancel each other out.
7
We conclude this section with an important wish list for candidate quantum com-
puters that has been formulated by David P. DiVincenzo of IBM.
DiVincenzo’s Wish List/D2The quantum machine must have a sufﬁciently large number of individually ad-
dressable qubits.
7Caveat: one cannot repeat too many times, else the beneﬁts of quantum parallelism will get totally
eroded!

<<<PAGE 329>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
11.2 Implementing a Quantum Computer I: Ion Traps 311/D2It must be possible to initialize all the qubits to the zero state, i.e., |00···000/angbracketright./D2The error rate in doing computations should be reasonably low, i.e., decoherence
time must be substantially longer than gate operation time./D2We should be able to perform elementary logical operations between pairs of
qubits./D2Finally, we should be able to reliably read out the results of measurements.
These ﬁve points spell out the challenge that every prospective implementation
of a quantum computing device must meet. We are now going to see a few of theproposals that have emerged in the last ten odd years.
11.2 IMPLEMENTING A QUANTUM COMPUTER I: ION TRAPS
Before we start discussing concrete implementations, let us remind ourselves that aqubit is a state vector in a two-dimensional Hilbert space. Therefore, any physical
quantum system whose state space has dimension 2
Ncan, at least in principle, be
used to store an addressable sequence of Nqubits (a q-register, in the notation of
Chapter 7).
What are the options?
Generally, the standard strategy is to look for quantum systems with a two-
dimensional state space. One can then implement q-registers by assembling a num-ber of copies of such systems. The canonical two-dimensional quantum systems are
particles with spin. Electrons, as well as single atoms, have spin. There is thus plenty
of room in nature for encoding qubits. Spin is not the only one: another naturalchoice is excited states of atoms, as we are going to see in a moment.
Let us ﬁrst sumnmarize all the steps we need:/D2Initialize all particles to some well-deﬁned state./D2Perform controlled qubit rotations on a single particle (this step will implementa single-qubit gate)./D2Be able to mix the states of two particles (this step aims at implementing a uni-
versal two-qubit gate)./D2Measure the state of each individual particle./D2Keep the system of particles making up our q-register as insulated as possiblefrom the environment, at least for the short period of time when quantum gates
are applied.
The ﬁrst proposal for quantum hardware is known as the ion trap. It is the oldest
one, going back to the mid-nineties, and it is still the most popular candidate forquantum hardware.
8
The core idea is simple: as you may recall from your chemistry classes, an ion
is an electrically charged atom. Ions can be of two types: they are either positiveion, or cations , having lost one or more electrons. Or they are negative ions, or
anions , having acquired some electrons. Ionized atoms can be acted upon by means
8The ﬁrst quantum gate, the controlled-NOT, was experimentally realized with trapped ions by C.Monroe and D. Wineland in 1995. They followed a proposal by Cirac and Zoller put forward a yearearlier.

<<<PAGE 330>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
312 Hardware
Figure 11.4. A ni o ni nat r a p .
of an electromagnetic ﬁeld, as they are electrically charged; more precisely, we can
conﬁne our ionized atom in a speciﬁc volume, known as ion trap (Figure 11.4).
In practice, experiments have been conducted with positive ions of calcium: Ca+.
First, the metal is brought to its gaseous state. Next, the single atoms are stripped ofsome of their electrons, and third, by means of a suitable electromagnetic ﬁeld, theresulting ions are conﬁned to the trap.
How are qubits encoded? An atom can be in a excited state or in a ground state
(Figure 11.5).
These two states represent two energy levels of the atom and they form an or-
thogonal basis for a two-dimensional Hilbert space. As we have seen in Chapter 4(photoelectric effect), if we pump energy into an atom that is in ground state bymaking it absorb a photon, it will raise to its excited state. Conversely, the atom canlose its energy by emitting a photon. This process is known as optical pumping and
it is performed using a laser, i.e., a coherent beam of light. The reason for using alaser is that it has an extremely high resolution, allowing the operator to “hit” singleions and thereby achieving a good control of the quantum register. Through opti-
cal pumping we can initialize our register to some initial state with a high degree of
ﬁdelity (almost 100%).
Next, we need to manipulate the register. As we mentioned in Section 7.2, there
is a considerable degree of freedom in quantum computing when it comes to whichparticular set of gates is implemented, as long as the set is complete. The particularchoice depends on the hardware architecture: one chooses gates that are easy toimplement and provide a good degree of ﬁdelity. In the ion trap model, the usual
choice is as follows:/D2Single-qubit rotation: By “hitting” the single ion with a laser pulse of a givenamplitude, frequency, and duration, one can rotate its state appropriately./D2Two-qubit gates: The ions in the trap are, in a sense, strung together by what
is known as their common vibrational modes. Again, using a laser one can af-
fect their common mode, achieving the desired entanglement (see the paper
Figure 11.5. Ground and excited states.

<<<PAGE 331>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
11.3 Implementing a Quantum Computer II: Linear Optics 313
by Holzscheiter for details). The original choice for a two-qubit gate was the
controlled-NOT gate, which was proposed in 1995 by Cirac and Zoller (1995).
Recently, several other more reliable schemes have been implemented.
The last step is measurement. Essentially, the same mechanism we use for setting
the qubits can be employed for readouts. How? Aside from the two main long-lived
states|0/angbracketrightand|1/angbracketright(ground and excited), the ion can enter a short-lived state, let us
call it|s/angbracketright(“s” is for short), when gently hit by a pulse. Think of |s/angbracketrighta ss i t t i n gi nt h e
middle between the other two. If the ion is in the ground state and gets pushed to|s/angbracketrightit will revert to ground and emit a photon. On the other hand, if it is in an the
excited state, it will not. By repeating the transition many times, we can detect the
photons emitted (if any) and thus establish where the qubit is.
To conclude this section, let us list the main strengths and weaknesses of the ion
trap model:/D2On the plus side, this mode has long coherence time, in the order of 1–10 sec-
onds. Secondly, the measurements are quite reliable, very close to 100%. Finally,
one can transport qubits around in the computer, which is a nice feature to have(remember, no copying allowed, so moving things around is good)./D2On the minus side, the ion trap is slow, in terms of gate time (slow here means
that it takes tens of milliseconds). Secondly, it is not apparent how to scale the
optical part to thousands of qubits.
11.3 IMPLEMENTING A QUANTUM COMPUTER II: LINEAR OPTICS
The second implementation of a quantum machine we are going to consider is linear
optics . Here, one builds a quantum machine out of sheer light!
To build a quantum computer, the very ﬁrst step is to clearly state how we are
going to implement qubits. Now, as we said in Section 5.1, every quantum systemthat has dimension 2 is, in principle, a valid candidate. Quanta of light, alias photons,
are good enough, thanks to the physical phenomenon known as polarization (see
Section 4.3). We have all seen polarization at work: a beam of light passes through a
polarization ﬁlter, and the result is a coherent beam of light, i.e., an electromagnetic
wave that vibrates along a speciﬁc plane.
As photon can be polarized, one can stipulate how qubits are implemented: a
certain polarization axis, say vertical polarization, will model |0/angbracketright, whereas |1/angbracketrightwill be
represented by horizontal polarization.
So much for qubits. Initialization here is straightforward: a suitable polarization
ﬁlter will do. Gates are less trivial, particularly entanglement gates, as photons have
a tendency to stay aloof. It therefore pays to be on the economical side, i.e., to
implement some small universal set of quantum gates. We have met the controlled-
NOT gate in Chapter 5. If one were to follow the simple-minded route, controlled-NOT would require a two-photon interaction. This happens very seldom, and makes
this venue quite impractical. But, as it often happens, there is a way around.
To create controlled-NOT, we need control and target inputs and we need more
optical tools. Speciﬁcally, we need mirrors, polarizing beam splitters, additional
ancillary photons, and single-photon detectors. This approach is known as linear
optics quantum computing ,o r LOQC , as it uses only linear optics principles and

<<<PAGE 332>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
314 Hardware
Figure 11.6. Basic idea of LOQC-based controlled-NOT gate.
methodologies. In LOQC, the nonlinearity of measurements arises from the detec-
tion of additional, ancillary photons. Figure 11.6 is a schematic picture of a LOQC
controlled-NOT gate (details can be found in Pittman, Jacobs, and Franson (2004).
Measurement of the ﬁnal output presents no difﬁculties. A combination of po-
larization ﬁlters and single-photon detectors will do.
Before we quit this section let us point out strengths and weaknesses of the op-
tical scheme:/D2On the plus side, light travels . This means that quantum gates and quantum
memory devices can be easily connected via optical ﬁbers. In other approaches,
like the ion trap, this step can be a quite complex process. This plus is indeed a
big one, as it creates a great milieu for distributed quantum computing./D2On the minus side, unlike electrons and other matter particles, it is not easy for
photons to become entangled. This is actually a plus, as it prevents entanglement
with its environment (decoherence), but it also makes gate creation a bit more
challenging.

<<<PAGE 333>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
11.4 Implementing a Quantum Computer III: NMR and Superconductors 315
11.4 IMPLEMENTING A QUANTUM COMPUTER III: NMR AND
SUPERCONDUCTORS
Aside the two models described in the last sections, there are currently several other
proposals under investigation, and more may emerge soon. We mention in passing
two others that have received a lot of attention in the last years.
Nuclear Magnetic Resonance (NMR). The idea here is to encode qubits not as
single particles or atoms, but as global spin states of many molecules in some ﬂuid.These molecules ﬂoat in a cup, which is placed in an NMR machine, quite akin to
the devices used in hospitals for magnetic resonance imaging. This large ensemble ofmolecules has plenty of built-in redundancy, which allows it to maintain coherencefor a relatively long time span (several seconds).
The ﬁrst two-qubit NMR computers were demonstrated in 1998 by J.A. Jones
and M. Mosca at Oxford University and at the same time by Isaac L. Chuang atIBM’s Almaden Research Center, together with coworkers at Stanford University
and MIT. Berggren quoted in the references.
Superconductor Quantum Computers (SQP). Whereas NMR uses ﬂuids, SQP
employs superconductors.
9How? By means of Josephson junctions – thin layers of
nonconducting material sandwiched between two pieces of superconducting metal.
At very low temperatures, electrons within a superconductor become, as they were,friends, and pair up to form a “superﬂuid” ﬂowing with no resistance and travelingthrough the medium as a single, uniform wave pattern. This wave leaks into the
insulating middle. The current ﬂows back and forth through the junction much like
a ping-pong ball, in a rhythmic fashion.
How are qubits implemented? Through what is now known as the Josephson
junction qubit. In this implementation, the |0/angbracketrightand|1/angbracketrightstates are represented by the
two lowest-frequency oscillations of the currents ﬂowing back and forth throughthe junction. The frequency of these oscillations is very high, being of the order of
billions of times per second.
Where are we now?
In 2001 the ﬁrst execution of Shor’s algorithm was carried out at IBM’s Almaden
Research Center and Stanford University. They factored the number 15: not an
impressive number by any means, but a deﬁnite start! (By the way, the answer was
15=5∗3.)
In 2005, using NMR, a 12-qubit quantum register was benchmarked. So far at
least, scalability seems to be a major hurdle. Progress has been made almost a qubitat a time, in the last few years. On the positive side, new proposals and methodolo-gies crop up in a continuous stream.
If you wish to know more about recent news in quantum hardware research,
probably the best course is to take a look at the NIST Road Map. NIST, the US
National Institute of Science and Technology , a major force in the ongoing effort
to implement quantum computing machines, has recently released a comprehensive
road map listing all major directions toward quantum hardware, as well as compar-
ison tables pointing at weaknesses and strengths of each individual approach. Youcan download it at NIST Web site: http: //qist.lanl.gov/qcomp
map.shtml.
9A superconductor is matter at very low temperature, exhibiting so-called superconductivity properties.

<<<PAGE 334>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
316 Hardware
As you can imagine from this brief survey, people are pretty busy at the moment,
trying to make the magic quantum work.
It is worth mentioning that as of the time of this writing (late 2007), there are
already three companies whose main business is developing quantum computing
technologies: D-Wave Systems, MagicQ, and Id Quantique. Recently (February13, 2007), D-Wave has publicly demonstrated a prototypical quantum computer,
known as Orion, at the Historical Museum in Mountain View, CA. Orion was ap-
parently able to play the popular Sudoku game. D-Wave’s announcement has gen-erated some expected and healthy skepticism among academic researchers.
11.5 FUTURE OF QUANTUM WARE
At last, the future. The great physicist Niels Bohr, a major protagonist in the devel-opment of quantum mechanics, had a great punch line: “Prediction is always hard,especially of the future.”
10
We could not agree more. What we think is safe to say is that there is a reason-
able likelihood that quantum computing may become a reality in the future, perhapseven in the relatively near future. If that happens, it is also quite likely that manyareas of information technology will be affected. Certainly, the ﬁrst thought goes to
communication and cryptography. These areas are noticeably ahead, in that some
concrete quantum encryption systems have been implemented and tested.
Assuming that sizeable quantum devices will be available at some point in time,
there is yet another important area of computer science where one can reasonablyexpect some impact of quantum computation, namely, artiﬁcial intelligence. It hasbeen suggested in some quarters that the phenomenon of consciousness has somelinks with the quantum (see, for instance, the tantalizing paper by Paola Zizzi or
either of these two books by Sir Roger Penrose, 1994, 1999). Some people even go
as far as saying that our brain may be better modeled as an immense quantum com-puting network than are traditional neural networks (although this opinion is not
shared by most contemporary neuroscientists and cognitive scientists). Be that as
it may, a new area of research has already been spawned that merges traditionalartiﬁcial intelligence with quantum computing. The interaction happens both ways:
for instance, artiﬁcial intelligence methodologies such as genetic algorithms have
been proposed as a way to design quantum algorithms. Essentially, genes encodecandidate circuits and selection and mutation do the rest. This is an important di-rection, as for now our understanding of quantum algorithm design is still rather
limited. On the other hand, quantum computing suggests new tools for artiﬁcial
intelligence. A typical example is quantum neural networks. Here, the idea is toreplace activation maps with complex valued ones, akin to what we have seen in
Section 3.3.
Beyond these relatively tame predictions, there is the vast expanse of science
ﬁction out there. Interestingly, quantum computing has already percolated into sci-ence ﬁction (the nextQuant blog maintains a current list of science ﬁction works with
quantum computing themes). For instance, the well-known science ﬁction writerGreg Egan has written a new book called Schild’s Ladder (Egan, 2002), in which he
10The same line is sometimes attributed to Yogi Berra.

<<<PAGE 335>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
11.5 Future of Quantum Ware 317
speculates about the role of quantum computing devices in the far future to enhance
mind capabilities. True? False?
All too often, the dreams of today are the reality of tomorrow.
.................................................................................
References: Literature in the topics covered by this chapter abounds, although it
is a bit difﬁcult for nonexperts to keep track of it. Here are just a few useful pointers:
For decoherence, Wojciech H. Zurek has an excellent readable paper: Zurek
(2003).
David P. DiVincenzo’s rules can be found in DiVincenzo.The ion trap model is discussed in a number of places. A good general reference
is the paper by M. Holzscheiter.
Optical computers are clearly and elegantly presented in a paper by Pittman,
Jacobs, and Franson (2004).
For NMR computing, see Vandersypen et al. (2001).
An article by Karl Berggren (2004) provides a good introduction to supercon-
ductor quantum computing.

<<<PAGE 336>>>



<<<PAGE 337>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix A
Historical Bibliography of Quantum
Computing
Jill Cirasella
This bibliographic essay reviews seminal papers in quantum computing. Although
quantum computing is a young science, its researchers have already published thou-sands of noteworthy articles, far too many to list here. Therefore, this appendixis not a comprehensive chronicle of the emergence and evolution of the ﬁeld but
rather a guided tour of some of the papers that spurred, formalized, and furthered
its study.
Quantum computing draws on advanced ideas from computer science, physics,
and mathematics, and most major papers were written by researchers conversantin all three ﬁelds. Nevertheless, all the articles described in this appendix can beappreciated by computer scientists.
A.1 READING SCIENTIFIC ARTICLES
Do not be deterred if an article seems impenetrable. Keep in mind that profes-sors and professionals also struggle to understand these articles, and take com-
fort in this epigram usually attributed to the great physicist Richard Feynman:
“If you think you understand quantum mechanics, you don’t understand quantummechanics.”
Some articles are difﬁcult to understand not only because quantum theory is
devilishly elusive but also because scientiﬁc writing can be opaque. Fortunately,there are techniques for tackling scientiﬁc articles, beginning with these preliminarysteps:/D2Read the title. It may contain clues about the article’s purpose or ﬁndings./D2Read the abstract. It summarizes the article and will help you recognize impor-
tant points when you read them./D2Read the introduction and conclusion. Usually in plain language, the introduc-
tion and conclusion will help you decode the rest of the article./D2Skim the article. Skim to get a sense of the article’s structure, which will help
you stay oriented while you read.
319

<<<PAGE 338>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
320 Appendix A Historical Bibliography of Quantum Computing
Once you understand an article’s purpose and structure, you are ready to read
the full article. To maximize comprehension and minimize frustration, follow these
tips:/D2Read actively. Take notes while you read. Underline key phrases; mark impor-
tant passages; record important points; sketch arguments and proofs; and repro-
duce calculations. (Of course, don’t write on anything owned by a library; makecopies instead.)/D2Don’t dwell. Skim or skip difﬁcult parts and return to them later. They might
make more sense after you have read subsequent sections./D2Consult the bibliography. If something confuses you, one of the cited articles
might explain it better or provide helpful background information./D2Read the article multiple times. You’ll understand more with each pass./D2Know when to stop. Don’t obsess over an article. At some point, you will have
gotten as much as you are going to get (for the time being). Some or even most of
the article might still elude you; nevertheless, you will know more after reading
the article than you did before you started, and you will then be better equippedto read other articles./D2Talk about the article. Mull over the article with other students, and ask your
professor if you need help. After you have ﬁnished the article, keep talking aboutit. Explain it to your class, to your study group, or even to someone unfamiliar
with the ﬁeld. After all, the best way to learn something is to teach it to someone
else!
A.2 MODELS OF COMPUTATION
Richard Feynman was the ﬁrst to suggest, in a talk in 1981, that quantum-mechanicalsystems might be more powerful than classical computers. In this lecture, repro-
duced in the International Journal of Theoretical Physics in 1982 (Feynman, 1982),
Feynman asked what kind of computer could simulate physics and then argued that
only a quantum computer could simulate quantum physics efﬁciently. He focused on
quantum physics rather than classical physics because, as he colorfully put it, “nature
isn’t classical, dammit, and if you want to make a simulation of nature, you’d bet-ter make it quantum mechanical, and by golly it’s a wonderful problem, because itdoesn’t look so easy” (p. 486).
Around the same time, in “Quantum mechanical models of Turing machines that
dissipate no energy” (Benioff, 1982) and related articles, Paul Benioff demonstratedthat quantum-mechanical systems could model Turing machines. In other words, he
proved that quantum computation is at least as powerful as classical computation.
But is quantum computation more powerful than classical computation?
David Deutsch explored this question and more in his 1985 paper “Quan-
tum theory, the Church–Turing principle and the universal quantum computer”(Deutsch, 1985). First, he introduced quantum counterparts to both the Turing ma-chine and the universal Turing machine. He then demonstrated that the universalquantum computer can do things that the universal Turing machine cannot, includ-
ing generate genuinely random numbers, perform some parallel calculations in a
single register, and perfectly simulate physical systems with ﬁnite-dimensional statespaces.

<<<PAGE 339>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix A Historical Bibliography of Quantum Computing 321
In 1989, in “Quantum computational networks” (Deutsch, 1989), Deutsch de-
scribed a second model for quantum computation: quantum circuits. He demon-
strated that quantum gates can be combined to achieve quantum computation inthe same way that Boolean gates can be combined to achieve classical computa-tion. He then showed that quantum circuits can compute anything that the universal
quantum computer can compute, and vice versa.
Andrew Chi-Chih Yao picked up where Deutsch left off and addressed the com-
plexity of quantum computation in his 1993 paper “Quantum circuit complexity”(Yao, 1993). Speciﬁcally, he showed that any function that can be computed in poly-
nomial time by a quantum Turing machine can also be computed by a quantumcircuit of polynomial size. This ﬁnding allowed researchers to focus on quantum
circuits, which are easier than quantum Turing machines to design and analyze.
Also in 1993, Ethan Bernstein and Umesh Vazirani presented “Quantum com-
plexity theory” (Bernstein and Vazirani, 1993), in which they described a universal
quantum Turing machine that can efﬁciently simulate any quantum Turing machine.
(As with so many quantum articles, the ﬁnal version of the paper did not appear un-
til several years later, in the SIAM Journal of Computing ; Bernstein and Vazirani,
1997). As its title suggests, Bernstein and Vazirani’s paper kick-started the study of
quantum complexity theory.
A.3 QUANTUM GATES
In 1995, a cluster of articles examined which sets of quantum gates are adequate for
quantum computation – that is, which sets of gates are sufﬁcient for creating anygiven quantum circuit. Of these papers, the one that was cited the most in later
works was “Elementary gates for quantum computation” (Barenco et al., 1995), in
which Adriano Barenco et al. showed that any quantum circuit can be constructedusing nothing more than quantum gates on one qubit and controlled exclusive-
OR gates on two qubits. Though that paper was arguably the most inﬂuential,
other articles were important as well, including “Two-bit gates are universal forquantum computation” (DiVincenzo, 1995), in which David DiVincenzo proved
that two-qubit quantum gates are adequate; “Conditional quantum dynamics and
logic gates” (Barenco, Deutsch, Ekert, and Jozsa, 1995), in which Adriano Barenco,David Deutsch, Artur Ekert, and Richard Jozsa showed that quantum controlled-NOT gates and one-qubit gates are together adequate; and “Almost any quantum
logic gate is universal” (Lloyd, 1995), in which Seth Lloyd showed that almost any
quantum gate with two or more inputs is universal (i.e., by itself adequate).
A.4 QUANTUM ALGORITHMS AND IMPLEMENTATIONS
In 1992, David Deutsch and Richard Jozsa coauthored “Rapid solution of problemsby quantum computation” (Deutsch and Jozsa, 1992), in which they presented an al-gorithm that determines whether a function fis constant over all inputs (i.e., either
equal to 1 for all xor equal to 0 for all x) or balanced (i.e., equal to 1 for half of
the values of xand equal to 0 for the other half). The Deutsch–Jozsa algorithm was
the ﬁrst quantum algorithm to run faster, in all cases, than its classical counterparts.
So, even though the problem is somewhat contrived, the algorithm is notable and
the article is worth reading. Also worth reading is “Experimental realization of a

<<<PAGE 340>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
322 Appendix A Historical Bibliography of Quantum Computing
quantum algorithm” (Chuang et al., 1998), in which Isaac L. Chuang et al. detailed
how they used bulk nuclear magnetic resonance techniques to implement a simpli-
ﬁed version of the Deutsch–Jozsa algorithm.
In “Quantum complexity theory” (Bernstein and Vazirani, 1993) (also men-
tioned before), Bernstein and Vazirani were the ﬁrst to identify a problem that can
be solved in polynomial time by a quantum algorithm but requires superpolyno-
mial time classically. The following year, Daniel R. Simon introduced a problemthat a quantum algorithm can solve exponentially faster than any known classical
algorithm. His research inspired Peter W. Shor, who then invented two quantum al-gorithms that outshone all others: polynomial-time algorithms for ﬁnding prime fac-tors and discrete logarithms, problems widely believed to require exponential time
on classical computers. Simon and Shor both presented their discoveries at the 1994
IEEE Symposium on the Foundations of Computer Science (in “On the power ofquantum computation” (Simon, 1994) and “Algorithms for quantum computation:Discrete logarithms and factoring” (Shor, 1994), respectively) and published the ﬁ-
nal versions of their papers in a special quantum-themed issue of SIAM Journal of
Computing (Simon, 1997, and Shor, 1997, respectively).
Shor’s factorization algorithm in particular heightened excitement and even gen-
erated anxiety about the power and promise of quantum computing. Speciﬁcally,
the algorithm caused a furor because it threatened the security of information en-crypted according to the widely used cryptosystem developed by Ronald L. Rivest,
Adi Shamir, and Leonard M. Adleman. RSA cryptography, as it is known, relies on
the presumed difﬁculty of factoring large numbers, a problem that is not known torequire exponential time but for which no classical polynomial-time algorithm ex-ists. Rivest, Shamir, and Adleman described the cryptosystem in 1978 in “A method
for obtaining digital signatures and public-key cryptosystems” (Rivest, Shamir, and
Adleman, 1978), an article that is brief, elegant, and still very relevant to anyoneinterested in Shor’s algorithm, cryptography, or complexity theory.
Of course, to pose a practical threat to RSA cryptography, Shor’s algorithm
must be implemented on quantum computers that can hold and manipulate largenumbers, and these do not exist yet. That said, Isaac L. Chuang and his research
team made headlines when they factored the number 15 on a quantum computer
with seven qubits. Their 2001 pr ´ecis of their accomplishment, “Experimental real-
ization of Shor’s quantum factoring algorithm using nuclear magnetic resonance”(Vandersypen et al., 2001), is a well-illustrated reminder of just how astonishing
Shor’s algorithm is.
Another highly inﬂuential quantum algorithm is Lov K. Grover’s algorithm for
searching an unordered list, described in both “A fast quantum mechanical al-gorithm for database search” (Grover, 1996) and “Quantum mechanics helps in
searching for a needle in a haystack” (Grover, 1997). Unlike Shor’s algorithm,Grover’s algorithm solves a problem for which there are polynomial-time classical
algorithms; however, Grover’s algorithm does it quadratically faster than classical
algorithms can. With Grover’s algorithm, as with the algorithms mentioned ear-lier, Isaac L. Chuang was at the experimental fore; in 1998, he, Neil Gershenfeld,and Mark Kubinec reported on the ﬁrst implementation of Grover’s algorithm in
“Experimental implementation of fast quantum searching” (Chuang, Gershenfeld,
and Kubinec, 1998).

<<<PAGE 341>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix A Historical Bibliography of Quantum Computing 323
There are of course more quantum algorithms than those discussed earlier. How-
ever, there are far fewer than researchers had hoped there would be by now, and
research in quantum algorithms has not kept pace with research in other aspects
of quantum computing and quantum information. In 2003, Peter W. Shor addressedthis stagnation in a short article called “Why haven’t more quantum algorithms beenfound?” (Shor, 2003). Although unsure of the answer to that question, Shor offered
several possible explanations, including the possibility that computer scientists have
not yet developed intuitions for quantum behavior. The article should be requiredreading for all computer science students, whose intuitions are still being formed.
A.5 QUANTUM CRYPTOGRAPHY
As mentioned before, Shor’s factorization algorithm has yet to be implemented onmore than a few qubits. But if the efﬁcient factorization of large numbers becomespossible, RSA cryptography will need to be replaced by a new form of cryptogra-phy, one that will not be foiled by classical or quantum computers. Conveniently,
such a method already exists; in fact, it was developed before Shor invented his fac-
torization algorithm. Coincidentally, it too relies on quantum mechanics.
The cryptographic method in question is quantum key distribution, which was
introduced in 1984 by Charles H. Bennett and Gilles Brassard in “Quantum cryp-tography: Public key distribution and coin tossing” (Bennett and Brassard, 1984)and is thus commonly referred to as BB84. In short, quantum key distribution is se-
cure not because messages are encrypted in some difﬁcult-to-decrypt way but rather
because eavesdroppers cannot intercept messages undetected, regardless of compu-tational resources.
Although quantum key distribution is the most famous cryptographic applica-
tion of quantum mechanics, it is not the only one, and it was not the ﬁrst. In the1960s, Stephen Wiesner conceived of two applications: a way to send two messages,only one of which can be read, and a way to design money that cannot be counter-
feited. His ideas were largely unknown until 1983, when he described them in an
article called “Conjugate coding” (Wiesner, 1983).
Needless to say, the papers mentioned earlier were not the only milestones
in the development of quantum cryptography. Curious readers should consultthese two installments of SIGACT News ’ “Cryptology column”: “Quantum cryp-
tography: A bibliography” by Gilles Brassard (1993) and “25 years of quantumcryptography” by Gilles Brassard and Claude Cr ´epeau Brassard and Cr ´epeau
(1993). Since the publication of those articles, quantum cryptography has ma-tured from theory and experiments to commercially available products; devel-opments are frequently announced by manufacturers such as MagiQ Technolo-
gies (http://www.magiqtech.com/), id Quantique (http://www.idquantique.com/),
and Smart Quantum (http://www.smartquantum.com/).
A.6 QUANTUM INFORMATION
Secure channels of communication are of course crucial, but security is not the onlyconsideration in the transfer of information. Accordingly, quantum cryptography
is just one of several topics in the burgeoning ﬁeld of quantum information. Other

<<<PAGE 342>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
324 Appendix A Historical Bibliography of Quantum Computing
topics include quantum error correction, fault-tolerant quantum computation, quan-
tum data compression, and quantum teleportation.
Information needs to be protected not just from eavesdroppers but also from
errors caused by channel noise, implementation ﬂaws, and, in the quantum case,decoherence. Peter W. Shor, a trailblazer not just of quantum algorithms but alsoof quantum error correction and fault-tolerant quantum computation, was the ﬁrst
to describe a quantum error-correcting method. In his 1995 article “Scheme for re-
ducing decoherence in quantum computer memory” (Shor, 1995), he demonstratedthat encoding each qubit of information into nine qubits could provide some pro-
tection against decoherence. At almost the same time but without knowledge of
Shor’s article, Andrew M. Steane wrote “Error correcting codes in quantum theory”(Steane, 1997), which achieved similar results. Very shortly thereafter, Shor and
A.R. Calderbank presented improved results in “Good quantum error-correcting
codes exist” (Calderbank and Shor, 1996). In the late 1990s, when research onquantum error correction and fault-tolerant quantum computation ballooned, Shor,Steane, and Calderbank remained among the major contributors.
Error is not the only thing information theorists strive to reduce; they also seek
to reduce the space required to represent information. The landmark paper on theclassical representation and compression of data was “A mathematical theory of
communication” by Claude E. Shannon (1948), the “father” of information the-
ory. In this 1948 paper, Shannon showed that it is possible, up to a certain limit, tocompress data without loss of information; beyond that limit, some information is
necessarily lost. (Seminal in so many ways, this paper also laid the groundwork for
classical error-correcting codes.)
Almost 50 years later, Benjamin Schumacher developed a quantum version
of Shannon’s theorem. Schumacher ﬁrst described his ﬁnding in an article called
“Quantum coding,” which he submitted to Physical Review A in 1993 but which was
not published until 1995 (Schumacher, 1995). In the (unfortunate but not uncom-
mon) lag between submission and publication, he and Richard Jozsa published “A
new proof of the quantum noiseless coding theorem” (Jozsa and Schumacher, 1994),
which offered a simpler proof than the original article.
Not everything in quantum information theory has a precedent in classical infor-
mation theory. In 1993, Charles H. Bennett et al., dazzled the scientiﬁc communityand delighted science ﬁction fans by showing that quantum teleportation is theo-retically possible. In “Teleporting an unknown quantum state via dual classical andEinstein–Podolsky–Rosen channels” (Bennett et al., 1993), they described how an
unknown quantum state could be disassembled and then reconstructed perfectly in
another location. The ﬁrst researchers to verify this method of teleportation exper-imentally were Dik Bouwmeester et al., who reported their achievement in 1997 in
“Experimental quantum teleportation” (Bouwmeester, 1997).
A.7 MORE MILESTONES?
Quantum computing continues to entice and engross researchers, who will no doubt
continue to ask challenging questions, discover inventive and elegant solutions,identify stumbling blocks, and achieve experimental triumphs. To learn how to ap-
prise yourself of developments, consult Appendix D, “Keeping abreast of quantum
news: Quantum computing on the Web and in the literature.”

<<<PAGE 343>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix B
Answers to Selected Exercises
CHAPTER 1
Ex. 1.1.1:
x4+2x2+1=(x2+1)(x2+1)=0. (B.1)
As neither of the factors have real solutions, there are no real solutions to the entire
equation.Ex. 1.1.2: −i.
Ex. 1.1.3: −1−3i;−2+14i.
Ex. 1.1.4: Simply multiply out (−1 +i)
2+2(−1+i)+2 and show that it equals 0.
Ex. 1.2.1: (−5, 5).
Ex. 1.2.2: Setting c1=(a1,b1),c2=(a2,b2), and c3=(a3,b3). Then we have
c1×(c2×c3)=(a1,b1)×(a2a3−b2b3,a2b3+a3b2)
=(a1(a2a3−b2b3)−b1(a2b3+a3b2),a1(a2b3+a3b2)+(a2a3−b2b3)b1)
=(a1a2a3−a1b2b3−b1a2b3−b1b2a3,a1a2b3+a1b2a3+b1a2a3−b1b2b3)
=(a1a2−b1b2,a1b2+b1a2)×(a3,b3)
=((a1,b1)×(a2,b2))×(a3,b3)=(c1×c2)×c3. (B.2)
Ex. 1.2.3:−3−3i
2.
Ex. 1.2.4: 5.
Ex. 1.2.5: Setting c1=(a1,b1) and c2=(a2,b2). Then
|c1||c2|=/radicalBig
a2
1+b2
1/radicalBig
a2
2+b2
2=/radicalBig/parenleftbig
a2
1+b2
1/parenrightbig/parenleftbig
a2
2+b2
2/parenrightbig
=/radicalBig
a2
1a2
2+b2
1a2
2+b2
1b2
2+a2
1b2
2=/radicalBig
(a1b1−a2b2)2+(a1b2+a2b1)2
=|(a1b1−a2b2,a1b2+a2b1)|=| c1c2|. (B.3)
325

<<<PAGE 344>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
326 Appendix B Answers to Selected Exercises
Ex. 1.2.6: This can be carried out algebraically like Exercise 1.2.5. One should also
think of this geometrically after reading Section 1.3. Basically this says that any side
of a triangle is not greater than the sum of the other two sides.
Ex. 1.2.7: Examine it!
Ex. 1.2.8: Too easy.
Ex. 1.2.9: (a1,b1)(−1, 0)=(−1a1−0b1,0a1−1b1)=(−a1,−b1).
Ex. 1.2.10: Setting c1=(a1,b1) and c2=(a2,b2). Then
c1+c2=(a1,−b1)+(a2,−b2)=(a1+a2,−(b 1+b2))=c1+c2. (B.4)
Ex. 1.2.11: Setting c1=(a1,b1) and c2=(a2,b2). Then
c1×c2=(a1,−b1)×(a2,−b2)=(a1a2−b1b2,−a1b2−a2b1), (B.5)
(a1a2−b1b2,−(a1b2+a2b1))=c1×c2. (B.6)
Ex. 1.2.12: Although the map is bijective, it is not a ﬁeld isomorphism because it
does not respect the multiplication, i.e., in general,
−(c1×c2)/negationslash=−c1×−c2=c1×c2. (B.7)
Ex. 1.3.1: 3+0i.
Ex. 1.3.2: 1−2i.
Ex. 1.3.3: 1.5+2.6i.
Ex. 1.3.4: 5i.
Ex. 1.3.5: Ifc=a+bi, the effect of multiplying by r0is just r0a+r0bi. The vector
in the plane has been stretched by the constant factor r0. You can see it better in
polar coordinates: only the magnitude of the vector has changed, the angle stays the
same. The effect on the plane is an overall dilation by r0, and no rotation.
Ex. 1.3.6: The best way to grasp this exercise it to pass to the polar representation:
letc=(ρ,θ ) and c0=(ρ0,θ0). Their product is (ρρ 0,θ+θ0). This is true for all c.
The plane has been dilated by the factor ρ0and rotated by the angle θ0.
Ex. 1.3.7: 2i.
Ex. 1.3.8: (1−i)5=−4+4i.
Ex. 1.3.9: 1.0842+0.2905 i,−0.7937 +0.7937 i,−0.2905 −1.0842 i.
Ex. 1.3.12:
c1
c2=ρ1
ρ2ei(θ1−θ2). (B.8)
Ex. 1.3.15: Letc0=d0+d1ibe our constant complex number and x=a+bibe an
arbitrary complex input. Then ( a+d0)+(b+d1)i, i.e. the translation of xbyc0.
Ex. 1.3.17: Seta/prime/prime=(aa/prime+b/primec),b/prime/prime=(a/primeb+b/primed),c/prime/prime=(ac/prime+cd/prime), and d/prime/prime=(bc/prime+
dd/prime) to get the composition of the two transformations.
Ex. 1.3.18: a=1,b=0,c=0,d=1. Notice that ad−bc=1, so the condition is
satisﬁed.
Ex. 1.3.19: The transformationdx−b
−cx+awill do. Notice that it is still M ¨obius because
da−(−b)(−c )=da−bc=ad−bc. (B.9)

<<<PAGE 345>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix B Answers to Selected Exercises 327
CHAPTER 2
Ex. 2.1.1:
⎡
⎢⎢⎢⎢⎢⎢⎢⎣12+5i
6+6i
2.53−6i
21.4+3i⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (B.10)
Ex. 2.1.2:
(V+(W+X))[j]=V[j]+(W+X)[j]=V[j]+(W[j]+X[j])
=(V[j]+W[j])+X[j]=(V+W)[j]+X[j]
=((V+W)+X)[j]. (B.11)
Ex. 2.1.3:
⎡
⎢⎢⎢⎢⎢⎢⎢⎣132.6−13.6i
−14−56i
48−12i
32−42i⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (B.12)
Ex. 2.1.4:
((c
1+c2)·V)[j]=((c1+c2)×(V[j])=((c1×(V[j]))+(c2×(V[j]))
=(c1·V)[j]+(c2·V)[j]=((c1·V)+(c2·V))[j]. (B.13)
Ex. 2.2.1: They are both equal to⎡
⎣12
−24
6⎤⎦.
Ex. 2.2.3: For property (vi):
⎡
⎢⎣−2+6i−12+6i
−12−4i−18+4i⎤
⎥⎦. (B.14)
For property (viii):
⎡
⎢⎣5+3i 3+12i
−6+10i 17i⎤
⎥⎦. (B.15)

<<<PAGE 346>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
328 Appendix B Answers to Selected Exercises
Ex. 2.2.4: Property (v) has the unit 1. Property (vi) is done as follows:
(c1·(c2·A))[j,k]=c1×((c2·A)[j,k])=c1×(c2×A[j,k])
=(c1×c2)×A[j,k]=((c1×c2)·A)[j,k]. (B.16)
Property (viii) is similar to this and similar to Exercise 2.1.4.
Ex. 2.2.5:
⎡
⎢⎢⎢⎢⎣6−3i 01
2+12i5+2.1i2+5i
−19i 17 3 −4.5i⎤
⎥⎥⎥⎥⎦;⎡
⎢⎢⎢⎢⎣6+3i2−12i 19i
05−2.1i 17
12 −5i3+4.5`i⎤
⎥⎥⎥⎥⎦;
⎡
⎢⎢⎢⎢⎣6+3i 01
2−12i5−2.1`i2−5i
19i 17 3 +4.5`i⎤
⎥⎥⎥⎥⎦. (B.17)
Ex. 2.2.6:
(
c·A)[j,k]=(c×(A[j,k])=c×(A[j,k])=(c·A)[j,k]. (B.18)
Ex. 2.2.7: We shall only do Property (ix). The others are similar.
(c·A)†=(c·A)T=(c·A)T=c·AT=c·A†. (B.19)
Ex. 2.2.8:
⎡
⎢⎢⎢⎢⎣37−13i 10 50 −44i
12+3i 6+28i 3+4i
31+9i−6+32i4−60i⎤
⎥⎥⎥⎥⎦. (B.20)
Ex. 2.2.9:
((A⋆B)T)[j,k]=(A⋆B)[k,j]=n/summationdisplay
i=0A[k,i]×B[i,j]=n/summationdisplay
i=0B[i,j]×A[k,i]
=n/summationdisplay
i=0BT[j,i]×AT[i,k]=(BT⋆AT)[j,k]. (B.21)
Ex. 2.2.10:
⎡
⎢⎢⎢⎢⎣26+52i9−7i48+21i
60−24i1−29i15−22i
26 14 20 +22i⎤
⎥⎥⎥⎥⎦. (B.22)

<<<PAGE 347>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix B Answers to Selected Exercises 329
Ex. 2.2.11:
(A⋆B)†=(A⋆B)T=(A⋆B)T=BT⋆AT=B†⋆A†. (B.23)
Ex. 2.2.13: Every member of Poly 5can be written as
c0+c1x+c2x2+c3x3+c4x4+c5x5+0x6+0x7. (B.24)
It is obvious that this subset is closed under addition and scalar multiplication.
Ex. 2.2.14: Given two matrices
⎡
⎢⎣xy
−yx⎤
⎥⎦ and⎡
⎢⎣x/primey/prime
−y/primex/prime⎤
⎥⎦, (B.25)
their sum is
⎡
⎢⎣x+x/primey+y/prime
−(y+y/prime)x+x/prime⎤
⎥⎦, (B.26)
and so the set is closed under addition. Similar for scalar multiplication. This sum is
also equal to
f(x+yi)+f(x/prime+y/primei)=f((x+x/prime)+(y+y/prime)i). (B.27)
Ex. 2.2.17: A given pair/angbracketleftBigg⎡
⎢⎢⎢⎣c0
c1
...
cm−1⎤
⎥⎥⎥⎦,⎡
⎢⎢⎢⎣c/prime
0
c/prime
1
...
c/prime
n−1⎤
⎥⎥⎥⎦/angbracketrightBigg
goes to
[c0,c1,···,cm−1,c/prime
0,c/prime
1,···,cn−1]T. (B.28)
Ex. 2.2.18: An element [c 0,c1,···,cm−1]TofCmcan be seen as the element
/angbracketleftBigg⎡
⎢⎢⎢⎣c0
c1
...
cm−1⎤
⎥⎥⎥⎦,⎡
⎢⎢⎢⎣0
0
...
0⎤
⎥⎥⎥⎦/angbracketrightBigg
ofCm×Cn.
Ex. 2.3.1:
2·[1,2,3]T+[1,−4,−4]T=[3,0,2]T. (B.29)
Ex. 2.3.2: The canonical basis can easily be written as a linear combination of these
vectors.
Ex. 2.4.1: Both sides of Equation (2.101) are 11 and both sides of Equation (2.102)
are 31 .
Ex. 2.4.3: We shall show it for Equation (2.101).
(A+B)T=⎡
⎢⎣1−1
11⎤
⎥⎦;( A+B)T⋆C=⎡
⎢⎣1−2
3/prime4⎤
⎥⎦; (B.30)

<<<PAGE 348>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
330 Appendix B Answers to Selected Exercises
and the Trace of this matrix is 5. The right-hand side is Trace( AT⋆B)=−2 added
toTrace( AT⋆C)=7 for a sum of 5.
Ex. 2.4.5:√
439.
Ex. 2.4.6:√
47.
Ex. 2.4.7:√
11.
Ex. 2.4.8:
/angbracketleftV,V/prime/angbracketright=| V||V/prime|cosθ, (B.31)
8=3√
10 cos θ, (B.32)
cosθ=0.843, (B.33)
θ=32.51◦. (B.34)
Ex. 2.5.1: Their eigenvalues are –2, –2, and 4, respectively.
Ex. 2.6.1: Look at it.
Ex. 2.6.2: The key idea is that you take the transpose of both sides of
AT=A (B.35)
and remember that the Toperation is idempotent.
Ex. 2.6.3: The proof is the same as the hermitian case but with the dagger replaced
with the transpose operation.
Ex. 2.6.4: The proof is analogous to the hermitian case.
Ex. 2.6.5: Multiply it out by its adjoint and remember the basic trigonometric iden-
tity:
sin2θ+cos2θ=1. (B.36)
Ex. 2.6.6: Multiply it by its adjoint to get the identity.
Ex. 2.6.7: IfUis unitary, then U⋆U†=I. Similarly, if U/primeis unitary, then U/prime⋆U/prime†=
I.Combining these we get that
(U⋆U/prime)⋆(U⋆U/prime)†=(U⋆U/prime)⋆(U/prime†⋆U†)=U⋆U/prime⋆U/prime†⋆U†
=U⋆I⋆U†=U⋆U†=I. (B.37)
Ex. 2.6.8:
d(UV 1,UV 2)=|UV 1−UV 2|=| U(V1−V2)|=| V1−V2|=d(V1,V2).(B.38)
Ex. 2.6.9: It is a simple observation and they are their own adjoint.
Ex. 2.7.1:
[−3, 6,−4,8,−7,14]T. (B.39)
Ex. 2.7.2: No. We are looking for values such that
[z,y,z]T×[a,b]T=[5,6,3,2,0,1]T. (B.40)

<<<PAGE 349>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix B Answers to Selected Exercises 331
That would imply that za=0 and which means either z=0o r a=0. If z=0, then
we would not have zb=1 and if a=0 we would not have xa=5. So no such values
exist.
Ex. 2.7.3:
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣3+2i 1+18i 29−11i 5−i 19+17i 18−40i 2i−8+6i14+10i
26+26i18+12i−4+19i 52 30 −6i 15+23i−4+20i 12i−10+4i
03 +2i−12+31i 05 −i 19+43i 02 i−18+4i
00 0 1 2 3 6 +48i 60−84i 6−3i 30+15i9−57i
0 0 0 120 +24i 72 24 +60i 66−18i36−18i27+24i
0 0 0 0 12 24 +108i 06 −3i 39+48i
26 +8i 10−14i 4+4i−4+28i 48−8i 9+3i 15+45i66−48i
20+4i 12 4 +10i 32+48i24+24i−12+28i84+48i54+18i3+51i
02 4 +18i 04 +4i−28+44i 09 +3i−9+87i⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦.
(B.41)
Ex. 2.7.5: Both associations equal
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣18 15 12 10 36 30 24 20
9 6 6 4 18 12 12 8
−6−50 0−12 −10 0 0
−3−20 0 −6−400
0 0 0 0 18 15 12 10
0 0 00 9 6 6400 0 0 −6−500
00 0 0 −3−200⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (B.42)
Ex. 2.7.6: For A∈C
m×m/prime,B∈Cn×n/prime, and C∈Cp×p/primewe have
(A⊗(B⊗C))[j,k]=A[j/(np ),k/(n/primep/prime)]×(B⊗C)[jMod ( np),kMod ( n/primep/prime)]
=A[j/(np ),k/(n/primep/prime)]×B[(jMod ( np))/p,(kMod ( n/primep/prime))/p/prime]
×C[(jMod ( np)) Mod p,(kMod ( n/primep/prime)) Mod p/prime]
=A[(j/p)/n,(k/p/prime)/n/prime]×B[(j/p)M o d n,(k/p/prime)M o d n/prime]
×C[jMod p,kMod p/prime]=(A⊗B)[j/p,k/p/prime,]
×C[jMod p,kMod p/prime]=((A⊗B)⊗C)[j,k]. (B.43)

<<<PAGE 350>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
332 Appendix B Answers to Selected Exercises
The center equality follows from these three identities that can easily be checked:
j/(np )=(j/n)/p, (B.44)
(jMod ( np))/p=(j/p)M o d n, (B.45)
(jMod ( np)) Mod p=jMod p. (B.46)
Ex. 2.7.7: They are both equal to
⎡
⎢⎢⎢⎢⎢⎢⎢⎣26
483961 2⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (B.47)
Ex. 2.7.8: For A∈C
m×m/primeand B∈Cn×n/prime, we have
(A⊗B)†[j,k]=(A⊗B)[k,j]=(A[k/n,j/n/prime]×B[kMod n,jMod n/prime])
=A[k/n,j/n/prime]×B[kMod n,jMod n/prime]
=A†[j/n/prime,k/n]×B†[jMod n/prime,kMod n]
=(A†⊗B†)[j,k]. (B.48)
Ex. 2.7.9: ForA∈Cm×m/prime,A/prime∈Cm/prime×m/prime/prime,B∈Cn×n/prime, and B/prime∈Cn/prime×n/prime/primewe will have ( A⋆
A/prime)∈Cm×m/prime/prime,(B⋆B/prime)∈Cn×n/prime/prime,(A⊗B)∈Cmn× m/primen/prime, and ( A/prime⊗B/prime)∈Cm/primen/prime×m/prime/primen/prime/prime.
((A⊗B)⋆(A/prime⊗B/prime))[j,k]=m/primen/prime−1/summationdisplay
t=0((A⊗B)[j,t]×(A/prime⊗B/prime)[t,k])
=m/primen/prime−1/summationdisplay
t=0(A[j/n,t/n/prime]×B[jMod n,tMod n/prime]
×A/prime[t/n/prime,k/n/prime/prime]×B/prime[tMod n/prime,kMod n/prime/prime]).(B.49)
These m/primen/primeterms can be rearranged as follows:
/parenleftBiggm/prime−1/summationdisplay
i=0A[j/n,i]×A/prime[i,k/n/prime]/parenrightBigg
×/parenleftBiggn/prime−1/summationdisplay
i=0B[jMod n,i]×B/prime[i,kMod n/prime]/parenrightBigg
=(A⋆A/prime)[j/n,k/n/prime]×(B⋆B/prime)[jMod n,kMod n/prime]
=((A⋆A/prime)⊗(B⋆B/prime))[j,k]. (B.50)

<<<PAGE 351>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix B Answers to Selected Exercises 333
CHAPTER 3
Ex. 3.1.1:
[0,0,20,2,0,5]T. (B.51)
Ex. 3.1.2:
MM=M2=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣000000
000000100010000100010001001000⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦, (B.52)
MMM=M
2M=MM2=M3=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣000000
000000001000000100100010010001⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦, (B.53)
M
6=M3M3=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣000000
000000001000000100100010010001⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (B.54)
They all end up in vertex 2.
Ex. 3.1.3: The marbles in each vertex would “magically” multiply themselves and
the many copies of the marbles would go to each vertex that has an edge connecting
them. Think nondeterminism!

<<<PAGE 352>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
334 Appendix B Answers to Selected Exercises
Ex. 3.1.4: The marbles would “magically” disappear.
Ex. 3.1.5: The adjacency matrix is
A=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣010000000
100000000
000000000000100000000000000001000000000000000000010100000001011⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦, (B.55)
A
2=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣100000000
010000000000000000000100000000000000000000000000000000000000000
001011111⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦;A
4=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣100000000
010000000000000000000100000000000000000000000000000000000000000
001011111⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦.
(B.56)
If we start in state X=[1,1,1,1,1,1,1,1,1]
T, then AX=[ 110101023 ]T,
and A2X=A4X=[ 110100006 ]T.
Ex. 3.2.1:
Y=/bracketleftbigg5
12,3
12,4
12/bracketrightbiggT
. (B.57)

<<<PAGE 353>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix B Answers to Selected Exercises 335
Ex. 3.2.2: We are given that/summationtext
iM[i,k]=1 and/summationtext
iX[i]=1. Then we have
/summationdisplay
iY[i]=/summationdisplay
i(MX)[i]=/summationdisplay
i/summationdisplay
k(M[i,k]X[k])
=/summationdisplay
k/summationdisplay
i(M[i,k]X[k])=/summationdisplay
k(/summationdisplay
iM[i,k])X[k]=/summationdisplay
k(1×X[k])=1.
(B.58)
Ex. 3.2.3: This is done almost exactly like Exercise 3.2.2.
Ex. 3.2.4:
M⋆N=⎡
⎢⎣1
21
2
1
21
2⎤
⎥⎦. (B.59)
Ex. 3.2.5: LetMand Nbe two doubly stochastic matrices. We shall show that the
jth row of M⋆Nsums to 1 for any j. (The computation for the kth column is
similar.)
/summationdisplay
i(M⋆N)[j,i]=/summationdisplay
i/summationdisplay
k(M[j,k]×N[k,i])=/summationdisplay
k/summationdisplay
i(M[j,k]×N[k,i])
=/summationdisplay
k/bracketleftBigg
M[j,k]×(/summationdisplay
iN[k,i])/bracketrightBigg
=/summationdisplay
k[M[j,k]×(1)]=1.(B.60)
Ex. 3.2.6: Letmstand for math, pstand for physics, and cstand for computer sci-
ence. Then the corresponding adjacency matrix is
A=⎡
⎢⎣mpc
m 0.10 .70 .2
p 0.60 .20 .2
c 0.30 .10 .6⎤
⎥⎦; A2=⎡
⎢⎢⎢⎢⎣0.49 0.23 0 .28
0.24 0.48 0 .28
0.27 0.29 0 .44⎤
⎥⎥⎥⎥⎦; (B.61)
A
4=⎡
⎢⎢⎢⎢⎣0.3709 0.3043 0.3248
0.3084 0.3668 0.3248
0.3207 0.3289 0.3504⎤
⎥⎥⎥⎥⎦; A
8=⎡
⎢⎢⎢⎢⎣0.335576 0 .331309 0.333115
0.33167 0 .335215 0.333115
0.332754 0 .333476 0.33377⎤
⎥⎥⎥⎥⎦.
(B.62)
To calculate the probable majors, multiply these matrices by [1 ,0,0]
T,[0,1,0]T, and
[0,0,1]T.
Ex. 3.3.1:
⎡
⎢⎢⎢⎢⎣cos
2θ sin2θ 0
sin2θ cos2θ0
00 1⎤
⎥⎥⎥⎥⎦. (B.63)

<<<PAGE 354>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
336 Appendix B Answers to Selected Exercises
The fact that it is doubly stochastic follows from the trigonometric identity
sin2θ+cos2θ=1. (B.64)
Ex. 3.3.2: LetUbe a unitary matrix. Ubeing unitary means that
(U⋆U†)[j,k]=/summationdisplay
i/parenleftbig
U[j,i]×U†[i,k]/parenrightbig
=/summationdisplay
i/parenleftBig
U[j,i]×U[k,i]/parenrightBig
=δj,k,
(B.65)
where δj,kis the Kronecker delta function. We shall show that the sum of the jth
row of the modulus squared elements is 1. A similar proof shows the same for the
kth column.
/summationdisplay
k|U[j,k]|2=/summationdisplay
k/parenleftBig
U[j,k]×U[j,k]/parenrightBig
=δj,j=1. (B.66)
The ﬁrst equality follows from Equation (1.49).
Ex. 3.3.3: LetUbe unitary and Xbe a column vector such that/summationtext
j|X[j]|2=x.
/summationdisplay
j|(U⋆X)[j]|2=/summationdisplay
j/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/summationdisplay
k(U[j,k]×X[j])/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle2
=/summationdisplay
j/summationdisplay
k/vextendsingle/vextendsingle(U[j,k]×X[j])/vextendsingle/vextendsingle
2
=/summationdisplay
j/summationdisplay
k/bracketleftBig
(U[j,k]×X[j])×(U[j,k]×X[j])/bracketrightBig
=/summationdisplay
j/summationdisplay
k(|U[j,k]|2×|X[j]|2)=1×x=x, (B.67)
which follows from the solution to Exercise 3.3.2.
Ex. 3.4.2:
N⊗N=⎡
⎢⎢⎢⎢⎢⎢⎢⎣1
92
92
94
9
2
91
94
92
9
2
94
91
92
9
4
92
92
91
9⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (B.68)
Ex. 3.4.3:
M⊗N=⎡
⎢⎢⎢⎢⎢⎢⎢⎣1
61
62
62
6
1
61
62
62
6
2
62
61
61
6
2
62
61
61
6⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (B.69)

<<<PAGE 355>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix B Answers to Selected Exercises 337
Ex. 3.4.4: ForM∈Cm×m/primeand N∈Cn×n/prime, we will have M⊗N∈Cmn× m/primen/prime. The edge
from jtokinGM⊗Nwill have weight
M[j/n,k/n/prime]×N[jMod n,kMod n/prime] (B.70)
and will correspond to the pairs of edges
/angbracketleftj/n−→ k/n/prime,jMod n−→ kMod n/prime/angbracketright. (B.71)
Ex. 3.4.5: This is very similar to Exercise 3.4.4.
Ex. 3.4.6: “One marble traveling on the Mgraph and one marble traveling on the
Ngraph” is the same as “One marble on the Ngraph and one marble on the M
graph.”
Ex. 3.4.7: It basically means that “A marble moves from the Mgraph to the M/prime
graph and a marble moves from the Ngraph to the N/primegraph.” It is the same as saying
“Two marbles move from the Mand Ngraph to the M/primeand N/primegraph, respectively.
See the graph given in Equation (5.47).
CHAPTER 4
Ex. 4.1.1: The length of |ψ/angbracketrightis|ψ/angbracketright| = 4.4721. We get p(x3)=1
4.47212.p(x4)=4
4.47212.
Ex. 4.1.2: This was done in the text where c=2. The general problem is exactly the
same.Ex. 4.1.3: If they represented the same state, there would be a complex scalar csuch
that the second vector is the ﬁrst one times c. The ﬁrst component of the second
vector is 2 ⋆(1+i), and 1 +iis the ﬁrst component of the ﬁrst vector. However,
if we multiply the second component, we get 2 (2 −i)=4−2i, not 1−2i. Hence,
they do not represent the same state.Ex. 4.1.9: /angbracketleftψ|=[3−i,2i].
Ex. 4.2.2: S
x|↑ /angbracketright=|↓ /angbracketright . (It ﬂips them!) If we measure spin in state down, it will stay
there; therefore, the probability to ﬁnd it still in state up is zero.Ex. 4.2.3: Taking A[j,k]=
A[k,j] as the deﬁnition of hermitian, we consider r·A,
where ris a scalar.
(r·A)[j,k]=r×A[j,k]=r×A[k,j]=(r·A)[k,j]. (B.72)
We used the fact that for any real r,r=r.
Ex. 4.2.4: LetM=/bracketleftbigg
01
10/bracketrightbigg
. M is certainly hermitian (in fact, real symmetric). Multi-
ply it by i:
N=iM=⎡
⎢⎣0i
i0⎤
⎥⎦. (B.73)

<<<PAGE 356>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
338 Appendix B Answers to Selected Exercises
Now, Nis not hermitian: the conjugate of Nis/bracketleftbigg
0−i
−i0/bracketrightbigg
, whereas every hermitian is
its own conjugate.
Ex. 4.2.5 LetAand A/primebe two hermitian matrices.
(A+A/prime)[j,k]=A[j,k]+A/prime[j,k]=A[k,j]+A/prime[k,j]
=A[k,j]+A/prime[k,j]=(A+A/prime)[k,j]. (B.74)
Ex. 4.2.6 Both matrices are trivially hermitian by direct inspection (the ﬁrst one has
iand−ion the nondiagonal elements, and the second is diagonal with real entries).
Let us calculate their products:
/Omega11⋆/Omega1 2=⎡
⎢⎣2−4i
2i 4⎤
⎥⎦, (B.75)
/Omega12⋆/Omega1 1=⎡
⎢⎣2−2i
4i 4⎤
⎥⎦. (B.76)
They do not commute.
Ex. 4.2.7
[/Omega11,/Omega12]=/Omega11⋆/Omega1 2−/Omega12⋆/Omega1 1
=⎡
⎢⎣1+i−3−2i
−13 −i⎤
⎥⎦−⎡
⎢⎣1−i−1
−3+2i3+i⎤
⎥⎦=⎡
⎢⎣2i−2−2i
2−2i−2i⎤
⎥⎦. (B.77)
CHAPTER 5
Ex. 5.1.1:
(3+2i)|0/angbracketright+ (4−2i)|1/angbracketright. (B.78)
Ex. 5.1.2:
(0.67286−0.15252 i)|0/angbracketright+ (0.09420−0.71772 i)|1/angbracketright. (B.79)

<<<PAGE 357>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix B Answers to Selected Exercises 339
Ex. 5.1.3:
|1/angbracketright⊗| 0/angbracketright⊗| 1/angbracketright=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣000 0
001 0010 0011 0100 0101 1
110 0
111 0⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦;|011/angbracketright=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣000 0
001 0010 0011 1100 0101 0
110 0
111 0⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦;|1,1,1/angbracketright=⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣000 0
001 0010 0011 0100 0101 0
110 0
111 1⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦.
(B.80)
Ex. 5.1.4:
⎡
⎢⎢⎢⎣00 0
01 310 011 2⎤
⎥⎥⎥⎦. (B.81)
Ex. 5.2.1:
⎡
⎢⎣1110
00 0 1⎤
⎥⎦⎡
⎢⎢⎢⎢⎢⎢⎢⎣0
010⎤
⎥⎥⎥⎥⎥⎥⎥⎦=⎡
⎢⎣1
0⎤
⎥⎦=|0/angbracketright. (B.82)
Ex. 5.2.2:
⎡
⎢⎣1000
0111⎤
⎥⎦⎡
⎢⎢⎢⎢⎢⎢⎢⎣w
x
y
z⎤
⎥⎥⎥⎥⎥⎥⎥⎦=⎡
⎢⎣0
1⎤
⎥⎦=|1/angbracketright. (B.83)
if and only if either xoryorzis 1.
Ex. 5.2.3:
NOR=NOT ⋆OR=⎡
⎢⎣01
10⎤
⎥⎦⎡
⎢⎣1000
0111⎤
⎥⎦=⎡
⎢⎣0111
1000⎤
⎥⎦. (B.84)

<<<PAGE 358>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
340 Appendix B Answers to Selected Exercises
Ex. 5.2.4: It means that it does not matter which operation is the “top” and which is
the “bottom,” i.e., the wires can be crossed as follows:
• /d47/d47A/d47/d47•
• /d47/d47B/d47/d47•=•
/d26/d26/d52/d52/d52/d52/d52/d52/d52/d52/d52/d52/d52/d52/d52/d52/d52/d52/d52/d52/d52 • B/d47/d47•
•/d68/d68/d10/d10/d10/d10/d10/d10/d10/d10/d10/d10/d10/d10/d10/d10/d10/d10/d10/d10/d10 • A/d47/d47•(B.85)
Ex. 5.2.5: It means that we can think of the diagram as doing parallel operations,
each of which contain two sequential operations, or equivalently, we can think of the
diagram as representing two sequential operations, each consisting of two paralleloperations. Either way, the action of the operations are the same.
Ex. 5.2.7:
NOT ⋆OR⋆(NOT⊗NOT )
=⎡
⎢⎣01
10⎤
⎥⎦⋆⎡
⎢⎣1000
0111⎤
⎥⎦⋆⎡
⎢⎣01
10⎤
⎥⎦⊗⎡
⎢⎣01
10⎤
⎥⎦=⎡
⎢⎣1110
0001⎤
⎥⎦
=AND. (B.86)
Ex. 5.2.8:
⎡
⎢⎢⎢⎣000 001 010 011 100 101 110 111
00 10000000
01 00010110
10 01101000
11 00000001⎤
⎥⎥⎥⎦. (B.87)
Ex. 5.3.2:
|x/angbracketright
•|x/angbracketright
•|x/angbracketright
|y/angbracketright
•|y/angbracketright
•|y/angbracketright
|z/angbracketright/d31/d30/d29/d28 /d24/d25/d26/d27|z⊕(x∧y)/angbracketright/d31/d30/d29/d28 /d24/d25/d26/d27|z⊕(x∧y)⊕(x∧y)/angbracketright=| z/angbracketright(B.88)
Ex. 5.3.3: Setting|z/angbracketright=| 1/angbracketrightgives the NAND gate.

<<<PAGE 359>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix B Answers to Selected Exercises 341
Ex. 5.3.4: Combining a Fredkin gate followed by a Fredkin gate gives the following:
|0,y,z/angbracketright /mapsto−→ | 0,y,z/angbracketright /mapsto−→ | 0,y,z/angbracketright (B.89)
and
|1,y,z/angbracketright /mapsto−→ | 1,z,y/angbracketright /mapsto−→ | 1,y,z/angbracketright. (B.90)
Ex. 5.4.1: Except for Yall of them are their own conjugate. Simple multiplication
shows that one gets the identity.
Ex. 5.4.2:
⎡
⎢⎣01
10⎤
⎥⎦⎡
⎢⎣c0
c1⎤
⎥⎦=⎡
⎢⎣c1
c0⎤
⎥⎦, (B.91)
⎡
⎢⎣0−i
i 0⎤
⎥⎦⎡
⎢⎣a0+b0i
a1+b1i⎤
⎥⎦=⎡
⎢⎣b1−a1i
−b0+a0i⎤
⎥⎦. (B.92)
Ex. 5.4.9: One way of doing this is to show that both gates have the same matrix
that performs the action.
CHAPTER 6
Exercise0•/d31 /d47/d47•0
1•/d31 /d47/d47•10•/d31 /d47/d47•0
1•/d61/d62/d62/d125/d125/d125/d125/d125/d125/d125/d125
•10•/d1
/d32/d32/d65/d65/d65/d65/d65/d65/d65/d65•0
1•/d31 /d47/d47•1
6.1.1:⎡
⎣01
01 0
10 1⎤
⎦⎡⎣01
01 1
10 0⎤
⎦ ⎡⎣01
00 0
11 1⎤
⎦
6.1.31000
01000001
0010⎡
⎢⎢⎢⎣00 01 10 11
0 01000
0 10100
1 00010
1 10001⎤
⎥⎥⎥⎦⎡
⎢⎢⎢⎣00 01 10 11
0 00100
0 11000
1 00001
1 10010⎤
⎥⎥⎥⎦
6.1.4:|0,0/angbracketright+| 1,1/angbracketright√
2|0,0/angbracketright+| 1,0/angbracketright√
2|0,1/angbracketright+| 1,1/angbracketright√
2
6.1.5:/bracketleftBig
|0/angbracketright−| 1/angbracketright√
2/bracketrightBig/bracketleftBig
|0/angbracketright−| 1/angbracketright√
2/bracketrightBig/bracketleftBig
|0/angbracketright+| 1/angbracketright√
2/bracketrightBig/bracketleftBig
|0/angbracketright−| 1/angbracketright√
2/bracketrightBig /bracketleftBig
−|0/angbracketright−|1/angbracketright√
2/bracketrightBig/bracketleftBig
|0/angbracketright−| 1/angbracketright√
2/bracketrightBig
6.1.6: +1|0/angbracketright/bracketleftBig
|0/angbracketright−| 1/angbracketright√
2/bracketrightBig
+1|1/angbracketright/bracketleftBig
|0/angbracketright−| 1/angbracketright√
2/bracketrightBig
−1|1/angbracketright/bracketleftBig
|0/angbracketright−| 1/angbracketright√
2/bracketrightBig(B.93)
Ex 6.1.2: The conjugation of this matrix is the same as the original. If you multiply
it by itself, you get I4.
Ex. 6.2.1: 2(2n),2nC2n−1=(2n)!
((2n−1)!)2and 2.

<<<PAGE 360>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
342 Appendix B Answers to Selected Exercises
Ex. 6.2.2:
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣00,00 0 ,10 1 ,00 1 ,11 0 ,01 0 ,11 1 ,01 1 ,1
00,0 1
00,1 1
01,0 1
01,1 1
10,0 1
10,1 1
11,0 1
11,1 1⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (B.94)
Ex. 6.2.3:
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣00,00 0 ,10 1 ,00 1 ,11 0 ,01 0 ,11 1 ,01 1 ,1
00,0 1
00,1 1
01,0 1
01,1 1
10,0 1
10,1 1
11,0 1
11,1 1⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (B.95)
Ex. 6.2.4: We saw for n=1, the s calar
coefﬁcient is 2−1
2. Assume it is true for n=k.
That is the scalar coefﬁcient of H⊗kis 2−k
2.F o r n=k+1, that coefﬁcient will be
multiplied by 2−1
2to get
2−k
22−1
2=2−(k
2+1
2)=2−k+1
2. (B.96)
Ex. 6.2.5: It depends how far away the function is from being balanced or constant.
If it is close to constant than we will probably get|0/angbracketrightwhen we measure the top
qubit. If it is close to constant, then we will probably get|1/angbracketright. Otherwise it will be
random.
Ex. 6.3.1:/D2000⊕011=011; hence, f(000)=f(011)./D2001⊕011=010; hence, f(001)=f(010)./D2010⊕011=001; hence, f(010)=f(001)./D2011⊕011=000; hence, f(011)=f(000)./D2100⊕011=111; hence, f(100)=f(111)./D2101⊕011=110; hence, f(101)=f(110)./D2110⊕011=101; hence, f(110)=f(101)./D2111⊕011=101; hence, f(111)=f(101).

<<<PAGE 361>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix B Answers to Selected Exercises 343
Ex. 6.4.1: For the function that “picks out” 00, we have
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣00,00 0 ,10 1 ,00 1 ,11 0 ,01 0 ,11 1 ,01 1 ,1
00,0 1
00,1 1
01,0 1
01,1 1
10,0 1
10,1 1
11,0 1
11,1 1⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (B.97)
For the function that “picks out” 01, we have
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣00,00 0 ,10 1 ,00 1 ,11 0 ,01 0 ,11 1 ,01 1 ,1
00,0 1
00,1 1
01,0 1
01,1 1
10,0 1
10,1 1
11,0 1
11,1 1⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (B.98)
For the function that “picks out” 11, we have
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣00,00 0 ,10 1 ,00 1 ,11 0 ,01 0 ,11 1 ,01 1 ,1
00,0 1
00,1 1
01,0 1
01,1 1
10,0 1
10,1 1
11,0 1
11,1 1⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (B.99)
Ex. 6.4.2: The average is 36.5. The inverted numbers are 68, 35, 11, 15, 52, and 38.
Ex. 6.4.3:
(A⋆A)[i,j]=/summationdisplay
kA[i,k]×A[k,j]=/summationdisplay
k/parenleftbigg1
2n×1
2n/parenrightbigg
=2n×/parenleftbigg1
2n×1
2n/parenrightbigg
=1
2n=A[i,j]. (B.100)

<<<PAGE 362>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
344 Appendix B Answers to Selected Exercises
Ex. 6.5.1: 654, 123, and 1.
Ex. 6.5.2: The remainders of the pairs are 1, 128, and 221.
Ex. 6.5.3: The periods are 38, 20, and 11.
Ex. 6.5.4: GCD(76+1,247)=GCD(117650 ,247)=13 and GCD(76−1,247)=
GCD(117648 ,247)=19. 13×19=247.
CHAPTER 7
Ex. 7.2.2:
U1=CNOT ⊗CNOT ;U2=U1⋆U1
=(CNOT ⊗CNOT )⋆(CNOT ⊗CNOT ). (B.101)
CNOT =⎡
⎢⎢⎢⎢⎢⎢⎢⎣1000
01000001
0010⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (B.102)
CNOT ⊗CNOT =⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣1000000000000000
010000000000000000010000000000000010000000000000
0000100000000000
0000010000000000000000010000000000000010000000000000000000001000
0000000000000100
0000000000000001000000000000001000000000100000000000000001000000
0000000000010000
0000000000100000⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦.(B.103)

<<<PAGE 363>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix B Answers to Selected Exercises 345
(CNOT ⊗CNOT )⋆(CNOT ⊗CNOT )=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣1000000000000000
010000000000000000100000000000000001000000000000000010000000000000000100000000000000001000000000000000010000000000000000100000000000000001000000
0000000000100000
00000000000100000000000000001000000000000000010000000000000000100000000000000001⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. (B.104)
Ex. 7.2.3: Observe that Ucan be divided into four squares: the left on top is just
the 2-by-2 identity, the right on top and the left at the bottom are both the 2-by-2
zero matrix, and ﬁnally the right at the bottom is the phase shift matrix R
180. Thus,
U=I2⊗R180, and it acts on 2 qubits, leaving the ﬁrst untouched and shift the phase
of the second by 180.
CHAPTER 8
Ex. 8.1.2: n=1,417,122.
Ex. 8.1.3: The best way to show this is with a series of trees that show how to
split up at each step. If at a point, the Turing machine splits into n>2 states, then
perform something like the following substitution. If n=5, split it into four steps

<<<PAGE 364>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
346 Appendix B Answers to Selected Exercises
as follows:
B
C
A/d71/d71/d14/d14/d14/d14/d14/d14/d14/d14/d14/d14/d14/d14/d14/d14/d62/d62/d126/d126/d126/d126/d126/d126/d126/d47/d47
/d32/d32/d64/d64/d64/d64/d64/d64/d64/d64
/d23/d23/d48/d48/d48/d48/d48/d48/d48/d48/d48/d48/d48/d48/d48/d48D ≡
E
FB
A/d62/d62/d126/d126/d126/d126/d126/d126/d126
/d32/d32/d64/d64/d64/d64/d64/d64/d64/d64C
•/d63/d63/d126/d126/d126/d126/d126/d126/d126/d126
/d31/d31/d64/d64/d64/d64/d64/d64/d64/d64 D
•/d63/d63/d126/d126/d126/d126/d126/d126/d126/d126
/d32/d32/d65/d65/d65/d65/d65/d65/d65/d65 E
•/d62/d62/d125/d125/d125/d125/d125/d125/d125/d125
/d32/d32/d65/d65/d65/d65/d65/d65/d65/d65
F
(B.105)
Ifn=2, then no change has to be made. If n=1, then do the following substi-
tution:
B
A/d47/d47B ≡ A/d62/d62/d126/d126/d126/d126/d126/d126/d126
/d32/d32/d64/d64/d64/d64/d64/d64/d64
B(B.106)
And ﬁnally, if n=0, make the following substitution:
A
A ≡ A/d62/d62/d125/d125/d125/d125/d125/d125/d125
/d32/d32/d65/d65/d65/d65/d65/d65/d65
A(B.107)
Ex. 8.2.1: Following Exercise 8.1.3, every Turing machine can be made into one that
at every step splits into exactly two conﬁgurations. When a real number is generated
to determine which action the probabilistic Turing machine should perform, convertthat real number to binary. Let that binary expansion determine which action to
perform. If “0,” then go up. If “1,” then go down.

<<<PAGE 365>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix B Answers to Selected Exercises 347
Ex 8.3.1: For a reversible Turing machine, every row of the matrix Uwill need to
have exactly one 1 with the remaining entries 0. For a probabilistic Turing machine,
every column of the matrix Uwill need to sum to 1.
Ex. 8.3.3: We see from the table in the text that Grover’s algorithm starts get-
ting quicker somewhere between 10 and 15. A little analysis gives us the following
table:
Classical Brute-Force Search Quantum Grover’s Algorithm
n2nops Time√
2nops Time
10 1,024 0.01024 second 32 0.032 second
11 2,048 0.02048 second 45.254834 0.045254834 second
12 4,096 0.04096 second 64 0.064 second
13 8,192 0.08192 second 90.50966799 0.090509668 second14 1,6384 0.16384 second 128 0.128 second15 3,2768 0.32768 second 181.019336 0.181019336 second(B.108)
Already at n=14, Grover’s algorithm is quicker.
Ex. 8.3.4:
Classical Brute-Force Search Quantum Grover’s Algorithm Search
n n! ops Time√
n! ops Time
5 120 0.0012 second 10.95445115 0.010954451 second
10 3628800 36.288 seconds 1904.940944 1.904940944 seconds
15 1.30767E+12 151.3512 days 1143535.906 0.013235369 days
20 2.4329E+18 770940.1248 years 1559776269 18.05296607 days25 1.55112E+25 4.91521E+12 years 3.93843E+12 124.8012319 years
30 2.65253E+32 8.40536E+19 years 1.62866E+16 516090.7443 years
40 8.15915E+47 2.58548E+35 years 9.0328E+23 2.86232E+13 years50 3.04141E+64 9.63764E+51 years 1.74396E+32 5.52629E+21 years
60 8.32099E+81 2.63676E+69 years 9.12194E+40 2.89057E+30 years
70 1.1979E+100 3.79578E+87 years 1.09447E+50 3.46816E+39 years100 9.3326E+157 2.9573E+145 years 9.66055E+78 3.06124E+68 years125 1.8827E+209 5.9658E+196 years 4.339E+104 1.37494E+94 years(B.109)

<<<PAGE 366>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
348 Appendix B Answers to Selected Exercises
CHAPTER 9
Ex 9.1.1: No. It implies that ENC (−,KE) is injective (one-to-one) and that
DEC (−KD) is surjective (onto).
Ex 9.1.2: “QUANTUM CRYPTOGRAPHY IS FUN.”
Ex 9.2.1:/D2|← /angbracketright with respect to +will be−1|→ /angbracketright ./D2|↓ /angbracketrightwith respect to +will be−1|↑ /angbracketright ./D2|/arrowsouthwest /angbracketright with respect to +will be1√
2|↑ /angbracketright−1√
2|→ /angbracketright ./D2|/arrowsoutheast /angbracketright with respect to +will be−1√
2|↑ /angbracketright+1√
2|→ /angbracketright ./D2|← /angbracketright with respect to Xwill be−1√
2|/arrownortheast /angbracketright+1√
2|/arrownorthwest /angbracketright ./D2|↓ /angbracketrightwith respect to Xwill be−1√
2|/arrownortheast /angbracketright−1√
2|/arrownorthwest /angbracketright ./D2|/arrowsouthwest /angbracketright with respect to Xwill be−1√
2|/arrownortheast /angbracketright ./D2|/arrowsoutheast /angbracketright with respect to Xwill be−1√
2|/arrownorthwest /angbracketright .
CHAPTER 10
Ex 10.1.1: All probabilities piare positive numbers between 0 and 1. Therefore, all
the logarithms log2(pi) are negative or zero, and so are all terms pilog2(pi). Their
sum is negative or zero and therefore entropy is always positive (it reaches zero only
if one of the probabilities is 1).
Ex 10.1.3: Choose p(A)=3
4,p(B)=1
4, and P(C)=p(D)=0. We get H(S)=
0.81128.
Ex 10.2.1: In Equation (10.14), Dis deﬁned as the sum of the projectors |wi/angbracketright/angbracketleftw i|
weighted by their probabilities. If Alice always send one state, say |w1/angbracketright, that
means that all the pi=0, except p1=1. Replace them in Dand you will ﬁnd
D=1|w 1/angbracketright/angbracketleftw 1|.
Ex 10.2.3: Let us ﬁrst write down the density operator:
D=1
2|0/angbracketright/angbracketleft0|+1
6|1/angbracketright/angbracketleft1|+1
6/parenleftbigg1√
2|0/angbracketright+1√
2|1/angbracketright/parenrightbigg/parenleftbigg1√
2/angbracketleft0|+1√
2/angbracketleft1|/parenrightbigg
+1
6/parenleftbigg1√
2|0/angbracketright−1√
2|1/angbracketright/parenrightbigg/parenleftbigg1√
2/angbracketleft0|−1√
2/angbracketleft1|/parenrightbigg
(B.110)
Now, let us calculate D(|0/angbracketright) and D(|1/angbracketright):
D(|0/angbracketright)=2
3|0/angbracketright, and D(|1/angbracketright)=1
3|1/angbracketright. (B.111)
Thus the matrix (we shall use the same letter D) in the standard basis is
D=⎡
⎢⎣2
30
01
3⎤
⎥⎦. (B.112)

<<<PAGE 367>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix B Answers to Selected Exercises 349
Ex 10.4.1: Suppose you send “000” (i.e., the code for “0”). What are the chances
that the message gets decoded wrongly? For that to happen, at least two ﬂips must
have occurred: “110,” “011,” “101,” and “111.” Now, the ﬁrst three cases occur withprobability (0 .25)
2, and the last one with probability (0 .25)3(under the assumption
that ﬂips occur independently).
The total probability is therefore 3 ∗(0.25)2+(0.25)3=0.20312.
Similarly when you send “111.”
CHAPTER 11
Ex 11.1.1: At ﬁrst sight, the pure state
|ψ/angbracketright=1√
2|0/angbracketright+1√
2|1/angbracketright (B.113)
and the mixed state obtained by having |0/angbracketrightor|1/angbracketrightwith equal probability seem to be
undistinguishable. If you measure |ψ/angbracketrightin the standard basis, you will get 50% of the
time|0/angbracketrightand 50% of the time |1/angbracketright. However, if you measure |ψ/angbracketrightin the basis consisting
of|ψ/angbracketrightitself, and its orthogonal
|φ/angbracketright=1√
2|0/angbracketright−1√
2|1/angbracketright, (B.114)
you will always detect |ψ/angbracketright. But, measuring the mixed state in that basis, you will get
|ψ/angbracketright50% of the times and |φ/angbracketright50% of the times. The change of basis discriminates
between the two states.
Ex 11.1.2: Let us carry out the calculation of the average A.|ψ/angbracketrightis, in the standard
basis, of the column vector [1 ,eiθ]T. Thus the average is
A=/bracketleftbig
1,e−iθ/bracketrightbigh
2⎡
⎢⎣01
10⎤
⎥⎦1√
2/bracketleftbig
1,eiθ/bracketrightbigT. (B.115)
Multiplying, we get
A=1
2(e−iθ+eiθ), (B.116)
which simpliﬁes to
A=cos(θ ). (B.117)
Adoes indeed depend on θ, and reaches a maximum at θ=0.

<<<PAGE 368>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
350 Appendix B Answers to Selected Exercises
Ex 11.1.3: Let us compute the tensor product of Sxwith itself ﬁrst (we shall ignore
the factor/planckover2pi
2):
Sx⊗Sx=⎡
⎢⎢⎢⎢⎢⎢⎢⎣0001
001001001000⎤
⎥⎥⎥⎥⎥⎥⎥⎦. (B.118)
We can now calculate the average:
1
2e−iθ+1
2eiθ=cos(θ ) (B.119)
(using the Euler formula). We have indeed recovered the hidden phase θ!

<<<PAGE 369>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix C
Quantum Computing Experiments
with MATLAB
C.1 PLAYING WITH MATLAB
There is no better way to learn than playing. After all, that is how children learn. In
this appendix, we are going to provide the basic guidelines for “playing the quantum
computing game” with the help of the MATLAB environment.
.................................................................................
Reader Tip. This is not a full MATLAB tutorial. We assume that a fully func-
tional version of MATLAB is already installed on your machine and that you know
how to start a session, perform some basic calculations, save them, and quit. Youshould also know what M-ﬁles are and how to load them. For a crash brush up, you
can read the online tutorial by MathWorks: http://www.mathworks.com/academia/
student
center/tutorials/launchpad.html. ♥.................................................................................
C.2 COMPLEX NUMBERS AND MATRICES
We began this book by saying that complex numbers are fundamental for both quan-tum mechanics and quantum computing, so we are going to familiarize ourselveswith the way they are dealt with in MATLAB.
To begin with, we need to declare complex number variables. This is easy: a
complex has a real part and an imaginary part, both double. The imaginary part isdeclared by using the “i” or “j” character.
1For example, to declare the complex
variable c=5+i, just type
/angbracketrightc=5+i
and the computer will respond withc=5.000+1.000 i
1Signal processing engineers tend to use “j” to denote the imaginary unit, hence the notation.
351

<<<PAGE 370>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
352 Appendix C Quantum Computing Experiments with MATLAB
Or, equivalently,
/angbracketrightc=5+j
c=5.000+1.000 i
Adding and multiplying complex numbers are entirely straightforward:
/angbracketrightd=3−2i
d=3−2i
/angbracketrights=c+d
s=8+3i
/angbracketrightp=c∗d
p=25+5i
There is also a handy complex conjugate:
/angbracketrightc1=conj(c)
c1=5.000−1.000 i
You may get the real and imaginary parts of a complex number by typing
/angbracketrightre=real(c)
re=5
/angbracketrightim=imag (c)
im=5
One can switch from Cartesian representation to polar representation:
/angbracketrightr=abs(c )
r=7.0711
/angbracketrightangle(c)
ans=0.78540.
And back from
polar to Cartesian:
/angbracketrightc1=r∗exp(i∗a)
c1=5.0000+5.0000 i
It is extremely useful to plot a complex number. MATLAB has a lot of tools
for mathematical visualization. We are going to present just one option here: the
function compass :
/angbracketrightcompass(re, im)
The computer will output a picture of a complex number as an arrow as in Figure 1.1on page 16. The compass function plots the complex number as a vector springingfrom the origin. The function can take several complex vectors at once (refer to the
online MathWorks documentation).

<<<PAGE 371>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix C Quantum Computing Experiments with MATLAB 353
Our second ingredient is complex matrices. MATLAB is extremely powerful in
dealing with matrices; indeed, the name MATLAB means MATrix LABoratory .
What about vectors? Well, vectors are matrices.2Nevertheless, ﬁrst things ﬁrst, so
let us start with row and column vectors:
/angbracketrightbra=[1,2−i,3i]
br a=1+0i2−1i0+3i
/angbracketrightket=bra/prime
1+0i
2+1i
0+3i
As you can see, the operator/primeon a complex matrix M is its complex conjugate (if
the matrix is real, it is simply the transpose).
For the dot product (bra-ket), you just multiply them (there is, however, a dot( )
function):
/angbracketrightbra∗ket
ans=15
The norm function is built-in:
/angbracketrightnorm(ket)
ans=3.8730
So much for vectors. Let us declare a matrix, say, Hadamard:
/angbracketrightH=1/sqrt(2) ∗[11;1−1]
H=
0.70711 0 .70711
0.70711 −0.70711
Now, we can calculate its inverse (as we found out already, H happens to be its
own inverse):
/angbracketrightinv(H)
ans=
0.70711 0.70711
0.70711 −0.70711
MATLAB provides a trace function:
/angbracketrighttrace(H)
ans=0
The product is straightforward. (Caveat: If you make a dimensional mismatch,
MATLAB will return an error!)
2A big caveat: In MATLAB matrices and vectors start at 1, not 0!

<<<PAGE 372>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
354 Appendix C Quantum Computing Experiments with MATLAB
/angbracketrightH∗I
ans=
0.70711 0.70711
0.70711 −0.70711
We have met the tensor product several times throughout our text. Luckily,
there is a primitive for it: it is called kron , as the tensor product of matrices is often
referred to as the Kronecker product:
/angbracketrightkron(H, I)
ans=
0.70711 0.00000 0.70711 0.00000
0.00000 0.70711 0.00000 0.70711
0.70711 0.00000 −0.70711 −0.00000
0.00000 0.70711 −0.00000 −0.70711
We have used eigenvalues and eigenvectors throughout our text. How to com-
pute them? Worry not! MATLAB comes to rescue. The command [E, V] =eig(M)
returns two matrices: E, whose columns are the eigenvectors of M, and V, a diagonal
matrix whose diagonal elements are the eigenvalues of M.
/angbracketright[V,D]=eig(H)
V=
0.38268 −0.92388
−0.92388 −0.38268
D=
−10
01
There is so much more to aid
you in complex algebra. A quick Google search
will showcase numerous tutorials on complex matrices manipulation. You can alsoﬁnd more by typing HELP at the prompt.
C.3 QUANTUM COMPUTATIONS
We are now ready for quantum computation. Here, we have two options: the ﬁrst
one is to implement step by step a quantum computer emulator, following the indi-
cations of Section 7.4.
The second option is to learn how to use an existing emulator, and read the
source code (MATLAB applications are collections of M-ﬁles, it is quite easy to in-spect them and modify the code as we deem ﬁt). There are a few quantum emulators
in MATLAB. A very good and quite documented library is Quack , developed by
Peter Rohde at the Department of Physics of University of Queensland, Australia.
We are going to show a few things that Quack can do, and then it is your game: you
can download it, learn the few examples, and start playing right away.
3
3Although Quack is not at present a huge library, it is not a toy either. It contains functionality forquantum computation that goes beyond the scope of this book. But do not get deterred: you can usewhat you need, and perhaps, learn more as you go along.

<<<PAGE 373>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix C Quantum Computing Experiments with MATLAB 355
The ﬁrst thing one needs to do is to initialize Quack:
/angbracketrightquack
Welcome to Quack !version pi /4fo r MA TL AB
by Peter Rohde
Centre f or Quantum Computer Technology ,Br i s bane ,Australia
http ://www. physics .uq.edu.au/people /ro hde /
Now, we initialize a two-qubit register to the ground state(|00/angbracketright):
/angbracketrightinit state(2)
Just for fun, let us change the ﬁrst qubit
/angbracketrightprepare one(1)
To see what happens, print the circuit history:
/angbracketrightprint hist
{
[1,1]=|1>−
[2,1]=|0>−
}
Note: Ignore the left side of the circuit (it is there just to keep track of which cells
contain the information). The right side of the equation contains the entry points
of the circuit (in this case two qubits, initialized to |1/angbracketright, and |0/angbracketrightrespectively). As we
shall see momentarily, the circuit grows by concatenating gates and measurements.
Let us measure now the ﬁrst qubit:
/angbracketrightZmeasure(1)
ans=−1
and the second:
/angbracketrightZmeasure(2)
ans=1
Notice that the answer is −1f o r|1/angbracketrightand 1 for |0/angbracketright. This may be a bit confusing at
ﬁrst, but is consistent with the spin notation: |1/angbracketrightsimply means spin down along the
zaxis.
/angbracketrightprint hist
{[1,1]=|1>−<Z|−−−−−
[2,1]=|0>−−−−− <Z|−
}
How about applying a controlled-NOT using the ﬁrst qubit as control?
/angbracketrightcnot(1,2)
Better check what is happening . . .
/angbracketrightprint
hist

<<<PAGE 374>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
356 Appendix C Quantum Computing Experiments with MATLAB
{
[1,1]=|1>−<Z|−−−−− o−
[2,1]=|0>−−−−− <Z|−X−
}
And now let us apply Hadamard on the second qubit:
/angbracketrightH(2)
/angbracketrightprint hist
{
[1,1]=|1>−<Z|−−−−− o−−−
[2,1]=|0>−−−−− <Z|−X−H−
}
What if we liked to shift the phase of the ﬁrst qubit? T (see Section 5.4, it is there
for you):
/angbracketrightT(1)
/angbracketrightprint hist
{
[1,1]=|1>−<Z|−−−−− o−−− T−
[2,1]=|0>−−−−− <Z|−X−H−−−
}
Let us perform some measurement. This time we are going to measure the sec-
ond qubit, again along the z axis (i.e., in the standard basis):
/angbracketrightZmeasure(2)
ans=1
Hint: Pause a moment, jot down the steps, and try to follow what happened.
We have written a simple circuit, provided an input, and measured the results.
Now it is all up to you: there are plenty of other gates, initialization routines, and
measurement options in Quack, which you can dig up by reading the documenta-
tion. Investigate what is already there and play. (By the way, Quack can be easilyextended in a number of ways. For instance, you can provide a simple GUI for de-
signing circuits. You may want to start a mini project and create your personalized
quantum computing lab).
Have fun!

<<<PAGE 375>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix D
Keeping Abreast of Quantum News:
Quantum Computing on the Weband in the Literature
Jill Cirasella
This book covers many major developments in quantum computing, but the ﬁeld is
still young, and there will no doubt be many more developments in the future. Thesefuture developments will include research discoveries, of course, but they will also
include trends in industry, surges in media coverage, and tides of public interest.
This appendix describes tools that can help you track quantum developments of allkinds.
D.1 KEEPING ABREAST OF POPULAR NEWS
There are scores of newspapers, magazines, and other popular news sources, anyone of which might run a story about the newest quantum development. How willyou know if one does? You can keep an eye on your favorite news sources, but youwill miss many stories that way. A better tactic is to use a news aggregator, such
as Google News ( http://news.google.com/), which allows you to search current and
past stories from a multitude of news sources. You can add Google News to your
stable of frequently visited sites, but the most efﬁcient way to use it is to set up an
alert or RSS feed and let the news come to you. After you perform a Google News
search that yields good results, simply click “Alerts” to set up an alert that will notifyyou by e-mail of new stories that satisfy your search. Alternatively, click “RSS” to
set up an RSS feed that will deliver those stories directly to your RSS reader.
In addition to the mainstream news, blogs devoted to quantum topics can be
excellent sources of information. In fact, a blog whose focus overlaps with your in-
terests can serve as a compass for navigating quantum news. Because new blogs
are started all the time and existing blogs are often left to languish, there is little
point in recommending individual blogs. Use tools such as Technorati ( http://www.
technorati.com/) and Google Blog Search (http://blogsearch.google.com/) to search
for blog posts of interest and to identify blogs worth reading regularly. Look for
blogs that offer insightful analyses of news stories and easy-to-understand distilla-tions of scientiﬁc discoveries.
Occasionally, you will need to step back from the news and brush up on back-
ground information. The best site for refreshers is Quantiki (http://www.quantiki.
357

<<<PAGE 376>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
358 Appendix D Keeping Abreast of Quantum News
org/), a wiki with tutorials and encyclopedia-style articles about quantum informa-
tion. As with all wikis, anyone can edit Quantiki entries, which means that anyone
can (knowingly or unknowingly) insert errors, inconsistencies, and nonsense. So, al-though Quantiki is full of valid and valuable information, you cannot assume thateverything written there is correct. In other words, Quantiki is a wonderful and
informative site, but if you need to be absolutely certain of something, look it up
somewhere else too. The same is true of the popular, omnidisciplinary Wikipedia(http://en.wikipedia.org/), which is pocked by errors and vandalism but nevertheless
has some excellent entries on quantum computing.
D.2 KEEPING ABREAST OF SCIENTIFIC LITERATURE
Are news articles, wiki entries, and blog posts sufﬁcient to satisfy your curiosity?
Or do you want to track a topic more closely and read about developments in re-searchers’ own words? If the latter, familiarize yourself with one or more of the
following tools for tracking the scholarly literature of quantum computing. (For tips
on how to read scientiﬁc articles, see Appendix A.) The single best source for up-to-the-minute articles about quantum computing is arXiv (http://arxiv.org/), an online
archive of hundreds of thousands of scientiﬁc articles. Among quantum computing
researchers, there is a strong culture of sharing articles on arXiv as soon as they arecompleted, often months (sometimes years) before they are published in journals or
conference proceedings.
There are several ways to use arXiv to stay current with quantum computing.
You can periodically visit arXiv and search for articles relevant to your interests.
Alternatively, you can browse recent additions to arXiv’s quantum physics archive,
quant-ph, which includes quantum computing articles. If you prefer automatic noti-
ﬁcations, you can sign up for arXiv’s e-mail listing service or subscribe to the RSSfeed of new quant-ph submissions.
Because articles on arXiv are posted by their authors, the articles have not been
vetted by peer reviewers or cleaned up by editors. That said, arXiv has an endorse-ment system for authors, so there is some assurance that articles on arXiv are written
by reliable researchers.
Posting to arXiv is voluntary, and some researchers do not, or do not always,
post their articles. Thus, arXiv is not a comprehensive record of quantum computing
research; indeed, no single resource is a comprehensive record of the ﬁeld. That
said, there exist databases that index all articles published in high-quality science
journals. These databases are excellent aids to anyone who wants to systematicallytrack research on a certain topic or focus on ﬁndings that have passed a stringent
peer review process. The two biggest and best databases of this kind are Scopus and
Web of Science, both extraordinarily expensive and therefore usually available onlythrough academic libraries. If you have access to Scopus or Web of Science, you can
periodically visit and perform searches, or you can perform a search once and then
turn that search into an e-mail alert or RSS feed. If you are interested in multipletopics, you can set up multiple e-mail alerts or RSS feeds.
If you do not have access to either of these databases, your best option is Google
Scholar (http://scholar.google.com/), a free Google tool for searching for journal

<<<PAGE 377>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix D Keeping Abreast of Quantum News 359
articles and other kinds of scholarly literature. Google Scholar’s coverage has gaps
and its search features are not very sophisticated, but it is nevertheless remarkably
powerful and delightfully easy to use.
Once you ﬁnd out about an article, how do you ﬁnd the article itself? Sometimes,
the tool that makes you aware of the article’s existence also leads you to the text
of the article. For example, arXiv contains not just information about articles but
also the articles themselves. But this is not always the case. For example, although
Scopus and Web of Science contain a wealth of information about articles, they donot contain actual articles. In other words, they are indexing databases, not full-text
databases. Meanwhile, Google Scholar is a hybrid: some results link to the full text
of articles, some link to abstracts, and some are just citations with no links.
Luckily, many libraries subscribe to numerous full-text databases and employ
tools that link from article citations to articles themselves. As a result, the full text ofan article is often only a few clicks away from the article information in Scopus, Webof Science, or Google Scholar. Of course, different libraries subscribe to differentdatabases and choose different technologies for linking between databases; ask your
librarian about the tools available to you. Also, keep in mind that most journals are
available both electronically and in print. If your library does not have electronicaccess to the article you want, it might have a print copy; again, talk to your librarian
about how to determine deﬁnitively whether or not your library has a certain article.
Inevitably, your library will not have every article you want – what then? Perhaps
the article (or a version of it) is freely available on arXiv, the author’s homepage,an institutional repository, or elsewhere. In general, a search of both Google and
Google Scholar is sufﬁcient to determine whether an article is freely available on-line. If you do not ﬁnd the article but do ﬁnd a publisher’s page offering to sell youthe article, do not pay! Rather, request the article through interlibrary loan, a free
service at many libraries.
D.3 THE BEST WAY TO STAY ABREAST?
No single tool is sufﬁcient to keep you fully informed about quantum computing.
Different tools have different strengths, and you should familiarize yourself with
those that best satisfy your needs and curiosities. For example, if you are tracking
a speciﬁc problem or technology, scientiﬁc articles are best. Furthermore, if youvalue seeing new research as soon as it is released, keep an eye on arXiv. If you arecurious about which developments cause a stir and how they ﬁt into scientiﬁc and
social contexts, pay attention to popular news stories and quantum blogs.
If your interest in quantum computing is casual, stay abreast however and when-
ever suits you. But if quantum computing is your passion or specialty, read broadly.You never know what will excite your curiosity, provide an insight, or inspire a big
idea.

<<<PAGE 378>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix E
Selected Topics for Student Presentations
Although its history is relatively recent, quantum computing is already, by all stan-
dards, a very broad area of research. There is simply no way we can cover anythingmore than a relatively small fraction of its interesting topics. There are also many
fascinating themes that are not exactly part of quantum computing per se, but are
nevertheless closely related to it.
In this appendix, we list a number of suggestions for further exploration, cover-
ing some items we omitted from our text. It is our sincere hope that students willﬁnd them useful for their presentations or perhaps inspire them to select others thatthey can discover on their own.
Note to the student: Now it is your turn! The best way to really learn something is
to teach it. There is no substitute for spending hours preparing a lecture and getting
ideas straight so that you can present them. Knowing that other people will be asking
you questions and learning from you will force you to understand the material at adeeper level.
You are urged to choose a subject from an area that you ﬁnd interesting. Much
time and energy is going to be spent learning, understanding, and preparing, so youmight as well enjoy your choice from the start.
For each of these topics, there are many different levels on which you can go
about making a presentation. You can present a superﬁcial lecture in which the bareoutline of the idea is discussed, or you can get into the “nitty-gritty” of the techni-cal details. Obviously, the superﬁcial route is the easier one, but not much will be
gained from such an exercise. We urge you to understand and present a topic with
the utmost detail and depth. A presentation with a lot of hand waving is noticeablydeﬁcient. In contrast, one with equations and nice diagrams demonstrates under-
standing and knowledge. Do not just throw a few equations on the blackboard: show
how they are derived. Develop charts and diagrams. Obviously, if the presentationis done in a classroom setting, there are time considerations as well.
How do you go about preparing for such a task? The ﬁrst thing to do is to look for
a popular account of the topic. This can be in a nontechnical magazine or on Webpage. Some of the subjects are historical; hence, a look into a few encyclopedias
360

<<<PAGE 379>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix E Selected Topics for Student Presentations 361
might be helpful. Many nontechnical articles have suggestions for further reading.
Once an introductory article is understood, you should move on to deeper, more
detailed material. This is the safest and most effective way for you to go forward in
your research.
Note to the teacher: If you are going to insist that students make presentations, we
recommend that they choose their topics as early as possible in the semester. The
more time they are given to prepare, the better the presentation will be. One pos-
sible way of arranging this is to have your students give their presentations at the
end of the semester. There is, however, another way. You can have students’ pre-sentations scattered throughout the semester at the appropriate times. For example,
when Chapter 4 is done, you might have a student lecture on the different ways of
interpreting quantum theory (Presentation E.4.1). Before starting Shor’s algorithm,a student might make a presentation on RSA (Presentation E.6.4) or classical fac-toring algorithms (Presentation E.6.3). This will explain the importance of Shor’s
algorithm and place it in its historical context. Having the presentations through-
out the semester demands a lot of ﬂexibility and juggling from the teacher and thestudents (they have to present them at the time you prefer) but it can be done.
We have found that some students get lost in the morass of literature on a sub-
ject (regrettably, in this Web-centered world, to many students “doing research”means going to Google’s home page). We suggest that a few weeks after the stu-
dents choose their topics, a private meeting be held with each one during which
they present the articles they plan to use. At that meeting, they can also be told howmuch depth is expected from their presentation.
Note on the presentations: For each topic discussed, we/D2give a short explanation of what the topic is and how it is related to quantum
computing (when it is not obvious);/D2give a short list of possible subtopics to include in your presentation; and/D2recommend some starting places to look for information about the topic.
Our list is arranged to follow the chapters of the text. However, there are many
items that could have easily ﬁt in other places as well. It is important to realize that
our list is in no way comprehensive. There are many other areas that we could havementioned but did not. Feel free to ﬁnd your own topic of choice.
E.1 COMPLEX NUMBERS
E.1.1 The History of Complex Numbers
We use complex numbers to help us describe parts of quantum theory. However,complex numbers have a long and distinguished history (they go back to the six-
teenth century). At ﬁrst they began as a mathematical curiosity, but as time went
on, researchers progressively realized that complex numbers are ubiquitous and im-portant.
Make sure your presentation contains the basic facts about some of the main
players in this ﬁeld and what their contribution was.

<<<PAGE 380>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
362 Appendix E Selected Topics for Student Presentations
A good place to start is any of the many history of mathematics textbooks avail-
able, such as Eves (1976). Might we also suggest Mazur (2002) and Nahin (1998).
E.1.2 Geometry of the Complex Plane
In Section 1.3, we brieﬂy introduced some basic complex functions, such as the expo-
nential and polynomials. Maps from the complex plane to itself have a geometry: for
instance, the map x/mapsto−→ x+c0, where c0is a constant complex number, represents
a translation of the plane.
In this presentation you should describe in detail (with examples!) the geometry
of simple complex maps, such as the square function, exponential, and inverse. Someof this can be presented nicely with a computer graphics presentation.
Any basic textbook in complex analysis will do, but perhaps the classic Geometry
of Complex Numbers (Schwerdtfeger, 1980) is the best entry point.
E.1.3 The Riemannian Sphere and M ¨obius Transformations
The complex plane can be turned into a sphere! Indeed, by adding a point at inﬁnity,we can identify the plane with the so-called Riemann sphere. This is a representation
that is both pervasive and extremely fruitful in thinking of the complex domain. The
Riemann sphere model is not static: some special complex maps turn into rotationsof the sphere. We have brieﬂy met such maps at the end of Chapter 1: the M ¨obius
transformations.
In your presentation you should explicitly describe the charting map from the
extended complex plane to the sphere in details, and then proceed to illustrate thebasic rotations of the sphere (use examples!).
The same references of the previous item apply here (in fact, Presentations E.1.2
and E.1.3 could be done in sequence).
E.2 COMPLEX VECTOR SPACES
E.2.1 Matrices in Computer Graphics
Many of the ideas from linear algebra that we needed for quantum computingare also used for computer graphics. States of a graphical system are representedby vectors and two- and three-dimensional transformations are represented by
matrices.
Assuming the linear algebra presented in Chapter 2, one can proceed with a nice
presentation describing the way researchers who deal with computer graphics workwith these ideas. A nice computer presentation is always pleasant.
A good place to start is any comprehensive computer graphics textbook.
E.2.2 History of Vector Spaces
Although the ideas of vector spaces in particular and linear algebra in general
seem simple now, their development was a long and torturous path. The ideas of

<<<PAGE 381>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix E Selected Topics for Student Presentations 363
higher-dimensional vectors were greeted with skepticism and ridicule. Eventually
the mathematics and physics communities saw the importance of these ideas and
embraced them completely.
A nice presentation should include a mini biography of some of the main players
and what they accomplished. A talk should include the work of Sir William Rowan
Hamilton, Hermann Grassmann, Josia Gibbs, and several others.
A good place to start is one of the many history of mathematics textbooks avail-
able, such as Eves (1976). There is a also a fascinating history of this subject byMichael J. Crowe (1994), which is deﬁnitely worth the read.
E.3 THE LEAP FROM CLASSICAL TO QUANTUM
E.3.1 Huygens’ Principle and Wave Mechanics
The concept of interference has a long history. In 1678 the Dutch physicist Christi-aan Huygens presented the wave theory of light, a model that dominated optics up
to the discovery of quanta. In his revolutionary treatise, Huygens described the way
a wave front propagates – the so-called Huygens’ principle . In the early 1900s the
English physicist Thomas Young introduced the double-slit experiment, which we
have encountered in Chapter 3. This seminal experiment validated the wave model
of light.
In this presentation you should clearly articulate the evolution of wave mechan-
ics from Huygens to Schr ¨odinger, and illustrate with diagrams how it explains known
optical phenomena such as refraction and interference.
References? Plenty. Any good physics text will do. But, if we have to recom-
mend a single book, perhaps Wave Phenomena by D.H. Towne is the one (Towne,
1989).
E.3.2 Quantum Erasers
With the understanding of the double-slit experiment, one can move on to one ofthe most fascinating experiments at the cutting edge of research. In the double-slit
experiment, the photon passes through both slits simultaneously. Now consider a
way of “tagging” the photon so that we would know which slit the photon wentthrough. Such a “tagging” would eliminate the interference phenomenon. Now con-sider what would happen if we had some type of way to “erase” or remove the “tag”
once the photon passed the slits. In that case, the photon would have the interfer-
ence phenomenon. The amazing part is that whether or not a photon will go intoboth slits will depend on whether the “eraser” is present after it passes through the
slit(s).
A presentation should explain the types of tags and erasers used. Some nice
diagrams are a good idea. There are also many variations and improvements to this
experiment that should be discussed. This is also related to the Elitzur–Vaidman
bomb-tester experiment.
There are many articles in popular science magazines. They can point to more
technical articles.

<<<PAGE 382>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
364 Appendix E Selected Topics for Student Presentations
E.4 BASIC QUANTUM THEORY
E.4.1 Interpreting Quantum Theory
There are many different schools of thought of how one should interpret some of
the less classical aspects of quantum theory. Some examples of the more popularschools are Bohr’s Copenhagen interpretation, Everett’s many worlds interpreta-
tion, and Bohm’s wave function interpretation (to name a few). Many questions in
the foundations of quantum theory come down to asking what really exists and whatdoesn’t, the so-called ontological issues. Other issues are the measurement problem
and how should one interpret nonlocality.
A presentation should include several of these different schools and how they
deal with a few of the foundational issues of quantum mechanics.
There are many popular books on the topic, e.g., Herbert (1987) or Pagels
(1982). There are also a few great articles on the Web at the Stanford Encyclopedia
of Philosophy . These articles should lead you to more detailed articles. Any of the
books by Roger Penrose (1994, 1999, 2005) would be worth looking into.
E.4.2 The EPR Paradox
In 1935, Albert Einstein and two younger colleagues wrote a paper entitled
“Can quantum-mechanical description of physical reality be considered complete?”Einstein, Podolsky, and Rosen (1935). In this short paper, the authors give a simple
thought experiment in which they attempt to prove that quantum mechanics as we
have it is incomplete. They do this by considering two particles “entangled” and go-ing off in two directions. By measuring one particle, one can determine facts aboutthe other particle without disturbing it.
A presentation should include the historical context of the thought experi-
ment (Schr ¨odinger’s observation about entanglement); conservation of momentum;
Bohm’s version of the thought experiment (conservation of spin); how EPR relates
to the tensor product of two Hilbert spaces; a discussion of hidden variables; and
possible solutions to the paradox.
A nice place to start looking into this is a paper on Stanford Encyclopedia of
Philosophy by Arthur Fine that is very readable. See also Pagels (1982). The original
EPR paper is not too difﬁcult.
E.4.3 Bell’s Theorem
In 1964, John Bell wrote a paper (Bell, 1964, reprinted in Bell, 1987) that took theEPR paradox one step further. Bell shows that by doing some statistical analysis on
measurement of two entangled particles, one can show that quantum mechanics is
fundamentally nonlocal.
A presentation should include the explanation of the terms local, nonlocal; what
is the inequality; some variations of the inequality; Clause and Aspects experiments;and variations of the experiments.
There is a short discussion of Bell’s theorem in Section 9.4. There is much popu-
lar literature on this topic. Alas, much of it is silly and resorts to cheap “mysticism.”

<<<PAGE 383>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix E Selected Topics for Student Presentations 365
For two nice presentations, see Pagels (1982) and Gribbin (1984). That should get
you started.
E.4.4 Kochen–Specker Theorem
This is one of the most powerful and shocking theorems in the foundations of quan-
tum theory. Quantum mechanics says that before a measurement, a property is in asuperposition of basic states. Only after a measurement is there a collapse to a basic
state. One might be tempted to say that a property is really in an unknown basic
state before a measurement and the observer ﬁnds what basic state it was in after
measurement. The Kochen–Specker theorem shows that it is impossible for this to
be true. Before a measurement, the spin of a particle is in a superposition until it is
measured.
Begin by explaining why the theorem is important. The theorem is proven by
looking at a graph-coloring problem. A formal proof of this statement would be too
complicated. However, giving nice geometrical intuitive pictures would be helpful.
Show that it is possible to color the graph in two dimensions and then show how“there is not enough room” in three dimensions. Kernaghan’s proof (Kernaghan,
1994) with 20 vectors is fairly easy to present.
Unfortunately, there is a dearth of easy literature on this important theorem. A
good place to start looking is a nice article by Carsten Held in the Stanford Encyclo-
pedia of Philosophy .
E.4.5 Schr ¨odinger’s Cat
This is a thought experiment that shows that the quantum weirdness of the micro-
world can cross over into the macroworld. By looking at a fairly mischievous con-traption where a cat is placed in a box with a radioactive particle that is in a su-
perposition of being “half-way” alive and “half-way” dead, the cat is placed in a
superposition of being “half-way” alive and dead.
A presentation should include the basic construction; some history of the
thought experiment; some variations of the ideas; a discussion of “Wigner’s Friend”;and some possible answers to this puzzle. Do not harm any animals while makingyour presentation!
There are many popular articles and books that one can start looking into, e.g.,
Herbert (1987) and Gribbin (1984).
E.5 ARCHITECTURE
E.5.1 Maxwell’s Demon, Landauer’s Principle, and the Physics
of Information
These are several ideas at the crossroads of information theory and statistical me-
chanics. Maxwell’s demon is a seeming paradox that shows that one can create en-
ergy with information. Landauer’s principle concerns itself with the relationship ofenergy and erasing information. Both of these ideas are the starting point to a ﬁeld
that is called the physics of information. The basic theme of this ﬁeld is studying

<<<PAGE 384>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
366 Appendix E Selected Topics for Student Presentations
information from the physical point of view and studying physics from the informa-
tional point of view. One of their oft-quoted mottos is “It from bit,” i.e., the physical
world is created from information. David Deutsch has taken this idea a little further
and written a paper (available on the Web) titled “It from qubit.”
A presentation can be historical. Go through the major players in this story and
the advances they made.
There are several papers by Charles H. Bennett and Rolf Landauer freely avail-
able on the Web, e.g., Bennett (1988) and Landauer (1991). David Deutsch’s “Itfrom qubit” is available. There is also an excellent book titled Grammatical Man:
Information, Entropy, Language and Life by Jeremy Campbell (1982). It is a popu-
lar history of information theory. Deﬁnitely worth reading!
E.5.2 Classical Reversible Computation
With the ideas about energy use and losing information, several researchers wenton to develop machines that are reversible and theoretically do not use energy.
A presentation can show some basic circuits; some reversible algorithms; and a
discussion of the actual physical implementations of reversible computations andsome of the problems they had.
There are many popular articles that are good places to start. See also Bennett’s
history of reversible computation (Bennett, 1988).
E.5.3 More Quantum Gates and Universal Quantum Gates
In the text we talked about several different quantum gates (Toffoli, controlled-NOT, Pauli, etc.). There are, however, many others.
A well-rounded presentation should include a list of new quantum gates, as well
as their actions. For one-qubit gates, the geometry of their action on the Blochsphere should be articulated (a large children’s ball and a magic marker is a must
for this presentation!).
There are also many other results concerning which sets of gates form universal
sets. Here, you should identify one or two universal sets and explicitly show howfamiliar gates can be obtained from them. For instance, how can you get a pair of
qubits maximally entangled from your chosen universal set?
The best place to begin is Nielsen and Chuang (2000).
E.6 ALGORITHMS
E.6.1 Probabilistic Algorithms
Some of the algorithms given in our text have a probabilistic ﬂavor to them. Manystudents might be unfamiliar with this programming paradigm. It turns out that for
certain problems if one does some clever guessing, there are ways of solving algo-
rithmic problems.
A presentation should contain a few different algorithms; what they solve; what
is a classic deterministic algorithm to solve the same problem; a comparison of com-
plexity issues. A few computer simulations are easy.

<<<PAGE 385>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix E Selected Topics for Student Presentations 367
A nice place to start looking for such algorithms are in Chapter 5 of Corman
et al. (2001). There is also a more theoretical discussion in Chapter 10 of Sipser
(2005).
E.6.2 Hidden Subgroup Problem
All the algorithms presented in this text, besides Grover’s algorithm, can be stated
as examples of a single computational problem. Some familiarity with basic grouptheory is necessary for the statement of this problem.
Deﬁnition E.6.1 (The Hidden Subgroup Problem). Given a group G and a set func-
tion f :G−→ S such that we are assured that there exists a subgroup H ⊆G such
that f factors through the quotient G /H, i.e.,
G f/d47/d47
/d33/d33/d66/d66/d66/d66/d66/d66/d66/d66/d66/d66/d66/d66/d66/d66/d66/d66/d66S
G/H/d62/d62/d124/d124/d124/d124/d124/d124/d124/d124/d124/d124/d124/d124/d124/d124/d124/d124/d124(E.1)
or in other words, that f is constant on different cosets of G, the goal is to ﬁnd H.
Notice that this is a computational problem and not really a mathematical prob-
lem. Mathematically, His simply f−1(f(e)).
A presentation should include a statement and an explanation of the problem;
how each of the algorithms in Chapter 6 (besides Grover’s) can be seen as an in-stance of the problem; methods used to solve the general problem.
A good place to begin is Nielsen and Chuang (2000) and Hirvensalo (2001).
E.6.3 Classical Factoring Algorithms
Shor’s algorithm is the ﬁrst algorithm that can factor numbers in polynomial time.However, there are classical algorithms that factor large numbers. One of the algo-rithms is Pollard’s rho heuristic. There are several others.
The presentation should have a nice statement of the problem; some discussion
of the mathematical preliminaries necessary to understand the algorithm; the al-gorithms themselves; and the expected running time of the algorithm. One shouldalso discuss how large are the numbers that can successfully be factored by such an
algorithm. A computer implementation would be nice.
A nice place to start looking for material is Section 31.9 of Corman et al.
(2001).
E.6.4 Fourier Transforms
In the text, we mentioned the Fourier transform with its use in Shor’s algorithm.There are, however, many other uses for the Fourier transform in computer science.

<<<PAGE 386>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
368 Appendix E Selected Topics for Student Presentations
They are used for multiplying numbers more efﬁciently; they are used to ﬁnd pat-
terns; and many other tasks.
A presentation should go through different versions of the Fourier transform
such as the discrete Fourier transform, the fast Fourier transform, the quantumFourier transform. A discussion of complexity issues is also important. Mention al-gorithms that use Fourier transforms. A computer simulation of one or more algo-
rithms is not hard.
A few good places to start looking are Chapter 7 of Baase (1988), Chapter 30
of Corman et al. (2001), or Chapter 2 of Dasgupta, Papadimitriou, and Vazirani(2006).
E.7 PROGRAMMING LANGUAGES
E.7.1 SQRAM: A Full-Fledged Quantum Assembler
As we wrote in Chapter 7, our q-assembler is just a toy language to introduce thebasic concepts of q-programming. There is, however, at least one attempt to de-
scribe a concrete full-ﬂedged quantum assembler that would run on a special typeof QRAM, the so-called sequential QRAM, or SQRAM.
After carefully reading Nagarajan, Papanikolaou, and Williams (2005), you
should present the SQRAM model in detail, as well as the language it supports.Perhaps you could write a few simple programs for illustration purposes, and de-
scribe how the SQRAM machine executes them.
Can you think of additional desirable features?
E.7.2 QCL and Q: A Comparison
The languages by ¨Omer and Bettelli are two successful attempts to design an imper-
ative quantum language. They share a number of similarities, but also some differ-ence in the basic design philosophy.
Your presentations should clearly describe the basic features of the two propos-
als, and make explicit their intent.
The main references are ¨Omer (2000) and Bettelli, Calarco, and Seraﬁni (2001).
In an interview in R ¨udiger (2007), ¨Omer and Bettelli have presented their views on
designing a quantum programming language.
E.7.3 Functional Quantum Programming: QML
As we mentioned in passing in Section 7.3, quite recently there was a new proposalof a quantum functional language, known as QML, which attempts to provide quan-
tum control constructs. Try to present its syntax and discuss its quantum controlfeatures, particularly the “quantum if.” Do these constructs qualify for quantum
control?
This presentation should be undertaken by students who have had some previ-
ous exposure to functional programming, and possibly to Haskell.
There is an entire Web site dedicated to this language, where you can ﬁnd all
necessary references (and more): http://sneezy.cs.nott.ac.uk/QML.

<<<PAGE 387>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix E Selected Topics for Student Presentations 369
E.8 THEORETICAL COMPUTER SCIENCE
E.8.1 Primality Testing
Primality testing is concerned with telling if a given positive integer is a prime num-
ber or a composite number. With the knowledge of all the complexity classes men-tioned in Sections 8.1 and 8.2, it is interesting to look at one problem and see how,
over the past several decades, progress has been made in solving this problem. Al-
though this problem is related to the factoring problem, it should not be confusedwith it. Obviously if a number is prime, there will not be any nontrivial factors.
However, primality testing is a decision problem and factoring is a search problem.
A presentation should include some early results of primality testing, i.e., that it
is in coNP (obvious) and NP(Pratt certiﬁcates) and then at least state some of the
algorithms that show the problem is in the probabilistic polynomial time complexity
classes. A presentation should conclude with the recent result that PRIMES is, infact, in P.
Some early results are shown in Corman et al. (2001). There is a nice discussion
of probabilistic complexity classes and primality testing in Papadimitriou (1994) andSipser (2005). The result that PRIMES is in Pis in Agrawal, Kayal, and Saxena
(2004).
E.8.2 Quantum Finite Automata
One of the simplest types of computing machines is ﬁnite automaton. These aresimple (virtual) devices that can recognize regular languages. Just as there is a gen-eralization of a classical Turing machine to a quantum Turing machine, so too, there
is a generalization of the notion of a classical ﬁnite automaton to a quantum ﬁnite
automaton (QFA).
A presentation should include a clear deﬁnition of a QFA; a discussion of the
different types of QFAs; what type of languages they recognize; their relationshipswith quantum Turing machines, quantum pushdown automata, and classical two-way ﬁnite automata.
Information for such a presentation will be mostly found in research articles
easily found on xxx.lanl.gov.
E.8.3 QUANTUM ORACLE COMPUTATIONS
One of the more advanced topics in theoretical computer science is oracle compu-tation; that is, the study of one type of computation “relative to” another. The extra
knowledge given by an oracle changes the basic facts about complexity classes. For
a given complexity class Cand an oracle A, one constructs the complexity class C
A.
IfAis a general member of a complexity class A, then we can discuss the complexity
class CA. These new complexity classes are helpful in discussing the relative strength
of complexity classes.
A presentation should start with some classical results of oracle computation.
For example, there exists sets Aand Bsuch that
PA=NPAand PB/negationslash=NPB, (E.2)

<<<PAGE 388>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
370 Appendix E Selected Topics for Student Presentations
and move on to deﬁne what does it mean for a quantum Turing machine to have
an oracle. Move on to list and perhaps prove some of the results. Explain what a
random oracle is and why they are important.
A good place to start is the survey papers Cleve (1999); Fortnow (2003); Vazirani
(2002).
E.9 CRYPTOGRAPHY
E.9.1 RSA
One of the earliest public key cryptographic protocols is RSA. This protocol is used
throughout the World Wide Web and is the current standard on public key cryp-
tographic systems. RSA uses the fact that multiplication is computationally “easy”
and factoring is computationally “hard.”
The presentation should include a statement what the RSA protocol does; the
mathematical preliminaries necessary to understand the protocol; how the protocol
works; how the protocol would be destroyed if an efﬁcient polynomial algorithm for
factoring was found; and the present way it is implemented. A computer simulationis both easy and nice.
Many algorithms textbooks and discrete mathematics textbooks have chapters
on the RSA protocol.
E.9.2 Quantum Authentication
How can one be sure that the message just received was indeed sent by the one whoclaims it? As it turns out, quantum cryptography can help. Again, just like in other
areas, the magic of entanglement plays a major role.
An interesting paper by D. Richard Kuhn of NIST (Kuhn, 2003) can be used,
both as a baseline and for the good references to related work.
E.10 INFORMATION THEORY
E.10.1 Quantum Games
Quantum games is a new area of research that straddles between game theory and
quantum computing. It was started by David Meyer in 1999 as a coin ﬂip game
between Captain Picard of Enterprise Starship and Q, his “quantum opponent.”
The catch is that a qubit is used as the quantum coin. Whereas Captain Picard isallowed only to apply classical ﬂips, Q has a full range of quantum strategies at his
disposal. Q always wins.
For the hands-on reader, this presentation could also be an opportunity to
write a piece of quantum code. How about implementing a simulator of Meyer’sgame?
You can begin by reading the enjoyable Physics World online article: Lee and
Johnson (2002). At the end, you will ﬁnd a number of references to get further
along.

<<<PAGE 389>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Appendix E Selected Topics for Student Presentations 371
E.10.2 Quantum Entropy of Composite Systems
In Chapter 10, we have seen how quantum entropy measures the amount of order
of a given quantum system. Suppose now you are looking at a composite quantumsystem S. There is a way to deﬁne the entropies of the subsystems if the entropy of
Sis known. They are called residual entropies. The interesting thing is that, unlike
the classical case, the entropy of Scan be smaller than the sum of the entropies
of its parts. This is because of entanglement, a new form of order of the quantum
world.
Your presentation should clearly articulate the notion of residual entropy and
show an example of the above.
A good reference is the “Notes on quantum information theory” by Sam
Lomonaco (1996). (Caveat: The level of math sophistication is a bit higher than
the one of Chapter 10. This is a good presentation for a math-oriented class).
E.10.3 Quantum Error-Correcting Codes
The last section of Chapter 10 was just meant to whet your appetite. There is much
more on the topic of quantum error-correction and error-detection, and thus a nice
opportunity for a great presentation.
Start with the survey paper by Knill et al. (2002). Although the tone of the paper
is rather informal, it is packed with good stuff. A suggestion would be to review theﬁrst three sections, and go on to Section 6, where techniques for constructing codesare presented, in particular stabilizer codes.
E.11 HARDWARE
E.11.1 Decoherence and the Emergence of the Classical World
In the ﬁrst section we have introduced decoherence as a formidable opponent inour quest for quantum hardware. Decoherence is part of life, and it also has a bright
side: it is perhaps the key to the emergence of the macroscopic physical world.
For this presentation, you can present the excellent survey paper (Zurek, 2003).
A Google search with key words decoherence + classical world will provide other
useful references (in particular, an excellent site is www.decoherence.info).
E.11.2 A Comparison of Extant Approaches to Quantum Hardware
In Chapter 11, we have brieﬂy showcased a few approaches for quantum hardware.If this topic captivates you, it is worth preparing a presentation comparing all theknown proposals to date. As we mentioned at the end of Section 11.3, NIST has a
major ongoing effort toward implementing quantum devices, and it has made avail-
able a Quantum Roadmap (http://qist.lanl.gov/qcomp
map.shtml), divided into sev-
eral sections, each dedicated to a speciﬁc proposal. As our introduction of nuclearmagnetic resonance was sketchy at best, perhaps it could be your starting point (you
should highlight its strengths and weaknesses).

<<<PAGE 390>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
372 Appendix E Selected Topics for Student Presentations
E.11.3 Current Implementations of Quantum Cryptography
In Chapter 9 we familiarized ourselves with a few quantum cryptography protocols.
But, where are we in real life? As it turns out, a number of experiments have been
carried out. In fact, currently there are a few commercially available quantum cryp-
tographic communicating devices.
In this presentation, you should showcase a few milestones and the roadmap for
the future of quantum cryptography.
Where to start? A good entry point is the Quantum Cryptography Roadmap,
available at the Los Alamos Laboratories’, Web site: http://qist.lanl.gov/qcrypt
map.shtml. It is subdivided in several sections, each addressing a core method of
QKD.

<<<PAGE 391>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Bibliography
L.M. Adleman, J. DeMarrais, and M.-D. A. Huang. Quantum computability. SIAM
Journal on Computing, 26(5):1524–1540, 1997.
M. Agrawal, N. Kayal, and N. Saxena. PRIMES in P. Annals of Mathematics 2,
160(2):781–793, 2004. Available at http://www.cse.iitk.ac.in/users/manindra/.
D. Aharonov. Quantum computation. December 1998. Available at www.arxiv.
org/quant-ph/9812037.
Y. Aharonov and D. Rohrlich. Quantum Paradoxes: Quantum Theory for the
Perplexed . Wiley-VCH, Weinheim, 2005.
R.B. Ash. Information Theory. Dover Publications, New York, 1990.
S. Baase. Computer Algorithms: Introduction to Design and Analysis, Second Edi-
tion. Addison-Wesley, Reading, Mass, 1988.
J. Bak and D.J. Newman. Complex Analysis, Second Edition . Springer, New York,
1996.
A. Barenco, C.H. Bennett, R. Cleve, D.P. DiVincenzo, N. Margolus, P.W. Shor,
T. Sleator, J.A. Smolin, and H. Weinfurter. Elementary gates for quantum com-
putation. Physical Review A , 52(5):3457–3467, 1995.
A. Barenco, D. Deutsch, A. Ekert, and R. Jozsa. Conditional quantum dynamics
and logic gates. Physical Review Letters, 74(20):4083–4086, 1995.
H. Bass, H. Cartan, P. Freyd, A. Heller, and S. MacLane. Samuel Eilenberg (1913–
1998). Notices of American Mathematical Society, 45(10):1344–1352, 1998.
J.S. Bell. On the Einstein–Podolsky–Rosen paradox. Physics, 1:195–200, 1964.
J.S. Bell. Speakable and Unspeakable in Quantum Mechanics . Cambridge University
Press, Cambridge, UK, 1987.
P. Benioff. Quantum mechanical models of Turing machines that dissipate no en-
ergy. Physical Review Letters, 48(23):1581–1585, 1982.
373

<<<PAGE 392>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
374 Bibliography
C.H. Bennett. Notes on the history of reversible computation. IBM Journal of Re-
search and Development , 32(1):16–23, 1988.
C.H. Bennett. Quantum cryptography using any two nonorthogonal states. Physical
Review Letters, 68:3121, 1992.
C.H. Bennett, E. Bernstein, G. Brassard, and U. Vazirani. Strengths and weak-
nesses of quantum computing. SIAM Journal on Computing , 26(5):1510–1523,
1997.
C.H. Bennett and G. Brassard. Quantum cryptography: Public key distribution
and coin tossing. In Proceedings of IEEE International Conference on Comput-
ers Systems and Signal Processing , pages 175–179, Bangalore, India, December
1984.
C.H. Bennett, G. Brassard, C. Cr ´epeau, R. Jozsa, A. Peres, and W.K. Woot-
ters. Teleporting an unknown quantum state via dual classical and Einstein–
Podolsky–Rosen channels. Physical Review Letters , 70(13):1895–1899, March
1993.
K.K. Berggren. Quantum computing with superconductors. Proceedings of the
IEEE, 92(10), October 2004.
E. Bernstein and U. Vazirani. Quantum complexity theory. In STOC ’93: Proceed-
ings of the Twenty-Fifth Annual ACM Symposium on Theory of Computing ,
pages 11–20, ACM, New York, 1993.
E. Bernstein and U. Vazirani. Quantum complexity theory. SIAM Journal on Com-
puting, 26(5):1411–1473, 1997.
S. Bettelli, T. Calarco, and L. Seraﬁni. Toward an architecture for quantum pro-
gramming. CoRR, 2001. Available at http://arxiv.org/abs/cs.PL/0103009.
D. Bouwmeester, J.-W. Pan, K. Mattle, M. Eibl, H. Weinfurter, and A. Zeilinger.
Experimental quantum teleportation. Nature , 390:575–579, 1997.
G. Brassard. Cryptology column–quantum cryptography. A bibliography. SIGACT
News, 24(3):16–20, 1993.
G. Brassard and C. Cr ´epeau. Cryptology column – 25 years of quantum cryptogra-
phy. SIGACT News , 27(3):13–24, 1993.
A.R. Calderbank and P.W. Shor. Good quantum error-correcting codes exist. Phys-
ical Review A, 54(2):1098–1105, August 1996.
J. Campbell. Grammatical Man: Information, Entropy, Language and Life .S i m o n
& Schuster, New York, July 1982.
M. Chester. Primer of Quantum Mechanics . Dover Publications, Mineola, N.Y.,
2003.
I.L. Chuang, N. Gershenfeld, and M. Kubinec. Experimental implementation of fast
quantum searching. Physical Review Letters, 80 (15):3408–3411, 1998.
I.L. Chuang, L.M.K. Vandersypen, X. Zhou, D.W. Leung, and S. Lloyd. Experimen-
tal realization of a quantum algorithm. Nature , 393:143–146, 1998.

<<<PAGE 393>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Bibliography 375
J.I. Cirac and P. Zoller. Quantum computations with cold trapped ions. Physical
Review Letters, 74:4091–4094, 1995.
J. Cirasella. Classical and quantum algorithms for ﬁnding cycles. 2006. Available at
http://www.illc.uva.nl/Publications/ResearchReports/MoL-2006-06.text.pdf.
R. Cleve. An introduction to quantum complexity theory. Available at http://arxiv.
org/abs/quant-ph/9906111, 1999.
G.P. Collins. Quantum bug: Qubits might spontaneously decay in seconds. Anarticle
from Scientiﬁc American available at http://www.sciam.com.
T.H. Corman, C.E. Leiserson, R.E. Rivest, and C. Stein. Introduction to Algorithms,
Second Edition. The MIT Press, Cambridge, Mass., 2001.
M.J. Crowe. A History of Vector Analysis: The Evolution of the Idea of a Vectorial
System. Dover Publications, Mineola, N.Y., 1994.
S. Dasgupta, C.H. Papadimitriou, and U. Vazirani. Algorithms . McGraw-Hill
Science/Engineering/Math, New York, 2006.
M.D. Davis, E.J. Weyuker, and R. Sigal. Computability, Complexity, and Languages:
Fundamentals of Theoretical Computer Science . Morgan Kaufmann, Boston,
1994.
D. Deutsch. Quantum theory, the Church–Turing principle and the univer-
sal quantum computer. Proceedings of the Royal Society of London, Series
A, 400(1818):97–117, 1985. Available at http://www.qubit.org/oldsite/resource/
deutsch85.pdf.
D. Deutsch. Quantum computational networks. Proceedings of the Royal Society of
London, Series A, 425(1868):73–90, 1989.
D. Deutsch and R. Jozsa. Rapid solution of problems by quantum computation. Pro-
ceedings of the Royal Society of London, Series A , 439:553–558, October 1992.
D. Dieks. Comunicating by EPR devices. Physical Letters A, 92(6):271–272, 1982.
P.A.M. Dirac. The Principles of Quantum Mechanics (The International Series of
Monographs on Physics). Oxford University Press, Oxford, UK, 1982.
D.P. DiVincenzo. The physical implementation of quantum computation. http://
arxiv.org/abs/quant-ph/0002077.
D.P. DiVincenzo. Two-bit gates are universal for quantum computation. Physical
Review A, 51(2):1015–1022, 1995.
G. Egan. Schild’s Ladder. Harper Collins Publishers, New York, 2002.
A. Einstein, B. Podolsky, and N. Rosen. Can quantum-mechanical description of
physical reality be considered complete? Physical Review, 47:777–780, May 1935.
A.K. Ekert. Quantum cryptography based on Bell’s theorem. Physical Review
Letters, 67:661–663, 1991.
H. Eves. An Introduction to the History of Numbers, Fourth Edition . Holt, Rinehart
and Winston, New York, 1976.

<<<PAGE 394>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
376 Bibliography
R.P. Feynman. Feynman Lectures on Physics (3 Volume Set) . Addison-Wesley,
Boston, 1963.
R.P. Feynman. Simulating physics with computers. International Journal of Theoret-
ical Physics, 21(6/7):467–488, 1982.
L. Fortnow. One complexity theorist’s view of quantum computing. Theoretical
Computer Science, 292(3):597–610, 2003.
G. Gamow. Thirty Years That Shook Physics: The Story of Quantum Theory . Dover
Publications, Mineda, N.Y., 1985.
M.R. Garey and D.S. Johnson. Computers and Intractability: A Guide to the Theory
of NP-Completeness. WH Freeman & Co., New York, 1979.
S.J. Gay. Quantum programming languages: Survey and bibliography. Bulletin
of the EATCS , 86:176–196, 2005. Available at http://dblp.uni-trier.de/db/
journals/eatcs/eatcs86.html#Gay05.
J. Gilbert and L. Gilbert. Linear Algebra and Matrix Theory, Second Edition . Thom-
son, Brooks/Cole, San Diego, 2004.
D.T. Gillespie. A Quantum Mechanics Primer: An Introduction to the Formal The-
ory of Non-relativistic Quantum Mechanics . John Wiley & Sons, New York, 1974.
J. Grattage and T. Altenkirch. QML: Quantum data and control. February 2005.
Available at http://www.cs.nott.ac.uk/ txa/publ/jqpl.pdf.
J. Gribbin. In Search of Schrodinger’s Cat: Quantum Physics and Reality. Bantam,
New York, 1984.
R.P. Grimaldi. Discrete and Combinatorial Mathematics: An Applied Introduction,
Fifth Edition. Addison-Wesley, Boston, 2003.
L.K. Grover. A fast quantum mechanical algorithm for database search. In STOC
’96: Proceedings of the Twenty-Eighth Annual ACM Symposium on Theory of
Computing, pages 212–219, ACM, New York, 1996.
L.K. Grover. Quantum mechanics helps in searching for a needle in a haystack.
Physical Review Letters, 79(2):325–328, 1997.
K. Hannabuss. An Introduction to Quantum Theory . Oxford University Press, New
York, 1997.
N. Herbert. Quantum Reality: Beyond the New Physics . Anchor, Garden City, N.Y.,
1987.
M. Hirvensalo. Quantum Computing. Springer, New York, 2001.
M.H. Holzscheiter. Ion-trap quantum computation. Los Alamos Science. Available
athttp://library.lanl.gov/cgi-bin/getﬁle?27-20.pdf.
R. Jozsa and B. Schumacher. A new proof of the quantum noiseless coding theorem.
Journal of Modern Optics, 41(12):2343–2349, 1994.
M. Kernaghan. Bell–Kochen–Specker theorem for 20 vectors. Journal of Physics A ,
27:L829–L830, 1994.

<<<PAGE 395>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Bibliography 377
A.Yu. Kitaev, A.H. Shen, and M.N. Vyalyi. Classical and Quantum Computation
(Graduate Studies in Mathematics). American Mathematical Society, 2002.
E. Knill. Conventions for quantum pseudocode. Los Alamos National Laboratory
Technical Report , LAUR-96-2724, 1996.
E. Knill, R. Laﬂamme, A. Ashikhmin, H. Barnum, L. Viola, and W.H. Zurek.
Introduction to quantum error correction. 2002. Available at http://arxiv.org/
abs/quant-ph/0207170.
N. Koblitz. A Course in Number Theory and Cryptography, Second Edition.
Springer, New York, 1994.
D.R. Kuhn. A hybrid authentication protocol using quantum entanglement and
symmetric cryptography. 2003. Available at http://arxiv.org/abs/quant-
ph/0301150.
R. Landauer. Information is physical. Physics Today, 44:23–29, 1991.
S. Lang. Introduction to Linear Algebra, Second Edition . Springer, New York, 1986.
S. Lang. Algebra, Third Edition. Addison-Wesley, Reading, Mass., 1993.
C.F. Lee and N.F. Johnson. Let the quantum games begin. Physics World , 2002.
Available at http://physicsworld.com/cws/article/print/9995.
S. Lloyd. Almost any quantum logic gate is universal. Physical Review Letters ,7 5
(2):346–349, 1995.
S.J. Lomonaco. Notes on quantum information theory. 1996. Available at
http://www.cs.umbc.edu/ lomonaco/lecturenotes/Qinfo.pdf.
S.J. Lomonaco Jr. A talk on quantum cryptography, or how Alice outwits Eve, 2001.
In Quantum Computation: A Grand Mathematical Challenge for the 21st Cen-
tury Ed by Somuel J. Lomonaco.
J.L. Martin. Basic Quantum Mechanics (Oxford Physics Series) . Oxford University
Press, New York, 1982.
B. Mazur. Imagining Numbers (Particularly the Square Root of Minus Fifteen) .F a r -
rar, Straus and Giroux, New York, 2002.
R. Nagarajan, N. Papanikolaou, and D. Williams. Simulating and compiling
code for the sequential quantum random access machine, 2005. Available at
http://www.dcs.warwick.ac.uk/ nikos/downloads/newpaper.pdf.
P.J. Nahin. An Imaginary Tale: The Story of i (The Square Root of Minus One) .
Princeton University Press, Princeton, N.J., 1998.
T. Needham. Visual Complex Analysis . Oxford University Press, New York, 1999.
W.K. Nicholson. Linear Algebra with Applications, Third Edition . PWS Publishing
Company, Boston, 1994.
M.A. Nielsen. Quantum entropy. A PowerPoint presentation available at http://
michaelnielsen.org/blog/qicss/entropy.ppt.
M.A. Nielsen and I.L. Chuang. Quantum Computation and Quantum Information .
Cambridge University Press, Cambridge, UK, 2000.

<<<PAGE 396>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
378 Bibliography
B¨Omer. Quantum programming in qcl. 2000. Available at http://tph.tuwien.
ac.at/ oemer/doc/quprog.pdf.
M. O’Nan. Linear Algebra, Second Edition . Harcourt Brace Jovanovich, Inc., New
York, 1976.
H.R. Pagels. The Cosmic Code: Quantum Physics as the Language of Nature .S i m o n
& Schuster, New York, 1982.
C.H. Papadimitriou. Computational Complexity. Addison-Wesley, Reading, Mass.,
1994.
R.C. Penney. Linear Algebra, Ideas and Applications . John Wiley & Sons, New
York, 1998.
R. Penrose. Shadows of the Mind: A Search for the Missing Science of Consciousness .
Oxford University Press, Oxford, UK, 1994.
R. Penrose. The Emperor’s New Mind: Concerning Computers, Minds, and the Laws
of Physics (Popular Science) . Oxford University Press, Oxford, UK, 1999.
R. Penrose. The Road to Reality: A Complete Guide to the Laws of the Universe.
Knopf, New York, 2005.
I. Pitowsky. George Boole’s “conditions of possible experience” and the quantum
puzzle. The British Journal for the Philosophy of Science , 45(1):95–125, 1994.
T.B. Pittman, B.C. Jacobs, and J.D. Franson. Quantum computing using lin-
ear optics. Johns Hopkins APL Technical Digest , 25(2), 2004. Available at
http://arxiv.org/ftp/quant-ph/papers/0406/0406192.pdf.
J. Polkinghorne. Quantum Theory, A Very Short Introduction. Oxford University
Press, Oxford, UK, 2002.
R. Raussendorf and H.J. Briegel. A one-way quantum computer. Physical Review
Letters, 86(22), May 2001, 5188–5191.
R.L. Rivest, A. Shamir, and L. Adleman. A method for obtaining digital signa-
tures and public-key cryptosystems. Communications of the ACM , 21(2):120–
126, 1978.
P. Rodgers. The double-slit experiment. Physics World, 2002. Available at http://
physicsworld.com/cws/article/print/9745.
K.H. Rosen. Discrete Mathematics and Its Applications, Fifth Edition . McGraw-Hill,
Boston, 2003.
K.A. Ross and C.R.B. Wright. Discrete Mathematics, Fifth Edition. Prentice-Hall,
Upper Saddle River, N.J., 2003.
R. R ¨udiger. Quantum programming languages: An introductory overview. The
Computer Journal , 50(2):134–150, 2007. Available at http://comjnl.oxford-
journals.org/cgi/content/abstract/50/2/134.
J.J. Sakurai. Modern Quantum Mechanics , Revised edition, Addison-Wesley Pub-
lishing Company, Reading, Mass., 1994.

<<<PAGE 397>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Bibliography 379
K. Sayood. Introduction to Data Compression, Third Edition. Morgan Kaufmann,
Amsterdam, 2005.
B. Schneier. Applied Cryptography: Protocols, Algorithms, and Source Code in C,
Second Edition. John Wiley, & Sons, New York, 1995.
B. Schumacher. Quantum coding. Physical Review A, 51(4):2738–2747, 1995.
H. Schwerdtfeger. Geometry of Complex Numbers . Dover Publications, Mineola,
N.Y., 1980.
P. Selinger. A brief survey of quantum programming languages. In Y. Kameyama
and P.J. Stuckey, editors, Functional and Logic Programming, 7th International
Symposium, FLOPS 2004, Nara, Japan, April 7–9, 2004, volume 2998 of Lecture
Notes in Computer Science, pages 1–6. Springer, New York, 2004a.
P. Selinger. Towards a quantum programming language. Mathematical Structures
in Computer Science , 14(4):527–586, 2004b. Available at http://www.mathstat.
dal.ca/ selinger/papers/qpl.pdf.
C.E. Shannon. A mathematical theory of communication. Bell System Technical
Journal , 27:379–423, 623–656, 1948.
P.W. Shor. Algorithms for quantum computation: Discrete logarithms and factor-
ing. In S. Goldwasser, editor, Proceedings of the 35th Annual Symposium on the
Foundations of Computer Science, pages 124–134, . IEEE Computer Society, LosAlamitos, Calif., 1994.
P.W. Shor. Scheme for reducing decoherence in quantum computer memory. Phys-
ical Review A, 52(4):R2493–R2496, 1995.
P.W. Shor. Polynomial-time algorithms for prime factorization and discrete log-
arithms on a quantum computer. SIAM Journal Computing, 26(5):1484–1509,
1997.
P.W. Shor. Introduction to quantum algorithms. In Quantum Computation: A
Grand Mathematical Challenge for the Twenty-First Century and the Millennium ,
(Washington, DC, 2000), volume 58 of Proceedings of the Symposium in Applied
Mathematics , pages 143–159. American Mathematical Society, Providence, R.I.,
2002.
P.W. Shor. Why haven’t more quantum algorithms been found? Journal of the
ACM , 50(1):87–90, 2003.
R.A. Silverman. Introductory Complex Analysis. Dover Publications, Mineola,
N.Y., 1984.
D.R. Simon. On the power of quantum computation. In Proceedings of the 35th An-
nual Symposium on Foundations of Computer Science , pages 116–123, Institute
of Electrical and Electronic Engineers Computer Society Press, Los Alamitos,Calif., 1994.
D.R. Simon. On the power of quantum computation. SIAM Journal Computing ,
26(5):1474–1483, 1997.

<<<PAGE 398>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
380 Bibliography
M. Sipser. Introduction to the Theory of Computation, Second Edition . Thomson
Course Technology, Boston, 2005.
A.M. Steane. The ion trap quantum information processor. Applied Physics B , 64,
623, 1997.
A. Sudbery. Quantum Mechanics and the Particles of Nature: An Outline for Math-
ematicians . Cambridge University Press, Cambridge, UK, 1986.
D.H. Towne. Wave Phenomena. Dover Publications, Mineola, N.Y., 1989.
L.M.K. Vandersypen, G. Breyta, M. Steffen, C.S. Yannoni, M.H. Sherwood, and I.L.
Chuang. Experimental realization of Shor’s quantum factoring algorithm using
nuclear magnetic resonance. Nature , 414(6866):883–887, 2001.
U.V. Vazirani. A survey of qunatum complexity theory. In S. Lomonaco, Jr., editor,
Quantum Computation: A Grand Mathematical Challenge for the Twenty-First
Century and the Millennium , pages 193–217, 2002.
J. Watrous. On quantum and classical space-bounded processes with algebraic tran-
sition amplitudes. In IEEE Symposium on Foundations of Computer Science ,
pages 341–351, 1999.
R.L. White. Basic Quantum Mechanics. McGraw-Hill, New York, 1966.
S. Wiesner. Conjugate coding. SIGACT News , 15(1):78–88, 1983.
W.K. Wootters and W.H. Zurek. A single quantum cannot be cloned. Nature ,
299(5886):802–803, October 1982.
A.C-C. Yao. Quantum circuit complexity. In Proceedings of 34th IEEE Symposium
on Foundations of Computer Science, pages 352–361, 1993.
S. Zachos. Robustness of probabilistic computational complexity classes under def-
initional perturbations. Information and Control, 54(3):143–154, 1982.
P.A. Zizzi. Emergent consciousness: From the early universe to our mind. Available
at http://arxiv.org/abs/gr-qc/0007006.
W.H. Zurek. Decoherence and the transition from quantum to classical – revisited.
June 2003. Available at http://arxiv.org/abs/quant-ph/0306072.

<<<PAGE 399>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Index
Aaronson, Scott, 261
action, 42, 44, 61, 72
addition
of vectors, 30
additive inverse
of a vector, 32
Adleman, Leonard, 266, 322
adjoint, 39
Aharonov, Dorit, 219
Aharonov, Yakhir, 112
algebraically complete, 14
algorithm
Deutsch–Jozsa, 4, 170, 179–187, 196, 218, 259,
321, 322
Deutsch’s, 4, 170–180, 218, 230, 233
Euclid’s, 217
Grover’s search, 4, 170, 195–204, 218, 235, 259,
260, 322, 367
Huffman’s, 298, 304
Lempel–Ziv lossless compression, 296
modular-exponentiation, 218
Shor’s factoring, 4, 170, 204–219, 230, 259, 315,
322, 323, 361, 367
Simon’s periodicity, 4, 170, 187–196, 209, 218,
259, 322
ampliﬁcation lemma, 250, 257
analytic functions, 28
Argand plane, seecomplex plane
arXiv, 358, 359
associativity
of vector addition, 31
authentication, 267
B92 protocol, 273–275
Barenco, Adriano, 321
Barrow, John D., 239
basis, 47–53, 68, 183
canonical, 47–49, 59
orthogonal, 57
orthonormal, 57, 59, 64, 295
standard, seebasis, canonical
BB84 protocol, 268–273, 275–277, 283, 323
Bell basis, 278–283Bell, John, 277, 278, 364
Bell’s inequality, 277, 364
Benioff, Paul, 320
Bennett, Charles, 153, 268, 273, 323, 324, 366
Berggren, Karl, 317
Bernstein, Ethan, 321, 322
Berra, Yogi, 316
Bettelli, Stefano, 222
bijective, 15
bilinear map, 68
billiard ball
quantum, 91
stochastic, 84, 87, 91, 92
bit,138
Bloch sphere, 161
Bohm, David, 364
Bohr, Niels, 316, 364
Bombelli, Rafael, 28
Boole, George, 277
Bouwmeester, Dik, 324
BPP, 249–251, 258
BQP, 257, 258
bra, 112
Brassard, Gilles, 268, 323
Caesar’s protocol, 263
Calderbank, A.R., 324
Cardano, Gerolamo, 28
Cartesian product
of graphs, 99, 100
of sets, 45
of vector spaces, 45, 49, 66, 68
Cartesian representation, 18, 352
Cauchy sequence, 59
Chuang, Isaac L., xii, 315, 322
ciphertext, 262
Cirac, J.I., 311
Cirasella, Jill, xii, xiii, xvi, 319, 357
Collins, Graham P., 310
complex algebra, 42
complex analysis, 27
complex conjugation, 14, 39
complex plane, 16, 17, 21, 362
381

<<<PAGE 400>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
382 Index
complex subspace, 42, 43
complexity class, 243
conﬁguration, 242, 247, 252–255
coNP, 245, 246, 251, 258, 369
coP, 245, 246, 251, 258
coRP, 249–251, 258
Cr´epeau, Claude, 323
Crow, Michael J., 363
D-Wave Systems, 316
dagger, seeadjoint
data compression, 295–302, 304
lossless, 295
lossy, 295
De Broglie, Louis, 104
De Moivre’s formula, 25
decoherence, 5, 303, 305–317, 324, 371
decryption, 262
decryption key, 263
DeMorgan’s law, 150, 151
density operator, 288
Deutsch, David, 169, 320, 321, 366
Dick, Philip K., 103
Dijkstra, E.W., 170
dimension, 50–53, 183
Diogenes Laertius, vi
Dirac, P.A.M., 137
distance function, 57
DiVincenzo, David P., 310, 317, 321
division, 11
dot product, seeinner product
dynamics, 75, 79, 98
Egan, Greg, 316
eigenbasis, 64, 301, 302
eigenspace, 62
eigenvalue, 61–64, 354
eigenvector, 61–62, 64, 354
Eilenberg, Samuel, xv
Einstein, Albert, 2, 104, 282, 364
Ekert, Artur K., 275, 321
elliptic curves, 267
encryption, 262
encryption key, 263
entanglement, 2, 4, 100, 103, 132–137, 144, 164,
262, 275–278, 282, 306, 364, 370
entropy, 5, 307, 371
EPR paradox, 364
EPR protocol, 275–277
EQP, 258
error-correcting, 302–310
Euler’s formula, 24
Everett, Hugh, 364
expected value, 120
experiment
diffraction, 104
double-slit, 74, 93, 96, 102, 104, 105, 241, 256,
363
Elitzur–Vaidman bomb-tester, 363
probabilistic double-slit, 85
Stern–Gerlach, 110
exponential form, 25
Feynman, Richard, 96, 100, 102, 319, 320
ﬁeld, 14, 183
Fine, Arthur, 364
Fourier analysis, 1Fourier transform, 212, 367
discrete, 214, 368
fast, 368
quantum, 215, 368
Frost, Robert, 262
function
balanced, 171–187, 321
constant, 171–187, 321
transition, 240, 246, 252
Fundamental theorem of algebra, 9
Galilei, Galileo, 29
gate
AND, 145, 147, 149–151, 155
controlled-NOT, 153–155, 158, 165, 311, 313,
355, 366
controlled- U,164, 165
Deutsch, 165
Fredkin, 157, 158, 165, 168
Hadamard, 158, 165
identity, 151, 158
measurement, 159, 355
NAND, 146, 147, 156, 165
NOR, 147
NOT, 144, 145, 147, 149–151, 153, 155, 156, 158
OR, 146, 149, 150, 156
Pauli, 366
quantum, 3, 158–169, 366
reversible, 151–158
square root of NOT, 159
Toffoli, 154–156, 158, 165, 166, 168, 366
Gay, J., 234
Gershenfeld, Neil, 322
Gibbs, Josia, 363
G¨odel, Kurt, 239
Google, 354, 361
Blog Search, 357
News, 357
Scholar, 358, 359
Grassmann, Hermann, 363
group
Abelian, 32, 34
Grover, Lov, 196, 322
Hamilton, Sir
William Rowan, 363
Hamiltonian, 132
HAMILTONIAN GRAPH, 259
Heisenberg’s uncertainty principle, 3, 120, 124,
125
Held, Carsten, 365
Heller, Alex, xv
Heraclitus of Ephesus, vi
Hilbert space, 60, 226, 311
Huygens’ principle, 363
Holzscheiter, M., 317
Huygens, Christiaan, 363
id Quantique, 316, 323
inﬁnite
countably, 49
uncountably, 49
inner product, 54, 65, 183
inner product space, 54, 60
complete, 60
instantaneous description, seeconﬁguration
interference, 89, 92–95, 105, 256
intrusion detection, 267

<<<PAGE 401>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
Index 383
inversion about the average, seeinversion about
the mean
inversion about the mean, 198–204
ion trap, 311–314
isomorphism
of ﬁelds, 15
of graphs, 101
of matrices, 101
of vector spaces, 44, 50
Jeans, Sir James, 138
Jones, J.A., 315
Josephson junctions, 315
Jozsa, Richard, 321, 324
Julius Caesar, 263
Kernaghan, M., 365
ket, 106
Kirk, Captain James T., 283
Knill, Emanuel, 238, 371
Kochen–Specker theorem, 365
Kronecker delta function, 57, 336
Kryptonite, 262
Kubinec, Mark, 322
Kuhn, D. Richard, 370
Landauer principle, 151, 365
Landauer, Rolf, 151, 366
length (of a vector), seenorm
linear combination, 45–47
linear map, 43
linear optics, 313–314
linearly dependent, 47
linearly independent, 46
Lloyd, Seth, 321
Lomonaco, Samuel J., 371
Luthor, Lex, 262
MagiQ Technologies, 316, 323
MathWorks, 351, 352
MATLAB, xii, xiii, xvi, 206, 260, 351–356
matrix
adjacency, 74, 97
Boolean adjacency, 76
change of basis, 51
controlled-NOT, 226
density, 302, 307
diagonal, 64, 354
doubly stochastic, 80, 83–85, 87
Hadamard, 52, 53, 173–356
hermitian, 62–64, 115–129
identity, 41, 226
invertible, 64
multiplication, 40–42
Pauli, 158
phase shift, 226
symmetric, 62, 63, 90
transition, seematrix, change of basis
unitary, 64–66, 89–96, 129–132, 171–173, 180,
181, 186, 188, 196–198, 200, 201, 214, 215, 217,
218, 336
Vandermonde, 213
Maxwell’s demon, 365
mean value, 126
measurement, 96, 115–129
Meyer, David, 370
M¨obius transformation, 27, 362modulus, 13, 16
Monroe, C., 311
Mosca, M., 315
Musil, Robert, 7
Nagarajan, R., 225
negative
of a vector, 32
Nielsen, Michael A., xii, 304
NIST, 311, 315
NMR, 315–316, 371
No-cloning theorem, 166–169, 224, 268, 271,
278
nonlocality, 2
norm, 56, 65, 353
normalization, 140, 141, 160
normalized, 109
NP, 244–246, 251, 258, 369
NP-complete problem, 259
numbers
complex, 7–29, 361
tractably computable, 251, 252
i m a g i n a r y ,9 ,1 6
natural, 8
positive, 8
rational, 8
real, 8
tractably computable, 246, 252
whole, 8
observables, 129
¨Omer, Bernhard, 234
One-Time-Pad protocol, 265
operations
parallel, 148
sequential, 147
operator, 44
self-adjoint, 62, 64
oracle computation, 369
orthogonal, 57
P,243–246, 250, 251, 258, 369
Papanikolaou, N., 225
parallelogram rule, 17
pdf, seeprobability distribution
Penrose, Sir Roger, 7, 316
period (of a function), 188–195
phase, 19
phase change, 162
phase inversion, 197–204
phase shift, 356
photoelectric effect, 96, 104
plaintext, 262
pointwise, 44
polar representation, 18, 19, 352
polarization, 313
Pollard’s rho heuristic, 367
polynomials, 9, 26, 43
Pratt certiﬁcate, 369
primality testing, 369
probability distribution, 285
PSPACE, 245, 246, 251, 258
Pythagoras’ theorem, 16
QFC, 236
QRAM, 220–238, 256, 368
sequential, 368

<<<PAGE 402>>>

book-yanofsky CUUS235-Yanofsky ISBN 9780521879965 June 6, 2008 16:17 Char Count= 0
384 Index
QSPACE, 258
Quack, xiii, xvi, 354–356
Quantiki, 357
quantum assembler, 222
quantum circuits, 222, 256
quantum data compression scheme, 299
quantum eraser, 363
quantum error-correction, 371
quantum error-detection, 371
quantum ﬁnite automata, 369
quantum games, 370
quantum hardware interface, 223, 224
quantum key exchange, 268–277
quantum machine language, 222
quantum register, 224
qubit, xiii, 3, 138, 139
qubyte, 143, 225
R¨udiger, R., 234
rational functions, 27
reduced Planck constant, 117
reﬂection
imaginary axis, 14
real axis, 14
representation of an operator, 44
Riemann sphere, 362
Rivest, Ronald, 266, 322
Rohde, Peter, xvi, 354
Rohit Parikh, xv
roots of unity, 25
RP, 249–251, 258
RSA, 266, 322, 323, 361, 370
Saint Exupry, Antoine de, 305
SAT, 259
Savitch’s theorem, 245, 258
Sayood, Kahil, 304
scalar, 33
scalar multiplication, 33
scalar product, seeinner product
Schr ¨odinger equation, 131, 132
Schr ¨odinger, Erwin, 363–365
Schr ¨odinger’s cat, 365
Schumacher, Benjamin, 301, 324
Schumacher’s quantum coding theorem, 301,
304
Scopus, 358, 359
Selinger, Peter, 234, 236
Shamir, Adi, 266, 322
Shannon, Claude, 5, 284, 297, 304, 324
Shannon entropy, 284–302
Shannon’s noiseless channel coding theorem, 297,
301
Shor, Peter, 204, 219, 303, 322–324
Simon, Daniel R., 322
skew symmetric, 54
Smart Quantum, 323
snapshot, seeconﬁguration
Spectral theorem for self-adjoint operators, 64,
292
spin, 109, 141, 355
SQP, 315
stabilizer codes, 371
state
entangled, 135
entangled, 71
mixed, 307
pure, 306separable, 71, 135
well-deﬁned, 288, 306, 311
statistical mechanics, 2
Steane, Andrew M., 324
subﬁeld, 14
subtraction, 11
Sudoku game, 316
Suetonius, 263
superconductor, 315
superposition, 2–4, 96, 97, 107, 256
Tartaglia, Niccol Fontana, 28
Taylor expansion, 24
Technorati, 357
teleportation, 5, 262, 277–283, 324
tensor product
of matrices, 71, 99–101, 150, 354
of vectors, 69, 98, 100
of vector spaces, 66–73, 102, 132–137
thesis
classical Church–Turing, 241
Cook–Karp, 243
strong Church–Turing, 251, 259
time symmetry, 82
trace, 55, 353
transporting, 167
transpose, 39
triangle inequality, 56, 57, 295
Turing, Alan, 239
Turing machine, 239, 260
deterministic, 239–244, 258
nondeterministic, 239, 243–246
probabilistic, 239, 246–253, 260
quantum, 5, 223, 239, 252–260, 320, 369, 370
well-formed, 255
unit circle, 24
unit sphere, 65
universal logical gates, 165
universal quantum gates, 165
Vazirani, Umesh, 321, 322
vectors, 16
vector s
pace, 362
F2,183
Z2,183
complex, 29–73, 183, 254
real, 34, 183
Vernam cipher, seeOne-Time-Pad protocol
von Neumann entropy, 288, 302
Wang, Hao, 239
wave mechanics, 1, 363
Web of Science, 358, 359
Wiesner, Stephen, 323
Wigner’s friend, 365
Wikipedia, 358
Williams, D., 225
Wineland, D., 311
Yao, Andrew Chi-Chih, 321
Young, Thomas, 104, 105, 363
zero vector, 32
Zizzi, Paola, 316
Zoller, P., 311
ZPP, 250, 251, 258
ZQP, 257, 258
Zurek, Wojciech H., 317